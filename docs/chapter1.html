<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; Introduction to Statistics and Data Analysis for Political Science – Social Data Analysis: An Introduction (PL: Wprowadzenie do Analizy Danych Społecznych)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./rozdzial1.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-c27fdc8e5b00b532d2d5a75ada188648.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>

<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">


  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter1.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Statistics and Data Analysis for Political Science</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Social Data Analysis: An Introduction (PL: Wprowadzenie do Analizy Danych Społecznych)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter1.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Statistics and Data Analysis for Political Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Wprowadzenie do statystyki i analizy danych dla politologii</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Understanding Data Types in Social Sciences</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Typy Danych w Naukach Społecznych</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Reliability and Validity in Data Science Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Rzetelność i Trafność w Badaniach Statystycznych</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Research Designs: Experimental and Non-Experimental Approaches</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial4.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Projekty Badawcze: Podejścia Eksperymentalne i Nieeksperymentalne</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Fundamentals of Univariate Descriptive Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Podstawy Jednowymiarowej Statystyki Opisowej</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Data Visualization: with examples in R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Wizualizacja Danych: z przykładami w R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correg_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduction to Correlation and Regression Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correg_pl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Wprowadzenie do analizy korelacji i regresji <em>(Correlation and Regression Analysis)</em></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Introduction to (Discrete) Probability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability_pl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Wprowadzenie do Prawdopodobieństwa</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rv_pdf_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Random Variables and Probability Distributions</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Statistical Hypothesis Testing: A Fundamental Logic</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_pl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Wprowadzenie do Wnioskowania Statystycznego: Logika Testowania Hipotez Statystycznych</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#what-is-statistics" id="toc-what-is-statistics" class="nav-link active" data-scroll-target="#what-is-statistics"><span class="header-section-number">1.1</span> What Is Statistics?</a></li>
  <li><a href="#the-three-core-activities-of-statistics" id="toc-the-three-core-activities-of-statistics" class="nav-link" data-scroll-target="#the-three-core-activities-of-statistics"><span class="header-section-number">1.2</span> The Three Core Activities of Statistics</a>
  <ul class="collapse">
  <li><a href="#describe-what-does-our-data-show" id="toc-describe-what-does-our-data-show" class="nav-link" data-scroll-target="#describe-what-does-our-data-show">1. <strong>Describe</strong>: “What does our data show?”</a></li>
  <li><a href="#infer-what-can-we-learn-about-the-bigger-picture" id="toc-infer-what-can-we-learn-about-the-bigger-picture" class="nav-link" data-scroll-target="#infer-what-can-we-learn-about-the-bigger-picture">2. <strong>Infer</strong>: “What can we learn about the bigger picture?”</a></li>
  <li><a href="#predict-decide-what-might-happen-next-and-what-should-we-do" id="toc-predict-decide-what-might-happen-next-and-what-should-we-do" class="nav-link" data-scroll-target="#predict-decide-what-might-happen-next-and-what-should-we-do">3. <strong>Predict &amp; Decide</strong>: “What might happen next, and what should we do?”</a></li>
  </ul></li>
  <li><a href="#key-questions-statistics-helps-answer" id="toc-key-questions-statistics-helps-answer" class="nav-link" data-scroll-target="#key-questions-statistics-helps-answer"><span class="header-section-number">1.3</span> Key Questions Statistics Helps Answer</a>
  <ul class="collapse">
  <li><a href="#always-start-with-description" id="toc-always-start-with-description" class="nav-link" data-scroll-target="#always-start-with-description">Always Start with Description</a></li>
  <li><a href="#opinion-polls-why-one-number-isnt-enough" id="toc-opinion-polls-why-one-number-isnt-enough" class="nav-link" data-scroll-target="#opinion-polls-why-one-number-isnt-enough">Opinion Polls: Why One Number Isn’t Enough</a></li>
  </ul></li>
  <li><a href="#the-core-problem" id="toc-the-core-problem" class="nav-link" data-scroll-target="#the-core-problem"><span class="header-section-number">1.4</span> The Core Problem</a></li>
  <li><a href="#the-golden-rule-of-polling" id="toc-the-golden-rule-of-polling" class="nav-link" data-scroll-target="#the-golden-rule-of-polling"><span class="header-section-number">1.5</span> The Golden Rule of Polling</a></li>
  <li><a href="#understanding-95-confidence" id="toc-understanding-95-confidence" class="nav-link" data-scroll-target="#understanding-95-confidence"><span class="header-section-number">1.6</span> Understanding 95% Confidence</a></li>
  <li><a href="#why-choose-95" id="toc-why-choose-95" class="nav-link" data-scroll-target="#why-choose-95"><span class="header-section-number">1.7</span> Why Choose 95%?</a></li>
  <li><a href="#small-differences-and-uncertainty" id="toc-small-differences-and-uncertainty" class="nav-link" data-scroll-target="#small-differences-and-uncertainty"><span class="header-section-number">1.8</span> Small Differences and Uncertainty</a></li>
  <li><a href="#the-mathematical-foundation" id="toc-the-mathematical-foundation" class="nav-link" data-scroll-target="#the-mathematical-foundation"><span class="header-section-number">1.9</span> The Mathematical Foundation</a>
  <ul class="collapse">
  <li><a href="#understanding-the-1.96-multiplier" id="toc-understanding-the-1.96-multiplier" class="nav-link" data-scroll-target="#understanding-the-1.96-multiplier">Understanding the 1.96 Multiplier</a></li>
  <li><a href="#worst-case-calculation" id="toc-worst-case-calculation" class="nav-link" data-scroll-target="#worst-case-calculation">Worst-Case Calculation</a></li>
  </ul></li>
  <li><a href="#essential-poll-information" id="toc-essential-poll-information" class="nav-link" data-scroll-target="#essential-poll-information"><span class="header-section-number">1.10</span> Essential Poll Information</a></li>
  <li><a href="#key-principles" id="toc-key-principles" class="nav-link" data-scroll-target="#key-principles"><span class="header-section-number">1.11</span> Key Principles</a>
  <ul class="collapse">
  <li><a href="#regression-measuring-average-differences-and-modeling-relationship-between-variables" id="toc-regression-measuring-average-differences-and-modeling-relationship-between-variables" class="nav-link" data-scroll-target="#regression-measuring-average-differences-and-modeling-relationship-between-variables">Regression: Measuring Average Differences And Modeling Relationship Between Variables</a></li>
  <li><a href="#the-challenge-of-causality" id="toc-the-challenge-of-causality" class="nav-link" data-scroll-target="#the-challenge-of-causality">The Challenge of Causality</a></li>
  <li><a href="#what-we-really-want-to-know" id="toc-what-we-really-want-to-know" class="nav-link" data-scroll-target="#what-we-really-want-to-know">What We Really Want to Know</a></li>
  </ul></li>
  <li><a href="#randomness-a-foundation-of-statistical-inference" id="toc-randomness-a-foundation-of-statistical-inference" class="nav-link" data-scroll-target="#randomness-a-foundation-of-statistical-inference"><span class="header-section-number">1.12</span> Randomness: a foundation of statistical inference</a>
  <ul class="collapse">
  <li><a href="#what-is-randomness" id="toc-what-is-randomness" class="nav-link" data-scroll-target="#what-is-randomness">What is randomness?</a></li>
  <li><a href="#why-randomness-matters" id="toc-why-randomness-matters" class="nav-link" data-scroll-target="#why-randomness-matters">Why Randomness Matters</a></li>
  <li><a href="#the-power-of-random-sampling-quick-demo" id="toc-the-power-of-random-sampling-quick-demo" class="nav-link" data-scroll-target="#the-power-of-random-sampling-quick-demo">The Power of Random Sampling (quick demo)</a></li>
  </ul></li>
  <li><a href="#the-foundation-law-of-large-numbers" id="toc-the-foundation-law-of-large-numbers" class="nav-link" data-scroll-target="#the-foundation-law-of-large-numbers"><span class="header-section-number">1.13</span> The Foundation: Law of Large Numbers</a>
  <ul class="collapse">
  <li><a href="#visualizing-the-law-of-large-numbers-coin-flips" id="toc-visualizing-the-law-of-large-numbers-coin-flips" class="nav-link" data-scroll-target="#visualizing-the-law-of-large-numbers-coin-flips">Visualizing the Law of Large Numbers: Coin Flips</a></li>
  <li><a href="#the-mathematical-statement" id="toc-the-mathematical-statement" class="nav-link" data-scroll-target="#the-mathematical-statement">The Mathematical Statement</a></li>
  <li><a href="#examples-in-different-contexts" id="toc-examples-in-different-contexts" class="nav-link" data-scroll-target="#examples-in-different-contexts">Examples in Different Contexts</a></li>
  <li><a href="#why-this-matters-for-statistics" id="toc-why-this-matters-for-statistics" class="nav-link" data-scroll-target="#why-this-matters-for-statistics">Why This Matters for Statistics</a></li>
  </ul></li>
  <li><a href="#understanding-different-types-of-unpredictability" id="toc-understanding-different-types-of-unpredictability" class="nav-link" data-scroll-target="#understanding-different-types-of-unpredictability"><span class="header-section-number">1.14</span> Understanding Different Types of Unpredictability</a>
  <ul class="collapse">
  <li><a href="#key-distinctions-for-statistical-practice" id="toc-key-distinctions-for-statistical-practice" class="nav-link" data-scroll-target="#key-distinctions-for-statistical-practice">Key Distinctions for Statistical Practice</a></li>
  <li><a href="#quantum-mechanics-and-fundamental-randomness" id="toc-quantum-mechanics-and-fundamental-randomness" class="nav-link" data-scroll-target="#quantum-mechanics-and-fundamental-randomness">Quantum Mechanics and Fundamental Randomness</a></li>
  </ul></li>
  <li><a href="#inferential-statistics-from-samples-to-populations" id="toc-inferential-statistics-from-samples-to-populations" class="nav-link" data-scroll-target="#inferential-statistics-from-samples-to-populations"><span class="header-section-number">1.15</span> Inferential Statistics: From Samples to Populations</a>
  <ul class="collapse">
  <li><a href="#the-central-challenge" id="toc-the-central-challenge" class="nav-link" data-scroll-target="#the-central-challenge">The Central Challenge</a></li>
  <li><a href="#a-cautionary-tale-when-big-data-goes-wrong" id="toc-a-cautionary-tale-when-big-data-goes-wrong" class="nav-link" data-scroll-target="#a-cautionary-tale-when-big-data-goes-wrong">A Cautionary Tale: When Big Data Goes Wrong</a></li>
  <li><a href="#from-error-to-understanding-modern-polling" id="toc-from-error-to-understanding-modern-polling" class="nav-link" data-scroll-target="#from-error-to-understanding-modern-polling">From Error to Understanding: Modern Polling</a></li>
  <li><a href="#the-statistical-mindset" id="toc-the-statistical-mindset" class="nav-link" data-scroll-target="#the-statistical-mindset">The Statistical Mindset</a></li>
  </ul></li>
  <li><a href="#core-concepts-of-statistical-inference" id="toc-core-concepts-of-statistical-inference" class="nav-link" data-scroll-target="#core-concepts-of-statistical-inference"><span class="header-section-number">1.16</span> Core Concepts of Statistical Inference</a></li>
  <li><a href="#essential-terminology" id="toc-essential-terminology" class="nav-link" data-scroll-target="#essential-terminology"><span class="header-section-number">1.17</span> Essential Terminology</a></li>
  <li><a href="#sample-size-and-precision" id="toc-sample-size-and-precision" class="nav-link" data-scroll-target="#sample-size-and-precision"><span class="header-section-number">1.18</span> Sample Size and Precision</a></li>
  <li><a href="#understanding-confidence-intervals" id="toc-understanding-confidence-intervals" class="nav-link" data-scroll-target="#understanding-confidence-intervals"><span class="header-section-number">1.19</span> Understanding Confidence Intervals</a>
  <ul class="collapse">
  <li><a href="#what-95-confidence-means" id="toc-what-95-confidence-means" class="nav-link" data-scroll-target="#what-95-confidence-means">What 95% Confidence Means</a></li>
  <li><a href="#confidence-precision-trade-off" id="toc-confidence-precision-trade-off" class="nav-link" data-scroll-target="#confidence-precision-trade-off">Confidence-Precision Trade-off</a></li>
  </ul></li>
  <li><a href="#practical-example-library-hours-survey" id="toc-practical-example-library-hours-survey" class="nav-link" data-scroll-target="#practical-example-library-hours-survey"><span class="header-section-number">1.20</span> Practical Example: Library Hours Survey</a>
  <ul class="collapse">
  <li><a href="#three-sample-sizes-same-result-60-support" id="toc-three-sample-sizes-same-result-60-support" class="nav-link" data-scroll-target="#three-sample-sizes-same-result-60-support">Three Sample Sizes, Same Result (60% support)</a></li>
  </ul></li>
  <li><a href="#critical-limitations" id="toc-critical-limitations" class="nav-link" data-scroll-target="#critical-limitations"><span class="header-section-number">1.21</span> Critical Limitations</a>
  <ul class="collapse">
  <li><a href="#when-standard-calculations-dont-apply" id="toc-when-standard-calculations-dont-apply" class="nav-link" data-scroll-target="#when-standard-calculations-dont-apply">When Standard Calculations Don’t Apply</a></li>
  </ul></li>
  <li><a href="#best-practices" id="toc-best-practices" class="nav-link" data-scroll-target="#best-practices"><span class="header-section-number">1.22</span> Best Practices</a>
  <ul class="collapse">
  <li><a href="#essential-reporting-elements" id="toc-essential-reporting-elements" class="nav-link" data-scroll-target="#essential-reporting-elements">Essential Reporting Elements</a></li>
  <li><a href="#interpretation-guidelines" id="toc-interpretation-guidelines" class="nav-link" data-scroll-target="#interpretation-guidelines">Interpretation Guidelines</a></li>
  </ul></li>
  <li><a href="#mathematical-foundations" id="toc-mathematical-foundations" class="nav-link" data-scroll-target="#mathematical-foundations"><span class="header-section-number">1.23</span> Mathematical Foundations</a>
  <ul class="collapse">
  <li><a href="#standard-formulas" id="toc-standard-formulas" class="nav-link" data-scroll-target="#standard-formulas">Standard Formulas</a></li>
  <li><a href="#the-1.96-multiplier" id="toc-the-1.96-multiplier" class="nav-link" data-scroll-target="#the-1.96-multiplier">The 1.96 Multiplier</a></li>
  </ul></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><span class="header-section-number">1.24</span> Summary</a></li>
  <li><a href="#visualizing-sampling-variability" id="toc-visualizing-sampling-variability" class="nav-link" data-scroll-target="#visualizing-sampling-variability"><span class="header-section-number">1.25</span> Visualizing Sampling Variability</a></li>
  <li><a href="#statistical-errors-a-simple-guide" id="toc-statistical-errors-a-simple-guide" class="nav-link" data-scroll-target="#statistical-errors-a-simple-guide"><span class="header-section-number">1.26</span> Statistical Errors: A Simple Guide</a>
  <ul class="collapse">
  <li><a href="#why-this-matters" id="toc-why-this-matters" class="nav-link" data-scroll-target="#why-this-matters">Why this matters</a></li>
  </ul></li>
  <li><a href="#two-big-families-of-error" id="toc-two-big-families-of-error" class="nav-link" data-scroll-target="#two-big-families-of-error"><span class="header-section-number">1.27</span> Two Big Families of Error</a>
  <ul class="collapse">
  <li><a href="#random-error-samplingestimation-variability" id="toc-random-error-samplingestimation-variability" class="nav-link" data-scroll-target="#random-error-samplingestimation-variability">1) Random Error (Sampling/Estimation Variability)</a></li>
  <li><a href="#systematic-error-bias" id="toc-systematic-error-bias" class="nav-link" data-scroll-target="#systematic-error-bias">2) Systematic Error (Bias)</a></li>
  </ul></li>
  <li><a href="#biasvariance-mse-decomposition" id="toc-biasvariance-mse-decomposition" class="nav-link" data-scroll-target="#biasvariance-mse-decomposition"><span class="header-section-number">1.28</span> Bias–Variance (MSE) Decomposition</a></li>
  <li><a href="#common-sources-of-bias-across-many-study-types" id="toc-common-sources-of-bias-across-many-study-types" class="nav-link" data-scroll-target="#common-sources-of-bias-across-many-study-types"><span class="header-section-number">1.29</span> Common Sources of Bias (Across Many Study Types)</a></li>
  <li><a href="#interpreting-precision-without-extra-formulas" id="toc-interpreting-precision-without-extra-formulas" class="nav-link" data-scroll-target="#interpreting-precision-without-extra-formulas"><span class="header-section-number">1.30</span> Interpreting Precision (without extra formulas)</a></li>
  <li><a href="#hypothesis-tests-two-kinds-of-mistakes" id="toc-hypothesis-tests-two-kinds-of-mistakes" class="nav-link" data-scroll-target="#hypothesis-tests-two-kinds-of-mistakes"><span class="header-section-number">1.31</span> Hypothesis Tests: Two Kinds of Mistakes</a></li>
  <li><a href="#quick-practices-that-help" id="toc-quick-practices-that-help" class="nav-link" data-scroll-target="#quick-practices-that-help"><span class="header-section-number">1.32</span> Quick Practices That Help</a></li>
  <li><a href="#one-minute-checklist" id="toc-one-minute-checklist" class="nav-link" data-scroll-target="#one-minute-checklist"><span class="header-section-number">1.33</span> One-Minute Checklist</a></li>
  <li><a href="#glossary-acronyms-spelled-out" id="toc-glossary-acronyms-spelled-out" class="nav-link" data-scroll-target="#glossary-acronyms-spelled-out"><span class="header-section-number">1.34</span> Glossary (acronyms spelled out)</a></li>
  <li><a href="#population-sample-and-superpopulation-foundations-of-statistical-inference" id="toc-population-sample-and-superpopulation-foundations-of-statistical-inference" class="nav-link" data-scroll-target="#population-sample-and-superpopulation-foundations-of-statistical-inference"><span class="header-section-number">1.35</span> Population, Sample, and Superpopulation: Foundations of Statistical Inference</a></li>
  <li><a href="#defining-populations-in-political-science-and-economics" id="toc-defining-populations-in-political-science-and-economics" class="nav-link" data-scroll-target="#defining-populations-in-political-science-and-economics"><span class="header-section-number">1.36</span> Defining Populations in Political Science and Economics</a>
  <ul class="collapse">
  <li><a href="#individual-level-populations" id="toc-individual-level-populations" class="nav-link" data-scroll-target="#individual-level-populations">Individual-Level Populations</a></li>
  <li><a href="#country-level-analysis" id="toc-country-level-analysis" class="nav-link" data-scroll-target="#country-level-analysis">Country-Level Analysis</a></li>
  <li><a href="#subnational-government-units" id="toc-subnational-government-units" class="nav-link" data-scroll-target="#subnational-government-units">Subnational Government Units</a></li>
  <li><a href="#organizational-analysis" id="toc-organizational-analysis" class="nav-link" data-scroll-target="#organizational-analysis">Organizational Analysis</a></li>
  <li><a href="#temporal-and-event-based-populations" id="toc-temporal-and-event-based-populations" class="nav-link" data-scroll-target="#temporal-and-event-based-populations">Temporal and Event-Based Populations</a></li>
  </ul></li>
  <li><a href="#the-logic-of-statistical-inference-from-sample-to-population" id="toc-the-logic-of-statistical-inference-from-sample-to-population" class="nav-link" data-scroll-target="#the-logic-of-statistical-inference-from-sample-to-population"><span class="header-section-number">1.37</span> The Logic of Statistical Inference: From Sample to Population</a></li>
  <li><a href="#sampling-methods-and-the-representation-challenge" id="toc-sampling-methods-and-the-representation-challenge" class="nav-link" data-scroll-target="#sampling-methods-and-the-representation-challenge"><span class="header-section-number">1.38</span> Sampling Methods and the Representation Challenge</a>
  <ul class="collapse">
  <li><a href="#convenience-sampling" id="toc-convenience-sampling" class="nav-link" data-scroll-target="#convenience-sampling">1. Convenience Sampling</a></li>
  <li><a href="#voluntary-response-sampling" id="toc-voluntary-response-sampling" class="nav-link" data-scroll-target="#voluntary-response-sampling">2. Voluntary Response Sampling</a></li>
  <li><a href="#simple-random-sampling" id="toc-simple-random-sampling" class="nav-link" data-scroll-target="#simple-random-sampling">3. Simple Random Sampling</a></li>
  <li><a href="#stratified-random-sampling" id="toc-stratified-random-sampling" class="nav-link" data-scroll-target="#stratified-random-sampling">4. Stratified Random Sampling</a></li>
  <li><a href="#cluster-sampling" id="toc-cluster-sampling" class="nav-link" data-scroll-target="#cluster-sampling">5. Cluster Sampling</a></li>
  </ul></li>
  <li><a href="#understanding-parameters-statistics-and-estimates" id="toc-understanding-parameters-statistics-and-estimates" class="nav-link" data-scroll-target="#understanding-parameters-statistics-and-estimates"><span class="header-section-number">1.39</span> Understanding Parameters, Statistics, and Estimates</a>
  <ul class="collapse">
  <li><a href="#the-parameter-statistic-distinction" id="toc-the-parameter-statistic-distinction" class="nav-link" data-scroll-target="#the-parameter-statistic-distinction">The Parameter-Statistic Distinction</a></li>
  <li><a href="#estimators-and-estimates" id="toc-estimators-and-estimates" class="nav-link" data-scroll-target="#estimators-and-estimates">Estimators and Estimates</a></li>
  <li><a href="#estimands-what-exactly-are-we-trying-to-estimate" id="toc-estimands-what-exactly-are-we-trying-to-estimate" class="nav-link" data-scroll-target="#estimands-what-exactly-are-we-trying-to-estimate">Estimands: What Exactly Are We Trying to Estimate?</a></li>
  <li><a href="#the-complete-framework" id="toc-the-complete-framework" class="nav-link" data-scroll-target="#the-complete-framework">The Complete Framework</a></li>
  </ul></li>
  <li><a href="#understanding-sampling-variability-through-simulation" id="toc-understanding-sampling-variability-through-simulation" class="nav-link" data-scroll-target="#understanding-sampling-variability-through-simulation"><span class="header-section-number">1.40</span> Understanding Sampling Variability Through Simulation</a></li>
  <li><a href="#beyond-simple-population-sample-models-superpopulations" id="toc-beyond-simple-population-sample-models-superpopulations" class="nav-link" data-scroll-target="#beyond-simple-population-sample-models-superpopulations"><span class="header-section-number">1.41</span> Beyond Simple Population-Sample Models: Superpopulations</a>
  <ul class="collapse">
  <li><a href="#when-we-observe-complete-populations" id="toc-when-we-observe-complete-populations" class="nav-link" data-scroll-target="#when-we-observe-complete-populations">When We Observe Complete Populations</a></li>
  <li><a href="#the-superpopulation-concept" id="toc-the-superpopulation-concept" class="nav-link" data-scroll-target="#the-superpopulation-concept">The Superpopulation Concept</a></li>
  </ul></li>
  <li><a href="#a-practical-analogy-the-soup-tasting-approach-to-statistical-inference" id="toc-a-practical-analogy-the-soup-tasting-approach-to-statistical-inference" class="nav-link" data-scroll-target="#a-practical-analogy-the-soup-tasting-approach-to-statistical-inference"><span class="header-section-number">1.42</span> A Practical Analogy: The Soup-Tasting Approach to Statistical Inference</a>
  <ul class="collapse">
  <li><a href="#key-principles-illustrated" id="toc-key-principles-illustrated" class="nav-link" data-scroll-target="#key-principles-illustrated">Key Principles Illustrated</a></li>
  </ul></li>
  <li><a href="#summary-framework-sources-of-uncertainty-in-statistical-inference" id="toc-summary-framework-sources-of-uncertainty-in-statistical-inference" class="nav-link" data-scroll-target="#summary-framework-sources-of-uncertainty-in-statistical-inference"><span class="header-section-number">1.43</span> Summary Framework: Sources of Uncertainty in Statistical Inference</a></li>
  <li><a href="#measurement-transforming-concepts-into-numbers" id="toc-measurement-transforming-concepts-into-numbers" class="nav-link" data-scroll-target="#measurement-transforming-concepts-into-numbers"><span class="header-section-number">1.44</span> Measurement: Transforming Concepts into Numbers</a>
  <ul class="collapse">
  <li><a href="#the-political-world-is-full-of-data" id="toc-the-political-world-is-full-of-data" class="nav-link" data-scroll-target="#the-political-world-is-full-of-data">The Political World is Full of Data</a></li>
  <li><a href="#the-challenge-of-measurement-in-social-sciences" id="toc-the-challenge-of-measurement-in-social-sciences" class="nav-link" data-scroll-target="#the-challenge-of-measurement-in-social-sciences">The Challenge of Measurement in Social Sciences</a></li>
  <li><a href="#levels-of-measurement" id="toc-levels-of-measurement" class="nav-link" data-scroll-target="#levels-of-measurement">Levels of Measurement</a></li>
  <li><a href="#special-case-psychometric-test-results" id="toc-special-case-psychometric-test-results" class="nav-link" data-scroll-target="#special-case-psychometric-test-results">Special Case: Psychometric Test Results</a></li>
  </ul></li>
  <li><a href="#statistical-significance-making-sense-of-uncertain-evidence" id="toc-statistical-significance-making-sense-of-uncertain-evidence" class="nav-link" data-scroll-target="#statistical-significance-making-sense-of-uncertain-evidence"><span class="header-section-number">1.45</span> Statistical Significance: Making Sense of Uncertain Evidence</a>
  <ul class="collapse">
  <li><a href="#the-courtroom-analogy-for-hypothesis-testing" id="toc-the-courtroom-analogy-for-hypothesis-testing" class="nav-link" data-scroll-target="#the-courtroom-analogy-for-hypothesis-testing">The Courtroom Analogy for Hypothesis Testing</a></li>
  <li><a href="#what-is-statistical-significance" id="toc-what-is-statistical-significance" class="nav-link" data-scroll-target="#what-is-statistical-significance">What is Statistical Significance?</a></li>
  <li><a href="#the-logic-of-hypothesis-testing" id="toc-the-logic-of-hypothesis-testing" class="nav-link" data-scroll-target="#the-logic-of-hypothesis-testing">The Logic of Hypothesis Testing</a></li>
  <li><a href="#understanding-p-values-three-complementary-perspectives" id="toc-understanding-p-values-three-complementary-perspectives" class="nav-link" data-scroll-target="#understanding-p-values-three-complementary-perspectives">Understanding p-values: Three Complementary Perspectives</a></li>
  <li><a href="#visualizing-p-values-the-distribution-of-possibilities" id="toc-visualizing-p-values-the-distribution-of-possibilities" class="nav-link" data-scroll-target="#visualizing-p-values-the-distribution-of-possibilities">Visualizing p-values: The Distribution of Possibilities</a></li>
  </ul></li>
  <li><a href="#statistical-significance-distinguishing-signal-from-noise" id="toc-statistical-significance-distinguishing-signal-from-noise" class="nav-link" data-scroll-target="#statistical-significance-distinguishing-signal-from-noise"><span class="header-section-number">1.46</span> Statistical Significance: Distinguishing Signal from Noise</a></li>
  <li><a href="#understanding-hypothesis-testing-through-legal-principles" id="toc-understanding-hypothesis-testing-through-legal-principles" class="nav-link" data-scroll-target="#understanding-hypothesis-testing-through-legal-principles"><span class="header-section-number">1.47</span> Understanding Hypothesis Testing Through Legal Principles</a>
  <ul class="collapse">
  <li><a href="#the-fundamental-framework" id="toc-the-fundamental-framework" class="nav-link" data-scroll-target="#the-fundamental-framework">The Fundamental Framework</a></li>
  <li><a href="#evidence-based-decision-making" id="toc-evidence-based-decision-making" class="nav-link" data-scroll-target="#evidence-based-decision-making">Evidence-Based Decision Making</a></li>
  </ul></li>
  <li><a href="#the-p-value-quantifying-statistical-surprise" id="toc-the-p-value-quantifying-statistical-surprise" class="nav-link" data-scroll-target="#the-p-value-quantifying-statistical-surprise"><span class="header-section-number">1.48</span> The p-value: Quantifying Statistical Surprise</a>
  <ul class="collapse">
  <li><a href="#illustrative-example-testing-coin-fairness" id="toc-illustrative-example-testing-coin-fairness" class="nav-link" data-scroll-target="#illustrative-example-testing-coin-fairness">Illustrative Example: Testing Coin Fairness</a></li>
  <li><a href="#interpreting-p-value-magnitudes" id="toc-interpreting-p-value-magnitudes" class="nav-link" data-scroll-target="#interpreting-p-value-magnitudes">Interpreting p-value Magnitudes</a></li>
  </ul></li>
  <li><a href="#common-misinterpretations-of-p-values" id="toc-common-misinterpretations-of-p-values" class="nav-link" data-scroll-target="#common-misinterpretations-of-p-values"><span class="header-section-number">1.49</span> Common Misinterpretations of p-values</a>
  <ul class="collapse">
  <li><a href="#misinterpretation-1-probability-of-the-hypothesis" id="toc-misinterpretation-1-probability-of-the-hypothesis" class="nav-link" data-scroll-target="#misinterpretation-1-probability-of-the-hypothesis">Misinterpretation 1: Probability of the Hypothesis</a></li>
  <li><a href="#misinterpretation-2-effect-size-indicator" id="toc-misinterpretation-2-effect-size-indicator" class="nav-link" data-scroll-target="#misinterpretation-2-effect-size-indicator">Misinterpretation 2: Effect Size Indicator</a></li>
  <li><a href="#misinterpretation-3-proof-of-no-effect" id="toc-misinterpretation-3-proof-of-no-effect" class="nav-link" data-scroll-target="#misinterpretation-3-proof-of-no-effect">Misinterpretation 3: Proof of No Effect</a></li>
  </ul></li>
  <li><a href="#types-of-statistical-errors" id="toc-types-of-statistical-errors" class="nav-link" data-scroll-target="#types-of-statistical-errors"><span class="header-section-number">1.50</span> Types of Statistical Errors</a>
  <ul class="collapse">
  <li><a href="#type-i-error-false-positive" id="toc-type-i-error-false-positive" class="nav-link" data-scroll-target="#type-i-error-false-positive">Type I Error (False Positive)</a></li>
  <li><a href="#type-ii-error-false-negative" id="toc-type-ii-error-false-negative" class="nav-link" data-scroll-target="#type-ii-error-false-negative">Type II Error (False Negative)</a></li>
  <li><a href="#the-error-trade-off" id="toc-the-error-trade-off" class="nav-link" data-scroll-target="#the-error-trade-off">The Error Trade-off</a></li>
  </ul></li>
  <li><a href="#the-historical-context-of-α-0.05" id="toc-the-historical-context-of-α-0.05" class="nav-link" data-scroll-target="#the-historical-context-of-α-0.05"><span class="header-section-number">1.51</span> The Historical Context of α = 0.05</a>
  <ul class="collapse">
  <li><a href="#historical-development" id="toc-historical-development" class="nav-link" data-scroll-target="#historical-development">Historical Development</a></li>
  <li><a href="#context-dependent-thresholds" id="toc-context-dependent-thresholds" class="nav-link" data-scroll-target="#context-dependent-thresholds">Context-Dependent Thresholds</a></li>
  </ul></li>
  <li><a href="#statistical-significance-versus-practical-importance" id="toc-statistical-significance-versus-practical-importance" class="nav-link" data-scroll-target="#statistical-significance-versus-practical-importance"><span class="header-section-number">1.52</span> Statistical Significance Versus Practical Importance</a>
  <ul class="collapse">
  <li><a href="#the-sample-size-effect" id="toc-the-sample-size-effect" class="nav-link" data-scroll-target="#the-sample-size-effect">The Sample Size Effect</a></li>
  <li><a href="#confidence-intervals-a-more-informative-approach" id="toc-confidence-intervals-a-more-informative-approach" class="nav-link" data-scroll-target="#confidence-intervals-a-more-informative-approach">Confidence Intervals: A More Informative Approach</a></li>
  </ul></li>
  <li><a href="#essential-concepts-for-beginners" id="toc-essential-concepts-for-beginners" class="nav-link" data-scroll-target="#essential-concepts-for-beginners"><span class="header-section-number">1.53</span> Essential Concepts for Beginners</a>
  <ul class="collapse">
  <li><a href="#key-principles-1" id="toc-key-principles-1" class="nav-link" data-scroll-target="#key-principles-1">Key Principles</a></li>
  <li><a href="#critical-questions-when-evaluating-p-values" id="toc-critical-questions-when-evaluating-p-values" class="nav-link" data-scroll-target="#critical-questions-when-evaluating-p-values">Critical Questions When Evaluating p-values</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion">Conclusion</a></li>
  </ul></li>
  <li><a href="#statistical-significance-real-world-examples" id="toc-statistical-significance-real-world-examples" class="nav-link" data-scroll-target="#statistical-significance-real-world-examples"><span class="header-section-number">1.54</span> Statistical Significance: Real-World Examples</a>
  <ul class="collapse">
  <li><a href="#example-1-testing-a-voter-turnout-campaign" id="toc-example-1-testing-a-voter-turnout-campaign" class="nav-link" data-scroll-target="#example-1-testing-a-voter-turnout-campaign">Example 1: Testing a Voter Turnout Campaign</a></li>
  <li><a href="#the-research-question" id="toc-the-research-question" class="nav-link" data-scroll-target="#the-research-question">The Research Question</a></li>
  <li><a href="#the-study-setup" id="toc-the-study-setup" class="nav-link" data-scroll-target="#the-study-setup">The Study Setup</a></li>
  <li><a href="#the-results" id="toc-the-results" class="nav-link" data-scroll-target="#the-results">The Results</a></li>
  <li><a href="#the-big-question" id="toc-the-big-question" class="nav-link" data-scroll-target="#the-big-question">The Big Question</a></li>
  <li><a href="#what-the-statistics-tell-us" id="toc-what-the-statistics-tell-us" class="nav-link" data-scroll-target="#what-the-statistics-tell-us">What the Statistics Tell Us</a></li>
  <li><a href="#but-waitis-this-difference-actually-important" id="toc-but-waitis-this-difference-actually-important" class="nav-link" data-scroll-target="#but-waitis-this-difference-actually-important">But Wait—Is This Difference Actually Important?</a></li>
  </ul></li>
  <li><a href="#example-2-when-weather-affects-voting" id="toc-example-2-when-weather-affects-voting" class="nav-link" data-scroll-target="#example-2-when-weather-affects-voting"><span class="header-section-number">1.55</span> Example 2: When Weather Affects Voting</a>
  <ul class="collapse">
  <li><a href="#the-research-question-1" id="toc-the-research-question-1" class="nav-link" data-scroll-target="#the-research-question-1">The Research Question</a></li>
  <li><a href="#the-logic" id="toc-the-logic" class="nav-link" data-scroll-target="#the-logic">The Logic</a></li>
  <li><a href="#a-simple-study" id="toc-a-simple-study" class="nav-link" data-scroll-target="#a-simple-study">A Simple Study</a></li>
  <li><a href="#the-statistical-test" id="toc-the-statistical-test" class="nav-link" data-scroll-target="#the-statistical-test">The Statistical Test</a></li>
  <li><a href="#why-this-matters-1" id="toc-why-this-matters-1" class="nav-link" data-scroll-target="#why-this-matters-1">Why This Matters</a></li>
  </ul></li>
  <li><a href="#example-3-when-we-dont-find-evidence" id="toc-example-3-when-we-dont-find-evidence" class="nav-link" data-scroll-target="#example-3-when-we-dont-find-evidence"><span class="header-section-number">1.56</span> Example 3: When We Don’t Find Evidence</a>
  <ul class="collapse">
  <li><a href="#the-research-question-2" id="toc-the-research-question-2" class="nav-link" data-scroll-target="#the-research-question-2">The Research Question</a></li>
  <li><a href="#the-study" id="toc-the-study" class="nav-link" data-scroll-target="#the-study">The Study</a></li>
  <li><a href="#the-results-1" id="toc-the-results-1" class="nav-link" data-scroll-target="#the-results-1">The Results</a></li>
  <li><a href="#what-this-means" id="toc-what-this-means" class="nav-link" data-scroll-target="#what-this-means">What This Means</a></li>
  <li><a href="#important-what-no-evidence-actually-means" id="toc-important-what-no-evidence-actually-means" class="nav-link" data-scroll-target="#important-what-no-evidence-actually-means">Important: What “No Evidence” Actually Means</a></li>
  <li><a href="#why-studies-sometimes-find-nothing" id="toc-why-studies-sometimes-find-nothing" class="nav-link" data-scroll-target="#why-studies-sometimes-find-nothing">Why Studies Sometimes Find “Nothing”</a></li>
  </ul></li>
  <li><a href="#key-takeaways-for-understanding-statistical-significance" id="toc-key-takeaways-for-understanding-statistical-significance" class="nav-link" data-scroll-target="#key-takeaways-for-understanding-statistical-significance"><span class="header-section-number">1.57</span> Key Takeaways for Understanding Statistical Significance</a>
  <ul class="collapse">
  <li><a href="#statistical-significance-probably-not-just-chance" id="toc-statistical-significance-probably-not-just-chance" class="nav-link" data-scroll-target="#statistical-significance-probably-not-just-chance">1. Statistical Significance = “Probably Not Just Chance”</a></li>
  <li><a href="#the-magic-number-0.05" id="toc-the-magic-number-0.05" class="nav-link" data-scroll-target="#the-magic-number-0.05">2. The Magic Number: 0.05</a></li>
  <li><a href="#significant-important" id="toc-significant-important" class="nav-link" data-scroll-target="#significant-important">3. Significant ≠ Important</a></li>
  <li><a href="#not-significant-no-effect" id="toc-not-significant-no-effect" class="nav-link" data-scroll-target="#not-significant-no-effect">4. Not Significant ≠ No Effect</a></li>
  <li><a href="#always-ask-how-big-is-the-effect" id="toc-always-ask-how-big-is-the-effect" class="nav-link" data-scroll-target="#always-ask-how-big-is-the-effect">5. Always Ask: “How Big Is the Effect?”</a></li>
  </ul></li>
  <li><a href="#how-to-read-statistical-results-like-a-pro" id="toc-how-to-read-statistical-results-like-a-pro" class="nav-link" data-scroll-target="#how-to-read-statistical-results-like-a-pro"><span class="header-section-number">1.58</span> How to Read Statistical Results Like a Pro</a></li>
  <li><a href="#common-p-value-misconceptions-and-corrections" id="toc-common-p-value-misconceptions-and-corrections" class="nav-link" data-scroll-target="#common-p-value-misconceptions-and-corrections"><span class="header-section-number">1.59</span> Common p-value Misconceptions and Corrections</a>
  <ul class="collapse">
  <li><a href="#fundamental-misinterpretations" id="toc-fundamental-misinterpretations" class="nav-link" data-scroll-target="#fundamental-misinterpretations">Fundamental Misinterpretations</a></li>
  <li><a href="#the-prosecutors-fallacy-in-statistical-context" id="toc-the-prosecutors-fallacy-in-statistical-context" class="nav-link" data-scroll-target="#the-prosecutors-fallacy-in-statistical-context">The Prosecutor’s Fallacy in Statistical Context</a></li>
  </ul></li>
  <li><a href="#understanding-p-values-and-confidence-intervals-together" id="toc-understanding-p-values-and-confidence-intervals-together" class="nav-link" data-scroll-target="#understanding-p-values-and-confidence-intervals-together"><span class="header-section-number">1.60</span> Understanding p-values and Confidence Intervals Together</a>
  <ul class="collapse">
  <li><a href="#the-simple-connection" id="toc-the-simple-connection" class="nav-link" data-scroll-target="#the-simple-connection">The Simple Connection</a></li>
  <li><a href="#why-confidence-intervals-are-better-than-p-values-alone" id="toc-why-confidence-intervals-are-better-than-p-values-alone" class="nav-link" data-scroll-target="#why-confidence-intervals-are-better-than-p-values-alone">Why Confidence Intervals Are Better Than p-values Alone</a></li>
  <li><a href="#real-example-campaign-text-messages" id="toc-real-example-campaign-text-messages" class="nav-link" data-scroll-target="#real-example-campaign-text-messages">Real Example: Campaign Text Messages</a></li>
  <li><a href="#reading-confidence-intervals-like-a-pro" id="toc-reading-confidence-intervals-like-a-pro" class="nav-link" data-scroll-target="#reading-confidence-intervals-like-a-pro">Reading Confidence Intervals Like a Pro</a></li>
  <li><a href="#examples-in-action" id="toc-examples-in-action" class="nav-link" data-scroll-target="#examples-in-action">Examples in Action</a></li>
  <li><a href="#common-mistakes-to-avoid" id="toc-common-mistakes-to-avoid" class="nav-link" data-scroll-target="#common-mistakes-to-avoid">Common Mistakes to Avoid</a></li>
  <li><a href="#best-practices-for-understanding-research" id="toc-best-practices-for-understanding-research" class="nav-link" data-scroll-target="#best-practices-for-understanding-research">Best Practices for Understanding Research</a></li>
  <li><a href="#how-to-report-results-properly" id="toc-how-to-report-results-properly" class="nav-link" data-scroll-target="#how-to-report-results-properly">How to Report Results Properly</a></li>
  <li><a href="#the-big-picture" id="toc-the-big-picture" class="nav-link" data-scroll-target="#the-big-picture">The Big Picture</a></li>
  </ul></li>
  <li><a href="#regression-the-workhorse-of-political-science" id="toc-regression-the-workhorse-of-political-science" class="nav-link" data-scroll-target="#regression-the-workhorse-of-political-science"><span class="header-section-number">2</span> Regression: The Workhorse of Political Science</a>
  <ul class="collapse">
  <li><a href="#before-you-start-what-you-need-to-know" id="toc-before-you-start-what-you-need-to-know" class="nav-link" data-scroll-target="#before-you-start-what-you-need-to-know"><span class="header-section-number">2.1</span> Before You Start: What You Need to Know</a></li>
  <li><a href="#variables-and-variation" id="toc-variables-and-variation" class="nav-link" data-scroll-target="#variables-and-variation"><span class="header-section-number">2.2</span> Variables and Variation</a>
  <ul class="collapse">
  <li><a href="#defining-variables" id="toc-defining-variables" class="nav-link" data-scroll-target="#defining-variables">Defining Variables</a></li>
  </ul></li>
  <li><a href="#what-is-regression" id="toc-what-is-regression" class="nav-link" data-scroll-target="#what-is-regression"><span class="header-section-number">2.3</span> What is Regression?</a>
  <ul class="collapse">
  <li><a href="#the-fundamental-model" id="toc-the-fundamental-model" class="nav-link" data-scroll-target="#the-fundamental-model">The Fundamental Model</a></li>
  </ul></li>
  <li><a href="#building-intuition-everyday-examples" id="toc-building-intuition-everyday-examples" class="nav-link" data-scroll-target="#building-intuition-everyday-examples"><span class="header-section-number">2.4</span> Building Intuition: Everyday Examples</a>
  <ul class="collapse">
  <li><a href="#example-1-height-and-basketball-performance" id="toc-example-1-height-and-basketball-performance" class="nav-link" data-scroll-target="#example-1-height-and-basketball-performance">Example 1: Height and Basketball Performance</a></li>
  <li><a href="#example-2-coffee-and-productivity" id="toc-example-2-coffee-and-productivity" class="nav-link" data-scroll-target="#example-2-coffee-and-productivity">Example 2: Coffee and Productivity</a></li>
  <li><a href="#example-3-study-hours-and-exam-scores" id="toc-example-3-study-hours-and-exam-scores" class="nav-link" data-scroll-target="#example-3-study-hours-and-exam-scores">Example 3: Study Hours and Exam Scores</a></li>
  </ul></li>
  <li><a href="#simple-linear-regression" id="toc-simple-linear-regression" class="nav-link" data-scroll-target="#simple-linear-regression"><span class="header-section-number">2.5</span> Simple Linear Regression</a>
  <ul class="collapse">
  <li><a href="#political-science-example-education-and-participation" id="toc-political-science-example-education-and-participation" class="nav-link" data-scroll-target="#political-science-example-education-and-participation">Political Science Example: Education and Participation</a></li>
  <li><a href="#understanding-r-squared-r²" id="toc-understanding-r-squared-r²" class="nav-link" data-scroll-target="#understanding-r-squared-r²">Understanding R-squared (R²)</a></li>
  </ul></li>
  <li><a href="#multiple-regression-accounting-for-complexity" id="toc-multiple-regression-accounting-for-complexity" class="nav-link" data-scroll-target="#multiple-regression-accounting-for-complexity"><span class="header-section-number">2.6</span> Multiple Regression: Accounting for Complexity</a>
  <ul class="collapse">
  <li><a href="#understanding-controlling-for" id="toc-understanding-controlling-for" class="nav-link" data-scroll-target="#understanding-controlling-for">Understanding “Controlling For”</a></li>
  <li><a href="#real-example-what-determines-electoral-success" id="toc-real-example-what-determines-electoral-success" class="nav-link" data-scroll-target="#real-example-what-determines-electoral-success">Real Example: What Determines Electoral Success?</a></li>
  <li><a href="#the-fundamental-problem-of-causal-inference" id="toc-the-fundamental-problem-of-causal-inference" class="nav-link" data-scroll-target="#the-fundamental-problem-of-causal-inference">The Fundamental Problem of Causal Inference</a></li>
  <li><a href="#when-can-we-make-causal-claims" id="toc-when-can-we-make-causal-claims" class="nav-link" data-scroll-target="#when-can-we-make-causal-claims">When Can We Make Causal Claims?</a></li>
  </ul></li>
  <li><a href="#summary-what-youve-learned" id="toc-summary-what-youve-learned" class="nav-link" data-scroll-target="#summary-what-youve-learned"><span class="header-section-number">2.7</span> Summary: What You’ve Learned</a>
  <ul class="collapse">
  <li><a href="#the-core-ideas" id="toc-the-core-ideas" class="nav-link" data-scroll-target="#the-core-ideas">The Core Ideas</a></li>
  <li><a href="#reading-regression-results-a-practical-guide" id="toc-reading-regression-results-a-practical-guide" class="nav-link" data-scroll-target="#reading-regression-results-a-practical-guide">Reading Regression Results: A Practical Guide</a></li>
  <li><a href="#common-pitfalls-to-avoid" id="toc-common-pitfalls-to-avoid" class="nav-link" data-scroll-target="#common-pitfalls-to-avoid">Common Pitfalls to Avoid</a></li>
  </ul></li>
  <li><a href="#quick-reference-regression-in-three-sentences" id="toc-quick-reference-regression-in-three-sentences" class="nav-link" data-scroll-target="#quick-reference-regression-in-three-sentences"><span class="header-section-number">2.8</span> Quick Reference: Regression in Three Sentences</a></li>
  <li><a href="#common-pitfalls-in-regression-analysis" id="toc-common-pitfalls-in-regression-analysis" class="nav-link" data-scroll-target="#common-pitfalls-in-regression-analysis"><span class="header-section-number">2.9</span> Common Pitfalls in Regression Analysis (*)</a>
  <ul class="collapse">
  <li><a href="#pitfall-1-confusing-statistical-and-practical-significance" id="toc-pitfall-1-confusing-statistical-and-practical-significance" class="nav-link" data-scroll-target="#pitfall-1-confusing-statistical-and-practical-significance">Pitfall 1: Confusing Statistical and Practical Significance</a></li>
  <li><a href="#pitfall-2-overfitting" id="toc-pitfall-2-overfitting" class="nav-link" data-scroll-target="#pitfall-2-overfitting">Pitfall 2: Overfitting</a></li>
  <li><a href="#pitfall-3-multiple-testing-problem" id="toc-pitfall-3-multiple-testing-problem" class="nav-link" data-scroll-target="#pitfall-3-multiple-testing-problem">Pitfall 3: Multiple Testing Problem</a></li>
  <li><a href="#pitfall-4-ecological-fallacy" id="toc-pitfall-4-ecological-fallacy" class="nav-link" data-scroll-target="#pitfall-4-ecological-fallacy">Pitfall 4: Ecological Fallacy</a></li>
  <li><a href="#pitfall-5-selection-bias" id="toc-pitfall-5-selection-bias" class="nav-link" data-scroll-target="#pitfall-5-selection-bias">Pitfall 5: Selection Bias</a></li>
  <li><a href="#pitfall-6-ignoring-uncertainty" id="toc-pitfall-6-ignoring-uncertainty" class="nav-link" data-scroll-target="#pitfall-6-ignoring-uncertainty">Pitfall 6: Ignoring Uncertainty</a></li>
  <li><a href="#pitfall-7-spurious-correlations" id="toc-pitfall-7-spurious-correlations" class="nav-link" data-scroll-target="#pitfall-7-spurious-correlations">Pitfall 7: Spurious Correlations</a></li>
  <li><a href="#pitfall-8-confounding-variables" id="toc-pitfall-8-confounding-variables" class="nav-link" data-scroll-target="#pitfall-8-confounding-variables">Pitfall 8: Confounding Variables</a></li>
  </ul></li>
  <li><a href="#guidelines-for-research-consumers" id="toc-guidelines-for-research-consumers" class="nav-link" data-scroll-target="#guidelines-for-research-consumers"><span class="header-section-number">2.10</span> Guidelines for Research Consumers</a></li>
  <li><a href="#conclusion-1" id="toc-conclusion-1" class="nav-link" data-scroll-target="#conclusion-1"><span class="header-section-number">2.11</span> Conclusion</a></li>
  <li><a href="#practical-advice-for-political-science-research" id="toc-practical-advice-for-political-science-research" class="nav-link" data-scroll-target="#practical-advice-for-political-science-research"><span class="header-section-number">2.12</span> Practical Advice for Political Science Research</a>
  <ul class="collapse">
  <li><a href="#start-with-theory" id="toc-start-with-theory" class="nav-link" data-scroll-target="#start-with-theory">1. Start with Theory</a></li>
  <li><a href="#know-your-data" id="toc-know-your-data" class="nav-link" data-scroll-target="#know-your-data">2. Know Your Data</a></li>
  <li><a href="#match-method-to-question" id="toc-match-method-to-question" class="nav-link" data-scroll-target="#match-method-to-question">3. Match Method to Question</a></li>
  <li><a href="#interpret-substantively" id="toc-interpret-substantively" class="nav-link" data-scroll-target="#interpret-substantively">4. Interpret Substantively</a></li>
  <li><a href="#be-transparent" id="toc-be-transparent" class="nav-link" data-scroll-target="#be-transparent">5. Be Transparent</a></li>
  </ul></li>
  <li><a href="#practice-problems" id="toc-practice-problems" class="nav-link" data-scroll-target="#practice-problems"><span class="header-section-number">2.13</span> Practice Problems</a>
  <ul class="collapse">
  <li><a href="#problem-1-identifying-populations-and-samples" id="toc-problem-1-identifying-populations-and-samples" class="nav-link" data-scroll-target="#problem-1-identifying-populations-and-samples">Problem 1: Identifying Populations and Samples</a></li>
  <li><a href="#problem-2-interpreting-results" id="toc-problem-2-interpreting-results" class="nav-link" data-scroll-target="#problem-2-interpreting-results">Problem 2: Interpreting Results</a></li>
  <li><a href="#problem-3-correlation-vs.-causation" id="toc-problem-3-correlation-vs.-causation" class="nav-link" data-scroll-target="#problem-3-correlation-vs.-causation">Problem 3: Correlation vs.&nbsp;Causation</a></li>
  <li><a href="#problem-4-regression-interpretation" id="toc-problem-4-regression-interpretation" class="nav-link" data-scroll-target="#problem-4-regression-interpretation">Problem 4: Regression Interpretation</a></li>
  </ul></li>
  <li><a href="#essential-r-code-for-getting-started" id="toc-essential-r-code-for-getting-started" class="nav-link" data-scroll-target="#essential-r-code-for-getting-started"><span class="header-section-number">2.14</span> Essential R Code for Getting Started</a></li>
  <li><a href="#final-thoughts" id="toc-final-thoughts" class="nav-link" data-scroll-target="#final-thoughts"><span class="header-section-number">2.15</span> Final Thoughts</a></li>
  <li><a href="#appendix-a-sampling-methods" id="toc-appendix-a-sampling-methods" class="nav-link" data-scroll-target="#appendix-a-sampling-methods"><span class="header-section-number">2.16</span> Appendix A: Sampling Methods</a>
  <ul class="collapse">
  <li><a href="#probability-sampling" id="toc-probability-sampling" class="nav-link" data-scroll-target="#probability-sampling">Probability Sampling</a></li>
  <li><a href="#non-probability-sampling" id="toc-non-probability-sampling" class="nav-link" data-scroll-target="#non-probability-sampling">Non-probability Sampling</a></li>
  <li><a href="#why-pollsters-increasingly-use-quota-sampling" id="toc-why-pollsters-increasingly-use-quota-sampling" class="nav-link" data-scroll-target="#why-pollsters-increasingly-use-quota-sampling">Why Pollsters Increasingly Use Quota Sampling</a></li>
  </ul></li>
  <li><a href="#appendix-a-measuring-uncertainty-in-data" id="toc-appendix-a-measuring-uncertainty-in-data" class="nav-link" data-scroll-target="#appendix-a-measuring-uncertainty-in-data"><span class="header-section-number">2.17</span> Appendix A: Measuring Uncertainty in Data (*)</a>
  <ul class="collapse">
  <li><a href="#fundamental-principle" id="toc-fundamental-principle" class="nav-link" data-scroll-target="#fundamental-principle">Fundamental Principle</a></li>
  <li><a href="#two-types-of-error-random-error-and-bias" id="toc-two-types-of-error-random-error-and-bias" class="nav-link" data-scroll-target="#two-types-of-error-random-error-and-bias">1. Two Types of Error: Random Error and Bias</a></li>
  <li><a href="#two-types-of-variability" id="toc-two-types-of-variability" class="nav-link" data-scroll-target="#two-types-of-variability">2. Two Types of Variability</a></li>
  <li><a href="#core-statistical-formulas" id="toc-core-statistical-formulas" class="nav-link" data-scroll-target="#core-statistical-formulas">3. Core Statistical Formulas</a></li>
  <li><a href="#the-multiplier-1.96-an-empirical-constant" id="toc-the-multiplier-1.96-an-empirical-constant" class="nav-link" data-scroll-target="#the-multiplier-1.96-an-empirical-constant">4. The Multiplier 1.96: An Empirical Constant</a></li>
  <li><a href="#worked-example-analysis-of-study-hours" id="toc-worked-example-analysis-of-study-hours" class="nav-link" data-scroll-target="#worked-example-analysis-of-study-hours">5. Worked Example: Analysis of Study Hours</a></li>
  <li><a href="#bootstrap-methods-detailed-explanation" id="toc-bootstrap-methods-detailed-explanation" class="nav-link" data-scroll-target="#bootstrap-methods-detailed-explanation">6. Bootstrap Methods: Detailed Explanation</a></li>
  <li><a href="#strategies-for-managing-uncertainty" id="toc-strategies-for-managing-uncertainty" class="nav-link" data-scroll-target="#strategies-for-managing-uncertainty">7. Strategies for Managing Uncertainty</a></li>
  <li><a href="#sample-size-determination-for-proportions" id="toc-sample-size-determination-for-proportions" class="nav-link" data-scroll-target="#sample-size-determination-for-proportions">8. Sample Size Determination for Proportions</a></li>
  <li><a href="#implementation-in-r" id="toc-implementation-in-r" class="nav-link" data-scroll-target="#implementation-in-r">9. Implementation in R</a></li>
  <li><a href="#summary-1" id="toc-summary-1" class="nav-link" data-scroll-target="#summary-1">Summary</a></li>
  </ul></li>
  <li><a href="#appendix-b-quantifying-uncertainty-for-a-proportion" id="toc-appendix-b-quantifying-uncertainty-for-a-proportion" class="nav-link" data-scroll-target="#appendix-b-quantifying-uncertainty-for-a-proportion"><span class="header-section-number">2.18</span> Appendix B: Quantifying Uncertainty for a Proportion (*)</a>
  <ul class="collapse">
  <li><a href="#setting-and-notation" id="toc-setting-and-notation" class="nav-link" data-scroll-target="#setting-and-notation">Setting and Notation</a></li>
  <li><a href="#estimation-precision-and-a-95-interval" id="toc-estimation-precision-and-a-95-interval" class="nav-link" data-scroll-target="#estimation-precision-and-a-95-interval">Estimation, Precision, and a 95% Interval</a></li>
  <li><a href="#worked-examples-hand-calculation" id="toc-worked-examples-hand-calculation" class="nav-link" data-scroll-target="#worked-examples-hand-calculation">Worked Examples (hand calculation)</a></li>
  <li><a href="#mini-poll-illustration" id="toc-mini-poll-illustration" class="nav-link" data-scroll-target="#mini-poll-illustration">Mini-Poll Illustration</a></li>
  <li><a href="#simulation-sampling-variability-and-coverage" id="toc-simulation-sampling-variability-and-coverage" class="nav-link" data-scroll-target="#simulation-sampling-variability-and-coverage">Simulation: Sampling Variability and Coverage</a></li>
  <li><a href="#what-a-95-ci-doesand-does-notsay" id="toc-what-a-95-ci-doesand-does-notsay" class="nav-link" data-scroll-target="#what-a-95-ci-doesand-does-notsay">What a 95% CI Does—and Does Not—Say</a></li>
  <li><a href="#understanding-confidence-intervals-through-simulation" id="toc-understanding-confidence-intervals-through-simulation" class="nav-link" data-scroll-target="#understanding-confidence-intervals-through-simulation">Understanding Confidence Intervals Through Simulation</a></li>
  <li><a href="#factors-affecting-uncertainty" id="toc-factors-affecting-uncertainty" class="nav-link" data-scroll-target="#factors-affecting-uncertainty">Factors Affecting Uncertainty</a></li>
  <li><a href="#practical-guidelines-for-working-with-uncertainty" id="toc-practical-guidelines-for-working-with-uncertainty" class="nav-link" data-scroll-target="#practical-guidelines-for-working-with-uncertainty">Practical Guidelines for Working with Uncertainty</a></li>
  <li><a href="#summary-2" id="toc-summary-2" class="nav-link" data-scroll-target="#summary-2">Summary</a></li>
  </ul></li>
  <li><a href="#appendix-c-randomness-the-foundation-of-statistical-inference" id="toc-appendix-c-randomness-the-foundation-of-statistical-inference" class="nav-link" data-scroll-target="#appendix-c-randomness-the-foundation-of-statistical-inference"><span class="header-section-number">2.19</span> Appendix C: Randomness: The Foundation of Statistical Inference (*)</a>
  <ul class="collapse">
  <li><a href="#what-is-randomness-1" id="toc-what-is-randomness-1" class="nav-link" data-scroll-target="#what-is-randomness-1">What is Randomness?</a></li>
  <li><a href="#predictable-frequencies-law-of-large-numbers" id="toc-predictable-frequencies-law-of-large-numbers" class="nav-link" data-scroll-target="#predictable-frequencies-law-of-large-numbers">Predictable Frequencies (Law of Large Numbers)</a></li>
  <li><a href="#shannon-entropy-measuring-uncertainty" id="toc-shannon-entropy-measuring-uncertainty" class="nav-link" data-scroll-target="#shannon-entropy-measuring-uncertainty">Shannon Entropy: Measuring Uncertainty</a></li>
  <li><a href="#randomness-chaos-entropy-haphazardness-at-a-glance" id="toc-randomness-chaos-entropy-haphazardness-at-a-glance" class="nav-link" data-scroll-target="#randomness-chaos-entropy-haphazardness-at-a-glance">Randomness, Chaos, Entropy, Haphazardness (at a glance)</a></li>
  <li><a href="#why-randomness-matters-1" id="toc-why-randomness-matters-1" class="nav-link" data-scroll-target="#why-randomness-matters-1">Why Randomness Matters</a></li>
  <li><a href="#the-power-of-random-sampling-quick-demo-1" id="toc-the-power-of-random-sampling-quick-demo-1" class="nav-link" data-scroll-target="#the-power-of-random-sampling-quick-demo-1">The Power of Random Sampling (quick demo)</a></li>
  </ul></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction to Statistics and Data Analysis for Political Science</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Rounding and Scientific Notation in Statistics
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Main Rule:</strong> Unless otherwise specified, round the <strong>decimal parts</strong> of decimal numbers to <strong>at least 2 significant figures</strong>. In statistics, we often work with long decimal parts and very small numbers — don’t round excessively in intermediate steps, round <strong>at the end</strong> of calculations.</p>
<section id="rounding-in-statistical-context" class="level3">
<h3 class="anchored" data-anchor-id="rounding-in-statistical-context">Rounding in Statistical Context</h3>
<p>The <strong>decimal part</strong> consists of digits after the decimal point. In statistics, it’s particularly important to maintain appropriate precision:</p>
<p><strong>Descriptive statistics:</strong></p>
<ul>
<li>Mean: <span class="math inline">\bar{x} = 15.847693... \rightarrow 15.85</span></li>
<li>Standard deviation: <span class="math inline">s = 2.7488... \rightarrow 2.75</span></li>
<li>Correlation coefficient: <span class="math inline">r = 0.78432... \rightarrow 0.78</span></li>
</ul>
<p><strong>Very small numbers (p-values, probabilities):</strong></p>
<ul>
<li><span class="math inline">p = 0.000347... \rightarrow 0.00035</span> or <span class="math inline">3.5 \times 10^{-4}</span></li>
<li><span class="math inline">P(X &gt; 2) = 0.0000891... \rightarrow 0.000089</span> or <span class="math inline">8.9 \times 10^{-5}</span></li>
</ul>
</section>
<section id="significant-figures-in-decimal-parts" class="level3">
<h3 class="anchored" data-anchor-id="significant-figures-in-decimal-parts">Significant Figures in Decimal Parts</h3>
<p>In the decimal part, significant figures are all digits except leading zeros:</p>
<ul>
<li><span class="math inline">.78432</span> has 5 significant figures → round to <span class="math inline">.78</span> (2 s.f.)</li>
<li><span class="math inline">.000347</span> has 3 significant figures → round to <span class="math inline">.00035</span> (2 s.f.)</li>
<li><span class="math inline">.050600</span> has 4 significant figures → round to <span class="math inline">.051</span> (2 s.f.)</li>
</ul>
</section>
<section id="rounding-rules-in-statistics" class="level3">
<h3 class="anchored" data-anchor-id="rounding-rules-in-statistics">Rounding Rules in Statistics</h3>
<ol type="1">
<li><strong>Round only the decimal part</strong> to at least 2 significant figures</li>
<li><strong>The integer part</strong> remains unchanged</li>
<li><strong>In long calculations</strong> keep 3-4 digits in the decimal part until the final step</li>
<li><strong>NEVER round to zero</strong> - small values have interpretive significance</li>
<li><strong>For very small numbers</strong> use scientific notation when it improves readability</li>
<li><strong>P-values</strong> often require greater precision — keep 2-3 significant figures</li>
</ol>
</section>
<section id="warning-dont-round-to-zero" class="level3">
<h3 class="anchored" data-anchor-id="warning-dont-round-to-zero">⚠️ WARNING: Don’t round to zero!</h3>
<p>In statistics, small values have critical interpretive significance:</p>
<p><strong>Incorrect rounding:</strong></p>
<ul>
<li><span class="math inline">p = 0.00034 \rightarrow 0.00</span> ❌ (suggests p = 0, which is false)</li>
<li><span class="math inline">\sigma = 0.00089 \rightarrow 0.00</span> ❌ (suggests no variability)</li>
</ul>
<p><strong>Correct approach:</strong></p>
<ul>
<li><span class="math inline">p = 0.00034 \rightarrow 0.00034</span> or <span class="math inline">3.4 \times 10^{-4}</span> ✅</li>
<li><span class="math inline">p = 0.00034 \rightarrow p &lt; 0.001</span> ✅ (in reports)</li>
<li><span class="math inline">\sigma = 0.00089 \rightarrow 0.00089</span> or <span class="math inline">8.9 \times 10^{-4}</span> ✅</li>
</ul>
</section>
<section id="scientific-notation-in-statistics" class="level3">
<h3 class="anchored" data-anchor-id="scientific-notation-in-statistics">Scientific Notation in Statistics</h3>
<p>In statistics, we often encounter very small numbers. Use scientific notation when it improves readability:</p>
<p><strong>P-values and probabilities:</strong></p>
<ul>
<li><span class="math inline">p = 0.000347 = 3.47 \times 10^{-4}</span> (better: <span class="math inline">3.5 \times 10^{-4}</span>)</li>
<li><span class="math inline">P(Z &gt; 3.5) = 0.000233 = 2.33 \times 10^{-4}</span></li>
</ul>
<p><strong>Very small standard deviations:</strong> - <span class="math inline">\sigma = 0.000892 = 8.92 \times 10^{-4}</span></p>
<p><strong>Large numbers (rare in basic statistics):</strong> - <span class="math inline">N = 1\,234\,567 = 1.23 \times 10^6</span></p>
<p><strong>When in doubt:</strong> Better to keep an extra digit than to round too aggressively</p>
</section>
</div>
</div>
<section id="what-is-statistics" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="what-is-statistics"><span class="header-section-number">1.1</span> What Is Statistics?</h2>
<p><strong>Statistics</strong> is the science of learning from data under uncertainty.</p>
<p>Statistics is a way to learn about the world from data when results vary and are uncertain. It teaches how to collect data wisely, spot patterns, estimate population quantities, and make predictions—always stating how wrong we might be.</p>
<hr>
</section>
<section id="the-three-core-activities-of-statistics" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="the-three-core-activities-of-statistics"><span class="header-section-number">1.2</span> The Three Core Activities of Statistics</h2>
<p>Every statistical analysis does at least one of these three things:</p>
<section id="describe-what-does-our-data-show" class="level3">
<h3 class="anchored" data-anchor-id="describe-what-does-our-data-show">1. <strong>Describe</strong>: “What does our data show?”</h3>
<p>We summarize and visualize data to understand what we’re working with. This means creating clear graphs, calculating averages, and spotting patterns.</p>
<p><strong>Example</strong>: Plotting unemployment rates before and after a Universal Basic Income (UBI) pilot program starts, or showing voter turnout across different age groups.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding Policy Pilots
</div>
</div>
<div class="callout-body-container callout-body">
<p>A <strong>pilot program</strong> is a small-scale, time-limited test of a policy before broader implementation.</p>
<p><strong>For UBI pilots</strong>:</p>
<ul>
<li>Selected participants receive regular, unconditional cash payments for a fixed period (typically 6-24 months)</li>
<li>Researchers compare outcomes between those offered the pilot and similar people not offered it</li>
<li>If participants are chosen by lottery, differences can be interpreted as causal effects of the program</li>
</ul>
<p><strong>Why pilots matter</strong>: They let policymakers test ideas on a small scale before committing to expensive, large-scale programs.</p>
</div>
</div>
</section>
<section id="infer-what-can-we-learn-about-the-bigger-picture" class="level3">
<h3 class="anchored" data-anchor-id="infer-what-can-we-learn-about-the-bigger-picture">2. <strong>Infer</strong>: “What can we learn about the bigger picture?”</h3>
<p>We use sample data to make educated guesses about larger populations, always acknowledging our uncertainty.</p>
<p><strong>Example</strong>: Using a poll of 1,000 people to estimate how the entire country might vote, complete with a margin of error.</p>
</section>
<section id="predict-decide-what-might-happen-next-and-what-should-we-do" class="level3">
<h3 class="anchored" data-anchor-id="predict-decide-what-might-happen-next-and-what-should-we-do">3. <strong>Predict &amp; Decide</strong>: “What might happen next, and what should we do?”</h3>
<p>We use patterns from the past to forecast the future and guide decisions, always showing how confident (or uncertain) we are.</p>
<p><strong>Example</strong>: Predicting election turnout to decide how many polling stations to open, or forecasting economic impacts of a new policy.</p>
<hr>
</section>
</section>
<section id="key-questions-statistics-helps-answer" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="key-questions-statistics-helps-answer"><span class="header-section-number">1.3</span> Key Questions Statistics Helps Answer</h2>
<ul>
<li>Does a <strong>universal basic income pilot</strong> change how much people work?</li>
<li>Do <strong>changes to voting rules</strong> affect who shows up to vote?</li>
<li>What do <strong>opinion polls</strong> really tell us about election outcomes?</li>
<li>How does <strong>education spending</strong> relate to <strong>student performance</strong>?</li>
<li>Is there a <strong>gender pay gap</strong> in your field, and how large is it?</li>
</ul>
<hr>
<section id="always-start-with-description" class="level3">
<h3 class="anchored" data-anchor-id="always-start-with-description">Always Start with Description</h3>
<p>Before diving into complex analyses, <strong>look at your data</strong>. Good statistics starts with good pictures and simple summaries.</p>
<p><strong>For UBI research</strong>: Plot unemployment rates in pilot areas versus similar non-pilot areas over time. Mark when the program started. Does anything obvious jump out?</p>
<p><strong>For voting research</strong>: Show turnout rates over several elections. Mark when electoral rules changed. Do you see any clear before/after patterns?</p>
<p><strong>Why this matters</strong>: If you can’t explain what your data shows in plain English, you’re not ready for fancy models.</p>
<hr>
</section>
<section id="opinion-polls-why-one-number-isnt-enough" class="level3">
<h3 class="anchored" data-anchor-id="opinion-polls-why-one-number-isnt-enough">Opinion Polls: Why One Number Isn’t Enough</h3>
</section>
</section>
<section id="the-core-problem" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="the-core-problem"><span class="header-section-number">1.4</span> The Core Problem</h2>
<p>Polls use <strong>samples</strong> of people rather than surveying the entire population, so results naturally <strong>vary</strong>. A result like “Candidate A: 52%, Candidate B: 48%” is <strong>incomplete</strong> without expressing the uncertainty inherent in sampling.</p>
</section>
<section id="the-golden-rule-of-polling" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="the-golden-rule-of-polling"><span class="header-section-number">1.5</span> The Golden Rule of Polling</h2>
<p>With approximately <strong>1,000</strong> randomly selected respondents, the <strong>95% margin of sampling error</strong> is roughly <strong>±3 percentage points</strong> in the worst-case scenario. When a poll reports “52%,” the true population support likely falls <strong>between 49% and 55%</strong> — assuming no other sources of error.</p>
</section>
<section id="understanding-95-confidence" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="understanding-95-confidence"><span class="header-section-number">1.6</span> Understanding 95% Confidence</h2>
<p>Consider repeating the same poll 100 times with different random samples of 1,000 people. Each time, you calculate the ±3% range around your result. <strong>Approximately 95 of those 100 ranges would contain the true population value.</strong></p>
<p>The remaining 5 times represent sampling variation—occasions when the random sample happens to differ substantially from the population.</p>
</section>
<section id="why-choose-95" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="why-choose-95"><span class="header-section-number">1.7</span> Why Choose 95%?</h2>
<p>The confidence level represents a trade-off between precision and reliability:</p>
<ul>
<li><strong>90% confidence</strong> → narrower intervals, but incorrect more frequently</li>
<li><strong>95% confidence</strong> → moderate width (most common choice)<br>
</li>
<li><strong>99% confidence</strong> → wider intervals, but incorrect less frequently</li>
</ul>
<p>Higher confidence requires wider intervals, reducing precision.</p>
</section>
<section id="small-differences-and-uncertainty" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="small-differences-and-uncertainty"><span class="header-section-number">1.8</span> Small Differences and Uncertainty</h2>
<p>The <strong>difference</strong> between candidates carries more uncertainty than individual percentages. With n≈1,000, a 4-percentage-point lead may be <strong>within the margin of sampling error</strong> when accounting for random sampling variation.</p>
</section>
<section id="the-mathematical-foundation" class="level2" data-number="1.9">
<h2 data-number="1.9" class="anchored" data-anchor-id="the-mathematical-foundation"><span class="header-section-number">1.9</span> The Mathematical Foundation</h2>
<p>For a sample proportion <span class="math inline">\hat{p}</span> from <span class="math inline">n</span> respondents, the <strong>margin of sampling error</strong> is:</p>
<p><span class="math display">\text{Margin of sampling error (95\%)} \approx 1.96 \times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</span></p>
<section id="understanding-the-1.96-multiplier" class="level3">
<h3 class="anchored" data-anchor-id="understanding-the-1.96-multiplier">Understanding the 1.96 Multiplier</h3>
<p>The value 1.96 represents a mathematical constant that ensures 95% coverage. Here is the conceptual explanation:</p>
<p>When drawing many samples from a population, the sample results form a predictable pattern around the true value. To capture the middle 95% of all possible sample results, statisticians have determined that the interval must extend <strong>1.96 times the typical variation</strong> in each direction from the sample result.</p>
<p>This multiplier ensures that if you repeated the polling process many times, approximately 95% of your calculated intervals would contain the true population parameter.</p>
</section>
<section id="worst-case-calculation" class="level3">
<h3 class="anchored" data-anchor-id="worst-case-calculation">Worst-Case Calculation</h3>
<p>The margin of sampling error reaches its maximum when <span class="math inline">\hat{p} = 0.5</span> (a 50-50 split):</p>
<p><span class="math display">\text{Margin of sampling error} \approx 1.96 \times \sqrt{\frac{0.5 \times 0.5}{n}} = \frac{0.98}{\sqrt{n}}</span></p>
<p>With <span class="math inline">n = 1,000</span>: <span class="math inline">\frac{0.98}{\sqrt{1000}} \approx 0.031 = 3.1\%</span></p>
</section>
</section>
<section id="essential-poll-information" class="level2" data-number="1.10">
<h2 data-number="1.10" class="anchored" data-anchor-id="essential-poll-information"><span class="header-section-number">1.10</span> Essential Poll Information</h2>
<p>Quality polls should report:</p>
<ul>
<li><strong>Field dates</strong> when interviews occurred</li>
<li><strong>Sample definition</strong> (adults, registered voters, likely voters) and <strong>sample size</strong> (<span class="math inline">n</span>)</li>
<li><strong>Treatment of undecided responses</strong> and third-party candidates</li>
<li><strong>Margin of sampling error</strong> for individual candidates</li>
<li><strong>Uncertainty in vote margins</strong> when possible</li>
</ul>
</section>
<section id="key-principles" class="level2" data-number="1.11">
<h2 data-number="1.11" class="anchored" data-anchor-id="key-principles"><span class="header-section-number">1.11</span> Key Principles</h2>
<p><strong>Primary rule:</strong> Differences smaller than the margin of sampling error may represent <strong>random sampling variation rather than meaningful differences</strong>.</p>
<p><strong>Critical limitation:</strong> The margin of sampling error addresses only <strong>random variation from sampling</strong>. It does <strong>not</strong> account for systematic errors, which are often larger and more consequential:</p>
<ul>
<li><strong>Non-response bias</strong> (certain groups declining to participate)</li>
<li><strong>Coverage bias</strong> (certain groups absent from contact lists)<br>
</li>
<li><strong>Question wording effects</strong> and response order</li>
<li><strong>Social desirability bias</strong> (respondents giving socially acceptable answers)</li>
<li><strong>Timing effects</strong> and current events influence</li>
</ul>
<p>These systematic errors can cause polls to miss the true value by much more than ±3%, yet they are invisible in the reported margin of sampling error.</p>
<p><strong>Rule of thumb</strong>: Don’t over-interpret differences smaller than the margin of error—they might just be noise.</p>
<section id="random-error-vs.-systematic-error" class="level4">
<h4 class="anchored" data-anchor-id="random-error-vs.-systematic-error">Random Error vs.&nbsp;Systematic Error</h4>
<p><strong>Random error</strong> is the unpredictable variability that occurs in any sample-based study. The larger the sample, the smaller the random error. This is what the margin of error accounts for.</p>
<p><strong>Systematic error (bias)</strong> is a consistent shift in results in one direction. It can result from:</p>
<ul>
<li>Unrepresentative samples (e.g., polling only landline phones)</li>
<li>Leading questions (“Do you support wasting taxpayer money on program X?”)</li>
<li>Non-response from certain groups (e.g., young people less likely to answer calls)</li>
</ul>
<p><strong>Key difference</strong>: A larger sample reduces random error but <strong>does not</strong> eliminate systematic error. A poll of 10,000 people with systematic bias can be less accurate than a poll of 1,000 people without such bias.</p>
<hr>
</section>
<section id="regression-measuring-average-differences-and-modeling-relationship-between-variables" class="level3">
<h3 class="anchored" data-anchor-id="regression-measuring-average-differences-and-modeling-relationship-between-variables">Regression: Measuring Average Differences And Modeling Relationship Between Variables</h3>
<p>At its heart, regression answers: “On average, how much do outcomes differ between groups?”</p>
<p><span class="math display">Y_i = \alpha + \beta X_i + \varepsilon_i</span></p>
<p><strong>Translation into English</strong>:</p>
<ul>
<li><span class="math inline">Y_i</span>: The outcome we care about (e.g., hours worked per week)</li>
<li><span class="math inline">X_i</span>: Group membership (e.g., <span class="math inline">X=1</span> for UBI recipients, <span class="math inline">X=0</span> for others)</li>
<li><span class="math inline">\beta</span>: <strong>The average difference</strong> in outcomes between groups</li>
<li><span class="math inline">\varepsilon_i</span>: Everything else that affects the outcome</li>
</ul>
<p><strong>Example</strong>: If <span class="math inline">\beta = -2</span> in a study of UBI and work hours, UBI recipients worked 2 fewer hours per week on average than non-recipients.</p>
<p><strong>Critical point</strong>: This shows a <strong>relationship</strong> or <strong>association</strong>. By itself, it does <strong>not</strong> prove the UBI <strong>caused</strong> the difference.</p>
<hr>
</section>
<section id="the-challenge-of-causality" class="level3">
<h3 class="anchored" data-anchor-id="the-challenge-of-causality">The Challenge of Causality</h3>
<p>The hardest question in statistics: Did the policy <strong>cause</strong> the change, or would it have happened anyway?</p>
</section>
<section id="what-we-really-want-to-know" class="level3">
<h3 class="anchored" data-anchor-id="what-we-really-want-to-know">What We Really Want to Know</h3>
<p>For the <strong>same people</strong> in the <strong>same circumstances</strong>: What would happen <strong>with</strong> the policy versus <strong>without</strong> it? Since we can’t observe both realities for the same people, we need clever comparisons.</p>
<section id="strategies-for-better-causal-inference" class="level4">
<h4 class="anchored" data-anchor-id="strategies-for-better-causal-inference">Strategies for Better Causal Inference</h4>
<p><strong>Random Assignment (The Gold Standard)</strong> - Randomly assign some people to get UBI, others not - Groups are similar <strong>by design</strong>, so differences are likely due to UBI</p>
<p><strong>Before/After with Comparison Groups</strong> - Compare how much the UBI group <strong>changes</strong> versus how much a similar non-UBI group changes over the same period - Controls for other things happening at the same time</p>
<p><strong>Sharp Rules or Cutoffs</strong> - Compare people just above vs.&nbsp;just below eligibility thresholds - Example: Compare 17-year-olds to 18-year-olds for voting studies</p>
</section>
<section id="causal-claims-checklist" class="level4">
<h4 class="anchored" data-anchor-id="causal-claims-checklist">Causal Claims Checklist</h4>
<p>Before believing any causal claim, ask:</p>
<ul>
<li>What exactly is the <strong>treatment/policy</strong>?</li>
<li>What is the <strong>outcome</strong> being measured?</li>
<li>Who is the <strong>comparison group</strong>?</li>
<li>Why is this comparison <strong>fair</strong>?</li>
<li>Could other explanations account for the difference?</li>
</ul>
<hr>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Takeaways
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Always describe first</strong>: Understand your data through visualization and summary statistics before attempting complex modeling</li>
<li><strong>Embrace uncertainty</strong>: Report margins of error and confidence intervals, not just point estimates</li>
<li><strong>Association ≠ Causation</strong>: Regression shows relationships between variables; establishing causation requires careful research design</li>
<li><strong>Fair comparisons matter</strong>: Good causal inference depends on comparing like with like—the closer the comparison groups, the stronger your conclusions</li>
<li><strong>Be transparent</strong>: Good statistics clearly communicates methods, limitations, and uncertainty to help others evaluate your work</li>
</ul>
</div>
</div>
<hr>
</section>
</section>
</section>
<section id="randomness-a-foundation-of-statistical-inference" class="level2" data-number="1.12">
<h2 data-number="1.12" class="anchored" data-anchor-id="randomness-a-foundation-of-statistical-inference"><span class="header-section-number">1.12</span> Randomness: a foundation of statistical inference</h2>
<section id="what-is-randomness" class="level3">
<h3 class="anchored" data-anchor-id="what-is-randomness">What is randomness?</h3>
<p>In statistics, <strong>randomness</strong> is an orderly way to describe uncertainty: individual outcomes are unpredictable, yet in <strong>long sequences of repetitions</strong> stable regularities emerge (e.g., frequencies, means).</p>
<p><strong>Two perspectives</strong></p>
<ol type="1">
<li><strong>Single realisation</strong> — we cannot determine how a specific voter will vote at a given moment.<br>
</li>
<li><strong>Aggregate</strong> — we can describe the share of voters supporting a party and quantify the associated estimation uncertainty.</li>
</ol>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Epistemic vs.&nbsp;ontological randomness</strong></p>
<ul>
<li><p><strong>Epistemic</strong> (due to incomplete knowledge): we treat an outcome as random because not all determinants are observed or conditions are not controlled.</p>
<p><strong>Examples:</strong></p>
<ul>
<li>the decision of an individual respondent in a poll (we do not know the full set of motivations),</li>
<li>measurement error in a survey (limited precision, item nonresponse),</li>
<li>a coin toss modeled as random because minute, unobserved differences in initial conditions determine the outcome.</li>
</ul></li>
<li><p><strong>Ontological</strong> (intrinsic indeterminacy): even complete knowledge does not remove outcome uncertainty.</p>
<p><strong>Examples:</strong></p>
<ul>
<li>the time to radioactive decay of an atom.</li>
</ul></li>
</ul>
</div>
</div>
</section>
<section id="why-randomness-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-randomness-matters">Why Randomness Matters</h3>
<ul>
<li><p><strong>Random sampling</strong></p>
<ul>
<li>Reduces systematic selection bias so the sample resembles the target population (in expectation).</li>
<li>Makes uncertainty <strong>quantifiable</strong> (e.g., margins of error; later we’ll name these “confidence intervals”), assuming genuinely random selection and good coverage.</li>
</ul></li>
<li><p><strong>Random assignment (experiments)</strong></p>
<ul>
<li>Breaks the link between treatment and other factors, making groups comparable <strong>on average</strong> (both observed and unobserved).</li>
<li>Supports credible <strong>cause-and-effect</strong> claims (identifies average treatment effects under standard conditions).</li>
</ul></li>
</ul>
</section>
<section id="the-power-of-random-sampling-quick-demo" class="level3">
<h3 class="anchored" data-anchor-id="the-power-of-random-sampling-quick-demo">The Power of Random Sampling (quick demo)</h3>
<p>Suppose we take a <strong>random sample</strong> of <span class="math inline">n=1000</span> voters and observe <span class="math inline">\hat p = 0.55</span> (i.e., 55% support). Then:</p>
<ul>
<li><p>Our best single-number estimate of the population share is <span class="math inline">\hat p = 0.55</span>.</p></li>
<li><p>A typical “<span class="math inline">95\%</span> range of plausible values” around <span class="math inline">\hat p</span> can be approximated by <span class="math display">
\hat p \;\pm\; 2\sqrt{\frac{\hat p(1-\hat p)}{n}}
\;=\;
0.55 \;\pm\; 2\sqrt{\frac{0.55\cdot 0.45}{1000}}
\approx
0.55 \pm 0.031,
</span> i.e., roughly <span class="math inline">52\%\text{–}58\%</span> (about <span class="math inline">\pm 3.1</span> percentage points).</p></li>
<li><p>The width of this range shrinks predictably with sample size: <span class="math display">
\text{width} \;\propto\; \frac{1}{\sqrt{n}}.
</span> For example, increasing <span class="math inline">n</span> from <span class="math inline">1000</span> to <span class="math inline">4000</span> cuts the range by about half.</p></li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>How to read the “95% range”</strong></p>
<ul>
<li><p>Imagine repeating the same random survey many times. In about <strong>19 out of 20</strong> such surveys, the computed range would include the true population percentage.</p></li>
<li><p>This rule-of-thumb assumes <strong>random sampling</strong> from the target population and similar survey conditions.<br>
Non-sampling issues (nonresponse, coverage, measurement) or complex designs (e.g., clustering) can make the real uncertainty larger.</p></li>
</ul>
</div>
</div>
</section>
</section>
<section id="the-foundation-law-of-large-numbers" class="level2" data-number="1.13">
<h2 data-number="1.13" class="anchored" data-anchor-id="the-foundation-law-of-large-numbers"><span class="header-section-number">1.13</span> The Foundation: Law of Large Numbers</h2>
<p>The Law of Large Numbers is one of the most important principles in statistics. It explains why we can make reliable inferences from samples, even when individual outcomes are unpredictable.</p>
<p><strong>The basic idea</strong>: When you repeat a random process many times, the average result gets closer and closer to what you’d expect theoretically.</p>
<section id="visualizing-the-law-of-large-numbers-coin-flips" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-law-of-large-numbers-coin-flips">Visualizing the Law of Large Numbers: Coin Flips</h3>
<p>Let’s see this in action with coin flips. A fair coin has a 50% chance of landing heads, but individual flips are unpredictable.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate coin flips and show convergence</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>n_flips <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>flips <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_flips, <span class="dv">1</span>, <span class="fl">0.5</span>)  <span class="co"># 1 = heads, 0 = tails</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate cumulative proportion of heads</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>cumulative_prop <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(flips) <span class="sc">/</span> <span class="fu">seq_along</span>(flips)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data frame for plotting</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>lln_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">flip_number =</span> <span class="dv">1</span><span class="sc">:</span>n_flips,</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">cumulative_proportion =</span> cumulative_prop</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the convergence</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(lln_data, <span class="fu">aes</span>(<span class="at">x =</span> flip_number, <span class="at">y =</span> cumulative_proportion)) <span class="sc">+</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="fl">0.45</span>, <span class="fl">0.55</span>), <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Law of Large Numbers: Coin Flip Proportions Converge to 0.5"</span>,</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Number of coin flips"</span>,</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Cumulative proportion of heads"</span>,</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">"Red dashed line = true probability (0.5)</span><span class="sc">\n</span><span class="st">Dotted lines = ±5% range"</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.7</span>), <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="fl">0.3</span>, <span class="fl">0.7</span>, <span class="fl">0.1</span>)) <span class="sc">+</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/lln-demo-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p><strong>What this shows:</strong></p>
<ul>
<li>Early flips show wild variation (first 10 flips might be 70% or 30% heads)</li>
<li>As we add more flips, the proportion stabilizes around 50%</li>
<li>The “noise” of individual outcomes averages out over time</li>
</ul>
</section>
<section id="the-mathematical-statement" class="level3">
<h3 class="anchored" data-anchor-id="the-mathematical-statement">The Mathematical Statement</h3>
<p>Let <span class="math inline">A</span> denote an event of interest (e.g., “heads on a coin flip”, “vote for party X”, “sum of dice equals 7”). If <span class="math inline">P(A) = p</span> and we observe <span class="math inline">n</span> <strong>independent trials with the same distribution</strong> (i.i.d.), then the <strong>sample frequency of <span class="math inline">A</span></strong>:</p>
<p><span class="math display">\hat{p}_n = \frac{\text{number of occurrences of } A}{n}</span></p>
<p><strong>converges to <span class="math inline">p</span> as <span class="math inline">n</span> increases</strong>.</p>
</section>
<section id="examples-in-different-contexts" class="level3">
<h3 class="anchored" data-anchor-id="examples-in-different-contexts">Examples in Different Contexts</h3>
<p><strong>Dice example</strong>: The event “sum = 7” with two dice has probability <span class="math inline">6/36 ≈ 16.7\%</span>, while “sum = 4” has <span class="math inline">3/36 ≈ 8.3\%</span>. Over many throws, a sum of 7 appears about twice as often as a sum of 4.</p>
<p><strong>Election polling</strong>: If population support for a party equals <span class="math inline">p</span>, then under random sampling of size <span class="math inline">n</span>, the observed frequency <span class="math inline">\hat{p}_n</span> will approach <span class="math inline">p</span> as <span class="math inline">n</span> grows (assuming random sampling and independence).</p>
<p><strong>Quality control</strong>: If 2% of products are defective, then in large batches, approximately 2% will be found defective (assuming independent production).</p>
</section>
<section id="why-this-matters-for-statistics" class="level3">
<h3 class="anchored" data-anchor-id="why-this-matters-for-statistics">Why This Matters for Statistics</h3>
<p><strong>Bottom line</strong>: Randomness underpins statistical inference by turning uncertainty in individual outcomes into <strong>predictable distributions</strong> for estimates. The Law of Large Numbers guarantees that the “noise” of individual outcomes averages out, allowing us to:</p>
<ul>
<li>Predict long-run frequencies</li>
<li>Quantify uncertainty (margins of error)<br>
</li>
<li>Draw reliable inferences from samples</li>
<li>Make probabilistic statements about populations</li>
</ul>
<p>This principle works in surveys, experiments, and even quantum phenomena (in the frequentist interpretation).</p>
<hr>
</section>
</section>
<section id="understanding-different-types-of-unpredictability" class="level2" data-number="1.14">
<h2 data-number="1.14" class="anchored" data-anchor-id="understanding-different-types-of-unpredictability"><span class="header-section-number">1.14</span> Understanding Different Types of Unpredictability</h2>
<p>Not all uncertainty is the same. Understanding different sources of unpredictability helps us choose appropriate statistical methods and interpret results correctly.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 40%">
<col style="width: 30%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th>Concept</th>
<th>What is it?</th>
<th>Source of unpredictability</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Randomness</strong></td>
<td>Individual outcomes are uncertain, but the <strong>probability distribution</strong> is known or modeled.</td>
<td>Fluctuations across realizations; lack of information about a specific outcome.</td>
<td>Dice roll, coin toss, polling sample</td>
</tr>
<tr class="even">
<td><strong>Chaos</strong></td>
<td><strong>Deterministic</strong> dynamics <strong>highly sensitive</strong> to initial conditions (butterfly effect).</td>
<td>Tiny initial differences grow rapidly → large trajectory divergences.</td>
<td>Weather forecasting, double pendulum, population dynamics</td>
</tr>
<tr class="odd">
<td><strong>Entropy</strong></td>
<td>A <strong>measure</strong> of uncertainty/dispersion (information-theoretic or thermodynamic).</td>
<td>Larger when outcomes are more evenly distributed (less predictive information).</td>
<td>Shannon entropy in data compression</td>
</tr>
<tr class="even">
<td><strong>“Haphazardness”</strong> (colloquial)</td>
<td>A felt lack of order without an explicit model; a mixture of mechanisms.</td>
<td>No structured description or stable rules; overlapping processes.</td>
<td>Traffic patterns, social media trends</td>
</tr>
<tr class="odd">
<td><strong>Quantum randomness</strong></td>
<td>A single outcome is <strong>not determined</strong>; only the distribution is specified (Born rule).</td>
<td><strong>Fundamental (ontological)</strong> indeterminacy of individual measurements.</td>
<td>Electron spin measurement, photon polarization</td>
</tr>
</tbody>
</table>
<section id="key-distinctions-for-statistical-practice" class="level3">
<h3 class="anchored" data-anchor-id="key-distinctions-for-statistical-practice">Key Distinctions for Statistical Practice</h3>
<p><strong>Deterministic chaos ≠ statistical randomness</strong>: A chaotic system is fully deterministic yet practically unpredictable due to extreme sensitivity to initial conditions. Statistical randomness, by contrast, models uncertainty via probability distributions where individual outcomes are genuinely uncertain.</p>
<p><strong>Why this matters</strong>: In statistics, we typically model phenomena as random processes, assuming we can specify probability distributions even when individual outcomes are unpredictable. This assumption underlies most statistical inference.</p>
</section>
<section id="quantum-mechanics-and-fundamental-randomness" class="level3">
<h3 class="anchored" data-anchor-id="quantum-mechanics-and-fundamental-randomness">Quantum Mechanics and Fundamental Randomness</h3>
<p>In the Copenhagen interpretation, randomness is <strong>fundamental (ontological)</strong>: a <strong>single</strong> outcome cannot be predicted, but the <strong>probability distribution</strong> is given by the Born rule:</p>
<p><span class="math display">P(\text{outcome}) \propto \lvert \psi \rvert^{2}</span></p>
<p>This represents true randomness at the most basic level of nature, not just our ignorance of determining factors.</p>
<hr>
</section>
</section>
<section id="inferential-statistics-from-samples-to-populations" class="level2" data-number="1.15">
<h2 data-number="1.15" class="anchored" data-anchor-id="inferential-statistics-from-samples-to-populations"><span class="header-section-number">1.15</span> Inferential Statistics: From Samples to Populations</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Fundamental Principle</strong>: Statistics does not eliminate uncertainty—it helps us measure, manage, and communicate it effectively.</p>
</div>
</div>
<section id="the-central-challenge" class="level3">
<h3 class="anchored" data-anchor-id="the-central-challenge">The Central Challenge</h3>
<p><strong>Research Question</strong>: What proportion of students support keeping the library open 24/7?</p>
<p><strong>The Challenge</strong>:</p>
<ul>
<li>Population: 20,000 students at the university</li>
<li>Practical constraint: Can only survey 100 students<br>
</li>
<li>Problem: Different samples will yield different results</li>
</ul>
<p><strong>Without Statistical Thinking</strong>: “60 out of 100 students said yes, therefore exactly 60% support it.”</p>
<p><strong>With Statistical Thinking</strong>: “We estimate 60% support with a margin of error of ±10%. We can be reasonably confident the true support lies between 50% and 70%.”</p>
<p>The difference is <strong>acknowledging and quantifying uncertainty</strong> rather than pretending it doesn’t exist.</p>
</section>
<section id="a-cautionary-tale-when-big-data-goes-wrong" class="level3">
<h3 class="anchored" data-anchor-id="a-cautionary-tale-when-big-data-goes-wrong">A Cautionary Tale: When Big Data Goes Wrong</h3>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Historical Example: The 1936 Literary Digest Poll
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Literary Digest conducted one of the largest polls in history with <strong>2.4 million responses</strong>, predicting Alf Landon would defeat Franklin D. Roosevelt in the 1936 presidential election. Despite the massive sample size:</p>
<p><strong>Prediction</strong>: Landon 57%, Roosevelt 43%<br>
<strong>Actual Result</strong>: Roosevelt 62%, Landon 38%<br>
<strong>Error</strong>: 25 percentage points!</p>
<p><strong>What went wrong?</strong> The poll suffered from systematic bias:</p>
<p><strong>Selection bias in sampling frame</strong>:</p>
<ul>
<li>Sources: telephone directories, automobile registrations, club memberships</li>
<li>Problem: In 1936, these sources overrepresented wealthy Americans who favored Landon</li>
<li>Result: The sample systematically excluded Roosevelt supporters</li>
</ul>
<p><strong>Non-response bias</strong>:</p>
<ul>
<li>Only 24% of those contacted responded</li>
<li>Likely respondents: those with strong anti-Roosevelt opinions</li>
<li>Non-respondents: many Roosevelt supporters didn’t feel compelled to participate</li>
</ul>
<p><strong>Key Lessons</strong>:</p>
<ol type="1">
<li><strong>A large biased sample is worse than a small representative sample</strong></li>
<li><strong>Standard errors only measure random error, not bias</strong><br>
</li>
<li><strong>Sample size cannot fix fundamental sampling problems</strong></li>
<li><strong>Representative sampling matters more than sample size</strong></li>
</ol>
<p>This disaster led to major improvements in polling methodology, including the development of probability sampling and response rate tracking.</p>
</div>
</div>
</section>
<section id="from-error-to-understanding-modern-polling" class="level3">
<h3 class="anchored" data-anchor-id="from-error-to-understanding-modern-polling">From Error to Understanding: Modern Polling</h3>
<p>Today’s polls, while much smaller than the Literary Digest’s 2.4 million responses, are far more accurate because they focus on:</p>
<p><strong>Representative sampling</strong>: Using probability-based methods to ensure all groups have known chances of selection</p>
<p><strong>Bias detection and correction</strong>: Monitoring response rates across demographics and adjusting for known biases</p>
<p><strong>Uncertainty quantification</strong>: Reporting margins of error that honestly communicate the limits of what we know</p>
<p><strong>Example</strong>: A modern poll of 1,000 randomly selected voters with a 3% margin of error is far more reliable than the Literary Digest’s massive but biased survey.</p>
</section>
<section id="the-statistical-mindset" class="level3">
<h3 class="anchored" data-anchor-id="the-statistical-mindset">The Statistical Mindset</h3>
<p>Statistical thinking transforms how we approach uncertainty:</p>
<p><strong>Before</strong>: “This sample gives us the answer”<br>
<strong>After</strong>: “This sample gives us evidence, with known limitations”</p>
<p><strong>Before</strong>: “Larger samples are always better”<br>
<strong>After</strong>: “Representative samples with quantified uncertainty are better”</p>
<p><strong>Before</strong>: “We either know something or we don’t”<br>
<strong>After</strong>: “We know things with varying degrees of confidence”</p>
<p>This mindset is essential not just for conducting research, but for being an informed consumer of statistics in news, policy debates, and everyday decisions.</p>
<hr>
<p><strong>Research Question:</strong> What proportion of students support keeping the library open 24/7?</p>
<p><strong>The Challenge:</strong> - Population: 20,000 students at the university - Practical constraint: Can only survey 100 students - Problem: Different samples will yield different results</p>
<p><strong>Without Statistical Thinking:</strong> “60 out of 100 students said yes, therefore 60% support it.”</p>
<p><strong>With Statistical Thinking:</strong> “We estimate 60% support with a margin of error of ±10%. We can be reasonably confident the true support lies between 50% and 70%.”</p>
<hr>
</section>
</section>
<section id="core-concepts-of-statistical-inference" class="level2" data-number="1.16">
<h2 data-number="1.16" class="anchored" data-anchor-id="core-concepts-of-statistical-inference"><span class="header-section-number">1.16</span> Core Concepts of Statistical Inference</h2>
</section>
<section id="essential-terminology" class="level2" data-number="1.17">
<h2 data-number="1.17" class="anchored" data-anchor-id="essential-terminology"><span class="header-section-number">1.17</span> Essential Terminology</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Concepts
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Point estimate</strong>: The single value calculated from sample data (e.g., <span class="math inline">\hat{p} = 0.60</span>)</p>
<p><strong>Standard error (SE)</strong>: Typical variability in the estimate across repeated samples</p>
<p><strong>Margin of error</strong>: Range added around point estimate to account for sampling uncertainty</p>
<p><strong>Confidence interval</strong>: Point estimate ± margin of error (e.g., 60% ± 3%)</p>
</div>
</div>
<p>When 60 out of 100 surveyed students support a proposal, <span class="math inline">\hat{p} = 0.60</span> is your <strong>point estimate</strong>—the best single approximation of the population parameter from your sample.</p>
</section>
<section id="sample-size-and-precision" class="level2" data-number="1.18">
<h2 data-number="1.18" class="anchored" data-anchor-id="sample-size-and-precision"><span class="header-section-number">1.18</span> Sample Size and Precision</h2>
<p>Sample size directly controls estimate precision. For binary outcomes near 50% with simple random sampling:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Sample Size</th>
<th>Margin of Error (95%)</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n = 100</td>
<td>± 10%</td>
<td>Broad direction only</td>
</tr>
<tr class="even">
<td>n = 400</td>
<td>± 5%</td>
<td>General trends</td>
</tr>
<tr class="odd">
<td>n = 1,000</td>
<td>± 3%</td>
<td>Actionable precision</td>
</tr>
<tr class="even">
<td>n = 2,500</td>
<td>± 2%</td>
<td>High precision</td>
</tr>
<tr class="odd">
<td>n = 10,000</td>
<td>± 1%</td>
<td>Very high precision</td>
</tr>
</tbody>
</table>
<p><strong>Key insight</strong>: To halve the margin of error, you need <strong>four times</strong> the sample size (law of diminishing returns).</p>
<p><strong>Mathematical basis</strong>: Since <span class="math inline">\text{MoE} \propto \frac{1}{\sqrt{n}}</span>, precision improvements require quadratic increases in sample size.</p>
</section>
<section id="understanding-confidence-intervals" class="level2" data-number="1.19">
<h2 data-number="1.19" class="anchored" data-anchor-id="understanding-confidence-intervals"><span class="header-section-number">1.19</span> Understanding Confidence Intervals</h2>
<section id="what-95-confidence-means" class="level3">
<h3 class="anchored" data-anchor-id="what-95-confidence-means">What 95% Confidence Means</h3>
<p>Imagine repeating your study 100 times with different random samples. Each produces a confidence interval around its point estimate. <strong>Approximately 95 of those 100 intervals would contain the true population parameter.</strong></p>
<p>The 95% describes the <strong>reliability of the method</strong>, not the probability for any specific interval.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Common Misinterpretation
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Incorrect</strong>: “There’s a 95% chance the true value is between 57% and 63%”</p>
<p><strong>Correct</strong>: “Using this method repeatedly, 95% of such intervals would contain the true value”</p>
</div>
</div>
</section>
<section id="confidence-precision-trade-off" class="level3">
<h3 class="anchored" data-anchor-id="confidence-precision-trade-off">Confidence-Precision Trade-off</h3>
<p>Higher confidence requires wider intervals:</p>
<ul>
<li><strong>90% confidence</strong>: ±2% (narrower, less certain)</li>
<li><strong>95% confidence</strong>: ±3% (standard choice)<br>
</li>
<li><strong>99% confidence</strong>: ±5% (wider, more certain)</li>
</ul>
</section>
</section>
<section id="practical-example-library-hours-survey" class="level2" data-number="1.20">
<h2 data-number="1.20" class="anchored" data-anchor-id="practical-example-library-hours-survey"><span class="header-section-number">1.20</span> Practical Example: Library Hours Survey</h2>
<p><strong>Research question</strong>: What percentage of students support extending library hours?</p>
<section id="three-sample-sizes-same-result-60-support" class="level3">
<h3 class="anchored" data-anchor-id="three-sample-sizes-same-result-60-support">Three Sample Sizes, Same Result (60% support)</h3>
<p><strong>Small sample (n = 100)</strong> - <strong>95% CI</strong>: 50% to 70% (±10%) - <strong>Interpretation</strong>: General direction clear, but too imprecise for policy decisions</p>
<p><strong>Moderate sample (n = 400)</strong><br>
- <strong>95% CI</strong>: 55% to 65% (±5%) - <strong>Interpretation</strong>: Adequate for understanding broad support levels</p>
<p><strong>Large sample (n = 1,000)</strong> - <strong>95% CI</strong>: 57% to 63% (±3%)<br>
- <strong>Interpretation</strong>: Actionable precision for implementation decisions</p>
</section>
</section>
<section id="critical-limitations" class="level2" data-number="1.21">
<h2 data-number="1.21" class="anchored" data-anchor-id="critical-limitations"><span class="header-section-number">1.21</span> Critical Limitations</h2>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What Margin of Error Does NOT Cover
</div>
</div>
<div class="callout-body-container callout-body">
<p>Margin of error quantifies only <strong>random sampling variation</strong>. It does NOT account for:</p>
<ul>
<li><strong>Selection bias</strong>: Unrepresentative samples</li>
<li><strong>Non-response bias</strong>: Systematic differences between respondents and non-respondents</li>
<li><strong>Question wording effects</strong>: Leading or confusing questions</li>
<li><strong>Social desirability bias</strong>: Socially acceptable responses</li>
<li><strong>Coverage error</strong>: Missing population segments</li>
</ul>
<p><strong>These systematic errors can exceed ±3% by substantial margins.</strong></p>
</div>
</div>
<section id="when-standard-calculations-dont-apply" class="level3">
<h3 class="anchored" data-anchor-id="when-standard-calculations-dont-apply">When Standard Calculations Don’t Apply</h3>
<p><strong>Avoid traditional margins of error with</strong>: - Non-probability samples (convenience, volunteer surveys) - Heavy statistical weighting - Very low response rates - Complex survey designs without proper adjustments</p>
</section>
</section>
<section id="best-practices" class="level2" data-number="1.22">
<h2 data-number="1.22" class="anchored" data-anchor-id="best-practices"><span class="header-section-number">1.22</span> Best Practices</h2>
<section id="essential-reporting-elements" class="level3">
<h3 class="anchored" data-anchor-id="essential-reporting-elements">Essential Reporting Elements</h3>
<ol type="1">
<li><strong>Complete uncertainty</strong>: Always report confidence intervals, never just point estimates</li>
<li><strong>Methodology transparency</strong>: Acknowledge design features affecting precision</li>
<li><strong>Appropriate claims</strong>: Match precision claims to actual methodology</li>
</ol>
</section>
<section id="interpretation-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="interpretation-guidelines">Interpretation Guidelines</h3>
<p><strong>Do</strong>: - Treat small differences within the margin of error as potentially due to sampling variation - Consider systematic error sources beyond sampling - Report effective sample sizes when design complexity reduces precision</p>
<p><strong>Don’t</strong>: - Over-interpret differences smaller than the margin of error - Claim traditional margins of error for non-probability samples - Ignore substantial non-response or coverage issues</p>
</section>
</section>
<section id="mathematical-foundations" class="level2" data-number="1.23">
<h2 data-number="1.23" class="anchored" data-anchor-id="mathematical-foundations"><span class="header-section-number">1.23</span> Mathematical Foundations</h2>
<section id="standard-formulas" class="level3">
<h3 class="anchored" data-anchor-id="standard-formulas">Standard Formulas</h3>
<p><strong>Margin of error relationship</strong>: <span class="math inline">\text{MoE} \approx 2 \times \text{SE}</span> (for 95% confidence)</p>
<p><strong>Standard errors</strong>: - Proportion: <span class="math inline">\text{SE}(\hat{p}) = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</span> - Mean: <span class="math inline">\text{SE}(\bar{x}) = \frac{s}{\sqrt{n}}</span></p>
<p><strong>Rule of thumb</strong>: For proportions near 50%, <span class="math inline">\text{MoE} \approx \frac{1}{\sqrt{n}}</span></p>
</section>
<section id="the-1.96-multiplier" class="level3">
<h3 class="anchored" data-anchor-id="the-1.96-multiplier">The 1.96 Multiplier</h3>
<p>For 95% confidence intervals, we multiply the standard error by 1.96. This value ensures that if you repeated the process many times, approximately 95% of your calculated intervals would contain the true population parameter.</p>
</section>
</section>
<section id="summary" class="level2" data-number="1.24">
<h2 data-number="1.24" class="anchored" data-anchor-id="summary"><span class="header-section-number">1.24</span> Summary</h2>
<p><strong>Margin of error</strong> quantifies uncertainty from studying a sample rather than the entire population. <strong>Standard error</strong> measures typical sampling variability. <strong>95% confidence intervals</strong> use methods that capture the true parameter 95% of the time across repeated applications.</p>
<p><strong>Key insight</strong>: These measures help distinguish meaningful differences from sampling noise, but remember they address only one source of uncertainty—random sampling variation.</p>
<hr>
</section>
<section id="visualizing-sampling-variability" class="level2" data-number="1.25">
<h2 data-number="1.25" class="anchored" data-anchor-id="visualizing-sampling-variability"><span class="header-section-number">1.25</span> Visualizing Sampling Variability</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>n_polls      <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>n_people     <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>true_support <span class="ot">&lt;-</span> <span class="fl">0.50</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate independent polls (binomial counts -&gt; proportions)</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>support <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_polls, n_people, true_support) <span class="sc">/</span> n_people</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Per-poll standard error for a proportion (plug-in using that poll's estimate)</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>se   <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(support <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> support) <span class="sc">/</span> n_people)</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co"># "95%" margin of error ≈ 2 × SE (plain-English multiplier, no distribution jargon)</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a>moe  <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> se</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Clamp intervals to [0, 1] to avoid plotting outside the parameter space</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a>lower <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="dv">0</span>, support <span class="sc">-</span> moe)</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>upper <span class="ot">&lt;-</span> <span class="fu">pmin</span>(<span class="dv">1</span>, support <span class="sc">+</span> moe)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Does the interval cover the true value?</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>covers <span class="ot">&lt;-</span> (lower <span class="sc">&lt;=</span> true_support) <span class="sc">&amp;</span> (upper <span class="sc">&gt;=</span> true_support)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a>n_cover <span class="ot">&lt;-</span> <span class="fu">sum</span>(covers)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a>n_miss  <span class="ot">&lt;-</span> n_polls <span class="sc">-</span> n_cover</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">poll =</span> <span class="fu">seq_len</span>(n_polls),</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>  support, se, moe, lower, upper, covers</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(results, <span class="fu">aes</span>(<span class="at">x =</span> poll, <span class="at">y =</span> support, <span class="at">color =</span> covers)) <span class="sc">+</span></span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper), <span class="at">width =</span> <span class="fl">0.3</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> true_support, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"TRUE"</span> <span class="ot">=</span> <span class="st">"forestgreen"</span>, <span class="st">"FALSE"</span> <span class="ot">=</span> <span class="st">"darkorange"</span>),</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"TRUE"</span> <span class="ot">=</span> <span class="st">"Covers truth"</span>, <span class="st">"FALSE"</span> <span class="ot">=</span> <span class="st">"Misses truth"</span>),</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">name   =</span> <span class="cn">NULL</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">title    =</span> <span class="st">"Sampling Variability in 20 Independent Polls"</span>,</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">paste0</span>(</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a>      <span class="st">"Each poll surveys "</span>, n_people, <span class="st">" different people.  Truth = "</span>,</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a>      scales<span class="sc">::</span><span class="fu">percent</span>(true_support),</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a>      <span class="st">". Intervals covering truth: "</span>, n_cover, <span class="st">"/"</span>, n_polls,</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a>      <span class="st">" ("</span>, <span class="fu">round</span>(<span class="dv">100</span> <span class="sc">*</span> n_cover <span class="sc">/</span> n_polls), <span class="st">"%)."</span></span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Poll Number"</span>,</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Estimated Proportion"</span></span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">13</span>) <span class="sc">+</span></span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Key observation</strong>: Each sample yields a different result, but most estimates—and their intervals—cluster around the true value; a few “miss” purely due to the randomness of sampling.</p>
<hr>
</section>
<section id="statistical-errors-a-simple-guide" class="level2" data-number="1.26">
<h2 data-number="1.26" class="anchored" data-anchor-id="statistical-errors-a-simple-guide"><span class="header-section-number">1.26</span> Statistical Errors: A Simple Guide</h2>
<section id="why-this-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-this-matters">Why this matters</h3>
<p>Knowing where error comes from helps you:</p>
<ul>
<li><strong>Design</strong> better studies and measurements</li>
<li><strong>Interpret</strong> estimates correctly</li>
<li><strong>Report</strong> honest limitations</li>
</ul>
<hr>
</section>
</section>
<section id="two-big-families-of-error" class="level2" data-number="1.27">
<h2 data-number="1.27" class="anchored" data-anchor-id="two-big-families-of-error"><span class="header-section-number">1.27</span> Two Big Families of Error</h2>
<section id="random-error-samplingestimation-variability" class="level3">
<h3 class="anchored" data-anchor-id="random-error-samplingestimation-variability">1) Random Error (Sampling/Estimation Variability)</h3>
<p>Unpredictable ups and downs caused by chance (e.g., which people were sampled, day-to-day noise).</p>
<ul>
<li><strong>Quantifiable</strong> by statistical theory (e.g., <em>standard error</em> <strong>SE</strong>, <em>confidence interval</em> <strong>CI</strong>, <em>margin of error</em> <strong>MoE</strong>)</li>
<li><strong>Decreases</strong> with larger sample size <span class="math inline">n</span></li>
<li><strong>Address</strong> by increasing <span class="math inline">n</span>, using efficient estimators, and sound designs</li>
</ul>
</section>
<section id="systematic-error-bias" class="level3">
<h3 class="anchored" data-anchor-id="systematic-error-bias">2) Systematic Error (Bias)</h3>
<p>A consistent shift away from the truth due to design or measurement problems.</p>
<ul>
<li><strong>Not</strong> fixed by larger <span class="math inline">n</span></li>
<li>Often <strong>hard to quantify</strong> with simple formulas</li>
<li><strong>Address</strong> by improving design, measurement, and data collection</li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Key idea:</strong> A large <strong>biased</strong> sample gives a <strong>precisely wrong</strong> answer. Increase <span class="math inline">n</span> to reduce <strong>random error</strong>; improve design/measurement to reduce <strong>bias</strong>.</p>
</div>
</div>
<hr>
</section>
</section>
<section id="biasvariance-mse-decomposition" class="level2" data-number="1.28">
<h2 data-number="1.28" class="anchored" data-anchor-id="biasvariance-mse-decomposition"><span class="header-section-number">1.28</span> Bias–Variance (MSE) Decomposition</h2>
<p>For an estimator <span class="math inline">\hat\theta</span>:</p>
<p><span class="math display">
\mathrm{MSE}(\hat\theta) \;=\; \underbrace{\mathrm{Var}(\hat\theta)}_{\text{random error}} \;+\; \underbrace{\big(\mathrm{Bias}(\hat\theta)\big)^2}_{\text{systematic error}}.
</span></p>
<ul>
<li><strong>Variance</strong>: How much the estimate would bounce around if you repeated the study many times (random error).</li>
<li><strong>Bias</strong>: How far the average estimate is from the truth (systematic error).</li>
<li><strong>Goal</strong>: Keep <strong>both</strong> small. More data lowers variance; better design lowers bias.</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>For <strong>prediction</strong>, a tiny amount of bias can sometimes reduce variance enough to lower overall <strong>MSE</strong> (mean squared error). For <strong>causal questions</strong>, uncontrolled bias is usually unacceptable.</p>
</div>
</div>
<hr>
</section>
<section id="common-sources-of-bias-across-many-study-types" class="level2" data-number="1.29">
<h2 data-number="1.29" class="anchored" data-anchor-id="common-sources-of-bias-across-many-study-types"><span class="header-section-number">1.29</span> Common Sources of Bias (Across Many Study Types)</h2>
<ol type="1">
<li><p><strong>Selection Bias</strong> Sample/data do not represent the target group. <em>Mitigation:</em> Define the target population clearly; use probability sampling where possible; use credible reweighting.</p></li>
<li><p><strong>Nonresponse / Attrition Bias</strong> Some types of participants are more likely to be missing or to drop out. <em>Mitigation:</em> Reduce burden (shorter instruments), send reminders, offer small incentives; report who is missing and why.</p></li>
<li><p><strong>Measurement Bias</strong> Systematic distortion in how variables are measured (miscalibrated device, leading wording, consistent misclassification). <em>Mitigation:</em> Calibrate instruments, pilot and neutralize questions, use validated scales, blind assessors where possible.</p></li>
<li><p><strong>Design / Causal Bias</strong> Confounding or bad conditioning (e.g., controlling for a mediator). <em>Mitigation:</em> Randomize when feasible; pre-specify plans; use design tools and careful variable selection.</p></li>
<li><p><strong>Model / Specification Bias</strong> Wrong functional form or missing key interactions; extrapolating beyond the data. <em>Mitigation:</em> Inspect relationships; try reasonable alternatives; check predictions on new data.</p></li>
<li><p><strong>Overfitting and Data Leakage</strong> Great in-sample fit that fails on new data; accidental sharing of information between training and testing. <em>Mitigation:</em> Keep a true test set; use cross-validation; lock down preprocessing steps.</p></li>
<li><p><strong>Processing / Pipeline Errors</strong> Coding mistakes, merge issues, unit conversion errors. <em>Mitigation:</em> Reproducible scripts, checks and audits, version control.</p></li>
</ol>
<hr>
</section>
<section id="interpreting-precision-without-extra-formulas" class="level2" data-number="1.30">
<h2 data-number="1.30" class="anchored" data-anchor-id="interpreting-precision-without-extra-formulas"><span class="header-section-number">1.30</span> Interpreting Precision (without extra formulas)</h2>
<ul>
<li><strong>Standard Error (SE):</strong> Average estimation noise due to sampling. Smaller SE means more precise estimates.</li>
<li><strong>Confidence Interval (CI):</strong> A range that aims to capture the true value with a stated confidence level (e.g., 95%).</li>
<li><strong>Margin of Error (MoE):</strong> A common shorthand for how wide the CI is in simple settings.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Increasing <span class="math inline">n</span> narrows <strong>SE</strong>, <strong>CI</strong>, and <strong>MoE</strong>. It does <strong>not</strong> remove <strong>bias</strong>.</p>
</div>
</div>
<hr>
</section>
<section id="hypothesis-tests-two-kinds-of-mistakes" class="level2" data-number="1.31">
<h2 data-number="1.31" class="anchored" data-anchor-id="hypothesis-tests-two-kinds-of-mistakes"><span class="header-section-number">1.31</span> Hypothesis Tests: Two Kinds of Mistakes</h2>
<ul>
<li><strong>Type I Error (False Positive):</strong> Concluding there is an effect when there is none. The preset risk of this is the <strong>significance level</strong> (often 5%).</li>
<li><strong>Type II Error (False Negative):</strong> Missing a real effect. <strong>Power</strong> is the chance to detect a real effect (higher power is better).</li>
</ul>
<p><strong>Multiple comparisons:</strong> Testing many hypotheses inflates false positives. Consider controlling the <strong>false discovery rate (FDR)</strong>—the expected proportion of false “discoveries” among all claimed findings.</p>
<hr>
</section>
<section id="quick-practices-that-help" class="level2" data-number="1.32">
<h2 data-number="1.32" class="anchored" data-anchor-id="quick-practices-that-help"><span class="header-section-number">1.32</span> Quick Practices That Help</h2>
<ul>
<li><strong>Before collecting data:</strong> define the target population, outcomes, and main comparisons; pilot your measurements.</li>
<li><strong>During data collection:</strong> minimize burden, keep wording neutral, record response/attrition patterns.</li>
<li><strong>During analysis:</strong> check simple diagnostics, try reasonable alternative specifications, guard against overfitting/leakage.</li>
<li><strong>When reporting:</strong> describe data origins, missingness, uncertainty (SE/CI/MoE), and the <em>likely direction</em> of any remaining bias.</li>
</ul>
<hr>
</section>
<section id="one-minute-checklist" class="level2" data-number="1.33">
<h2 data-number="1.33" class="anchored" data-anchor-id="one-minute-checklist"><span class="header-section-number">1.33</span> One-Minute Checklist</h2>
<ul>
<li><strong>Bias:</strong> Any likely selection, measurement, or design issue?</li>
<li><strong>Variance:</strong> Is the sample size reasonable for the question?</li>
<li><strong>Model:</strong> Could a simpler or alternative model change conclusions?</li>
<li><strong>Validation:</strong> Does it work on new or held-out data?</li>
<li><strong>Transparency:</strong> Did you state assumptions, limitations, and likely bias direction?</li>
</ul>
<hr>
</section>
<section id="glossary-acronyms-spelled-out" class="level2" data-number="1.34">
<h2 data-number="1.34" class="anchored" data-anchor-id="glossary-acronyms-spelled-out"><span class="header-section-number">1.34</span> Glossary (acronyms spelled out)</h2>
<ul>
<li><strong>SE — Standard Error:</strong> Average sampling noise in an estimator.</li>
<li><strong>CI — Confidence Interval:</strong> Interval aiming to include the true value with a chosen confidence level.</li>
<li><strong>MoE — Margin of Error:</strong> A simple width measure for uncertainty in some settings.</li>
<li><strong>MSE — Mean Squared Error:</strong> Variance + Bias² (overall estimation error).</li>
<li><strong>FDR — False Discovery Rate:</strong> Expected share of false positives among all claimed findings.</li>
</ul>
<hr>
</section>
<section id="population-sample-and-superpopulation-foundations-of-statistical-inference" class="level2" data-number="1.35">
<h2 data-number="1.35" class="anchored" data-anchor-id="population-sample-and-superpopulation-foundations-of-statistical-inference"><span class="header-section-number">1.35</span> Population, Sample, and Superpopulation: Foundations of Statistical Inference</h2>
<p>In political science and economics, researchers seek to understand entire <strong>populations</strong>—the complete set of units they wish to study. However, examining entire populations is typically impossible, impractical, or unnecessary. Statistical methods enable us to learn about populations through carefully selected <strong>samples</strong>.</p>
<hr>
</section>
<section id="defining-populations-in-political-science-and-economics" class="level2" data-number="1.36">
<h2 data-number="1.36" class="anchored" data-anchor-id="defining-populations-in-political-science-and-economics"><span class="header-section-number">1.36</span> Defining Populations in Political Science and Economics</h2>
<p>A <strong>population</strong> in social science research encompasses various types of analytical units, depending on the research question:</p>
<section id="individual-level-populations" class="level3">
<h3 class="anchored" data-anchor-id="individual-level-populations">Individual-Level Populations</h3>
<p><strong>Population</strong>: All 240 million American adults<br>
<strong>Sample</strong>: 1,000 randomly selected adults in a national survey<br>
<strong>Research question</strong>: What percentage support universal healthcare policy?</p>
<p><strong>Population</strong>: All registered voters in Canada<br>
<strong>Sample</strong>: 2,500 randomly selected registered voters<br>
<strong>Research question</strong>: How do economic perceptions influence voting intentions?</p>
</section>
<section id="country-level-analysis" class="level3">
<h3 class="anchored" data-anchor-id="country-level-analysis">Country-Level Analysis</h3>
<p><strong>Population</strong>: All 195 sovereign nations worldwide<br>
<strong>Sample</strong>: 50 countries representing different regions and development levels<br>
<strong>Research question</strong>: Does democratic governance correlate with economic growth rates?</p>
</section>
<section id="subnational-government-units" class="level3">
<h3 class="anchored" data-anchor-id="subnational-government-units">Subnational Government Units</h3>
<p><strong>Population</strong>: All 3,143 counties in the United States<br>
<strong>Sample</strong>: 200 randomly selected counties from diverse demographic profiles<br>
<strong>Research question</strong>: How does local unemployment affect crime rates?</p>
<p><strong>Population</strong>: All municipalities in Poland<br>
<strong>Sample</strong>: 250 randomly selected municipalities<br>
<strong>Research question</strong>: What factors predict local government efficiency?</p>
</section>
<section id="organizational-analysis" class="level3">
<h3 class="anchored" data-anchor-id="organizational-analysis">Organizational Analysis</h3>
<p><strong>Population</strong>: All NGOs registered with the United Nations<br>
<strong>Sample</strong>: 100 NGOs operating across different policy domains<br>
<strong>Research question</strong>: What organizational characteristics predict NGO effectiveness?</p>
</section>
<section id="temporal-and-event-based-populations" class="level3">
<h3 class="anchored" data-anchor-id="temporal-and-event-based-populations">Temporal and Event-Based Populations</h3>
<p><strong>Population</strong>: All national elections held in European democracies since 1945<br>
<strong>Sample</strong>: 300 elections spanning different countries and decades<br>
<strong>Research question</strong>: How do economic conditions affect incumbent vote share?</p>
<p><strong>Population</strong>: All legislative bills introduced in the U.S. Congress from 2000–2020<br>
<strong>Sample</strong>: 500 randomly selected bills across policy areas<br>
<strong>Research question</strong>: What factors predict whether a bill becomes law?</p>
<hr>
</section>
</section>
<section id="the-logic-of-statistical-inference-from-sample-to-population" class="level2" data-number="1.37">
<h2 data-number="1.37" class="anchored" data-anchor-id="the-logic-of-statistical-inference-from-sample-to-population"><span class="header-section-number">1.37</span> The Logic of Statistical Inference: From Sample to Population</h2>
<p>A <strong>sample</strong> represents a subset of the population that researchers actually observe and measure. The fundamental insight of statistical inference is that we can learn about population characteristics by studying samples—provided we select them carefully.</p>
<p>The inferential process follows this logical structure:</p>
<p><span class="math display">\text{Sample Statistic} \xrightarrow{\text{Statistical Inference}} \text{Population Parameter}</span></p>
<p><strong>Example</strong>: If 52% of survey respondents support Candidate A (<span class="math inline">\hat{p} = 0.52</span>), what can we conclude about support levels in the entire voting population (<span class="math inline">\pi</span>)?</p>
<p><strong>The key principle</strong>: <strong>Random selection</strong> ensures that every unit in the population has an equal probability of inclusion, thereby preventing systematic bias in sample composition.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Essential Terminology
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Population Parameter</strong>: A numerical characteristic of the entire population (e.g., population mean <span class="math inline">\mu</span>, population proportion <span class="math inline">\pi</span>). Usually unknown and what we aim to estimate.</p>
<p><strong>Sample Statistic</strong>: A numerical value calculated from sample data (e.g., sample mean <span class="math inline">\bar{x}</span>, sample proportion <span class="math inline">\hat{p}</span>). What we actually observe and compute.</p>
<p><strong>Estimator</strong>: The method or formula used to approximate a population parameter from sample data (e.g., “calculate the sample average”).</p>
<p><strong>Estimate</strong>: The specific numerical result obtained by applying an estimator to a particular sample.</p>
</div>
</div>
<hr>
</section>
<section id="sampling-methods-and-the-representation-challenge" class="level2" data-number="1.38">
<h2 data-number="1.38" class="anchored" data-anchor-id="sampling-methods-and-the-representation-challenge"><span class="header-section-number">1.38</span> Sampling Methods and the Representation Challenge</h2>
<p>The quality of statistical inference depends critically on how we select our sample. Different sampling approaches carry distinct advantages and limitations:</p>
<section id="convenience-sampling" class="level3">
<h3 class="anchored" data-anchor-id="convenience-sampling">1. Convenience Sampling</h3>
<p><strong>Method</strong>: Surveying easily accessible units (e.g., students in your political science class)<br>
<strong>Limitation</strong>: Systematic underrepresentation of population subgroups<br>
<strong>Example problem</strong>: College students typically skew younger, more educated, and more liberal than the general electorate</p>
</section>
<section id="voluntary-response-sampling" class="level3">
<h3 class="anchored" data-anchor-id="voluntary-response-sampling">2. Voluntary Response Sampling</h3>
<p><strong>Method</strong>: Open participation surveys (e.g., online polls on news websites)<br>
<strong>Limitation</strong>: Self-selection bias—participants choose whether to respond<br>
<strong>Example problem</strong>: Individuals with strong opinions disproportionately participate, skewing results</p>
</section>
<section id="simple-random-sampling" class="level3">
<h3 class="anchored" data-anchor-id="simple-random-sampling">3. Simple Random Sampling</h3>
<p><strong>Method</strong>: Each population unit has equal probability of selection<br>
<strong>Advantage</strong>: Best theoretical foundation for representative samples<br>
<strong>Example</strong>: Randomly selected phone numbers from comprehensive databases covering all demographic groups</p>
</section>
<section id="stratified-random-sampling" class="level3">
<h3 class="anchored" data-anchor-id="stratified-random-sampling">4. Stratified Random Sampling</h3>
<p><strong>Method</strong>: Divide population into meaningful subgroups, then randomly sample within each stratum<br>
<strong>Advantage</strong>: Guarantees representation of key demographic or geographic categories<br>
<strong>Example</strong>: National survey ensuring proportional representation from each state or income bracket</p>
</section>
<section id="cluster-sampling" class="level3">
<h3 class="anchored" data-anchor-id="cluster-sampling">5. Cluster Sampling</h3>
<p><strong>Method</strong>: Randomly select groups (clusters), then survey all units within selected clusters<br>
<strong>Advantage</strong>: Cost-effective for geographically dispersed populations<br>
<strong>Example</strong>: Randomly select 50 cities nationwide, then comprehensively survey residents within those cities</p>
<hr>
</section>
</section>
<section id="understanding-parameters-statistics-and-estimates" class="level2" data-number="1.39">
<h2 data-number="1.39" class="anchored" data-anchor-id="understanding-parameters-statistics-and-estimates"><span class="header-section-number">1.39</span> Understanding Parameters, Statistics, and Estimates</h2>
<section id="the-parameter-statistic-distinction" class="level3">
<h3 class="anchored" data-anchor-id="the-parameter-statistic-distinction">The Parameter-Statistic Distinction</h3>
<p>Statistical inference rests on a fundamental distinction between what we observe and what we want to know:</p>
<p><strong>Population Parameters</strong></p>
<ul>
<li>Numerical characteristics describing the entire population</li>
<li>Typically unknown and represent our research targets</li>
<li>Denoted by Greek letters: <span class="math inline">\mu</span> (population mean), <span class="math inline">\sigma</span> (population standard deviation), <span class="math inline">\pi</span> (population proportion)</li>
<li><strong>Example</strong>: The true percentage of all eligible voters who support universal healthcare</li>
</ul>
<p><strong>Sample Statistics</strong></p>
<ul>
<li>Numerical characteristics calculated from observed sample data<br>
</li>
<li>What researchers actually measure and compute</li>
<li>Denoted by Roman letters: <span class="math inline">\bar{x}</span> (sample mean), <span class="math inline">s</span> (sample standard deviation), <span class="math inline">\hat{p}</span> (sample proportion)</li>
<li><strong>Example</strong>: The percentage of 1,000 survey respondents who express support for universal healthcare</li>
</ul>
</section>
<section id="estimators-and-estimates" class="level3">
<h3 class="anchored" data-anchor-id="estimators-and-estimates">Estimators and Estimates</h3>
<p>An <strong>estimator</strong> defines the computational method for approximating a population parameter. An <strong>estimate</strong> represents the specific numerical result obtained by applying that method to particular sample data.</p>
<p><strong>Estimator example</strong>: The sample mean formula <span class="math inline">\bar{x} = \frac{\sum_{i=1}^n x_i}{n}</span><br>
<strong>Estimate example</strong>: <span class="math inline">\bar{x} = 6.3</span> years (the actual computed value from our education data)</p>
</section>
<section id="estimands-what-exactly-are-we-trying-to-estimate" class="level3">
<h3 class="anchored" data-anchor-id="estimands-what-exactly-are-we-trying-to-estimate">Estimands: What Exactly Are We Trying to Estimate?</h3>
<p>An <strong>estimand</strong> is the specific quantity we aim to estimate—what we’re targeting with our statistical analysis. While this is often a population parameter, estimands can be more complex.</p>
<p><strong>Examples of different estimands</strong>:</p>
<p><strong>Simple parameter estimand</strong>: The population mean income (<span class="math inline">\mu</span>)<br>
<strong>Comparative estimand</strong>: The difference in mean income between two groups (<span class="math inline">\mu_1 - \mu_2</span>)<br>
<strong>Causal estimand</strong>: The average treatment effect of a job training program on earnings<br>
<strong>Conditional estimand</strong>: Expected voter turnout given specific weather conditions</p>
</section>
<section id="the-complete-framework" class="level3">
<h3 class="anchored" data-anchor-id="the-complete-framework">The Complete Framework</h3>
<p>Understanding statistical inference requires distinguishing between these related but distinct concepts:</p>
<ul>
<li><strong>Population Parameter</strong>: The true characteristic of the population (e.g., <span class="math inline">\mu</span>)</li>
<li><strong>Estimand</strong>: The specific quantity we want to estimate (often, but not always, a parameter)</li>
<li><strong>Estimator</strong>: The method for computing our estimate (e.g., sample mean)<br>
</li>
<li><strong>Estimate</strong>: The actual number we calculate from our data</li>
</ul>
<p><strong>Example in context</strong>:</p>
<ul>
<li><strong>Parameter</strong>: True mean voter turnout in all elections (<span class="math inline">\mu</span>)</li>
<li><strong>Estimand</strong>: Expected turnout difference between rainy vs.&nbsp;sunny election days (<span class="math inline">\mu_{\text{rainy}} - \mu_{\text{sunny}}</span>)</li>
<li><strong>Estimator</strong>: Difference between sample means from rainy and sunny elections</li>
<li><strong>Estimate</strong>: 3.2 percentage points lower turnout on rainy days</li>
</ul>
<p>This framework helps clarify exactly what question we’re answering and ensures our methods align with our research goals.</p>
<hr>
</section>
</section>
<section id="understanding-sampling-variability-through-simulation" class="level2" data-number="1.40">
<h2 data-number="1.40" class="anchored" data-anchor-id="understanding-sampling-variability-through-simulation"><span class="header-section-number">1.40</span> Understanding Sampling Variability Through Simulation</h2>
<p>The inherent uncertainty in statistical inference arises because different samples from the same population produce different results. We can illustrate this concept through simulation:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate sampling variability in polling</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Assume true population support is 60%</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>p_true <span class="ot">&lt;-</span> <span class="fl">0.60</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>n_per_poll <span class="ot">&lt;-</span> <span class="dv">1000</span>    <span class="co"># Sample size per poll</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>n_polls <span class="ot">&lt;-</span> <span class="dv">2000</span>       <span class="co"># Number of simulated polls</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate 2000 different polls, each with 1000 respondents</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>poll_results <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_polls, <span class="at">size =</span> n_per_poll, <span class="at">prob =</span> p_true) <span class="sc">/</span> n_per_poll</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate sampling variability</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>sampling_se <span class="ot">&lt;-</span> <span class="fu">sd</span>(poll_results)</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>poll_range <span class="ot">&lt;-</span> <span class="fu">quantile</span>(poll_results, <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize the distribution of poll results</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>poll_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">poll_number =</span> <span class="dv">1</span><span class="sc">:</span>n_polls,</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">support_percentage =</span> poll_results <span class="sc">*</span> <span class="dv">100</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(poll_data, <span class="fu">aes</span>(<span class="at">x =</span> support_percentage)) <span class="sc">+</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">50</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">fill =</span> <span class="st">"steelblue"</span>) <span class="sc">+</span></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> p_true <span class="sc">*</span> <span class="dv">100</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> poll_range <span class="sc">*</span> <span class="dv">100</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Distribution of Poll Results from 2,000 Simulated Polls"</span>,</span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">"Each poll surveys 1,000 people from population with 60% true support"</span>),</span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Observed support percentage in poll (%)"</span>,</span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Number of polls"</span>,</span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="fu">paste</span>(<span class="st">"Standard error:"</span>, <span class="fu">round</span>(sampling_se <span class="sc">*</span> <span class="dv">100</span>, <span class="dv">1</span>), <span class="st">"%</span><span class="sc">\n</span><span class="st">95% of polls fall between"</span>, </span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">round</span>(poll_range[<span class="dv">1</span>] <span class="sc">*</span> <span class="dv">100</span>, <span class="dv">1</span>), <span class="st">"% and"</span>, <span class="fu">round</span>(poll_range[<span class="dv">2</span>] <span class="sc">*</span> <span class="dv">100</span>, <span class="dv">1</span>), <span class="st">"%"</span>)</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/sampling-variability-demo-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Sampling variability (standard error):"</span>, <span class="fu">round</span>(sampling_se <span class="sc">*</span> <span class="dv">100</span>, <span class="dv">2</span>), <span class="st">"%</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sampling variability (standard error): 1.54 %</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"95% of poll results fall between:"</span>, <span class="fu">round</span>(poll_range[<span class="dv">1</span>] <span class="sc">*</span> <span class="dv">100</span>, <span class="dv">1</span>), <span class="st">"% and"</span>, <span class="fu">round</span>(poll_range[<span class="dv">2</span>] <span class="sc">*</span> <span class="dv">100</span>, <span class="dv">1</span>), <span class="st">"%"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>95% of poll results fall between: 57 % and 62.9 %</code></pre>
</div>
</div>
<p><strong>Key insight</strong>: Even when population characteristics remain constant, repeated sampling produces varying results. This <strong>sampling variability</strong> constitutes the primary source of uncertainty that statistical inference must address and quantify.</p>
<hr>
</section>
<section id="beyond-simple-population-sample-models-superpopulations" class="level2" data-number="1.41">
<h2 data-number="1.41" class="anchored" data-anchor-id="beyond-simple-population-sample-models-superpopulations"><span class="header-section-number">1.41</span> Beyond Simple Population-Sample Models: Superpopulations</h2>
<section id="when-we-observe-complete-populations" class="level3">
<h3 class="anchored" data-anchor-id="when-we-observe-complete-populations">When We Observe Complete Populations</h3>
<p>Researchers sometimes access entire populations within specific contexts:</p>
<ul>
<li>National census data covering all residents</li>
<li>Complete records of all stock transactions in 2024<br>
</li>
<li>Comprehensive hospital admission data for 2023</li>
<li>All municipalities in Poland with their characteristics in 2024</li>
</ul>
<p><strong>Question</strong>: If we can compute exact population parameters for 2024, why discuss uncertainty?</p>
<p><strong>Answer</strong>: We typically seek to understand underlying <strong>processes</strong>, not merely describe single time periods.</p>
</section>
<section id="the-superpopulation-concept" class="level3">
<h3 class="anchored" data-anchor-id="the-superpopulation-concept">The Superpopulation Concept</h3>
<p>The <strong>superpopulation</strong> or <strong>Data Generating Process (DGP)</strong> represents the conceptual mechanism that produces observed data—an ongoing process that could generate different outcomes under slightly altered conditions.</p>
<p>Instead of thinking only:</p>
<pre><code>Population → Sample</code></pre>
<p>We often conceptualize:</p>
<pre><code>SUPERPOPULATION (underlying process)
    ↓
[Data-generating mechanism operating under specific conditions]
    ↓
OBSERVED POPULATION (particular year/context)
    ↓
[Statistical analysis and interpretation]
    ↓
INSIGHTS about the general process</code></pre>
<section id="applied-examples" class="level4">
<h4 class="anchored" data-anchor-id="applied-examples">Applied Examples</h4>
<p><strong>Electoral Behavior Analysis</strong></p>
<ul>
<li><strong>Observed data</strong>: Voter turnout across all municipalities in 2024 election</li>
<li><strong>Underlying process</strong>: How weather conditions, campaign intensity, local issues, and institutional factors generally influence participation<br>
</li>
<li><strong>Research goal</strong>: Develop generalizable understanding of turnout determinants applicable to future elections</li>
</ul>
<p><strong>Economic Performance Studies</strong></p>
<ul>
<li><strong>Observed data</strong>: All business transactions recorded in 2024</li>
<li><strong>Underlying process</strong>: How market demand, pricing strategies, promotional activities, and economic conditions interact to generate sales</li>
<li><strong>Research goal</strong>: Understand business performance drivers to inform future strategy and policy</li>
</ul>
<p><strong>Educational Effectiveness Research</strong></p>
<ul>
<li><strong>Observed data</strong>: All student grades in current semester<br>
</li>
<li><strong>Underlying process</strong>: How teaching methods, curriculum design, student preparation, and institutional support affect learning outcomes</li>
<li><strong>Research goal</strong>: Assess whether pedagogical innovations generally improve educational effectiveness</li>
</ul>
<hr>
</section>
</section>
</section>
<section id="a-practical-analogy-the-soup-tasting-approach-to-statistical-inference" class="level2" data-number="1.42">
<h2 data-number="1.42" class="anchored" data-anchor-id="a-practical-analogy-the-soup-tasting-approach-to-statistical-inference"><span class="header-section-number">1.42</span> A Practical Analogy: The Soup-Tasting Approach to Statistical Inference</h2>
<p>Consider a chef preparing soup for 100 people who needs to assess its flavor without consuming the entire batch:</p>
<p><strong>Population</strong>: The entire pot of soup (100 servings)<br>
<strong>Sample</strong>: A single spoonful for tasting<br>
<strong>Population Parameter</strong>: The true average saltiness of the complete pot (unknown)<br>
<strong>Sample Statistic</strong>: The saltiness level detected in the spoonful (observable)<br>
<strong>Statistical Inference</strong>: Using the spoonful’s characteristics to draw conclusions about the entire pot</p>
<section id="key-principles-illustrated" class="level3">
<h3 class="anchored" data-anchor-id="key-principles-illustrated">Key Principles Illustrated</h3>
<p><strong>1. Random sampling is essential</strong>: The chef must thoroughly stir the soup before sampling. Consistently sampling from the surface might miss seasoning that has settled, introducing systematic bias.</p>
<p><strong>2. Sample size affects precision</strong>: A larger spoonful provides more reliable information about overall flavor than a small sip, though practical constraints limit sample size.</p>
<p><strong>3. Uncertainty is inherent</strong>: Even with proper sampling technique, the spoonful might not perfectly represent the entire pot’s characteristics.</p>
<p><strong>4. Systematic bias undermines inference</strong>: If someone secretly adds salt only to the sampling area, conclusions about the whole pot become invalid—illustrating how sampling bias distorts statistical inference.</p>
<p><strong>5. Inference has scope limitations</strong>: The sample can estimate average saltiness but cannot reveal whether some portions are saltier than others, highlighting the limits of what samples can tell us about population variability.</p>
<p>This analogy captures the essence of statistical reasoning: using carefully selected samples to learn about larger populations while explicitly acknowledging and quantifying the inherent uncertainty in this process.</p>
<hr>
</section>
</section>
<section id="summary-framework-sources-of-uncertainty-in-statistical-inference" class="level2" data-number="1.43">
<h2 data-number="1.43" class="anchored" data-anchor-id="summary-framework-sources-of-uncertainty-in-statistical-inference"><span class="header-section-number">1.43</span> Summary Framework: Sources of Uncertainty in Statistical Inference</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 16%">
<col style="width: 21%">
<col style="width: 44%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Concept</strong></th>
<th><strong>Definition</strong></th>
<th><strong>Primary Source of Uncertainty</strong></th>
<th><strong>Example</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Sample</strong></td>
<td>Subset of population units actually observed</td>
<td><strong>Sampling variability</strong>: Different samples yield different results</td>
<td>1,000 surveyed voters from population of millions</td>
</tr>
<tr class="even">
<td><strong>Population</strong></td>
<td>Complete set of units in specific context/time</td>
<td><strong>Temporal/contextual variation</strong>: Different time periods or conditions produce different population characteristics</td>
<td>All registered voters in 2024 vs.&nbsp;2028</td>
</tr>
<tr class="odd">
<td><strong>Superpopulation (DGP)</strong></td>
<td>Underlying process generating observable data</td>
<td><strong>Model uncertainty</strong>: Our theoretical understanding may be incomplete or simplified</td>
<td>Voter behavior mechanism influenced by unobserved factors</td>
</tr>
</tbody>
</table>
<p><strong>Practical implication</strong>: Comprehensive statistical analysis acknowledges multiple sources of uncertainty, from sampling variation to model limitations, providing appropriately humble conclusions about what data can and cannot tell us.</p>
<hr>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Common Statistical Pitfalls in Political Science
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Ecological fallacy</strong>: Assuming group-level patterns apply to individuals</li>
<li><strong>Selection bias</strong>: Non-random samples that systematically exclude certain groups<br>
</li>
<li><strong>Confounding</strong>: Failing to account for variables that affect both X and Y</li>
<li><strong>P-hacking</strong>: Testing multiple hypotheses until finding significance</li>
<li><strong>Overgeneralization</strong>: Extending findings beyond the studied population</li>
</ol>
</div>
</div>
</section>
<section id="measurement-transforming-concepts-into-numbers" class="level2" data-number="1.44">
<h2 data-number="1.44" class="anchored" data-anchor-id="measurement-transforming-concepts-into-numbers"><span class="header-section-number">1.44</span> Measurement: Transforming Concepts into Numbers</h2>
<section id="the-political-world-is-full-of-data" class="level3">
<h3 class="anchored" data-anchor-id="the-political-world-is-full-of-data">The Political World is Full of Data</h3>
<p>Political science has evolved from a primarily theoretical discipline to one that increasingly relies on empirical evidence. Whether we’re studying:</p>
<ul>
<li><strong>Election outcomes</strong>: Why do people vote the way they do?</li>
<li><strong>Public opinion</strong>: What shapes attitudes toward immigration or climate policy?</li>
<li><strong>International relations</strong>: What factors predict conflict between nations?</li>
<li><strong>Policy effectiveness</strong>: Did a new education policy actually improve outcomes?</li>
</ul>
<p>We need systematic ways to analyze data and draw conclusions that go beyond anecdotes and personal impressions.</p>
<p>Consider this question: “Does democracy lead to economic growth?”</p>
<p>Your intuition might suggest yes—democratic countries tend to be wealthier. But is this causation or correlation? Are there exceptions? How confident can we be in our conclusions?</p>
<p>Statistics provides the tools to move from hunches to evidence-based answers, helping us distinguish between what seems true and what actually is true.</p>
</section>
<section id="the-challenge-of-measurement-in-social-sciences" class="level3">
<h3 class="anchored" data-anchor-id="the-challenge-of-measurement-in-social-sciences">The Challenge of Measurement in Social Sciences</h3>
<p>In social sciences, we often struggle with the fact that key concepts do not translate directly into numbers:</p>
<ul>
<li>How do we measure “democracy”?</li>
<li>What number captures “political ideology”?</li>
<li>How do we quantify “institutional strength”?</li>
<li>How do we measure “political participation”?</li>
</ul>
</section>
<section id="levels-of-measurement" class="level3">
<h3 class="anchored" data-anchor-id="levels-of-measurement">Levels of Measurement</h3>
<p><strong>Nominal (categories without order)</strong></p>
<ul>
<li>Party affiliation: Democratic, Republican, Independent</li>
<li>Country: Poland, Germany, France</li>
<li>Voting choice: Candidate A, Candidate B, Did not vote</li>
</ul>
<p><strong>Permitted operations:</strong> frequency counts, mode, cross-tabulation, chi-square test.</p>
<p><strong>Ordinal (ordered categories)</strong></p>
<ul>
<li>Education level: elementary &lt; high school &lt; bachelor’s &lt; master’s &lt; doctoral degree</li>
<li>Likert scales: Strongly disagree &lt; Disagree &lt; Neutral &lt; Agree &lt; Strongly agree</li>
<li>Political knowledge level: low &lt; medium &lt; high</li>
</ul>
<p><strong>Permitted operations:</strong> ordering, median, quartiles, Spearman’s rank correlation, non-parametric tests (e.g., Mann-Whitney).</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Key characteristic:</strong> Distances between categories do not have to be equal. For example, the difference in knowledge between “low” and “medium” levels may be much larger or smaller than the difference between “medium” and “high” levels. We only know that one level is higher than another, but not “by how much.”</p>
</div>
</div>
<p><strong>Interval (equal intervals, arbitrary zero)</strong></p>
<ul>
<li>Calendar years: difference between 2020–2021 = difference between 2023–2024</li>
<li>Temperature in °C or °F</li>
<li><strong>Standardized scores</strong> based on linear transformation (e.g., z-score, T-score)</li>
</ul>
<p><strong>Permitted operations:</strong> addition, subtraction, arithmetic mean, standard deviation, Pearson correlation, linear regression.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Limitation:</strong> Comparisons like “twice as much” make no sense because the zero point is arbitrary. For example: 20°C is not “twice as warm” as 10°C. If we used the Fahrenheit scale, these same temperatures would be 68°F and 50°F – suddenly one is no longer “twice” the other.</p>
</div>
</div>
<p><strong>Ratio (equal intervals + true zero)</strong></p>
<ul>
<li>Number of votes cast (0 = actually zero votes)</li>
<li>Age, income, campaign expenditures</li>
<li>Number of correct answers on a test, percentage of correct answers</li>
</ul>
<p><strong>Permitted operations:</strong> all operations, including ratios (“twice as many votes”).</p>
<hr>
</section>
<section id="special-case-psychometric-test-results" class="level3">
<h3 class="anchored" data-anchor-id="special-case-psychometric-test-results">Special Case: Psychometric Test Results</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Type of Score</th>
<th>Level of Measurement</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Letter grades (A/B/C), stanines, categories</td>
<td>Ordinal</td>
<td>Only ordering, no equal intervals</td>
</tr>
<tr class="even">
<td>Percentiles</td>
<td>Ordinal</td>
<td>Same percentile increase means different change in actual scores</td>
</tr>
<tr class="odd">
<td>IQ scores</td>
<td><strong>Ordinal</strong></td>
<td>Rank-ordered and transformed to normal distribution</td>
</tr>
<tr class="even">
<td>z-score, T-score</td>
<td>Interval*</td>
<td>*Only if original scores truly have equal intervals</td>
</tr>
<tr class="odd">
<td>Raw number of points, % correct</td>
<td>Ratio</td>
<td>True zero, constant increment</td>
</tr>
</tbody>
</table>
<p><strong>Example of the percentile problem:</strong> Moving from the 50th to 60th percentile might mean a change of 2-3 points on a test, while moving from the 90th to 95th percentile might mean a change of 10 points. Percentiles only tell us what percentage of people scored worse, but they don’t tell us about the actual magnitude of differences in abilities.</p>
<hr>
</section>
</section>
<section id="statistical-significance-making-sense-of-uncertain-evidence" class="level2" data-number="1.45">
<h2 data-number="1.45" class="anchored" data-anchor-id="statistical-significance-making-sense-of-uncertain-evidence"><span class="header-section-number">1.45</span> Statistical Significance: Making Sense of Uncertain Evidence</h2>
<section id="the-courtroom-analogy-for-hypothesis-testing" class="level3">
<h3 class="anchored" data-anchor-id="the-courtroom-analogy-for-hypothesis-testing">The Courtroom Analogy for Hypothesis Testing</h3>
<p>Statistical hypothesis testing follows a logic analogous to legal proceedings:</p>
<ul>
<li><strong>Null hypothesis (<span class="math inline">H_0</span>)</strong>: The defendant is innocent (no real effect exists)</li>
<li><strong>Alternative hypothesis (<span class="math inline">H_1</span>)</strong>: The defendant is guilty (a real effect exists)</li>
<li><strong>Evidence</strong>: Our data and statistical test</li>
<li><strong>Verdict</strong>: Reject <span class="math inline">H_0</span> (find significance) or fail to reject <span class="math inline">H_0</span> (no significance)</li>
</ul>
<p>As in legal proceedings, we require strong evidence to reject the presumption of innocence (no effect). This framework leads to two types of potential errors:</p>
<ul>
<li><strong>Type I error</strong> (false positive): Convicting an innocent person (rejecting <span class="math inline">H_0</span> when <span class="math inline">H_0</span> is true), controlled by significance level <span class="math inline">\alpha</span> (typically 0.05)</li>
<li><strong>Type II error</strong> (false negative): Acquitting a guilty person (failing to reject <span class="math inline">H_0</span> when <span class="math inline">H_1</span> is true), with probability <span class="math inline">\beta</span> and power <span class="math inline">1-\beta</span></li>
</ul>
</section>
<section id="what-is-statistical-significance" class="level3">
<h3 class="anchored" data-anchor-id="what-is-statistical-significance">What is Statistical Significance?</h3>
<p>When we observe a difference in our data, we face a fundamental question: Does this difference reflect a true population characteristic or merely sampling variability?</p>
<p><strong>Statistical significance</strong> provides a framework for answering:</p>
<blockquote class="blockquote">
<p>Is the observed pattern likely due to a real effect, or could it plausibly arise from random chance alone?</p>
</blockquote>
<p>This framework distinguishes between:</p>
<ul>
<li><strong>Signal</strong>: Real patterns reflecting true relationships in the population</li>
<li><strong>Noise</strong>: Random variation arising from sampling</li>
</ul>
</section>
<section id="the-logic-of-hypothesis-testing" class="level3">
<h3 class="anchored" data-anchor-id="the-logic-of-hypothesis-testing">The Logic of Hypothesis Testing</h3>
<p>The <strong>null hypothesis</strong> represents our default assumption—typically that no effect or relationship exists:</p>
<ul>
<li>No difference between groups</li>
<li>No relationship between variables</li>
<li>No treatment effect</li>
</ul>
<p>We maintain this skeptical stance until the data provide sufficient evidence to reject it.</p>
</section>
<section id="understanding-p-values-three-complementary-perspectives" class="level3">
<h3 class="anchored" data-anchor-id="understanding-p-values-three-complementary-perspectives">Understanding p-values: Three Complementary Perspectives</h3>
<p>The p-value remains one of the most misunderstood concepts in statistics. Consider three complementary interpretations:</p>
<section id="the-surprise-metric" class="level4">
<h4 class="anchored" data-anchor-id="the-surprise-metric">1. The Surprise Metric</h4>
<p>The p-value quantifies how surprised we should be to observe our data if nothing systematic were occurring:</p>
<ul>
<li>Small p-value (&lt; 0.05): Very surprising under the null → Evidence for an effect</li>
<li>Large p-value (&gt; 0.05): Not surprising under the null → Insufficient evidence</li>
</ul>
</section>
<section id="the-coin-flip-illustration" class="level4">
<h4 class="anchored" data-anchor-id="the-coin-flip-illustration">2. The Coin Flip Illustration</h4>
<p>Consider testing whether a coin is fair. You flip it 10 times and observe 8 heads.</p>
<p>The p-value answers: If the coin were actually fair, how often would we observe 8 or more heads in 10 flips?</p>
<p>Calculation: <span class="math inline">P(X \geq 8) = \sum_{k=8}^{10} \binom{10}{k} 0.5^{10} = \frac{56}{1024} \approx 0.0547</span></p>
<p>Since this probability is relatively small (5.47%), we have moderate evidence against fairness.</p>
</section>
<section id="the-formal-definition" class="level4">
<h4 class="anchored" data-anchor-id="the-formal-definition">3. The Formal Definition</h4>
<p>A <strong>p-value</strong> is:</p>
<blockquote class="blockquote">
<p>The probability of observing data at least as extreme as what we obtained, <strong>assuming the null hypothesis is true</strong>.</p>
</blockquote>
<p>Formally, for test statistic <span class="math inline">T</span> and observed value <span class="math inline">t_{\text{obs}}</span>:</p>
<ul>
<li>One-sided: <span class="math inline">p = P(T \geq t_{\text{obs}} \mid H_0)</span> or <span class="math inline">P(T \leq t_{\text{obs}} \mid H_0)</span></li>
<li>Two-sided: <span class="math inline">p = 2 \min\{P(T \geq |t_{\text{obs}}| \mid H_0), P(T \leq -|t_{\text{obs}}| \mid H_0)\}</span></li>
</ul>
<p><strong>Critical clarification</strong>: The p-value assumes the null hypothesis is true—it does not provide the probability that the null hypothesis is true.</p>
</section>
</section>
<section id="visualizing-p-values-the-distribution-of-possibilities" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-p-values-the-distribution-of-possibilities">Visualizing p-values: The Distribution of Possibilities</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization demonstrating p-value concept</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data for null distribution</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>x_values <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>y_values <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x_values)  <span class="co"># Standard normal distribution</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>observed_statistic <span class="ot">&lt;-</span> <span class="fl">2.1</span>  <span class="co"># Observed test result</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data frame</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x_values, <span class="at">y =</span> y_values)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate visualization</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Display null distribution</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">fill =</span> <span class="st">"#4A90E2"</span>) <span class="sc">+</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"#2E5F88"</span>, <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Highlight p-value regions</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">data =</span> <span class="fu">subset</span>(data, x <span class="sc">&gt;=</span> observed_statistic), </span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>            <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">fill =</span> <span class="st">"#E74C3C"</span>) <span class="sc">+</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">data =</span> <span class="fu">subset</span>(data, x <span class="sc">&lt;=</span> <span class="sc">-</span>observed_statistic), </span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>            <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">fill =</span> <span class="st">"#E74C3C"</span>) <span class="sc">+</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Mark observed statistics</span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> observed_statistic, </span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">"#C0392B"</span>, <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="sc">-</span>observed_statistic, </span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">"#C0392B"</span>, <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Labels and formatting</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Understanding p-values in Hypothesis Testing"</span>,</span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Shaded regions represent the probability of extreme results under the null hypothesis"</span>,</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Standardized Test Statistic"</span>,</span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Probability Density"</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">12</span>) <span class="sc">+</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add annotations</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">0</span>, <span class="at">y =</span> <span class="fl">0.25</span>, </span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="st">"Expected distribution</span><span class="sc">\n</span><span class="st">under null hypothesis"</span>, </span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>           <span class="at">color =</span> <span class="st">"#2E5F88"</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">fontface =</span> <span class="st">"bold"</span>) <span class="sc">+</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="fl">2.8</span>, <span class="at">y =</span> <span class="fl">0.1</span>, </span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="st">"p-value region"</span>, </span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a>           <span class="at">color =</span> <span class="st">"#C0392B"</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">fontface =</span> <span class="st">"bold"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The shaded regions represent the p-value: the probability of observing results at least as extreme as our actual findings, assuming the null hypothesis is true.</p>
<hr>
</section>
</section>
<section id="statistical-significance-distinguishing-signal-from-noise" class="level2" data-number="1.46">
<h2 data-number="1.46" class="anchored" data-anchor-id="statistical-significance-distinguishing-signal-from-noise"><span class="header-section-number">1.46</span> Statistical Significance: Distinguishing Signal from Noise</h2>
<p>When researchers observe patterns in their data—whether a difference between groups, a correlation between variables, or a treatment effect—they face a fundamental question: Does this pattern reflect a genuine phenomenon in the population, or could it have arisen purely by chance through the random process of sampling?</p>
<p><strong>Statistical significance</strong> provides a systematic framework for addressing this question, helping us distinguish between meaningful <strong>signal</strong> (real patterns reflecting population characteristics) and random <strong>noise</strong> (variation due to sampling variability).</p>
<hr>
</section>
<section id="understanding-hypothesis-testing-through-legal-principles" class="level2" data-number="1.47">
<h2 data-number="1.47" class="anchored" data-anchor-id="understanding-hypothesis-testing-through-legal-principles"><span class="header-section-number">1.47</span> Understanding Hypothesis Testing Through Legal Principles</h2>
<p>Statistical hypothesis testing follows a logical framework similar to legal proceedings. Before examining any evidence, we begin with a presumption of innocence—or in statistical terms, a presumption that no effect exists.</p>
<section id="the-fundamental-framework" class="level3">
<h3 class="anchored" data-anchor-id="the-fundamental-framework">The Fundamental Framework</h3>
<p>In hypothesis testing, we evaluate two competing propositions:</p>
<ul>
<li><strong>The Null Hypothesis (<span class="math inline">H_0</span>)</strong>: The default assumption that no effect or relationship exists</li>
<li><strong>The Alternative Hypothesis (<span class="math inline">H_1</span>)</strong>: The proposition that an effect or relationship does exist</li>
</ul>
<p><strong>Example</strong>: When evaluating whether a new teaching method improves student performance: - Null hypothesis: The new method produces no change in test scores - Alternative hypothesis: The new method improves test scores</p>
</section>
<section id="evidence-based-decision-making" class="level3">
<h3 class="anchored" data-anchor-id="evidence-based-decision-making">Evidence-Based Decision Making</h3>
<p>Similar to legal proceedings, statistical decisions require sufficient evidence to overturn the initial assumption:</p>
<ul>
<li><strong>Strong evidence</strong> → Reject the null hypothesis (analogous to a guilty verdict)</li>
<li><strong>Insufficient evidence</strong> → Fail to reject the null hypothesis (analogous to a not guilty verdict)</li>
</ul>
<p><strong>Important distinction</strong>: Failing to reject the null hypothesis does not prove its truth—it merely indicates insufficient evidence to conclude otherwise. This parallels how “not guilty” does not equate to “innocent” in legal terms.</p>
<hr>
</section>
</section>
<section id="the-p-value-quantifying-statistical-surprise" class="level2" data-number="1.48">
<h2 data-number="1.48" class="anchored" data-anchor-id="the-p-value-quantifying-statistical-surprise"><span class="header-section-number">1.48</span> The p-value: Quantifying Statistical Surprise</h2>
<p>The p-value measures how surprising your observed results would be if the null hypothesis were true. It provides a standardized way to evaluate evidence strength.</p>
<section id="illustrative-example-testing-coin-fairness" class="level3">
<h3 class="anchored" data-anchor-id="illustrative-example-testing-coin-fairness">Illustrative Example: Testing Coin Fairness</h3>
<p>Consider testing whether a coin is biased toward heads:</p>
<ul>
<li><strong>Experiment</strong>: Flip the coin 10 times</li>
<li><strong>Observation</strong>: 8 heads and 2 tails</li>
<li><strong>Question</strong>: If this were a fair coin, what is the probability of observing 8 or more heads?</li>
</ul>
<p><strong>Calculation</strong>: <span class="math inline">P(X \geq 8 \mid \text{fair coin}) = \sum_{k=8}^{10} \binom{10}{k} 0.5^{10} = \frac{56}{1024} \approx 0.055</span></p>
<p>This outcome would occur approximately 5.5% of the time with a fair coin—relatively uncommon but not impossible. The calculation shows that getting 8, 9, or 10 heads out of 10 flips has a combined probability of about 5.5% under the assumption of fairness.</p>
</section>
<section id="interpreting-p-value-magnitudes" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-p-value-magnitudes">Interpreting p-value Magnitudes</h3>
<ul>
<li><strong>Small p-values (e.g., 0.01)</strong>: The observed results would be highly unusual if the null hypothesis were true, suggesting evidence against it</li>
<li><strong>Large p-values (e.g., 0.30)</strong>: The observed results are consistent with what we would expect under the null hypothesis</li>
</ul>
<p>The conventional threshold of 0.05 represents a widely accepted but arbitrary cutoff for statistical significance.</p>
<hr>
</section>
</section>
<section id="common-misinterpretations-of-p-values" class="level2" data-number="1.49">
<h2 data-number="1.49" class="anchored" data-anchor-id="common-misinterpretations-of-p-values"><span class="header-section-number">1.49</span> Common Misinterpretations of p-values</h2>
<section id="misinterpretation-1-probability-of-the-hypothesis" class="level3">
<h3 class="anchored" data-anchor-id="misinterpretation-1-probability-of-the-hypothesis">Misinterpretation 1: Probability of the Hypothesis</h3>
<p><strong>Incorrect</strong>: “p = 0.03 means there is a 3% probability that the null hypothesis is true”</p>
<p><strong>Correct</strong>: “p = 0.03 means that if the null hypothesis were true, we would observe results this extreme only 3% of the time”</p>
</section>
<section id="misinterpretation-2-effect-size-indicator" class="level3">
<h3 class="anchored" data-anchor-id="misinterpretation-2-effect-size-indicator">Misinterpretation 2: Effect Size Indicator</h3>
<p><strong>Incorrect</strong>: “p = 0.001 indicates a larger effect than p = 0.04”</p>
<p><strong>Correct</strong>: p-values indicate evidence strength against the null hypothesis, not effect magnitude. Effect size must be assessed separately.</p>
</section>
<section id="misinterpretation-3-proof-of-no-effect" class="level3">
<h3 class="anchored" data-anchor-id="misinterpretation-3-proof-of-no-effect">Misinterpretation 3: Proof of No Effect</h3>
<p><strong>Incorrect</strong>: “p = 0.06 proves no effect exists”</p>
<p><strong>Correct</strong>: “p = 0.06 indicates insufficient evidence to reject the null hypothesis at the 0.05 significance level”</p>
<hr>
</section>
</section>
<section id="types-of-statistical-errors" class="level2" data-number="1.50">
<h2 data-number="1.50" class="anchored" data-anchor-id="types-of-statistical-errors"><span class="header-section-number">1.50</span> Types of Statistical Errors</h2>
<p>Statistical hypothesis testing involves two potential types of errors, each with distinct implications:</p>
<section id="type-i-error-false-positive" class="level3">
<h3 class="anchored" data-anchor-id="type-i-error-false-positive">Type I Error (False Positive)</h3>
<ul>
<li><strong>Definition</strong>: Rejecting the null hypothesis when it is actually true</li>
<li><strong>Legal analogy</strong>: Convicting an innocent defendant</li>
<li><strong>Scientific context</strong>: Concluding an effect exists when it does not</li>
<li><strong>Probability</strong>: Controlled by the significance level (α), typically set at 0.05</li>
</ul>
</section>
<section id="type-ii-error-false-negative" class="level3">
<h3 class="anchored" data-anchor-id="type-ii-error-false-negative">Type II Error (False Negative)</h3>
<ul>
<li><strong>Definition</strong>: Failing to reject the null hypothesis when the alternative is true</li>
<li><strong>Legal analogy</strong>: Acquitting a guilty defendant</li>
<li><strong>Scientific context</strong>: Failing to detect a genuine effect</li>
<li><strong>Probability</strong>: Denoted as β; statistical power equals 1 - β</li>
</ul>
</section>
<section id="the-error-trade-off" class="level3">
<h3 class="anchored" data-anchor-id="the-error-trade-off">The Error Trade-off</h3>
<p>A fundamental tension exists between these error types: - Decreasing Type I error risk (using stricter significance levels) increases Type II error risk - Increasing sample size helps reduce both error types simultaneously - The optimal balance depends on the relative costs of each error type in your specific context</p>
<hr>
</section>
</section>
<section id="the-historical-context-of-α-0.05" class="level2" data-number="1.51">
<h2 data-number="1.51" class="anchored" data-anchor-id="the-historical-context-of-α-0.05"><span class="header-section-number">1.51</span> The Historical Context of α = 0.05</h2>
<p>The conventional significance threshold of 0.05 lacks mathematical necessity and instead reflects historical precedent.</p>
<section id="historical-development" class="level3">
<h3 class="anchored" data-anchor-id="historical-development">Historical Development</h3>
<ul>
<li>Ronald Fisher popularized the 0.05 threshold in the 1920s</li>
<li>He considered it a convenient balance between Type I and Type II errors</li>
<li>The threshold became entrenched through scientific tradition rather than theoretical justification</li>
</ul>
</section>
<section id="context-dependent-thresholds" class="level3">
<h3 class="anchored" data-anchor-id="context-dependent-thresholds">Context-Dependent Thresholds</h3>
<p>Different fields adopt different significance levels based on their specific requirements:</p>
<ul>
<li><strong>Medical research</strong>: Often employs α = 0.01 to minimize false positive findings</li>
<li><strong>Exploratory research</strong>: May use α = 0.10 when the cost of missing effects is high</li>
<li><strong>Particle physics</strong>: Requires extremely stringent thresholds (e.g., 5-sigma, corresponding to p &lt; 0.0000003)</li>
</ul>
<p>The appropriate threshold should reflect the consequences of potential errors in your specific application.</p>
<hr>
</section>
</section>
<section id="statistical-significance-versus-practical-importance" class="level2" data-number="1.52">
<h2 data-number="1.52" class="anchored" data-anchor-id="statistical-significance-versus-practical-importance"><span class="header-section-number">1.52</span> Statistical Significance Versus Practical Importance</h2>
<p>Statistical significance addresses whether an effect exists; practical significance concerns whether the effect matters in real-world terms.</p>
<section id="the-sample-size-effect" class="level3">
<h3 class="anchored" data-anchor-id="the-sample-size-effect">The Sample Size Effect</h3>
<p>Large samples can detect trivially small effects with high statistical significance:</p>
<p><strong>Example</strong>: In a survey of 100,000 voters, a 1% difference in candidate preference might achieve p &lt; 0.001 while having negligible political importance.</p>
</section>
<section id="confidence-intervals-a-more-informative-approach" class="level3">
<h3 class="anchored" data-anchor-id="confidence-intervals-a-more-informative-approach">Confidence Intervals: A More Informative Approach</h3>
<p>Confidence intervals provide richer information than p-values alone:</p>
<ul>
<li><strong>Statistical significance</strong>: Whether the interval excludes the null value</li>
<li><strong>Effect magnitude</strong>: The estimated size of the effect</li>
<li><strong>Precision</strong>: The width of the interval indicating uncertainty</li>
</ul>
<p><strong>Example</strong>: “The new teaching method increases scores by 5 points (95% CI: 2 to 8 points)”</p>
<p>This conveys: - Statistical significance (interval excludes zero) - Estimated effect size (5 points) - Uncertainty range (could be as low as 2 or as high as 8 points)</p>
<hr>
</section>
</section>
<section id="essential-concepts-for-beginners" class="level2" data-number="1.53">
<h2 data-number="1.53" class="anchored" data-anchor-id="essential-concepts-for-beginners"><span class="header-section-number">1.53</span> Essential Concepts for Beginners</h2>
<section id="key-principles-1" class="level3">
<h3 class="anchored" data-anchor-id="key-principles-1">Key Principles</h3>
<ol type="1">
<li><p><strong>Hypothesis testing evaluates evidence strength</strong>, not absolute truth</p></li>
<li><p><strong>p-values quantify statistical surprise</strong>: They measure the probability of observing results at least as extreme as yours if no effect exists</p></li>
<li><p><strong>The 0.05 threshold is conventional</strong>, not mathematically derived</p></li>
<li><p><strong>Statistical significance does not imply practical importance</strong>: Effect size and context must be considered</p></li>
<li><p><strong>Two error types exist</strong>: False positives (Type I) and false negatives (Type II)</p></li>
<li><p><strong>Context determines appropriate thresholds</strong>: Different situations require different levels of evidence</p></li>
</ol>
</section>
<section id="critical-questions-when-evaluating-p-values" class="level3">
<h3 class="anchored" data-anchor-id="critical-questions-when-evaluating-p-values">Critical Questions When Evaluating p-values</h3>
<p>When encountering statistical results, consider:</p>
<ul>
<li>What hypothesis was being tested?</li>
<li>What is the magnitude of the observed effect?</li>
<li>Does this effect size have practical relevance?</li>
<li>What was the sample size?</li>
<li>What are the consequences of Type I versus Type II errors in this context?</li>
</ul>
</section>
<section id="conclusion" class="level3">
<h3 class="anchored" data-anchor-id="conclusion">Conclusion</h3>
<p>Statistical hypothesis testing provides a framework for making decisions under uncertainty. Understanding both its capabilities and limitations enables more informed interpretation of research findings and better decision-making in the presence of statistical evidence.</p>
<hr>
</section>
</section>
<section id="statistical-significance-real-world-examples" class="level2" data-number="1.54">
<h2 data-number="1.54" class="anchored" data-anchor-id="statistical-significance-real-world-examples"><span class="header-section-number">1.54</span> Statistical Significance: Real-World Examples</h2>
<section id="example-1-testing-a-voter-turnout-campaign" class="level3">
<h3 class="anchored" data-anchor-id="example-1-testing-a-voter-turnout-campaign">Example 1: Testing a Voter Turnout Campaign</h3>
<p>Let’s see how statistical significance works in practice with a simple, realistic example.</p>
</section>
<section id="the-research-question" class="level3">
<h3 class="anchored" data-anchor-id="the-research-question">The Research Question</h3>
<p><strong>Does sending text message reminders increase voter turnout?</strong></p>
</section>
<section id="the-study-setup" class="level3">
<h3 class="anchored" data-anchor-id="the-study-setup">The Study Setup</h3>
<p>A research team wants to test whether text reminders help more people vote. Here’s what they did:</p>
<ul>
<li><strong>Total participants</strong>: 10,000 registered voters</li>
<li><strong>Treatment group</strong>: 5,000 voters got text reminders</li>
<li><strong>Control group</strong>: 5,000 voters got no messages</li>
<li><strong>What they measured</strong>: Did each person vote? (Yes or No)</li>
</ul>
</section>
<section id="the-results" class="level3">
<h3 class="anchored" data-anchor-id="the-results">The Results</h3>
<p>After election day, they counted who actually voted:</p>
<ul>
<li><strong>Text message group</strong>: 68% voted (3,400 out of 5,000 people)</li>
<li><strong>No message group</strong>: 64% voted (3,200 out of 5,000 people)</li>
<li><strong>Difference</strong>: 4 percentage points higher turnout</li>
</ul>
</section>
<section id="the-big-question" class="level3">
<h3 class="anchored" data-anchor-id="the-big-question">The Big Question</h3>
<p>Is this 4-point difference <strong>real and meaningful</strong>, or could it just be <strong>random chance</strong>?</p>
<p>Think about it this way: Even if text messages did absolutely nothing, you’d still expect some random variation between the two groups. Maybe by pure luck, a few more motivated voters happened to end up in the text message group.</p>
</section>
<section id="what-the-statistics-tell-us" class="level3">
<h3 class="anchored" data-anchor-id="what-the-statistics-tell-us">What the Statistics Tell Us</h3>
<p>The researchers ran a statistical test and found a <strong>p-value of 0.00001</strong> (that’s 0.001%).</p>
<p><strong>Translation</strong>: If text messages actually had no effect, there’s only a 1 in 100,000 chance we’d see a difference this large or larger by pure coincidence.</p>
<p><strong>Conclusion</strong>: This difference is almost certainly not due to chance—the text messages really do seem to increase turnout.</p>
</section>
<section id="but-waitis-this-difference-actually-important" class="level3">
<h3 class="anchored" data-anchor-id="but-waitis-this-difference-actually-important">But Wait—Is This Difference Actually Important?</h3>
<p>Statistical significance tells us the effect is <strong>real</strong>, but is it <strong>meaningful</strong>?</p>
<p>A 4-percentage-point increase could be: - <strong>Politically significant</strong>: In close elections, this could change who wins - <strong>Cost-effective</strong>: Text messages are cheap to send - <strong>Practically meaningful</strong>: 200 extra voters out of every 5,000 contacted</p>
</section>
</section>
<section id="example-2-when-weather-affects-voting" class="level2" data-number="1.55">
<h2 data-number="1.55" class="anchored" data-anchor-id="example-2-when-weather-affects-voting"><span class="header-section-number">1.55</span> Example 2: When Weather Affects Voting</h2>
<section id="the-research-question-1" class="level3">
<h3 class="anchored" data-anchor-id="the-research-question-1">The Research Question</h3>
<p><strong>Does rainy weather reduce voter turnout?</strong></p>
</section>
<section id="the-logic" class="level3">
<h3 class="anchored" data-anchor-id="the-logic">The Logic</h3>
<p>When it’s raining, voting becomes slightly more inconvenient. You have to:</p>
<ul>
<li>Get wet walking to the polling station</li>
<li>Deal with traffic and parking issues</li>
<li>Maybe decide staying dry isn’t worth the trouble</li>
</ul>
</section>
<section id="a-simple-study" class="level3">
<h3 class="anchored" data-anchor-id="a-simple-study">A Simple Study</h3>
<p>Researchers looked at 60 elections:</p>
<ul>
<li><strong>30 rainy election days</strong>: Average turnout 62%</li>
<li><strong>30 sunny election days</strong>: Average turnout 68%</li>
<li><strong>Difference</strong>: 6 percentage points lower turnout on rainy days</li>
</ul>
</section>
<section id="the-statistical-test" class="level3">
<h3 class="anchored" data-anchor-id="the-statistical-test">The Statistical Test</h3>
<p>The p-value was 0.003 (0.3%).</p>
<p><strong>Translation</strong>: If weather really didn’t affect voting, there’s only a 3 in 1,000 chance we’d see this big a difference just by coincidence.</p>
<p><strong>Conclusion</strong>: Rain probably does reduce voter turnout.</p>
</section>
<section id="why-this-matters-1" class="level3">
<h3 class="anchored" data-anchor-id="why-this-matters-1">Why This Matters</h3>
<p>This finding suggests:</p>
<ul>
<li><strong>Election timing matters</strong>: Scheduling elections during likely bad weather could affect outcomes</li>
<li><strong>Voting access is important</strong>: Even small barriers (like weather) can influence democratic participation</li>
<li><strong>Effect size matters</strong>: A 6-point difference is substantial in political terms</li>
</ul>
</section>
</section>
<section id="example-3-when-we-dont-find-evidence" class="level2" data-number="1.56">
<h2 data-number="1.56" class="anchored" data-anchor-id="example-3-when-we-dont-find-evidence"><span class="header-section-number">1.56</span> Example 3: When We Don’t Find Evidence</h2>
<section id="the-research-question-2" class="level3">
<h3 class="anchored" data-anchor-id="the-research-question-2">The Research Question</h3>
<p><strong>Does social media use increase political knowledge among college students?</strong></p>
</section>
<section id="the-study" class="level3">
<h3 class="anchored" data-anchor-id="the-study">The Study</h3>
<p>Researchers surveyed 150 college students about:</p>
<ul>
<li>How many hours per day they use social media</li>
<li>How much they know about politics (scored 0-100)</li>
</ul>
</section>
<section id="the-results-1" class="level3">
<h3 class="anchored" data-anchor-id="the-results-1">The Results</h3>
<ul>
<li>Students who used social media more did know slightly more about politics</li>
<li>But the difference was very small and inconsistent</li>
<li><strong>p-value</strong>: 0.15 (15%)</li>
</ul>
</section>
<section id="what-this-means" class="level3">
<h3 class="anchored" data-anchor-id="what-this-means">What This Means</h3>
<p><strong>Translation</strong>: If social media use really had no effect on political knowledge, we’d see a pattern this strong or stronger in 15 out of 100 similar studies just by chance.</p>
<p><strong>Conclusion</strong>: We don’t have strong evidence that social media use increases political knowledge.</p>
</section>
<section id="important-what-no-evidence-actually-means" class="level3">
<h3 class="anchored" data-anchor-id="important-what-no-evidence-actually-means">Important: What “No Evidence” Actually Means</h3>
<p><strong>This does NOT mean</strong>: - ❌ “Social media definitely has no effect” - ❌ “The study was useless” - ❌ “We proved social media doesn’t matter”</p>
<p><strong>This DOES mean</strong>: - ✅ “We can’t reliably tell the difference between a real effect and random noise” - ✅ “More research with better methods might be needed” - ✅ “Any effect, if it exists, is probably pretty small”</p>
</section>
<section id="why-studies-sometimes-find-nothing" class="level3">
<h3 class="anchored" data-anchor-id="why-studies-sometimes-find-nothing">Why Studies Sometimes Find “Nothing”</h3>
<ol type="1">
<li><strong>Maybe there really is no effect</strong> - Social media use might truly be unrelated to political knowledge</li>
<li><strong>The effect might be too small to detect</strong> - With only 150 students, small effects are hard to spot</li>
<li><strong>The measurement might be flawed</strong> - Maybe the political knowledge test wasn’t very good</li>
<li><strong>The relationship might be complicated</strong> - Perhaps social media helps some people but hurts others</li>
</ol>
</section>
</section>
<section id="key-takeaways-for-understanding-statistical-significance" class="level2" data-number="1.57">
<h2 data-number="1.57" class="anchored" data-anchor-id="key-takeaways-for-understanding-statistical-significance"><span class="header-section-number">1.57</span> Key Takeaways for Understanding Statistical Significance</h2>
<section id="statistical-significance-probably-not-just-chance" class="level3">
<h3 class="anchored" data-anchor-id="statistical-significance-probably-not-just-chance">1. Statistical Significance = “Probably Not Just Chance”</h3>
<p>When we say a result is “statistically significant,” we mean:</p>
<ul>
<li>The pattern we observed would be very unlikely if nothing real was happening</li>
<li>We’re confident something genuine is going on, not just random luck</li>
</ul>
</section>
<section id="the-magic-number-0.05" class="level3">
<h3 class="anchored" data-anchor-id="the-magic-number-0.05">2. The Magic Number: 0.05</h3>
<ul>
<li>Scientists traditionally use 5% (0.05) as the cutoff</li>
<li>If p &lt; 0.05: “Statistically significant”</li>
<li>If p &gt; 0.05: “Not statistically significant”</li>
<li>But this cutoff is somewhat arbitrary—0.049 and 0.051 are practically identical!</li>
</ul>
</section>
<section id="significant-important" class="level3">
<h3 class="anchored" data-anchor-id="significant-important">3. Significant ≠ Important</h3>
<p>Just because something is statistically significant doesn’t mean it matters in the real world:</p>
<ul>
<li><strong>Statistical significance</strong>: “This effect is probably real”</li>
<li><strong>Practical significance</strong>: “This effect is large enough to care about”</li>
</ul>
</section>
<section id="not-significant-no-effect" class="level3">
<h3 class="anchored" data-anchor-id="not-significant-no-effect">4. Not Significant ≠ No Effect</h3>
<p>When studies don’t find statistical significance:</p>
<ul>
<li>It doesn’t prove there’s no effect</li>
<li>It means we don’t have strong enough evidence to be confident</li>
<li>The effect might exist but be too small to detect reliably</li>
</ul>
</section>
<section id="always-ask-how-big-is-the-effect" class="level3">
<h3 class="anchored" data-anchor-id="always-ask-how-big-is-the-effect">5. Always Ask: “How Big Is the Effect?”</h3>
<ul>
<li>A tiny effect in a huge study might be statistically significant but practically meaningless</li>
<li>A large effect in a small study might be practically important but not statistically significant</li>
<li>The ideal result is both statistically significant AND practically meaningful</li>
</ul>
</section>
</section>
<section id="how-to-read-statistical-results-like-a-pro" class="level2" data-number="1.58">
<h2 data-number="1.58" class="anchored" data-anchor-id="how-to-read-statistical-results-like-a-pro"><span class="header-section-number">1.58</span> How to Read Statistical Results Like a Pro</h2>
<p>When you see research results, ask yourself:</p>
<ol type="1">
<li><strong>Is it statistically significant?</strong> (p &lt; 0.05 usually means yes)</li>
<li><strong>How big is the effect?</strong> (Don’t just look at significance—look at the actual size of the difference)</li>
<li><strong>Does the size matter practically?</strong> (Would this difference actually affect real-world decisions?)</li>
<li><strong>How confident should we be?</strong> (Smaller p-values mean stronger evidence)</li>
<li><strong>Could there be other explanations?</strong> (Correlation doesn’t prove causation!)</li>
</ol>
<p>Remember: Statistics help us make sense of uncertainty, but they don’t give us absolute truth. They’re tools for thinking more clearly about evidence, not magic formulas that solve all debates.</p>
<hr>
</section>
<section id="common-p-value-misconceptions-and-corrections" class="level2" data-number="1.59">
<h2 data-number="1.59" class="anchored" data-anchor-id="common-p-value-misconceptions-and-corrections"><span class="header-section-number">1.59</span> Common p-value Misconceptions and Corrections</h2>
<p>Misunderstanding p-values represents one of the most pervasive problems in applied statistics. These misconceptions lead to flawed reasoning and poor decision-making.</p>
<section id="fundamental-misinterpretations" class="level3">
<h3 class="anchored" data-anchor-id="fundamental-misinterpretations">Fundamental Misinterpretations</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 38%">
<col style="width: 25%">
<col style="width: 35%">
</colgroup>
<thead>
<tr class="header">
<th><strong>Incorrect Interpretation</strong></th>
<th><strong>Why It’s Wrong</strong></th>
<th><strong>Correct Interpretation</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>“p = 0.03 means 97% probability the effect is real”</td>
<td>p-values assume the null is true; they don’t give probabilities about hypotheses</td>
<td>“If no effect existed, we’d observe data this extreme only 3% of the time”</td>
</tr>
<tr class="even">
<td>“p = 0.20 indicates a small effect”</td>
<td>p-values measure evidence strength, not effect magnitude</td>
<td>“We have weak evidence against the null hypothesis”</td>
</tr>
<tr class="odd">
<td>“p &gt; 0.05 proves no effect exists”</td>
<td>Absence of evidence ≠ evidence of absence</td>
<td>“We lack sufficient evidence to reject the null hypothesis”</td>
</tr>
<tr class="even">
<td>“Lower p-values mean more important findings”</td>
<td>Statistical significance ≠ practical importance</td>
<td>“Lower p-values indicate stronger evidence, but effect size determines importance”</td>
</tr>
<tr class="odd">
<td>“p = 0.05 means 5% chance results are due to chance”</td>
<td>p-values are calculated assuming results could be due to chance</td>
<td>“p-values quantify how surprising our data would be if only chance were operating”</td>
</tr>
</tbody>
</table>
</section>
<section id="the-prosecutors-fallacy-in-statistical-context" class="level3">
<h3 class="anchored" data-anchor-id="the-prosecutors-fallacy-in-statistical-context">The Prosecutor’s Fallacy in Statistical Context</h3>
<p>A classic logical error parallels a common p-value misinterpretation:</p>
<p><strong>Legal context</strong>: “If the defendant is innocent, the probability of this DNA evidence is 1 in 10 million. Therefore, the probability the defendant is innocent is 1 in 10 million.”</p>
<p><strong>Statistical context</strong>: “If the null hypothesis is true, the probability of these data is 0.01. Therefore, the probability the null hypothesis is true is 0.01.”</p>
<p><strong>Both errors confuse P(Evidence|Innocent) with P(Innocent|Evidence)—fundamentally different quantities requiring Bayes’ theorem to connect.</strong></p>
<hr>
</section>
</section>
<section id="understanding-p-values-and-confidence-intervals-together" class="level2" data-number="1.60">
<h2 data-number="1.60" class="anchored" data-anchor-id="understanding-p-values-and-confidence-intervals-together"><span class="header-section-number">1.60</span> Understanding p-values and Confidence Intervals Together</h2>
<p>p-values and confidence intervals are like two sides of the same coin—they give you different but related information about your research findings.</p>
<section id="the-simple-connection" class="level3">
<h3 class="anchored" data-anchor-id="the-simple-connection">The Simple Connection</h3>
<p>Here’s the basic relationship you need to know:</p>
<ul>
<li><strong>If your confidence interval includes zero</strong> → your result is NOT statistically significant (p &gt; 0.05)</li>
<li><strong>If your confidence interval excludes zero</strong> → your result IS statistically significant (p &lt; 0.05)</li>
</ul>
</section>
<section id="why-confidence-intervals-are-better-than-p-values-alone" class="level3">
<h3 class="anchored" data-anchor-id="why-confidence-intervals-are-better-than-p-values-alone">Why Confidence Intervals Are Better Than p-values Alone</h3>
<p>Think of p-values as a simple yes/no answer, while confidence intervals give you the whole story.</p>
<p><strong>What a p-value tells you:</strong> - Is this result probably real or probably just chance?</p>
<p><strong>What a confidence interval tells you:</strong> - Is this result probably real or probably just chance? (same as p-value) - How big is the effect? - How confident should we be about the size? - What’s the range of possible true effects?</p>
</section>
<section id="real-example-campaign-text-messages" class="level3">
<h3 class="anchored" data-anchor-id="real-example-campaign-text-messages">Real Example: Campaign Text Messages</h3>
<p>Let’s say researchers found that text message reminders increased voter turnout by 4 percentage points.</p>
<p><strong>Just the p-value</strong>: p = 0.02 - Translation: “This result is statistically significant” - What you don’t know: How big is the effect really? How confident should we be?</p>
<p><strong>With confidence interval</strong>: 4 percentage points (95% CI: 1.2 to 6.8) - Translation: “Text messages increased turnout by about 4 points, and we’re 95% confident the true effect is somewhere between 1.2 and 6.8 points” - This tells you much more!</p>
</section>
<section id="reading-confidence-intervals-like-a-pro" class="level3">
<h3 class="anchored" data-anchor-id="reading-confidence-intervals-like-a-pro">Reading Confidence Intervals Like a Pro</h3>
<p><strong>The three things every confidence interval tells you:</strong></p>
<ol type="1">
<li><p><strong>Statistical significance</strong>: Does the interval include zero?</p>
<ul>
<li>Includes zero = not significant</li>
<li>Excludes zero = significant</li>
</ul></li>
<li><p><strong>Effect size</strong>: What’s the middle number?</p>
<ul>
<li>This is your best guess at the true effect size</li>
</ul></li>
<li><p><strong>Precision</strong>: How wide is the interval?</p>
<ul>
<li>Narrow interval = more precise, more confident</li>
<li>Wide interval = less precise, less confident</li>
</ul></li>
</ol>
</section>
<section id="examples-in-action" class="level3">
<h3 class="anchored" data-anchor-id="examples-in-action">Examples in Action</h3>
<p><strong>Example 1: Strong, Precise Finding</strong> “Campaign ads increased support by 7 percentage points (95% CI: 5.2 to 8.8)”</p>
<ul>
<li><strong>Significant?</strong> Yes (doesn’t include zero)</li>
<li><strong>Effect size?</strong> 7 percentage points</li>
<li><strong>Precision?</strong> High (narrow range from 5.2 to 8.8)</li>
</ul>
<p><strong>Example 2: Weak, Imprecise Finding</strong> “Social media use affected political knowledge by 2.1 points (95% CI: -1.5 to 5.7)”</p>
<ul>
<li><strong>Significant?</strong> No (includes zero, since -1.5 is below zero)</li>
<li><strong>Effect size?</strong> About 2 points, but…</li>
<li><strong>Precision?</strong> Low (wide range, could be negative or positive!)</li>
</ul>
<p><strong>Example 3: Significant but Small</strong> “Online ads increased clicks by 0.3% (95% CI: 0.1 to 0.5)”</p>
<ul>
<li><strong>Significant?</strong> Yes (doesn’t include zero)</li>
<li><strong>Effect size?</strong> Very small (0.3%)</li>
<li><strong>Practical importance?</strong> Questionable</li>
</ul>
</section>
<section id="common-mistakes-to-avoid" class="level3">
<h3 class="anchored" data-anchor-id="common-mistakes-to-avoid">Common Mistakes to Avoid</h3>
<p><strong>Mistake 1: Ignoring confidence intervals</strong></p>
<ul>
<li>Bad: “The result was significant (p = 0.03)”</li>
<li>Good: “The intervention increased scores by 12 points (95% CI: 2 to 22, p = 0.03)”</li>
</ul>
<p><strong>Mistake 2: Treating borderline results as black and white</strong></p>
<ul>
<li>Bad: “p = 0.06, so there’s no effect”</li>
<li>Good: “p = 0.06 suggests some evidence for an effect, but it’s not conclusive”</li>
</ul>
<p><strong>Mistake 3: Focusing only on significance, not size</strong></p>
<ul>
<li>Bad: “The effect was highly significant!”</li>
<li>Good: “The effect was statistically significant but small in practical terms”</li>
</ul>
</section>
<section id="best-practices-for-understanding-research" class="level3">
<h3 class="anchored" data-anchor-id="best-practices-for-understanding-research">Best Practices for Understanding Research</h3>
<p>When you read research results, ask these questions:</p>
<ol type="1">
<li><p><strong>What’s the actual size of the effect?</strong> (Don’t just look at significance)</p></li>
<li><p><strong>How confident should we be?</strong> (Look at confidence interval width)</p></li>
<li><p><strong>Does the size matter practically?</strong> (A tiny but significant effect might not be important)</p></li>
<li><p><strong>What’s the range of possibilities?</strong> (Confidence intervals show this)</p></li>
<li><p><strong>How strong is the evidence?</strong> (Smaller p-values = stronger evidence)</p></li>
</ol>
</section>
<section id="how-to-report-results-properly" class="level3">
<h3 class="anchored" data-anchor-id="how-to-report-results-properly">How to Report Results Properly</h3>
<p><strong>Instead of this:</strong> “The treatment was effective (p &lt; 0.05)”</p>
<p><strong>Write this:</strong> “The treatment increased performance by 15% (95% CI: 8% to 22%, p = 0.003), representing a meaningful improvement in outcomes.”</p>
<p>This gives readers:</p>
<ul>
<li>The size of the effect (15%)</li>
<li>How confident we are (CI from 8% to 22%)</li>
<li>The strength of evidence (p = 0.003)</li>
<li>What it means practically (meaningful improvement)</li>
</ul>
</section>
<section id="the-big-picture" class="level3">
<h3 class="anchored" data-anchor-id="the-big-picture">The Big Picture</h3>
<p><strong>Remember these key points:</strong></p>
<ul>
<li><strong>p-values answer</strong>: “Is this probably real?”</li>
<li><strong>Confidence intervals answer</strong>: “Is this probably real, how big is it, and how confident are we?”</li>
<li><strong>Always look at both</strong> the statistical significance AND the practical importance</li>
<li><strong>Wide confidence intervals</strong> mean we’re less certain about the exact effect size</li>
<li><strong>Narrow confidence intervals</strong> mean we’re more confident about the effect size</li>
</ul>
<p>Statistical significance is just the starting point. The real question is always: “What does this mean in the real world?”</p>
<hr>
</section>
</section>
<section id="regression-the-workhorse-of-political-science" class="level1" data-number="2">
<h1 data-number="2"><span class="header-section-number">2</span> Regression: The Workhorse of Political Science</h1>
<blockquote class="blockquote">
<p><strong>The One-Sentence Summary:</strong> Regression helps us understand how things relate to each other in a messy, complicated world where everything affects everything else.</p>
</blockquote>
<section id="before-you-start-what-you-need-to-know" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="before-you-start-what-you-need-to-know"><span class="header-section-number">2.1</span> Before You Start: What You Need to Know</h2>
<ul>
<li>Basic algebra (we’ll use simple equations like y = mx + b)</li>
<li>How to read a graph with x and y axes<br>
</li>
<li>Curiosity about why things happen in politics and society!</li>
</ul>
<p><em>Don’t worry - we’ll explain everything else as we go, with lots of examples.</em></p>
<hr>
<p>Consider a typical pre-election news headline: “Candidate Smith’s approval rating reaches 68%.” Your immediate inference likely suggests favorable electoral prospects for Smith—not guaranteed victory, but a strong position.</p>
<p>This intuitive assessment exemplifies the essence of regression analysis. You utilized one piece of information (approval rating) to predict another outcome (electoral success), automatically recognizing that higher approval ratings correlate with better electoral performance, despite an imperfect relationship.</p>
<p>Regression analysis systematizes this intuitive process, enabling researchers to:</p>
<ul>
<li>Generate predictions based on available information</li>
<li>Identify which factors matter most</li>
<li>Quantify uncertainty in predictions</li>
<li>Test theoretical propositions with empirical data</li>
</ul>
</section>
<section id="variables-and-variation" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="variables-and-variation"><span class="header-section-number">2.2</span> Variables and Variation</h2>
<section id="defining-variables" class="level3">
<h3 class="anchored" data-anchor-id="defining-variables">Defining Variables</h3>
<p>A <strong>variable</strong> is any characteristic that can take different values across units of observation. In political science:</p>
<ul>
<li><strong>Units of analysis</strong>: Countries, individuals, elections, policies, years</li>
<li><strong>Variables</strong>: GDP, voting preference, democracy score, conflict occurrence</li>
</ul>
<blockquote class="blockquote">
<p><strong>💡 In Plain English:</strong> A variable is anything that changes. If everyone voted the same way, “voting preference” wouldn’t be a variable—it would be a constant. We study variables because we want to understand why things differ.</p>
</blockquote>
</section>
</section>
<section id="what-is-regression" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="what-is-regression"><span class="header-section-number">2.3</span> What is Regression?</h2>
<p>Regression analysis constitutes the foundational statistical tool in political science. It models relationships between variables and operationalizes our fundamental statistical model.</p>
<section id="the-fundamental-model" class="level3">
<h3 class="anchored" data-anchor-id="the-fundamental-model">The Fundamental Model</h3>
<p>A model represents an object, person, or system in an informative way. Models divide into physical representations (such as architectural models) and abstract representations (such as mathematical equations describing atmospheric dynamics).</p>
<p>The core of statistical thinking can be expressed as:</p>
<p><span class="math display">Y = f(X) + \text{error}</span></p>
<p>This equation states that our outcome (<span class="math inline">Y</span>) equals some function of our predictors (<span class="math inline">X</span>), plus unpredictable variation.</p>
<p><strong>Components</strong>:</p>
<ul>
<li><span class="math inline">Y</span> = Dependent variable (the phenomenon we seek to explain)</li>
<li><span class="math inline">X</span> = Independent variable(s) (explanatory factors)</li>
<li><span class="math inline">f()</span> = The functional relationship (often assumed linear)</li>
<li>error (<span class="math inline">\epsilon</span>) = Unexplained variation</li>
</ul>
<blockquote class="blockquote">
<p><strong>💡 What This Really Means:</strong> Think of it like a recipe. Your grade in a class (<span class="math inline">Y</span>) depends on study hours (<span class="math inline">X</span>), but not perfectly. Two students studying 10 hours might get different grades because of test anxiety, prior knowledge, or just luck (the error term). Regression finds the average relationship.</p>
</blockquote>
<p>This model provides the foundation for all statistical analysis—from simple correlations to complex machine learning algorithms.</p>
<p>Regression helps answer fundamental questions such as:</p>
<ul>
<li>How much does education increase political participation?</li>
<li>What factors predict electoral success?</li>
<li>Do democratic institutions promote economic growth?</li>
</ul>
</section>
</section>
<section id="building-intuition-everyday-examples" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="building-intuition-everyday-examples"><span class="header-section-number">2.4</span> Building Intuition: Everyday Examples</h2>
<p>Before diving into politics, let’s build intuition with scenarios you encounter daily.</p>
<section id="example-1-height-and-basketball-performance" class="level3">
<h3 class="anchored" data-anchor-id="example-1-height-and-basketball-performance">Example 1: Height and Basketball Performance</h3>
<p>Suppose you want to predict basketball players’ scoring based on their height. Expected patterns include:</p>
<ul>
<li>Taller players generally score more points</li>
<li>Height alone does not determine scoring (skill, position, and playing time matter)</li>
<li>Substantial variation exists—some shorter players excel at scoring</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Create basketball example for intuition</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>n_players <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate realistic basketball data</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>height_inches <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_players, <span class="dv">78</span>, <span class="dv">4</span>)  <span class="co"># Average NBA height ~6'6"</span></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Scoring increases with height, but with substantial variation</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>points_per_game <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fl">0.5</span> <span class="sc">*</span> (height_inches <span class="sc">-</span> <span class="dv">70</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(n_players, <span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>points_per_game <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="dv">0</span>, points_per_game)  <span class="co"># No negative scoring</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>basketball_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">height =</span> height_inches,</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">points =</span> points_per_game</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualization</span></span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(basketball_data, <span class="fu">aes</span>(<span class="at">x =</span> height, <span class="at">y =</span> points)) <span class="sc">+</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">"orange"</span>, <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Height versus Points Scored: The Basic Concept of Regression"</span>,</span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"The blue line shows the general relationship; points show individual players"</span>,</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Height (inches)"</span>,</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Points Per Game"</span>,</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">"Each point represents one player; the line summarizes the overall pattern"</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/basketball-example-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Interpretation</strong>: Each orange point represents one player. The blue line indicates the overall trend—taller players score more points on average. The variation around the line reflects other unmeasured factors: skill, position, minutes played, team system, and other determinants of scoring ability.</p>
<blockquote class="blockquote">
<p><strong>🧠 Sanity Check:</strong> If this plot showed ALL players exactly on the blue line (perfect correlation), you should be suspicious. Human performance is never that predictable! The scatter around the line is normal and expected.</p>
</blockquote>
</section>
<section id="example-2-coffee-and-productivity" class="level3">
<h3 class="anchored" data-anchor-id="example-2-coffee-and-productivity">Example 2: Coffee and Productivity</h3>
<p>Here’s something you might wonder about: Do people who drink more coffee get more work done?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Coffee consumption and productivity</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">234</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>n_workers <span class="ot">&lt;-</span> <span class="dv">150</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>coffee_cups <span class="ot">&lt;-</span> <span class="fu">rpois</span>(n_workers, <span class="dv">2</span>) <span class="sc">+</span> <span class="fu">runif</span>(n_workers, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>productivity <span class="ot">&lt;-</span> <span class="dv">60</span> <span class="sc">+</span> <span class="dv">3</span> <span class="sc">*</span> coffee_cups <span class="sc">+</span> <span class="fu">rnorm</span>(n_workers, <span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>productivity <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="dv">20</span>, <span class="fu">pmin</span>(<span class="dv">100</span>, productivity))</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>coffee_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">coffee =</span> <span class="fu">round</span>(coffee_cups, <span class="dv">1</span>),</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">productivity =</span> <span class="fu">round</span>(productivity, <span class="dv">1</span>)</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(coffee_data, <span class="fu">aes</span>(<span class="at">x =</span> coffee, <span class="at">y =</span> productivity)) <span class="sc">+</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">"#6F4E37"</span>, <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">color =</span> <span class="st">"#2E7D32"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Daily Coffee Consumption vs. Productivity Score"</span>,</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Each cup associated with ~3 point productivity increase"</span>,</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Cups of Coffee per Day"</span>,</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Productivity Score (0-100)"</span>,</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">"But does coffee CAUSE productivity, or do busy people drink more coffee?"</span></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/coffee-example-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<blockquote class="blockquote">
<p><strong>Think About It:</strong> The graph shows coffee drinkers are more productive. But what if stressed workers drink more coffee AND work harder? Or early risers drink coffee AND are naturally productive? The correlation doesn’t tell us if coffee helps or if something else explains both patterns.</p>
</blockquote>
</section>
<section id="example-3-study-hours-and-exam-scores" class="level3">
<h3 class="anchored" data-anchor-id="example-3-study-hours-and-exam-scores">Example 3: Study Hours and Exam Scores</h3>
<p>The most relatable example for students:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Study hours and exam performance</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>n_students <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Some students are naturally better test-takers</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>natural_ability <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_students, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Study hours influenced by motivation and ability</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>study_hours <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="dv">0</span>, <span class="dv">5</span> <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">runif</span>(n_students, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">2</span>) <span class="sc">-</span> <span class="fl">0.5</span><span class="sc">*</span>natural_ability <span class="sc">+</span> <span class="fu">rnorm</span>(n_students, <span class="dv">0</span>, <span class="dv">2</span>))</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Exam score depends on both study hours AND natural ability</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>exam_score <span class="ot">&lt;-</span> <span class="fu">pmin</span>(<span class="dv">100</span>, <span class="fu">pmax</span>(<span class="dv">0</span>, </span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>  <span class="dv">50</span> <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>study_hours <span class="sc">+</span> <span class="dv">10</span><span class="sc">*</span>natural_ability <span class="sc">+</span> <span class="fu">rnorm</span>(n_students, <span class="dv">0</span>, <span class="dv">8</span>)))</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>study_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">hours =</span> study_hours,</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">score =</span> exam_score,</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">ability =</span> natural_ability</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(study_data, <span class="fu">aes</span>(<span class="at">x =</span> hours, <span class="at">y =</span> score)) <span class="sc">+</span></span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">"darkblue"</span>, <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="fl">1.2</span>, <span class="at">se =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Study Hours and Exam Performance"</span>,</span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"More studying correlates with higher scores, but notice the spread"</span>,</span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Hours Studied"</span>,</span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Exam Score (%)"</span>,</span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">"Gray band shows uncertainty in the average relationship"</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/study-example-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Key Insight</strong>: Two students studying 10 hours might score 65% and 85%. Why? Natural ability, test anxiety, sleep quality, and prior knowledge all matter. The red line shows the <em>average</em> effect of studying.</p>
<blockquote class="blockquote">
<p><strong>💡 Student Reality Check:</strong> This is why your friend might get an A with less studying—it’s not just effort! Don’t get discouraged by outliers; focus on the general pattern.</p>
</blockquote>
</section>
</section>
<section id="simple-linear-regression" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="simple-linear-regression"><span class="header-section-number">2.5</span> Simple Linear Regression</h2>
<p>Now let’s formalize what we’ve been seeing. The basic regression equation is:</p>
<p><span class="math display">Y_i = \alpha + \beta X_i + \epsilon_i</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">Y_i</span> = outcome for observation <span class="math inline">i</span></li>
<li><span class="math inline">X_i</span> = predictor for observation <span class="math inline">i</span></li>
<li><span class="math inline">\alpha</span> = intercept (expected value of <span class="math inline">Y</span> when <span class="math inline">X = 0</span>)</li>
<li><span class="math inline">\beta</span> = slope (change in <span class="math inline">Y</span> for one-unit change in <span class="math inline">X</span>)</li>
<li><span class="math inline">\epsilon_i</span> = error term (everything else affecting <span class="math inline">Y</span>)</li>
</ul>
<blockquote class="blockquote">
<p><strong>How to Read This Equation - A Recipe:</strong></p>
<p>“A student’s exam score equals a baseline score (α), plus the benefit from each hour studied (β × hours), plus all the other stuff we didn’t measure (ε).”</p>
</blockquote>
<section id="political-science-example-education-and-participation" class="level3">
<h3 class="anchored" data-anchor-id="political-science-example-education-and-participation">Political Science Example: Education and Participation</h3>
<p>Consider a classic question: Does education increase political participation?</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/education-participation-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Statistical Results:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>• Each additional year of education increases participation by 0.029 points on average</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>• Education explains 9.2 % of variation in participation</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>• Remaining 90.8 % is explained by unmeasured factors</code></pre>
</div>
</div>
</section>
<section id="understanding-r-squared-r²" class="level3">
<h3 class="anchored" data-anchor-id="understanding-r-squared-r²">Understanding R-squared (R²)</h3>
<p>R² tells us the percentage of variation in the outcome explained by our predictor(s).</p>
<ul>
<li>R² = 0.3 means the model explains 30% of variation</li>
<li>R² = 1.0 would mean perfect prediction (never happens with human behavior)</li>
<li>R² = 0.0 means the predictor tells us nothing</li>
</ul>
<blockquote class="blockquote">
<p><strong>⚠️ Common Mistake:</strong> An R² of 0.3 doesn’t mean your model is “bad.” In social sciences, human behavior is complex! Even explaining 30% of why people act differently can be incredibly valuable for understanding society and making policy.</p>
</blockquote>
<p><strong>Think of it this way:</strong> If education explains 30% of participation differences, that’s huge! It means education policy could substantially impact democratic engagement, even if 70% depends on other factors like income, interest, and free time.</p>
<blockquote class="blockquote">
<p><strong>🧠 Reality Check for R² Values:</strong></p>
<ul>
<li><strong>R² = 0.05-0.15</strong>: Typical for complex human behaviors</li>
<li><strong>R² = 0.30-0.50</strong>: Pretty good for social science!</li>
<li><strong>R² = 0.80+</strong>: Suspicious for human behavior—check your data</li>
<li><strong>R² = 0.95+</strong>: Almost certainly an error or data problem</li>
</ul>
</blockquote>
</section>
</section>
<section id="multiple-regression-accounting-for-complexity" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="multiple-regression-accounting-for-complexity"><span class="header-section-number">2.6</span> Multiple Regression: Accounting for Complexity</h2>
<p>Real-world phenomena rarely have single causes. Education affects participation, but so do income, age, and political interest. Multiple regression accounts for several factors simultaneously.</p>
<section id="understanding-controlling-for" class="level3">
<h3 class="anchored" data-anchor-id="understanding-controlling-for">Understanding “Controlling For”</h3>
<p>This concept often confuses students, so let’s use a concrete example:</p>
<p><strong>Ice Cream and Crime Rates</strong></p>
<p>Imagine you discover that cities with more ice cream sales have higher crime rates. Should we ban ice cream to reduce crime?</p>
<p>Of course not! Both ice cream sales and crime increase in summer because of hot weather. Temperature is a <strong>confounding variable</strong>—it affects both variables we’re studying.</p>
<blockquote class="blockquote">
<p><strong>💡 What “Controlling For” Means:</strong> When we say “ice cream sales don’t affect crime, controlling for temperature,” we mean: “Among cities with the same temperature, ice cream sales don’t predict crime rates.” We’re comparing apples to apples.</p>
</blockquote>
<p>The multiple regression equation:</p>
<p><span class="math display">Y_i = \alpha + \beta_1 X_{1i} + \beta_2 X_{2i} + \ldots + \beta_k X_{ki} + \epsilon_i</span></p>
<p>Each <span class="math inline">\beta_j</span> represents the effect of <span class="math inline">X_j</span> <strong>holding all other variables constant</strong>.</p>
<hr>
</section>
<section id="real-example-what-determines-electoral-success" class="level3">
<h3 class="anchored" data-anchor-id="real-example-what-determines-electoral-success">Real Example: What Determines Electoral Success?</h3>
<p>Let’s tackle a question that political consultants, journalists, and voters all wonder about: <strong>What actually helps candidates win elections?</strong></p>
<p>Imagine you’re a campaign manager. Your candidate asks: “Should I focus on improving my approval ratings, hope the economy improves, or raise more money?” This is exactly what multiple regression can help answer.</p>
<section id="our-investigation" class="level4">
<h4 class="anchored" data-anchor-id="our-investigation">Our Investigation</h4>
<p>We’ll analyze 200 recent elections to understand what predicts the <strong>victory margin</strong>—how many percentage points the winner beats the runner-up by.</p>
<p><strong>Our three suspects:</strong></p>
<ol type="1">
<li><strong>Approval Rating</strong> - How popular is the candidate? (25-75% scale)</li>
<li><strong>Economic Growth</strong> - Is the economy helping or hurting? (GDP growth rate)</li>
<li><strong>Campaign Spending</strong> - Does money buy votes? (millions of dollars)</li>
</ol>
<blockquote class="blockquote">
<p><strong>Spoiler Alert:</strong> The answer isn’t what you might expect. One factor dominates, another helps a bit, and the third? Almost useless.</p>
</blockquote>
</section>
<section id="first-lets-look-at-the-data" class="level4">
<h4 class="anchored" data-anchor-id="first-lets-look-at-the-data">First, Let’s Look at the Data</h4>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/data-visualization-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<blockquote class="blockquote">
<p><strong>What do you notice?</strong> Approval shows the strongest relationship (steeper line), economy shows a moderate relationship, and spending? The relationship is barely visible!</p>
</blockquote>
</section>
<section id="step-1-the-simple-approach-one-factor-at-a-time" class="level4">
<h4 class="anchored" data-anchor-id="step-1-the-simple-approach-one-factor-at-a-time">Step 1: The Simple Approach (One Factor at a Time)</h4>
<p>Let’s start simple. What if we only looked at approval ratings?</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>SIMPLE MODEL - Just Approval Ratings</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>=====================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>The equation: Victory Margin =  -16.54  +  0.6  × Approval</code></pre>
</div>
</div>
<p><strong>Translation to Plain English:</strong></p>
<ul>
<li>Start with a baseline of -16.54 points (when approval = 0%, which never actually happens)</li>
<li>Add 0.6 points to victory margin for each 1% increase in approval</li>
<li>So a candidate with 60% approval beats one with 50% approval by about 6 points on average</li>
</ul>
<blockquote class="blockquote">
<p><strong>Problem with this approach:</strong> What if popular candidates also benefit from good economies or raise more money? We’re mixing up different effects!</p>
</blockquote>
</section>
<section id="step-2-the-full-picture-all-factors-together" class="level4">
<h4 class="anchored" data-anchor-id="step-2-the-full-picture-all-factors-together">Step 2: The Full Picture (All Factors Together)</h4>
<p>Now let’s use multiple regression to separate each factor’s individual contribution:</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code>MULTIPLE REGRESSION MODEL - All Factors</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>========================================</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Victory Margin =  -26.45  +  0.56  × Approval</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                 +  2.78  × Economic Growth</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>                 +  0.17  × Campaign Spending</code></pre>
</div>
</div>
</section>
<section id="understanding-the-regression-output" class="level4">
<h4 class="anchored" data-anchor-id="understanding-the-regression-output">Understanding the Regression Output</h4>
<p>Here’s what the computer tells us:</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-striped table-hover caption-top table-sm small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Variable</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Coefficient</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">What It Means</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Is It Significant?</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Baseline</td>
<td style="text-align: center;">-26.454</td>
<td style="text-align: left;">Starting point (mathematical construct)</td>
<td style="text-align: left;">Yes (p &lt; 0.001) ✓✓✓</td>
</tr>
<tr class="even">
<td style="text-align: left; font-weight: bold;">Approval Rating</td>
<td style="text-align: center; font-weight: bold;">0.558</td>
<td style="text-align: left; font-weight: bold;">Each 1% higher approval → 0.56 point larger victory</td>
<td style="text-align: left; font-weight: bold;">Yes (p &lt; 0.001) ✓✓✓</td>
</tr>
<tr class="odd">
<td style="text-align: left; font-weight: bold;">Economic Growth</td>
<td style="text-align: center; font-weight: bold;">2.783</td>
<td style="text-align: left; font-weight: bold;">Each 1% faster growth → 2.78 point larger victory</td>
<td style="text-align: left; font-weight: bold;">Yes (p &lt; 0.001) ✓✓✓</td>
</tr>
<tr class="even">
<td style="text-align: left; font-weight: bold;">Campaign Spending</td>
<td style="text-align: center; font-weight: bold;">0.165</td>
<td style="text-align: left; font-weight: bold;">Each extra $1 million → 0.17 point larger victory</td>
<td style="text-align: left; font-weight: bold;">Yes (p &lt; 0.001) ✓✓✓</td>
</tr>
</tbody><tfoot>
<tr class="odd">
<td style="text-align: left; padding: 0;"><span style="font-style: italic;">Note: </span></td>
<td style="text-align: center;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
<tr class="even">
<td style="text-align: left; padding: 0;"><sup></sup> Significant = unlikely to be due to random chance</td>
<td style="text-align: center;"></td>
<td style="text-align: left;"></td>
<td style="text-align: left;"></td>
</tr>
</tfoot>

</table>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>Model Performance:</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>• R-squared:  0.677  (explains  67.7 % of variation)</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>• Unexplained:  32.3 % due to other factors</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p><strong>💡 Reading p-values:</strong></p>
<ul>
<li>p &lt; 0.05 means “less than 5% chance this is just random noise”</li>
<li>p &lt; 0.001 means “less than 0.1% chance this is random”</li>
<li>The more checkmarks, the more confident we are the effect is real</li>
</ul>
</blockquote>
</section>
<section id="a-concrete-example-the-2024-governors-race" class="level4">
<h4 class="anchored" data-anchor-id="a-concrete-example-the-2024-governors-race">A Concrete Example: The 2024 Governor’s Race</h4>
<p>Let’s apply our model to a hypothetical but realistic scenario:</p>
<p><strong>Candidate Martinez:</strong></p>
<ul>
<li>Approval rating: 55%</li>
<li>Economic growth during term: 3%</li>
<li>Campaign war chest: $25 million</li>
</ul>
<p><strong>Candidate Johnson:</strong></p>
<ul>
<li>Approval rating: 45%</li>
<li>Economic growth during term: 1%</li>
<li>Campaign war chest: $15 million</li>
</ul>
<p><strong>Our Model’s Prediction:</strong></p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-striped table-hover caption-top table-sm small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th"></th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Factor</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">Calculation</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">Martinez's Edge (points)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">approval</td>
<td style="text-align: left;">Approval advantage</td>
<td style="text-align: left;">(55% - 45%) × 0.56</td>
<td style="text-align: right;">5.6</td>
</tr>
<tr class="even">
<td style="text-align: left;">econ_growth</td>
<td style="text-align: left;">Economic advantage</td>
<td style="text-align: left;">(3% - 1%) × 2.78</td>
<td style="text-align: right;">5.6</td>
</tr>
<tr class="odd">
<td style="text-align: left;">spending</td>
<td style="text-align: left;">Money advantage</td>
<td style="text-align: left;">($25M - $15M) × 0.17</td>
<td style="text-align: right;">1.7</td>
</tr>
<tr class="even">
<td style="text-align: left; font-weight: bold; color: white !important; background-color: blue !important;"></td>
<td style="text-align: left; font-weight: bold; color: white !important; background-color: blue !important;">TOTAL PREDICTED ADVANTAGE</td>
<td style="text-align: left; font-weight: bold; color: white !important; background-color: blue !important;">Sum of all advantages</td>
<td style="text-align: right; font-weight: bold; color: white !important; background-color: blue !important;">12.9</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>Prediction:</strong> Martinez wins by approximately 12.9 percentage points.</p>
<blockquote class="blockquote">
<p><strong>Reality Check:</strong> This assumes average conditions. Martinez could still lose if there’s a scandal, Johnson runs a brilliant campaign, or unexpected events occur. Remember the unexplained 32%!</p>
</blockquote>
</section>
<section id="the-truth-about-money" class="level4">
<h4 class="anchored" data-anchor-id="the-truth-about-money">The Truth About Money</h4>
<p>Look at the spending coefficient: only 0.17 points per million dollars!</p>
<p><strong>What this means:</strong></p>
<ul>
<li>Spending $10 million more only gains you about 1.7 percentage points</li>
<li>Compare that to approval: a 10% approval advantage gives you 5.6 points!</li>
<li><strong>Conclusion:</strong> Money helps, but popularity matters much more</li>
</ul>
<blockquote class="blockquote">
<p><strong>Think About It:</strong> If you’re a campaign manager with limited time, should you focus on fundraising or improving your candidate’s approval rating? The data is clear: work on approval!</p>
</blockquote>
</section>
<section id="why-did-the-approval-effect-change" class="level4">
<h4 class="anchored" data-anchor-id="why-did-the-approval-effect-change">Why Did the Approval Effect Change?</h4>
<p>Notice something interesting:</p>
<div class="cell">
<div class="cell-output-display">
<table class="table table-striped table-hover caption-top table-sm small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">Model Type</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Approval Coefficient</th>
<th style="text-align: center;" data-quarto-table-cell-role="th">Change</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Simple (approval only)</td>
<td style="text-align: center;">0.60</td>
<td style="text-align: center;">--</td>
</tr>
<tr class="even">
<td style="text-align: left;">Multiple (all factors)</td>
<td style="text-align: center;">0.56</td>
<td style="text-align: center;">-0.04 points</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>Why the difference?</strong></p>
<p>When we only looked at approval, we were actually capturing three things mixed together:</p>
<ol type="1">
<li>The direct effect of approval ✓</li>
<li>The fact that popular candidates often govern during good economies</li>
<li>The fact that popular candidates raise more money</li>
</ol>
<p>Multiple regression <strong>separates</strong> these effects. The “true” approval effect is 0.56, not 0.6.</p>
<blockquote class="blockquote">
<p><strong>The Statistical Detective Story:</strong> Simple regression is like a witness who says “I saw the popular candidate win big!” Multiple regression is like a detective who asks “But wait, was it the popularity, the good economy, or the money that caused the win?” and finds that popularity was the main culprit.</p>
</blockquote>
</section>
<section id="key-takeaways-for-real-elections" class="level4">
<h4 class="anchored" data-anchor-id="key-takeaways-for-real-elections">Key Takeaways for Real Elections</h4>
<p><strong>🏆 The Hierarchy of Electoral Factors:</strong></p>
<ol type="1">
<li><strong>Approval Rating</strong> (coefficient: 0.56) - <strong>The King</strong>
<ul>
<li>Most powerful predictor</li>
<li>10% approval edge ≈ 5.6 point victory margin</li>
</ul></li>
<li><strong>Economic Growth</strong> (coefficient: 2.78) - <strong>The Prince</strong>
<ul>
<li>Substantial but secondary</li>
<li>2% growth difference ≈ 5.6 point victory margin</li>
</ul></li>
<li><strong>Campaign Spending</strong> (coefficient: 0.17) - <strong>The Pauper</strong>
<ul>
<li>Surprisingly weak effect</li>
<li>$20 million extra ≈ only 3.4 point advantage</li>
</ul></li>
</ol>
<blockquote class="blockquote">
<p><strong>⚠️ Critical Warning:</strong> These are <strong>associations</strong>, not proven <strong>causes</strong>. Maybe approval doesn’t cause victory—maybe likely winners get higher approval ratings as the election approaches. Or maybe some third factor (like candidate quality) drives both. Always think about alternative explanations!</p>
</blockquote>
</section>
<section id="what-this-means-for-democracy" class="level4">
<h4 class="anchored" data-anchor-id="what-this-means-for-democracy">What This Means for Democracy</h4>
<p>Our findings suggest:</p>
<ul>
<li><strong>Good news:</strong> Elections aren’t simply bought by the highest bidder</li>
<li><strong>Governance matters:</strong> Approval ratings (reflecting job performance) predict success</li>
<li><strong>Economics matter:</strong> But isn’t everything—personality and performance count too</li>
<li><strong>Money has diminishing returns:</strong> First few millions help more than the last few</li>
</ul>
<blockquote class="blockquote">
<p><strong>Final Thought:</strong> If money strongly determined elections, democracy would be in trouble. Our analysis suggests that while money helps, what voters think of you (approval) matters far more. That’s reassuring for democratic theory—and frustrating for billionaires!</p>
</blockquote>
</section>
</section>
<section id="the-fundamental-problem-of-causal-inference" class="level3">
<h3 class="anchored" data-anchor-id="the-fundamental-problem-of-causal-inference">The Fundamental Problem of Causal Inference</h3>
<p>To truly know if money causes votes, we’d need to see the same candidate in parallel universes:</p>
<ul>
<li>Universe A: Candidate spends $5 million → gets 55% of votes</li>
<li>Universe B: Same candidate spends $1 million → gets 52% of votes</li>
<li>True causal effect: 3 percentage points</li>
</ul>
<p><strong>The Problem</strong>: We can’t observe both universes! Each candidate runs once with one amount of spending.</p>
<p>This illustrates the central challenge: <strong>correlation does not imply causation</strong>.</p>
</section>
<section id="when-can-we-make-causal-claims" class="level3">
<h3 class="anchored" data-anchor-id="when-can-we-make-causal-claims">When Can We Make Causal Claims?</h3>
<p>Researchers use several strategies to approximate causal effects:</p>
<p><strong>1. Randomized Experiments</strong></p>
<ul>
<li>Randomly assign treatment (like in medical trials)</li>
<li>Groups identical except for treatment</li>
<li>Differences must be causal</li>
</ul>
<p><em>Example</em>: Randomly mail voter registration forms to some households. Compare turnout.</p>
<p><strong>2. Natural Experiments</strong></p>
<ul>
<li>Find situations where something “as-if random” happens</li>
</ul>
<p>Sometimes nature or institutions create situations that are “as good as random” for research purposes. These natural experiments help us get closer to causal answers without actually running controlled trials.</p>
<p><strong>Example 1: Weather and Voting Behavior</strong></p>
<p><em>Research Question</em>: Does bad weather affect election outcomes?</p>
<p><em>The Natural Experiment</em>: Weather on election day varies randomly - some elections happen during storms, others on beautiful days. Researchers compared election results across similar districts that experienced different weather.</p>
<p><em>Key Findings</em>: Bad weather reduces turnout, and this hurts certain parties more than others (typically parties whose supporters are less motivated to vote in difficult conditions).</p>
<p><em>Why This Works</em>: Weather is random - politicians can’t control if it rains on election day. This gives us quasi-random variation in a factor that affects voting.</p>
<p><strong>Example 2: Terrorism and Economic Activity (Difference-in-Differences)</strong></p>
<p><em>Research Question</em>: What is the economic impact of terrorism?</p>
<p><em>The Natural Experiment</em>: When the Basque terrorist group ETA was active, some Spanish regions experienced terrorist attacks while others did not. Researchers compared economic trends before and after attacks in affected vs.&nbsp;unaffected regions.</p>
<p><em>Key Findings</em>: Regions experiencing terrorism saw reduced business investment and GDP growth compared to similar regions without attacks.</p>
<p><em>Why This Works</em>: Terrorist attacks are largely unpredictable and not based on economic conditions, allowing researchers to isolate terrorism’s causal economic impact.</p>
<p><strong>Example 3: Electoral Systems and Voter Turnout (Regression Discontinuity)</strong></p>
<p><em>Research Question</em>: Do different electoral systems affect how many people vote?</p>
<p><em>The Natural Experiment</em>: Some Spanish municipalities use proportional representation (if population ≥3,000) while others use plurality voting (if population &lt;3,000). Researchers compared turnout in municipalities just above vs.&nbsp;just below this 3,000 threshold.</p>
<p><em>Key Findings</em>: Municipalities with proportional representation have higher voter turnout than those with plurality systems.</p>
<p><em>Why This Works</em>: Municipalities with 2,999 vs.&nbsp;3,001 people are essentially identical except for their electoral system, making this a clean comparison.</p>
<p><strong>Example 4: Close Elections and Policy Outcomes</strong></p>
<p><em>Research Question</em>: Do election outcomes actually matter for policy?</p>
<p><em>The Natural Experiment</em>: In very close elections (decided by &lt;1% of votes), the winner is essentially determined by random factors - who happened to vote, weather, minor campaign events.</p>
<p><em>Key Findings</em>: Comparing districts where conservative candidates barely won vs.&nbsp;barely lost shows concrete differences: conservative winners spend less on social programs, cut taxes more, and appoint different types of judges.</p>
<p><em>Why This Works</em>: In razor-thin margins, which candidate wins is “as good as random,” letting researchers compare what happens under different party control.</p>
<p><strong>3. Statistical Control</strong></p>
<ul>
<li>Measure and include all confounding variables</li>
<li><strong>Big assumption</strong>: You’ve measured everything important</li>
<li>Often unrealistic in social science</li>
</ul>
<blockquote class="blockquote">
<p><strong>⚠️ Remember:</strong> Most regression analysis finds associations, not causation. When someone claims a causal effect, ask: “How do you know it’s not something else?”</p>
</blockquote>
</section>
</section>
<section id="summary-what-youve-learned" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="summary-what-youve-learned"><span class="header-section-number">2.7</span> Summary: What You’ve Learned</h2>
<section id="the-core-ideas" class="level3">
<h3 class="anchored" data-anchor-id="the-core-ideas">The Core Ideas</h3>
<ol type="1">
<li><p><strong>Regression finds average relationships</strong> between variables in messy, real-world data</p></li>
<li><p><strong>Simple regression</strong> examines how one variable predicts another</p></li>
<li><p><strong>Multiple regression</strong> accounts for several factors simultaneously (“controlling for”)</p></li>
<li><p><strong>R² measures predictive power</strong>, but even “low” R² can be meaningful</p></li>
<li><p><strong>Correlation ≠ Causation</strong>: Hidden factors can create spurious relationships</p></li>
</ol>
</section>
<section id="reading-regression-results-a-practical-guide" class="level3">
<h3 class="anchored" data-anchor-id="reading-regression-results-a-practical-guide">Reading Regression Results: A Practical Guide</h3>
<p>When you see: <em>“Education coefficient = 0.04, p &lt; 0.05, controlling for age and income”</em></p>
<p>✅ <strong>Say:</strong> “Among people of similar age and income, each year of education is associated with 0.04 higher participation”</p>
<p>❌ <strong>Don’t say:</strong> “Education causes participation to increase by 0.04”</p>
</section>
<section id="common-pitfalls-to-avoid" class="level3">
<h3 class="anchored" data-anchor-id="common-pitfalls-to-avoid">Common Pitfalls to Avoid</h3>
<ol type="1">
<li><p><strong>Over-interpreting R²</strong>: Human behavior is complex; explaining even 20% is often impressive</p></li>
<li><p><strong>Assuming causation</strong>: Always ask what else might explain the relationship</p></li>
<li><p><strong>Ignoring practical significance</strong>: A “statistically significant” effect might be too small to matter</p></li>
<li><p><strong>Forgetting unmeasured factors</strong>: The error term contains everything you didn’t measure</p></li>
</ol>
<blockquote class="blockquote">
<p><strong>Final Thought:</strong> Regression is like a sophisticated averaging tool. It tells us what typically happens, not what always happens. It reveals patterns but can’t prove causes. Used wisely, it illuminates how our complex social world works. Used carelessly, it misleads.</p>
</blockquote>
</section>
</section>
<section id="quick-reference-regression-in-three-sentences" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="quick-reference-regression-in-three-sentences"><span class="header-section-number">2.8</span> Quick Reference: Regression in Three Sentences</h2>
<ol type="1">
<li><strong>What it does</strong>: Regression finds the average relationship between variables</li>
<li><strong>What it tells us</strong>: How much Y typically changes when X changes</li>
<li><strong>What it doesn’t tell us</strong>: Whether X actually causes Y to change</li>
</ol>
<hr>
<p><em>Remember: The goal isn’t perfect prediction—it’s understanding relationships in our complex world.</em></p>
</section>
<section id="common-pitfalls-in-regression-analysis" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="common-pitfalls-in-regression-analysis"><span class="header-section-number">2.9</span> Common Pitfalls in Regression Analysis (*)</h2>
<section id="pitfall-1-confusing-statistical-and-practical-significance" class="level3">
<h3 class="anchored" data-anchor-id="pitfall-1-confusing-statistical-and-practical-significance">Pitfall 1: Confusing Statistical and Practical Significance</h3>
<p><strong>The Problem</strong>: Mistaking small but statistically significant effects for meaningful findings.</p>
<p><strong>Why It Occurs</strong>: Large samples make tiny effects statistically significant. A study of 100,000 voters might detect that negative ads reduce turnout by 0.0001 percentage points with p &lt; 0.001.</p>
<p><strong>Example</strong>:</p>
<ul>
<li><strong>Reported</strong>: “Negative Ads Significantly Reduce Voter Turnout”</li>
<li><strong>Reality</strong>: Effect = -0.001 percentage points per ad</li>
<li><strong>Practical Impact</strong>: Negligible</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstrate statistical vs practical significance</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Large sample, tiny effect</span></span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>n_large <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>treatment_large <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">each =</span> n_large<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>outcome_large <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.001</span> <span class="sc">*</span> treatment_large <span class="sc">+</span> <span class="fu">rnorm</span>(n_large, <span class="dv">0</span>, <span class="fl">0.1</span>)</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>result_large <span class="ot">&lt;-</span> <span class="fu">t.test</span>(outcome_large <span class="sc">~</span> treatment_large)</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Small sample, larger effect</span></span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>n_small <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>treatment_small <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">each =</span> n_small<span class="sc">/</span><span class="dv">2</span>)</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>outcome_small <span class="ot">&lt;-</span> <span class="fl">0.5</span> <span class="sc">+</span> <span class="fl">0.05</span> <span class="sc">*</span> treatment_small <span class="sc">+</span> <span class="fu">rnorm</span>(n_small, <span class="dv">0</span>, <span class="fl">0.1</span>)</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>result_small <span class="ot">&lt;-</span> <span class="fu">t.test</span>(outcome_small <span class="sc">~</span> treatment_small)</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Statistical versus Practical Significance:</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Statistical versus Practical Significance:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Large sample (n = 10,000):</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Large sample (n = 10,000):</code></pre>
</div>
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  Effect size:"</span>, <span class="fu">round</span>(<span class="fu">diff</span>(result_large<span class="sc">$</span>estimate), <span class="dv">5</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Effect size: 0.00064 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  P-value:"</span>, <span class="fu">format</span>(result_large<span class="sc">$</span>p.value, <span class="at">scientific =</span> <span class="cn">TRUE</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  P-value: 7.488156e-01 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  Assessment: Statistically significant but practically meaningless</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Assessment: Statistically significant but practically meaningless</code></pre>
</div>
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Small sample (n = 100):</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Small sample (n = 100):</code></pre>
</div>
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  Effect size:"</span>, <span class="fu">round</span>(<span class="fu">diff</span>(result_small<span class="sc">$</span>estimate), <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Effect size: 0.031 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  P-value:"</span>, <span class="fu">round</span>(result_small<span class="sc">$</span>p.value, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  P-value: 0.117 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"  Assessment: Not statistically significant but practically meaningful</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  Assessment: Not statistically significant but practically meaningful</code></pre>
</div>
</div>
<p><strong>Effect Size Guidelines</strong> (Cohen’s conventions):</p>
<ul>
<li><strong>Negligible</strong>: &lt; 0.1 standard deviations</li>
<li><strong>Small</strong>: 0.1-0.3 standard deviations</li>
<li><strong>Medium</strong>: 0.3-0.8 standard deviations</li>
<li><strong>Large</strong>: &gt; 0.8 standard deviations</li>
</ul>
<p><strong>Key Principle</strong>: Always evaluate whether effect sizes are large enough to matter substantively.</p>
</section>
<section id="pitfall-2-overfitting" class="level3">
<h3 class="anchored" data-anchor-id="pitfall-2-overfitting">Pitfall 2: Overfitting</h3>
<p><strong>The Problem</strong>: Creating models too complex for available data, causing the model to memorize rather than generalize.</p>
<p><strong>Consequences</strong>: Artificially inflated performance metrics that fail to replicate with new data.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare simple versus complex models</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>n_obs <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data where only X1 matters</span></span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_obs)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_obs)  <span class="co"># Irrelevant</span></span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>x3 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_obs)  <span class="co"># Irrelevant</span></span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>x4 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_obs)  <span class="co"># Irrelevant</span></span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>x5 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_obs)  <span class="co"># Irrelevant</span></span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">+</span> <span class="fl">1.5</span> <span class="sc">*</span> x1 <span class="sc">+</span> <span class="fu">rnorm</span>(n_obs, <span class="dv">0</span>, <span class="dv">1</span>)  <span class="co"># Only X1 actually matters</span></span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare models</span></span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>simple_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1)</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>complex_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> x1 <span class="sc">+</span> x2 <span class="sc">+</span> x3 <span class="sc">+</span> x4 <span class="sc">+</span> x5)</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Model Comparison:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Model Comparison:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Simple model R²:"</span>, <span class="fu">round</span>(<span class="fu">summary</span>(simple_model)<span class="sc">$</span>r.squared, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Simple model R²: 0.719 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Complex model R²:"</span>, <span class="fu">round</span>(<span class="fu">summary</span>(complex_model)<span class="sc">$</span>r.squared, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Complex model R²: 0.73 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Complex adjusted R²:"</span>, <span class="fu">round</span>(<span class="fu">summary</span>(complex_model)<span class="sc">$</span>adj.r.squared, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Complex adjusted R²: 0.699 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Note: Complex model's higher R² is misleading—adjusted R² reveals minimal improvement</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Note: Complex model's higher R² is misleading—adjusted R² reveals minimal improvement</code></pre>
</div>
</div>
<p><strong>Warning Signs</strong>:</p>
<ul>
<li>More variables than justified theoretically</li>
<li>R² increases but adjusted R² stagnates</li>
<li>Poor out-of-sample prediction</li>
<li>Inclusion of variables without theoretical justification</li>
</ul>
<p><strong>Adjusted R² Explanation</strong>: Unlike regular R², adjusted R² penalizes model complexity, providing honest assessment of model improvement.</p>
<p><strong>Prevention Strategies</strong>:</p>
<ul>
<li>Include only theoretically justified variables</li>
<li>Monitor adjusted R² rather than R²</li>
<li>Use cross-validation</li>
<li>Maintain parsimony</li>
</ul>
</section>
<section id="pitfall-3-multiple-testing-problem" class="level3">
<h3 class="anchored" data-anchor-id="pitfall-3-multiple-testing-problem">Pitfall 3: Multiple Testing Problem</h3>
<p><strong>The Problem</strong>: Testing numerous relationships and reporting only significant ones.</p>
<p><strong>Statistical Reality</strong>: With α = 0.05, expect 5% false positives. Testing 20 relationships yields approximately one spurious “significant” result.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate multiple testing problem</span></span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">789</span>)</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a>n_tests <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a>p_values <span class="ot">&lt;-</span> <span class="fu">numeric</span>(n_tests)</span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Run tests where no true effect exists</span></span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_tests) {</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>  x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">100</span>)  <span class="co"># Y unrelated to X</span></span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a>  test_result <span class="ot">&lt;-</span> <span class="fu">cor.test</span>(x, y)</span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>  p_values[i] <span class="ot">&lt;-</span> test_result<span class="sc">$</span>p.value</span>
<span id="cb57-12"><a href="#cb57-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb57-13"><a href="#cb57-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-14"><a href="#cb57-14" aria-hidden="true" tabindex="-1"></a>significant_tests <span class="ot">&lt;-</span> <span class="fu">sum</span>(p_values <span class="sc">&lt;</span> <span class="fl">0.05</span>)</span>
<span id="cb57-15"><a href="#cb57-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-16"><a href="#cb57-16" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Multiple Testing Demonstration:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Multiple Testing Demonstration:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Tests conducted:"</span>, n_tests, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Tests conducted: 20 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"'Significant' results:"</span>, significant_tests, <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>'Significant' results: 0 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Expected by chance:"</span>, <span class="fu">round</span>(n_tests <span class="sc">*</span> <span class="fl">0.05</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Expected by chance: 1 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Smallest p-value:"</span>, <span class="fu">round</span>(<span class="fu">min</span>(p_values), <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Smallest p-value: 0.0541 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span>(significant_tests <span class="sc">&gt;</span> <span class="dv">0</span>) {</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">cat</span>(<span class="st">"Selective reporting of significant results would create false positives</span><span class="sc">\n</span><span class="st">"</span>)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Pre-registration of hypotheses</li>
<li>Bonferroni or false discovery rate corrections</li>
<li>Complete reporting of all tests</li>
<li>Theory-driven hypothesis testing</li>
</ul>
</section>
<section id="pitfall-4-ecological-fallacy" class="level3">
<h3 class="anchored" data-anchor-id="pitfall-4-ecological-fallacy">Pitfall 4: Ecological Fallacy</h3>
<p><strong>The Problem</strong>: Inferring individual-level relationships from group-level data.</p>
<p><strong>Classic Example</strong>: “Wealthy states vote Democratic, therefore wealthy individuals vote Democratic” <strong>Reality</strong>: Within states, wealth often correlates with Republican voting</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstrate ecological fallacy</span></span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a><span class="co"># State-level: wealth correlates with Democratic voting</span></span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>state_income <span class="ot">&lt;-</span> <span class="fu">runif</span>(<span class="dv">50</span>, <span class="dv">40000</span>, <span class="dv">80000</span>)</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>state_dem_vote <span class="ot">&lt;-</span> <span class="dv">30</span> <span class="sc">+</span> <span class="fl">0.0005</span> <span class="sc">*</span> state_income <span class="sc">+</span> <span class="fu">rnorm</span>(<span class="dv">50</span>, <span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>state_correlation <span class="ot">&lt;-</span> <span class="fu">cor</span>(state_income, state_dem_vote)</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Individual-level: opposite relationship</span></span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>individual_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>) {</span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>  n_people <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>  indiv_income <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_people, state_income[i], <span class="dv">15000</span>)</span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a>  prob_dem <span class="ot">&lt;-</span> <span class="fu">plogis</span>((state_dem_vote[i]<span class="sc">/</span><span class="dv">100</span>) <span class="sc">-</span> <span class="fl">0.00002</span> <span class="sc">*</span> (indiv_income <span class="sc">-</span> state_income[i]))</span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>  vote_dem <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_people, <span class="dv">1</span>, prob_dem)</span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb68-17"><a href="#cb68-17" aria-hidden="true" tabindex="-1"></a>  state_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb68-18"><a href="#cb68-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">state =</span> i,</span>
<span id="cb68-19"><a href="#cb68-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">income =</span> indiv_income,</span>
<span id="cb68-20"><a href="#cb68-20" aria-hidden="true" tabindex="-1"></a>    <span class="at">dem_vote =</span> vote_dem <span class="sc">*</span> <span class="dv">100</span></span>
<span id="cb68-21"><a href="#cb68-21" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb68-22"><a href="#cb68-22" aria-hidden="true" tabindex="-1"></a>  individual_data <span class="ot">&lt;-</span> <span class="fu">rbind</span>(individual_data, state_data)</span>
<span id="cb68-23"><a href="#cb68-23" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb68-24"><a href="#cb68-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-25"><a href="#cb68-25" aria-hidden="true" tabindex="-1"></a>individual_correlation <span class="ot">&lt;-</span> <span class="fu">cor</span>(individual_data<span class="sc">$</span>income, individual_data<span class="sc">$</span>dem_vote)</span>
<span id="cb68-26"><a href="#cb68-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb68-27"><a href="#cb68-27" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"State-level correlation (income vs. Democratic vote):"</span>, <span class="fu">round</span>(state_correlation, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>State-level correlation (income vs. Democratic vote): 0.75 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb70"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Individual-level correlation (income vs. Democratic vote):"</span>, <span class="fu">round</span>(individual_correlation, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Individual-level correlation (income vs. Democratic vote): -0.09 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb72"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"</span><span class="sc">\n</span><span class="st">Opposite signs demonstrate the ecological fallacy</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Opposite signs demonstrate the ecological fallacy</code></pre>
</div>
</div>
</section>
<section id="pitfall-5-selection-bias" class="level3">
<h3 class="anchored" data-anchor-id="pitfall-5-selection-bias">Pitfall 5: Selection Bias</h3>
<p><strong>The Problem</strong>: Drawing inferences from non-representative samples.</p>
<p><strong>Common Sources</strong>:</p>
<ul>
<li>Surveying only landline users (age bias)</li>
<li>Studying only volunteers (motivation bias)</li>
<li>Analyzing only successful cases (survivorship bias)</li>
<li>Using convenience samples (accessibility bias)</li>
</ul>
<p><strong>Consequence</strong>: Systematic bias that statistical techniques cannot correct.</p>
</section>
<section id="pitfall-6-ignoring-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="pitfall-6-ignoring-uncertainty">Pitfall 6: Ignoring Uncertainty</h3>
<p><strong>The Problem</strong>: Treating point estimates as precise values.</p>
<p><strong>Incorrect</strong>: “Support is 52%” <strong>Better</strong>: “Support is 52% ± 3%” <strong>Best</strong>: “95% confidence interval: [49%, 55%]”</p>
<p><strong>Importance</strong>: Acknowledging uncertainty prevents overconfident conclusions.</p>
</section>
<section id="pitfall-7-spurious-correlations" class="level3">
<h3 class="anchored" data-anchor-id="pitfall-7-spurious-correlations">Pitfall 7: Spurious Correlations</h3>
<p><strong>The Problem</strong>: Variables correlate by coincidence, particularly with time trends.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb74"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstrate spurious correlation</span></span>
<span id="cb74-2"><a href="#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb74-3"><a href="#cb74-3" aria-hidden="true" tabindex="-1"></a>years <span class="ot">&lt;-</span> <span class="dv">1990</span><span class="sc">:</span><span class="dv">2020</span></span>
<span id="cb74-4"><a href="#cb74-4" aria-hidden="true" tabindex="-1"></a>n_years <span class="ot">&lt;-</span> <span class="fu">length</span>(years)</span>
<span id="cb74-5"><a href="#cb74-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-6"><a href="#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Unrelated variables with time trends</span></span>
<span id="cb74-7"><a href="#cb74-7" aria-hidden="true" tabindex="-1"></a>internet_users <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="sc">+</span> <span class="fl">2.5</span> <span class="sc">*</span> (years <span class="sc">-</span> <span class="dv">1990</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(n_years, <span class="dv">0</span>, <span class="dv">3</span>)</span>
<span id="cb74-8"><a href="#cb74-8" aria-hidden="true" tabindex="-1"></a>pizza_consumption <span class="ot">&lt;-</span> <span class="dv">50</span> <span class="sc">+</span> <span class="fl">1.2</span> <span class="sc">*</span> (years <span class="sc">-</span> <span class="dv">1990</span>) <span class="sc">+</span> <span class="fu">rnorm</span>(n_years, <span class="dv">0</span>, <span class="dv">2</span>)</span>
<span id="cb74-9"><a href="#cb74-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-10"><a href="#cb74-10" aria-hidden="true" tabindex="-1"></a>spurious_corr <span class="ot">&lt;-</span> <span class="fu">cor</span>(internet_users, pizza_consumption)</span>
<span id="cb74-11"><a href="#cb74-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-12"><a href="#cb74-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Remove time trends</span></span>
<span id="cb74-13"><a href="#cb74-13" aria-hidden="true" tabindex="-1"></a>internet_detrended <span class="ot">&lt;-</span> <span class="fu">residuals</span>(<span class="fu">lm</span>(internet_users <span class="sc">~</span> years))</span>
<span id="cb74-14"><a href="#cb74-14" aria-hidden="true" tabindex="-1"></a>pizza_detrended <span class="ot">&lt;-</span> <span class="fu">residuals</span>(<span class="fu">lm</span>(pizza_consumption <span class="sc">~</span> years))</span>
<span id="cb74-15"><a href="#cb74-15" aria-hidden="true" tabindex="-1"></a>true_corr <span class="ot">&lt;-</span> <span class="fu">cor</span>(internet_detrended, pizza_detrended)</span>
<span id="cb74-16"><a href="#cb74-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb74-17"><a href="#cb74-17" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Spurious Correlation Analysis:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Spurious Correlation Analysis:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb76"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Correlation with time trends:"</span>, <span class="fu">round</span>(spurious_corr, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Correlation with time trends: 0.982 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Correlation after detrending:"</span>, <span class="fu">round</span>(true_corr, <span class="dv">3</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Correlation after detrending: 0.136 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb80"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb80-1"><a href="#cb80-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Conclusion: Apparent correlation driven by common time trends</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Conclusion: Apparent correlation driven by common time trends</code></pre>
</div>
</div>
<p><strong>Detection Methods</strong>:</p>
<ul>
<li>Examine theoretical plausibility</li>
<li>Check for common time trends</li>
<li>Look for third variables</li>
<li>Inspect scatterplots</li>
</ul>
</section>
<section id="pitfall-8-confounding-variables" class="level3">
<h3 class="anchored" data-anchor-id="pitfall-8-confounding-variables">Pitfall 8: Confounding Variables</h3>
<p><strong>The Problem</strong>: A third variable influences both predictor and outcome, creating misleading relationships.</p>
<p><strong>The Confounding Structure</strong>:</p>
<ul>
<li>Z → X (confounder affects predictor)</li>
<li>Z → Y (confounder affects outcome)</li>
<li>Creates spurious X → Y relationship</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb82"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Demonstrate confounding</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a>n_districts <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Socioeconomic status confounds spending-votes relationship</span></span>
<span id="cb82-6"><a href="#cb82-6" aria-hidden="true" tabindex="-1"></a>ses <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_districts, <span class="dv">0</span>, <span class="dv">1</span>)</span>
<span id="cb82-7"><a href="#cb82-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-8"><a href="#cb82-8" aria-hidden="true" tabindex="-1"></a><span class="co"># SES affects both variables</span></span>
<span id="cb82-9"><a href="#cb82-9" aria-hidden="true" tabindex="-1"></a>campaign_spending <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="sc">+</span> <span class="dv">50</span> <span class="sc">*</span> ses <span class="sc">+</span> <span class="fu">rnorm</span>(n_districts, <span class="dv">0</span>, <span class="dv">20</span>)</span>
<span id="cb82-10"><a href="#cb82-10" aria-hidden="true" tabindex="-1"></a>campaign_spending <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="dv">10</span>, campaign_spending)</span>
<span id="cb82-11"><a href="#cb82-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-12"><a href="#cb82-12" aria-hidden="true" tabindex="-1"></a>vote_share <span class="ot">&lt;-</span> <span class="dv">50</span> <span class="sc">+</span> <span class="dv">8</span> <span class="sc">*</span> ses <span class="sc">+</span> <span class="fl">0.02</span> <span class="sc">*</span> campaign_spending <span class="sc">+</span> <span class="fu">rnorm</span>(n_districts, <span class="dv">0</span>, <span class="dv">5</span>)</span>
<span id="cb82-13"><a href="#cb82-13" aria-hidden="true" tabindex="-1"></a>vote_share <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="dv">0</span>, <span class="fu">pmin</span>(<span class="dv">100</span>, vote_share))</span>
<span id="cb82-14"><a href="#cb82-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-15"><a href="#cb82-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Compare models</span></span>
<span id="cb82-16"><a href="#cb82-16" aria-hidden="true" tabindex="-1"></a>naive_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(vote_share <span class="sc">~</span> campaign_spending, <span class="at">data =</span> <span class="fu">data.frame</span>(campaign_spending, vote_share))</span>
<span id="cb82-17"><a href="#cb82-17" aria-hidden="true" tabindex="-1"></a>controlled_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(vote_share <span class="sc">~</span> campaign_spending <span class="sc">+</span> ses, </span>
<span id="cb82-18"><a href="#cb82-18" aria-hidden="true" tabindex="-1"></a>                      <span class="at">data =</span> <span class="fu">data.frame</span>(campaign_spending, vote_share, ses))</span>
<span id="cb82-19"><a href="#cb82-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb82-20"><a href="#cb82-20" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Campaign Spending Effects:</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Campaign Spending Effects:</code></pre>
</div>
<div class="sourceCode cell-code" id="cb84"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Without SES control:"</span>, <span class="fu">round</span>(<span class="fu">coef</span>(naive_model)[<span class="dv">2</span>], <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Without SES control: 0.1601 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb86"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb86-1"><a href="#cb86-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"With SES control:"</span>, <span class="fu">round</span>(<span class="fu">coef</span>(controlled_model)[<span class="dv">2</span>], <span class="dv">4</span>), <span class="st">"</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>With SES control: 0.0052 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb88"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"True effect: 0.02</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>True effect: 0.02</code></pre>
</div>
</div>
<p><strong>Types of Confounding</strong>:</p>
<ol type="1">
<li><strong>Positive Confounding</strong>: Exaggerates relationships</li>
<li><strong>Negative Confounding</strong>: Masks relationships</li>
<li><strong>Sign Reversal</strong>: Reverses relationship direction</li>
</ol>
<p><strong>Solutions</strong>:</p>
<ul>
<li>Theoretical identification of confounders</li>
<li>Causal diagrams</li>
<li>Statistical control</li>
<li>Research design solutions</li>
</ul>
</section>
</section>
<section id="guidelines-for-research-consumers" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="guidelines-for-research-consumers"><span class="header-section-number">2.10</span> Guidelines for Research Consumers</h2>
<p>When evaluating research, consider:</p>
<ol type="1">
<li><strong>Effect Size</strong>: Is the magnitude practically meaningful?</li>
<li><strong>Sample</strong>: Who is included/excluded? How might this bias results?</li>
<li><strong>Multiple Testing</strong>: Were many tests conducted? Is there cherry-picking?</li>
<li><strong>Causation</strong>: What is the identification strategy?</li>
<li><strong>Model Complexity</strong>: Does complexity match data availability?</li>
<li><strong>Uncertainty</strong>: Are confidence intervals reported?</li>
</ol>
</section>
<section id="conclusion-1" class="level2" data-number="2.11">
<h2 data-number="2.11" class="anchored" data-anchor-id="conclusion-1"><span class="header-section-number">2.11</span> Conclusion</h2>
<p>Regression analysis provides systematic methods for testing theoretical propositions against empirical data. While it cannot definitively establish causation without appropriate research designs, it offers valuable tools for understanding relationships in observational data.</p>
<p><strong>Key Principles</strong>:</p>
<ul>
<li>Regression identifies best-fitting linear relationships</li>
<li>Multiple regression controls for confounding variables</li>
<li>Correlation does not establish causation</li>
<li>Effect sizes matter more than statistical significance</li>
<li>All analyses have limitations requiring acknowledgment</li>
</ul>
<p>These analytical skills enable critical evaluation of empirical claims in academic research, policy debates, and political discourse. Understanding regression means not only conducting analyses but also recognizing the strengths and limitations of statistical evidence in social science research.</p>
</section>
<section id="practical-advice-for-political-science-research" class="level2" data-number="2.12">
<h2 data-number="2.12" class="anchored" data-anchor-id="practical-advice-for-political-science-research"><span class="header-section-number">2.12</span> Practical Advice for Political Science Research</h2>
<section id="start-with-theory" class="level3">
<h3 class="anchored" data-anchor-id="start-with-theory">1. Start with Theory</h3>
<p>Statistics is a tool, not a substitute for thinking:</p>
<ul>
<li>What relationship do you expect and why?</li>
<li>What would falsify your hypothesis?</li>
<li>What alternative explanations exist?</li>
</ul>
</section>
<section id="know-your-data" class="level3">
<h3 class="anchored" data-anchor-id="know-your-data">2. Know Your Data</h3>
<p>Before any analysis:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb90"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Essential diagnostic steps</span></span>
<span id="cb90-2"><a href="#cb90-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)           <span class="co"># Basic statistics</span></span>
<span id="cb90-3"><a href="#cb90-3" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(data<span class="sc">$</span>variable)    <span class="co"># Frequency tables</span></span>
<span id="cb90-4"><a href="#cb90-4" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data<span class="sc">$</span>variable)     <span class="co"># Distribution</span></span>
<span id="cb90-5"><a href="#cb90-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x, y)             <span class="co"># Scatterplots</span></span>
<span id="cb90-6"><a href="#cb90-6" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(data)              <span class="co"># Correlation matrix</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="match-method-to-question" class="level3">
<h3 class="anchored" data-anchor-id="match-method-to-question">3. Match Method to Question</h3>
<ul>
<li><strong>Describing</strong>: Means, proportions, distributions</li>
<li><strong>Predicting</strong>: Regression, machine learning</li>
<li><strong>Causal inference</strong>: Experiments, quasi-experiments, panel methods</li>
</ul>
</section>
<section id="interpret-substantively" class="level3">
<h3 class="anchored" data-anchor-id="interpret-substantively">4. Interpret Substantively</h3>
<p>Always translate statistics back to political science:</p>
<ul>
<li>What does a one-unit change mean substantively?</li>
<li>Is the effect politically meaningful?</li>
<li>What are the policy implications?</li>
</ul>
</section>
<section id="be-transparent" class="level3">
<h3 class="anchored" data-anchor-id="be-transparent">5. Be Transparent</h3>
<ul>
<li>Report all analyses, not just significant results</li>
<li>Share data and code when possible</li>
<li>Acknowledge limitations</li>
<li>Describe robustness checks</li>
</ul>
</section>
</section>
<section id="practice-problems" class="level2" data-number="2.13">
<h2 data-number="2.13" class="anchored" data-anchor-id="practice-problems"><span class="header-section-number">2.13</span> Practice Problems</h2>
<section id="problem-1-identifying-populations-and-samples" class="level3">
<h3 class="anchored" data-anchor-id="problem-1-identifying-populations-and-samples">Problem 1: Identifying Populations and Samples</h3>
<p>You want to understand what factors influence democratic transitions.</p>
<ul>
<li>What could be your population?</li>
<li>How would you select a sample?</li>
<li>What biases might you face?</li>
</ul>
</section>
<section id="problem-2-interpreting-results" class="level3">
<h3 class="anchored" data-anchor-id="problem-2-interpreting-results">Problem 2: Interpreting Results</h3>
<p>A study finds: “Education increases voter turnout by 2.3 percentage points per year of schooling (p = 0.02)”</p>
<ul>
<li>What does the p = 0.02 mean in plain English?</li>
<li>If someone has 4 more years of education than another person, how much more likely are they to vote?</li>
<li>Is this a big or small effect? (Consider: typical turnout is around 60%)</li>
</ul>
</section>
<section id="problem-3-correlation-vs.-causation" class="level3">
<h3 class="anchored" data-anchor-id="problem-3-correlation-vs.-causation">Problem 3: Correlation vs.&nbsp;Causation</h3>
<p>“Countries with more McDonald’s restaurants have lower infant mortality rates”</p>
<ul>
<li>Give three possible explanations for this pattern</li>
<li>How could you test which explanation is correct?</li>
<li>What data would you need?</li>
</ul>
</section>
<section id="problem-4-regression-interpretation" class="level3">
<h3 class="anchored" data-anchor-id="problem-4-regression-interpretation">Problem 4: Regression Interpretation</h3>
<p>You run a regression predicting congressional vote share with these results:</p>
<pre><code>Vote Share = 45.2 + 0.31*Approval + 2.1*Economy - 0.05*Age
             (0.8)  (0.04)         (0.6)       (0.02)

R² = 0.67, n = 435
Standard errors in parentheses</code></pre>
<p>Interpret each coefficient substantively and assess statistical significance.</p>
</section>
</section>
<section id="essential-r-code-for-getting-started" class="level2" data-number="2.14">
<h2 data-number="2.14" class="anchored" data-anchor-id="essential-r-code-for-getting-started"><span class="header-section-number">2.14</span> Essential R Code for Getting Started</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb92"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Reading data</span></span>
<span id="cb92-2"><a href="#cb92-2" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"yourfile.csv"</span>)     <span class="co"># Load a CSV file</span></span>
<span id="cb92-3"><a href="#cb92-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-4"><a href="#cb92-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Basic exploration</span></span>
<span id="cb92-5"><a href="#cb92-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(data)                         <span class="co"># See basic statistics for all variables</span></span>
<span id="cb92-6"><a href="#cb92-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(data)                           <span class="co"># Look at first few rows</span></span>
<span id="cb92-7"><a href="#cb92-7" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(data<span class="sc">$</span>party)                    <span class="co"># Count how many in each category</span></span>
<span id="cb92-8"><a href="#cb92-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-9"><a href="#cb92-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple analysis</span></span>
<span id="cb92-10"><a href="#cb92-10" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(data<span class="sc">$</span>age)                       <span class="co"># Calculate average age</span></span>
<span id="cb92-11"><a href="#cb92-11" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(data<span class="sc">$</span>income, data<span class="sc">$</span>turnout)      <span class="co"># Correlation between two variables</span></span>
<span id="cb92-12"><a href="#cb92-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-13"><a href="#cb92-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Basic visualization</span></span>
<span id="cb92-14"><a href="#cb92-14" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(data<span class="sc">$</span>age)                       <span class="co"># Histogram of age distribution</span></span>
<span id="cb92-15"><a href="#cb92-15" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(data<span class="sc">$</span>education, data<span class="sc">$</span>turnout)  <span class="co"># Scatterplot of two variables</span></span>
<span id="cb92-16"><a href="#cb92-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-17"><a href="#cb92-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Difference between groups</span></span>
<span id="cb92-18"><a href="#cb92-18" aria-hidden="true" tabindex="-1"></a><span class="fu">t.test</span>(income <span class="sc">~</span> gender, <span class="at">data =</span> data) <span class="co"># Compare average income by gender</span></span>
<span id="cb92-19"><a href="#cb92-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-20"><a href="#cb92-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Simple regression</span></span>
<span id="cb92-21"><a href="#cb92-21" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(turnout <span class="sc">~</span> education, <span class="at">data =</span> data)  <span class="co"># Run regression</span></span>
<span id="cb92-22"><a href="#cb92-22" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model)                                  <span class="co"># See results</span></span>
<span id="cb92-23"><a href="#cb92-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-24"><a href="#cb92-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Multiple regression</span></span>
<span id="cb92-25"><a href="#cb92-25" aria-hidden="true" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(turnout <span class="sc">~</span> education <span class="sc">+</span> age <span class="sc">+</span> income, <span class="at">data =</span> data)</span>
<span id="cb92-26"><a href="#cb92-26" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model2)</span>
<span id="cb92-27"><a href="#cb92-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb92-28"><a href="#cb92-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create nice plots with ggplot2</span></span>
<span id="cb92-29"><a href="#cb92-29" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb92-30"><a href="#cb92-30" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data, <span class="fu">aes</span>(<span class="at">x =</span> education, <span class="at">y =</span> turnout)) <span class="sc">+</span></span>
<span id="cb92-31"><a href="#cb92-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb92-32"><a href="#cb92-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>) <span class="sc">+</span></span>
<span id="cb92-33"><a href="#cb92-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Education and Turnout"</span>,</span>
<span id="cb92-34"><a href="#cb92-34" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Years of Education"</span>, </span>
<span id="cb92-35"><a href="#cb92-35" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Voter Turnout"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="final-thoughts" class="level2" data-number="2.15">
<h2 data-number="2.15" class="anchored" data-anchor-id="final-thoughts"><span class="header-section-number">2.15</span> Final Thoughts</h2>
<p>Statistics is not just a tool—it’s a way of thinking about evidence, uncertainty, and inference. As citizens and scholars, developing statistical intuition helps us:</p>
<ul>
<li>Critically evaluate political claims</li>
<li>Design better research</li>
<li>Make more informed decisions</li>
<li>Understand the limits of what we can know</li>
</ul>
<p>Remember: <strong>Every number tells a story, but not every story told by numbers is true.</strong> Your job is to develop the skills to tell the difference.</p>
<p>The goal isn’t to become a statistician, but to become a political scientist who can evaluate and produce rigorous evidence. Statistics helps us move from hunches to hypotheses to evidence-based conclusions about the political world.</p>
<p>As you continue your journey in political science, always remember that behind every statistical analysis are real people, real policies, and real consequences. The tools you’ve learned here will help you contribute to our understanding of politics and hopefully make the world a bit better informed.</p>
<hr>
</section>
<section id="appendix-a-sampling-methods" class="level2" data-number="2.16">
<h2 data-number="2.16" class="anchored" data-anchor-id="appendix-a-sampling-methods"><span class="header-section-number">2.16</span> Appendix A: Sampling Methods</h2>
<section id="probability-sampling" class="level3">
<h3 class="anchored" data-anchor-id="probability-sampling">Probability Sampling</h3>
<p>Probability sampling methods involve random selection, giving each member of the population a known, non-zero chance of being selected. These methods allow researchers to calculate sampling error and make statistical inferences about the population.</p>
<ol type="1">
<li><strong>Simple Random Sampling (SRS)</strong>
<ul>
<li><strong>Definition</strong>: Each member of the population has an equal chance of being selected.</li>
<li><strong>Advantages</strong>: Minimizes selection bias; allows straightforward statistical analysis.</li>
<li><strong>Disadvantages</strong>: Requires a complete sampling frame; may not capture enough members of smaller subgroups.</li>
<li><strong>Example</strong>: To select 100 students from a university with 10,000 students, assign each student a number and use a random number generator to select 100 numbers.</li>
<li><strong>Best used when</strong>: The population is relatively homogeneous and a complete list of population members is available.</li>
</ul></li>
<li><strong>Stratified Random Sampling</strong>
<ul>
<li><strong>Definition</strong>: The population is divided into mutually exclusive subgroups (strata) based on shared characteristics, then samples are randomly selected from each stratum.</li>
<li><strong>Advantages</strong>: Ensures representation of key subgroups; can improve precision for same sample size as SRS; allows analysis within and between strata.</li>
<li><strong>Disadvantages</strong>: Requires prior knowledge of population characteristics for stratification; more complex analysis.</li>
<li><strong>Example</strong>: In a national political survey, divide the population into strata based on geographic regions (Northeast, Midwest, South, West) and then randomly sample from each region proportionally to their population size.</li>
<li><strong>Best used when</strong>: The population contains distinct subgroups that might respond differently to the research question.</li>
</ul></li>
<li><strong>Cluster Sampling</strong>
<ul>
<li><strong>Definition</strong>: The population is divided into clusters (usually geographic), some clusters are randomly selected, and all members within those clusters are studied.</li>
<li><strong>Advantages</strong>: More cost-effective when population is geographically dispersed; doesn’t require a complete list of population members.</li>
<li><strong>Disadvantages</strong>: Lower statistical precision than SRS or stratified sampling; clusters must be representative.</li>
<li><strong>Example</strong>: To study high school students’ study habits, randomly select 20 high schools from across the country and survey all students in those schools.</li>
<li><strong>Best used when</strong>: The population is widely dispersed geographically and traveling to all units would be costly.</li>
</ul></li>
<li><strong>Systematic Sampling</strong>
<ul>
<li><strong>Definition</strong>: Selecting every kth item from a list after a random start.</li>
<li><strong>Advantages</strong>: Simple to implement; often more practical than SRS; can avoid neighbor effects.</li>
<li><strong>Disadvantages</strong>: Can introduce bias if there’s a periodic pattern in the list.</li>
<li><strong>Example</strong>: At a busy shopping mall, survey every 20th person who enters, starting with a randomly chosen number between 1 and 20.</li>
<li><strong>Best used when</strong>: The population is ordered randomly or in a way unrelated to the study variables.</li>
</ul></li>
<li><strong>Multi-stage Sampling</strong>
<ul>
<li><strong>Definition</strong>: Combining multiple sampling methods in stages.</li>
<li><strong>Advantages</strong>: Practical for large-scale surveys; balances cost and precision.</li>
<li><strong>Disadvantages</strong>: Complex design and analysis; multiple stages can compound sampling errors.</li>
<li><strong>Example</strong>: First randomly select counties (cluster sampling), then randomly select households within those counties (simple random sampling), and finally select one adult from each household (systematic sampling).</li>
<li><strong>Best used when</strong>: Studying large, complex populations across wide geographical areas.</li>
</ul></li>
</ol>
</section>
<section id="non-probability-sampling" class="level3">
<h3 class="anchored" data-anchor-id="non-probability-sampling">Non-probability Sampling</h3>
<p>Non-probability sampling doesn’t involve random selection, which means statistical inferences about the population must be made with caution. While it can introduce bias, it may be necessary in certain situations.</p>
<ol type="1">
<li><strong>Convenience Sampling</strong>
<ul>
<li><strong>Definition</strong>: Selecting easily accessible subjects.</li>
<li><strong>Advantages</strong>: Fast, inexpensive, and easy to implement.</li>
<li><strong>Disadvantages</strong>: High risk of selection bias; limits generalizability.</li>
<li><strong>Example</strong>: A researcher studying college students’ sleep patterns might survey students in their own classes.</li>
<li><strong>Best used for</strong>: Pilot studies, exploratory research, or when resources are severely limited.</li>
</ul></li>
<li><strong>Purposive Sampling</strong>
<ul>
<li><strong>Definition</strong>: Selecting subjects based on specific characteristics relevant to the research question.</li>
<li><strong>Advantages</strong>: Focuses on relevant cases; useful for in-depth studies of specific groups.</li>
<li><strong>Disadvantages</strong>: Researcher bias in selection; limited generalizability.</li>
<li><strong>Example</strong>: For a study on the experiences of CEOs in the tech industry, intentionally seek out and interview CEOs from various tech companies.</li>
<li><strong>Best used for</strong>: Qualitative research, case studies, or studying unique populations.</li>
</ul></li>
<li><strong>Snowball Sampling</strong>
<ul>
<li><strong>Definition</strong>: Participants recruit other participants from their networks.</li>
<li><strong>Advantages</strong>: Access to hard-to-reach or hidden populations; builds on social networks.</li>
<li><strong>Disadvantages</strong>: Sample biased toward those in certain social networks; cannot calculate selection probabilities.</li>
<li><strong>Example</strong>: In a study of undocumented immigrants’ access to healthcare, researchers ask initial participants to refer other potential participants.</li>
<li><strong>Best used for</strong>: Studying rare populations or sensitive topics where no sampling frame exists.</li>
</ul></li>
<li><strong>Quota Sampling</strong>
<ul>
<li><strong>Definition</strong>: Selecting participants to meet specific quotas for certain characteristics to match known population parameters.</li>
<li><strong>Advantages</strong>: Ensures representation of key demographic groups; faster and cheaper than probability sampling; doesn’t require sampling frame.</li>
<li><strong>Disadvantages</strong>: Non-random selection within quotas can introduce bias; inference is limited.</li>
<li><strong>Example</strong>: In a market research study, researchers ensure they interview specific numbers of people from different age groups, genders, and income levels.</li>
<li><strong>Best used for</strong>: Commercial polling, market research, or when probability sampling is not feasible.</li>
</ul></li>
</ol>
</section>
<section id="why-pollsters-increasingly-use-quota-sampling" class="level3">
<h3 class="anchored" data-anchor-id="why-pollsters-increasingly-use-quota-sampling">Why Pollsters Increasingly Use Quota Sampling</h3>
<p>In recent years, many polling organizations have shifted toward quota sampling approaches for several key reasons:</p>
<ol type="1">
<li><p><strong>Declining Response Rates</strong>: Traditional probability-based telephone polls have seen response rates drop from about 36% in the 1990s to less than 10% today. This increases costs and potentially introduces non-response bias that can be worse than selection bias from non-probability methods.</p></li>
<li><p><strong>Coverage Issues</strong>: Random digit dialing no longer reaches a representative sample of the population as many people have abandoned landlines for cell phones, and many don’t answer calls from unknown numbers.</p></li>
<li><p><strong>Cost Efficiency</strong>: Probability-based polls have become prohibitively expensive as response rates decline, while online panels and quota sampling are more affordable.</p></li>
<li><p><strong>Speed</strong>: In fast-moving political campaigns or rapidly evolving public opinion situations, quota sampling can deliver results much faster than probability methods.</p></li>
<li><p><strong>Weighting and Modeling Improvements</strong>: Modern statistical techniques allow pollsters to adjust quota samples to better represent the target population by weighting responses based on known population parameters.</p></li>
<li><p><strong>Hybrid Approaches</strong>: Many pollsters now use hybrid methods that combine elements of probability and non-probability sampling, with sophisticated weighting and modeling to improve accuracy.</p></li>
</ol>
<p>The 2016 US presidential election, where many polls failed to predict the outcome accurately, led to considerable soul-searching among pollsters. Rather than abandoning quota sampling, many organizations have refined their methods, focusing on better quota definitions, improved weighting techniques, and more transparent reporting of methodological limitations.</p>
<p>Despite these trends, it’s important to note that probability sampling remains the gold standard for statistical inference. Well-designed probability samples still provide the most reliable foundation for generalizing from sample to population, especially for academic research where accuracy is prioritized over cost and speed.</p>
</section>
</section>
<section id="appendix-a-measuring-uncertainty-in-data" class="level2" data-number="2.17">
<h2 data-number="2.17" class="anchored" data-anchor-id="appendix-a-measuring-uncertainty-in-data"><span class="header-section-number">2.17</span> Appendix A: Measuring Uncertainty in Data (*)</h2>
<section id="fundamental-principle" class="level3">
<h3 class="anchored" data-anchor-id="fundamental-principle">Fundamental Principle</h3>
<p><strong>Statistics does not eliminate uncertainty—it helps us measure, manage, and communicate it effectively.</strong></p>
<hr>
</section>
<section id="two-types-of-error-random-error-and-bias" class="level3">
<h3 class="anchored" data-anchor-id="two-types-of-error-random-error-and-bias">1. Two Types of Error: Random Error and Bias</h3>
<p><strong>Random Error (Sampling Variability)</strong></p>
<ul>
<li>Varies unpredictably from sample to sample</li>
<li>Decreases with larger sample sizes</li>
<li>Can be quantified using standard errors and confidence intervals</li>
<li>Example: Different samples of 100 voters will yield slightly different percentages supporting a candidate</li>
</ul>
<p><strong>Bias (Systematic Error)</strong></p>
<ul>
<li>Consistent deviation from the true value</li>
<li>Does NOT decrease with larger sample sizes</li>
<li>Cannot be quantified through standard statistical formulas</li>
<li>Example: Conducting an online survey about household income excludes households without internet access, likely underestimating poverty rates</li>
</ul>
<hr>
</section>
<section id="two-types-of-variability" class="level3">
<h3 class="anchored" data-anchor-id="two-types-of-variability">2. Two Types of Variability</h3>
<p><strong>Standard Deviation (SD)</strong></p>
<ul>
<li>Measures the spread of individual data points around the mean</li>
<li>Quantifies the typical distance between observations and their average</li>
<li>Formula: <span class="math inline">s = \sqrt{\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2}</span></li>
</ul>
<p><strong>Standard Error (SE)</strong></p>
<ul>
<li>Measures the precision of a sample statistic (such as the mean)</li>
<li>Quantifies random sampling variability only (not bias)</li>
<li>Formula: <span class="math inline">SE(\bar{x}) = \frac{s}{\sqrt{n}}</span></li>
</ul>
<p><strong>Key Observation:</strong> As sample size increases, the standard deviation remains relatively stable while the standard error decreases.</p>
<hr>
</section>
<section id="core-statistical-formulas" class="level3">
<h3 class="anchored" data-anchor-id="core-statistical-formulas">3. Core Statistical Formulas</h3>
<section id="numerical-data-continuous-variables" class="level4">
<h4 class="anchored" data-anchor-id="numerical-data-continuous-variables">Numerical Data (Continuous Variables)</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 27%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Statistic</th>
<th>Formula</th>
<th>Application</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Sample mean</strong></td>
<td><span class="math inline">\bar{x} = \frac{1}{n}\sum_{i=1}^{n} x_i</span></td>
<td>Point estimate of population mean</td>
</tr>
<tr class="even">
<td><strong>Sample variance</strong></td>
<td><span class="math inline">s^2 = \frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})^2</span></td>
<td>Measure of data dispersion</td>
</tr>
<tr class="odd">
<td><strong>Standard deviation</strong></td>
<td><span class="math inline">s = \sqrt{s^2}</span></td>
<td>Spread in original units</td>
</tr>
<tr class="even">
<td><strong>Standard error of mean</strong></td>
<td><span class="math inline">SE(\bar{x}) = \frac{s}{\sqrt{n}}</span></td>
<td>Precision of mean estimate</td>
</tr>
<tr class="odd">
<td><strong>95% Confidence interval</strong></td>
<td><span class="math inline">\bar{x} \pm 1.96 \times SE(\bar{x})</span></td>
<td>Interval estimate (large samples)</td>
</tr>
</tbody>
</table>
</section>
<section id="categorical-data-proportions" class="level4">
<h4 class="anchored" data-anchor-id="categorical-data-proportions">Categorical Data (Proportions)</h4>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 27%">
<col style="width: 39%">
</colgroup>
<thead>
<tr class="header">
<th>Statistic</th>
<th>Formula</th>
<th>Application</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Sample proportion</strong></td>
<td><span class="math inline">\hat{p} = \frac{\text{number of successes}}{n}</span></td>
<td>Point estimate of population proportion</td>
</tr>
<tr class="even">
<td><strong>Standard error</strong></td>
<td><span class="math inline">SE(\hat{p}) = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</span></td>
<td>Precision of proportion estimate</td>
</tr>
<tr class="odd">
<td><strong>95% Confidence interval</strong></td>
<td><span class="math inline">\hat{p} \pm 1.96 \times SE(\hat{p})</span></td>
<td>Interval estimate</td>
</tr>
</tbody>
</table>
<p><strong>Validity conditions:</strong> - For means: sample size n ≥ 30 or approximately symmetric data distribution - For proportions: <span class="math inline">n\hat{p} \geq 10</span> and <span class="math inline">n(1-\hat{p}) \geq 10</span> - For small samples: replace 1.96 with the appropriate t-value - <strong>Critical assumption:</strong> Random sampling or random assignment (to avoid bias)</p>
<hr>
</section>
</section>
<section id="the-multiplier-1.96-an-empirical-constant" class="level3">
<h3 class="anchored" data-anchor-id="the-multiplier-1.96-an-empirical-constant">4. The Multiplier 1.96: An Empirical Constant</h3>
<p>The value <strong>1.96</strong> (often rounded to <strong>2</strong>) is an empirically-derived constant that ensures approximately 95% coverage in repeated sampling. This multiplier has been validated through extensive statistical practice and simulation studies.</p>
<p><strong>Practical interpretation:</strong> When we construct intervals using <span class="math inline">\text{estimate} \pm 1.96 \times SE</span>: - Empirical studies show that about 95 out of 100 such intervals will contain the true population value - This provides a standardized way to communicate uncertainty - The choice of 95% is a widely-adopted convention in scientific research</p>
<p><strong>Alternative multipliers for different coverage levels:</strong> - 90% coverage: use 1.645 - 99% coverage: use 2.576 - Quick approximation: use 2 for roughly 95% coverage</p>
<hr>
</section>
<section id="worked-example-analysis-of-study-hours" class="level3">
<h3 class="anchored" data-anchor-id="worked-example-analysis-of-study-hours">5. Worked Example: Analysis of Study Hours</h3>
<p><strong>Data:</strong> Survey of n = 40 students regarding weekly study hours<br>
<strong>Sample statistics:</strong> <span class="math inline">\bar{x} = 10.8</span> hours, <span class="math inline">s = 2.1</span> hours</p>
<p><strong>Calculations:</strong> 1. Standard error: <span class="math inline">SE = \frac{2.1}{\sqrt{40}} = 0.332</span> hours 2. Margin of error (95%): <span class="math inline">MoE = 1.96 \times 0.332 = 0.651</span> hours 3. 95% Confidence interval: <span class="math inline">[10.8 - 0.651, 10.8 + 0.651] = [10.15, 11.45]</span> hours</p>
<p><strong>Interpretation:</strong> Based on this sample, we estimate the mean study time to be 10.8 hours per week, with a margin of error of ±0.65 hours at the 95% confidence level. This accounts for random sampling error only, assuming no selection bias.</p>
<hr>
</section>
<section id="bootstrap-methods-detailed-explanation" class="level3">
<h3 class="anchored" data-anchor-id="bootstrap-methods-detailed-explanation">6. Bootstrap Methods: Detailed Explanation</h3>
<p>The bootstrap is a computer-intensive resampling technique that works regardless of the shape or pattern of your data. It simulates the process of taking many samples from the population by resampling from our single sample.</p>
<p><strong>Conceptual Foundation:</strong></p>
<ul>
<li>Our sample is treated as a “mini-population”</li>
<li>We draw many new samples from this mini-population (with replacement)</li>
<li>The variation across these resamples mimics what would happen if we could collect many real samples</li>
<li>This works because our sample contains information about the variability in the population</li>
<li>No need to assume data follows a bell curve or any other specific shape</li>
</ul>
<p><strong>Step-by-Step Procedure:</strong></p>
<ol type="1">
<li><strong>Start with your original sample</strong> of size n
<ul>
<li>Example: [7, 9, 10, 11, 12] (n = 5 study hours)</li>
</ul></li>
<li><strong>Create a bootstrap sample</strong> by randomly selecting n values WITH replacement
<ul>
<li>Bootstrap sample 1: [7, 10, 10, 11, 7] → mean = 9.0</li>
<li>Bootstrap sample 2: [12, 9, 11, 11, 10] → mean = 10.6</li>
<li>Bootstrap sample 3: [9, 7, 12, 9, 11] → mean = 9.6</li>
</ul></li>
<li><strong>Repeat B times</strong> (typically B = 1,000 to 10,000)
<ul>
<li>Calculate your statistic (e.g., mean) for each bootstrap sample</li>
<li>Store all B statistics</li>
</ul></li>
<li><strong>Construct confidence interval</strong> using percentiles
<ul>
<li>Sort the B statistics from smallest to largest</li>
<li>For 95% CI: take the 2.5th and 97.5th percentiles</li>
<li>If B = 1,000: CI = [25th smallest value, 975th smallest value]</li>
</ul></li>
</ol>
<p><strong>Advantages:</strong></p>
<ul>
<li>Works for any statistic (median, correlation, ratio, etc.)</li>
<li>No formula needed for complex statistics</li>
<li>Captures the actual shape of the sampling distribution</li>
<li>Particularly useful for small samples or skewed data</li>
<li>Does not require data to follow any specific pattern (bell-shaped, symmetric, etc.)</li>
</ul>
<hr>
</section>
<section id="strategies-for-managing-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="strategies-for-managing-uncertainty">7. Strategies for Managing Uncertainty</h3>
<p><strong>Minimize Bias Through Study Design</strong> - Use random sampling from a well-defined population - Ensure sampling frame matches target population - Minimize non-response through follow-up efforts - Use blinding when appropriate</p>
<p><strong>Reduce Random Error</strong> - Increase sample size (reduces SE by factor of <span class="math inline">1/\sqrt{n}</span>) - Use stratification to ensure representation - Improve measurement precision - Note: These strategies do NOT reduce bias</p>
<p><strong>Pre-Analysis Planning</strong> - Specify hypotheses and analysis methods before data collection - Determine required sample size based on desired precision - Document decision rules to maintain objectivity</p>
<hr>
</section>
<section id="sample-size-determination-for-proportions" class="level3">
<h3 class="anchored" data-anchor-id="sample-size-determination-for-proportions">8. Sample Size Determination for Proportions</h3>
<p>For estimating a proportion with margin of error m at 95% confidence:</p>
<p><span class="math display">n \approx \frac{0.96}{m^2}</span></p>
<p>This formula assumes maximum variability (<span class="math inline">p = 0.5</span>) and uses the approximation <span class="math inline">(1.96)^2 \times 0.25 \approx 0.96</span>.</p>
<p><strong>Examples:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Desired Margin of Error</th>
<th>Required Sample Size</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>±1%</td>
<td>~9,600</td>
</tr>
<tr class="even">
<td>±3%</td>
<td>~1,067</td>
</tr>
<tr class="odd">
<td>±5%</td>
<td>~384</td>
</tr>
<tr class="even">
<td>±10%</td>
<td>~96</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="implementation-in-r" class="level3">
<h3 class="anchored" data-anchor-id="implementation-in-r">9. Implementation in R</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb93"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Data: Weekly study hours for 40 students</span></span>
<span id="cb93-2"><a href="#cb93-2" aria-hidden="true" tabindex="-1"></a>study_hours <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">9</span>,<span class="dv">12</span>,<span class="dv">10</span>,<span class="dv">14</span>,<span class="dv">7</span>,<span class="dv">11</span>,<span class="dv">13</span>,<span class="dv">9</span>,<span class="dv">8</span>,<span class="dv">12</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">9</span>,<span class="dv">15</span>,<span class="dv">13</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">10</span>,<span class="dv">14</span>,<span class="dv">12</span>,</span>
<span id="cb93-3"><a href="#cb93-3" aria-hidden="true" tabindex="-1"></a>                 <span class="dv">11</span>,<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">8</span>,<span class="dv">12</span>,<span class="dv">13</span>,<span class="dv">9</span>,<span class="dv">7</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">13</span>,<span class="dv">14</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">10</span>,<span class="dv">9</span>,<span class="dv">12</span>)</span>
<span id="cb93-4"><a href="#cb93-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-5"><a href="#cb93-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate sample statistics</span></span>
<span id="cb93-6"><a href="#cb93-6" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(study_hours)</span>
<span id="cb93-7"><a href="#cb93-7" aria-hidden="true" tabindex="-1"></a>mean_hours <span class="ot">&lt;-</span> <span class="fu">mean</span>(study_hours)</span>
<span id="cb93-8"><a href="#cb93-8" aria-hidden="true" tabindex="-1"></a>sd_hours <span class="ot">&lt;-</span> <span class="fu">sd</span>(study_hours)</span>
<span id="cb93-9"><a href="#cb93-9" aria-hidden="true" tabindex="-1"></a>se_hours <span class="ot">&lt;-</span> sd_hours <span class="sc">/</span> <span class="fu">sqrt</span>(n)</span>
<span id="cb93-10"><a href="#cb93-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-11"><a href="#cb93-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Construct 95% confidence interval using normal approximation</span></span>
<span id="cb93-12"><a href="#cb93-12" aria-hidden="true" tabindex="-1"></a>z_critical <span class="ot">&lt;-</span> <span class="fl">1.96</span></span>
<span id="cb93-13"><a href="#cb93-13" aria-hidden="true" tabindex="-1"></a>margin_of_error <span class="ot">&lt;-</span> z_critical <span class="sc">*</span> se_hours</span>
<span id="cb93-14"><a href="#cb93-14" aria-hidden="true" tabindex="-1"></a>ci_lower <span class="ot">&lt;-</span> mean_hours <span class="sc">-</span> margin_of_error</span>
<span id="cb93-15"><a href="#cb93-15" aria-hidden="true" tabindex="-1"></a>ci_upper <span class="ot">&lt;-</span> mean_hours <span class="sc">+</span> margin_of_error</span>
<span id="cb93-16"><a href="#cb93-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb93-17"><a href="#cb93-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Display results</span></span>
<span id="cb93-18"><a href="#cb93-18" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"SAMPLE STATISTICS</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>SAMPLE STATISTICS</code></pre>
</div>
<div class="sourceCode cell-code" id="cb95"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Sample size: n = %d</span><span class="sc">\n</span><span class="st">"</span>, n))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sample size: n = 40</code></pre>
</div>
<div class="sourceCode cell-code" id="cb97"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Sample mean: %.2f hours</span><span class="sc">\n</span><span class="st">"</span>, mean_hours))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sample mean: 10.55 hours</code></pre>
</div>
<div class="sourceCode cell-code" id="cb99"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb99-1"><a href="#cb99-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Sample standard deviation: %.2f hours</span><span class="sc">\n</span><span class="st">"</span>, sd_hours))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Sample standard deviation: 2.12 hours</code></pre>
</div>
<div class="sourceCode cell-code" id="cb101"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb101-1"><a href="#cb101-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Standard error: %.3f hours</span><span class="sc">\n</span><span class="st">"</span>, se_hours))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Standard error: 0.336 hours</code></pre>
</div>
<div class="sourceCode cell-code" id="cb103"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Margin of error (95%%): %.3f hours</span><span class="sc">\n</span><span class="st">"</span>, margin_of_error))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Margin of error (95%): 0.658 hours</code></pre>
</div>
<div class="sourceCode cell-code" id="cb105"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"95%% Confidence interval: [%.2f, %.2f]</span><span class="sc">\n\n</span><span class="st">"</span>, ci_lower, ci_upper))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>95% Confidence interval: [9.89, 11.21]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb107"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Bootstrap confidence interval with visualization</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">5000</span></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate bootstrap samples and calculate means</span></span>
<span id="cb107-6"><a href="#cb107-6" aria-hidden="true" tabindex="-1"></a>bootstrap_means <span class="ot">&lt;-</span> <span class="fu">replicate</span>(B, {</span>
<span id="cb107-7"><a href="#cb107-7" aria-hidden="true" tabindex="-1"></a>  resample <span class="ot">&lt;-</span> <span class="fu">sample</span>(study_hours, <span class="at">size =</span> n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb107-8"><a href="#cb107-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(resample)</span>
<span id="cb107-9"><a href="#cb107-9" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb107-10"><a href="#cb107-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-11"><a href="#cb107-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate bootstrap confidence interval</span></span>
<span id="cb107-12"><a href="#cb107-12" aria-hidden="true" tabindex="-1"></a>boot_ci <span class="ot">&lt;-</span> <span class="fu">quantile</span>(bootstrap_means, <span class="at">probs =</span> <span class="fu">c</span>(<span class="fl">0.025</span>, <span class="fl">0.975</span>))</span>
<span id="cb107-13"><a href="#cb107-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb107-14"><a href="#cb107-14" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"BOOTSTRAP RESULTS</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>BOOTSTRAP RESULTS</code></pre>
</div>
<div class="sourceCode cell-code" id="cb109"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Bootstrap 95%% CI: [%.2f, %.2f]</span><span class="sc">\n</span><span class="st">"</span>, boot_ci[<span class="dv">1</span>], boot_ci[<span class="dv">2</span>]))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Bootstrap 95% CI: [9.90, 11.22]</code></pre>
</div>
<div class="sourceCode cell-code" id="cb111"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="fu">sprintf</span>(<span class="st">"Number of bootstrap samples: B = %d</span><span class="sc">\n\n</span><span class="st">"</span>, B))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Number of bootstrap samples: B = 5000</code></pre>
</div>
<div class="sourceCode cell-code" id="cb113"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb113-1"><a href="#cb113-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize bootstrap distribution</span></span>
<span id="cb113-2"><a href="#cb113-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb113-3"><a href="#cb113-3" aria-hidden="true" tabindex="-1"></a>bootstrap_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">means =</span> bootstrap_means)</span>
<span id="cb113-4"><a href="#cb113-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb113-5"><a href="#cb113-5" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(bootstrap_df, <span class="fu">aes</span>(<span class="at">x =</span> means)) <span class="sc">+</span></span>
<span id="cb113-6"><a href="#cb113-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">bins =</span> <span class="dv">50</span>, </span>
<span id="cb113-7"><a href="#cb113-7" aria-hidden="true" tabindex="-1"></a>                 <span class="at">fill =</span> <span class="st">"skyblue"</span>, <span class="at">color =</span> <span class="st">"black"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb113-8"><a href="#cb113-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mean_hours, <span class="at">color =</span> <span class="st">"red"</span>, </span>
<span id="cb113-9"><a href="#cb113-9" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"solid"</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb113-10"><a href="#cb113-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> boot_ci, <span class="at">color =</span> <span class="st">"darkgreen"</span>, </span>
<span id="cb113-11"><a href="#cb113-11" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb113-12"><a href="#cb113-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_hours, <span class="at">y =</span> <span class="dv">0</span>, <span class="at">label =</span> <span class="st">"Sample Mean"</span>, </span>
<span id="cb113-13"><a href="#cb113-13" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">1</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb113-14"><a href="#cb113-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> boot_ci[<span class="dv">1</span>], <span class="at">y =</span> <span class="dv">0</span>, <span class="at">label =</span> <span class="st">"2.5%"</span>, </span>
<span id="cb113-15"><a href="#cb113-15" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">color =</span> <span class="st">"darkgreen"</span>) <span class="sc">+</span></span>
<span id="cb113-16"><a href="#cb113-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> boot_ci[<span class="dv">2</span>], <span class="at">y =</span> <span class="dv">0</span>, <span class="at">label =</span> <span class="st">"97.5%"</span>, </span>
<span id="cb113-17"><a href="#cb113-17" aria-hidden="true" tabindex="-1"></a>           <span class="at">vjust =</span> <span class="sc">-</span><span class="dv">2</span>, <span class="at">color =</span> <span class="st">"darkgreen"</span>) <span class="sc">+</span></span>
<span id="cb113-18"><a href="#cb113-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Bootstrap Distribution of Sample Means"</span>,</span>
<span id="cb113-19"><a href="#cb113-19" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">sprintf</span>(<span class="st">"B = %d bootstrap samples"</span>, B),</span>
<span id="cb113-20"><a href="#cb113-20" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Bootstrap Sample Means (hours)"</span>,</span>
<span id="cb113-21"><a href="#cb113-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Density"</span>) <span class="sc">+</span></span>
<span id="cb113-22"><a href="#cb113-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb113-23"><a href="#cb113-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<hr>
</section>
<section id="summary-1" class="level3">
<h3 class="anchored" data-anchor-id="summary-1">Summary</h3>
<p><strong>Essential Concepts:</strong></p>
<ol type="1">
<li><strong>Distinguish between bias and random error</strong>: Large samples reduce random error but not bias</li>
<li><strong>The Literary Digest failure</strong>: Even 2.4 million responses could not overcome selection bias</li>
<li><strong>Standard errors measure precision, not accuracy</strong>: They quantify random variation only</li>
<li><strong>Bootstrap provides a universal method</strong>: Works without needing formulas or requiring data to follow specific patterns</li>
</ol>
<p><strong>Reporting Guidelines:</strong></p>
<ul>
<li>Always report point estimates with measures of uncertainty</li>
<li>Acknowledge potential sources of bias in study limitations</li>
<li>Use the format: “estimate (95% CI: lower bound–upper bound)”</li>
<li>Include sample size and sampling method when presenting results</li>
</ul>
<p><strong>Methodological Considerations:</strong></p>
<ul>
<li>Random sampling is essential for valid inference</li>
<li>Verify that validity conditions are met before applying formulas</li>
<li>Consider bootstrap methods when your data is skewed or when standard formulas don’t exist</li>
<li>Remember that no amount of statistical analysis can fix a biased sample</li>
</ul>
</section>
</section>
<section id="appendix-b-quantifying-uncertainty-for-a-proportion" class="level2" data-number="2.18">
<h2 data-number="2.18" class="anchored" data-anchor-id="appendix-b-quantifying-uncertainty-for-a-proportion"><span class="header-section-number">2.18</span> Appendix B: Quantifying Uncertainty for a Proportion (*)</h2>
<section id="setting-and-notation" class="level3">
<h3 class="anchored" data-anchor-id="setting-and-notation">Setting and Notation</h3>
<p>We observe a <strong>binary</strong> outcome (e.g., Heads vs.&nbsp;Tails; Support vs.&nbsp;No support). Let <span class="math inline">n</span> denote the number of independent trials and <span class="math inline">x</span> the number of “successes.” The sample proportion is <span class="math inline">\hat p = x/n</span>, which estimates the population proportion <span class="math inline">p</span>.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Assumptions for the formulas below</strong></p>
<ul>
<li><strong>Sampling:</strong> simple random sample (or randomized experiment) with observations that are independent (or close to independent).</li>
<li><strong>Population size:</strong> large relative to <span class="math inline">n</span>; if sampling without replacement from a finite population of size <span class="math inline">N</span>, a finite-population correction may apply: <span class="math inline">\mathrm{SE}\_\text{FPC}=\mathrm{SE}\sqrt{(N-n)/(N-1)}</span>.</li>
<li><strong>Measurement:</strong> outcome is correctly recorded.</li>
</ul>
</div>
</div>
</section>
<section id="estimation-precision-and-a-95-interval" class="level3">
<h3 class="anchored" data-anchor-id="estimation-precision-and-a-95-interval">Estimation, Precision, and a 95% Interval</h3>
<p><strong>Estimator.</strong> <span class="math inline">\hat p = x/n</span>.</p>
<p><strong>Standard error (precision).</strong></p>
<p><span class="math display">
\mathrm{SE}(\hat p) \approx \sqrt{\frac{\hat p(1-\hat p)}{n}},
</span></p>
<p>which follows from <span class="math inline">\mathrm{Var}(\hat p)=p(1-p)/n</span> for Bernoulli outcomes; replacing <span class="math inline">p</span> with <span class="math inline">\hat p</span> yields a practical estimate of uncertainty.</p>
<p><strong>“Wald” 95% confidence interval (quick approximation).</strong></p>
<p><span class="math display">
\hat p \ \pm\ 1.96 \times \mathrm{SE}(\hat p).
</span></p>
<p>This normal-approximation interval is serviceable for moderate to large <span class="math inline">n</span> and <span class="math inline">p</span> not too close to 0 or 1, but it can <strong>under-cover</strong> when <span class="math inline">n</span> is small.</p>
<p><strong>Wilson interval (recommended for small–moderate <span class="math inline">n</span>).</strong> The Wilson score interval provides more reliable coverage for small samples; the simulation below uses it by default.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Mental arithmetic for polls (worst case near <span class="math inline">p=0.5</span>).</strong> <span class="math inline">\text{MoE} \approx \dfrac{1}{\sqrt{n}}</span> (since <span class="math inline">1.96\sqrt{0.25/n}\approx 0.98/\sqrt{n}</span>).</p>
<ul>
<li><span class="math inline">n=100 \Rightarrow \pm 10\%</span> • <span class="math inline">n=400 \Rightarrow \pm 5\%</span> • <span class="math inline">n=1000 \Rightarrow \pm 3.2\%</span></li>
<li><span class="math inline">n=1600 \Rightarrow \pm 2.5\%</span> • <span class="math inline">n=2500 \Rightarrow \pm 2\%</span> • <span class="math inline">n=10000 \Rightarrow \pm 1\%</span></li>
</ul>
</div>
</div>
</section>
<section id="worked-examples-hand-calculation" class="level3">
<h3 class="anchored" data-anchor-id="worked-examples-hand-calculation">Worked Examples (hand calculation)</h3>
<ul>
<li><p><strong>Tiny sample:</strong> <span class="math inline">n=10</span>, <span class="math inline">x=7</span> ⇒ <span class="math inline">\hat p=0.70</span>. <span class="math inline">\mathrm{SE}\approx \sqrt{0.7\cdot0.3/10}\approx 0.145</span> ⇒ Wald 95% CI <span class="math inline">\approx 0.70 \pm 0.29 = [0.41,\,0.99]</span>. <em>(Very wide; small <span class="math inline">n</span> implies high sampling variability.)</em></p></li>
<li><p><strong>Small sample:</strong> <span class="math inline">n=30</span>, <span class="math inline">x=18</span> ⇒ <span class="math inline">\hat p=0.60</span>. <span class="math inline">\mathrm{SE}\approx \sqrt{0.6\cdot0.4/30}\approx 0.089</span> ⇒ Wald 95% CI <span class="math inline">\approx [0.42,\,0.78]</span>.</p></li>
<li><p><strong>Moderate sample:</strong> <span class="math inline">n=100</span>, <span class="math inline">x=56</span> ⇒ <span class="math inline">\hat p=0.56</span>. <span class="math inline">\mathrm{SE}\approx \sqrt{0.56\cdot0.44/100}\approx 0.050</span> ⇒ Wald 95% CI <span class="math inline">\approx [0.46,\,0.66]</span>.</p></li>
</ul>
<p><strong>Reporting template (concise).</strong> “Estimate <span class="math inline">p\approx \hat p</span> with a 95% CI <span class="math inline">[L, U]</span>; report <span class="math inline">n</span>, method (Wald/Wilson), and any design features affecting bias.”</p>
</section>
<section id="mini-poll-illustration" class="level3">
<h3 class="anchored" data-anchor-id="mini-poll-illustration">Mini-Poll Illustration</h3>
<p>Poll with <span class="math inline">n=100</span> respondents and <span class="math inline">x=56</span> supporters:</p>
<ul>
<li><span class="math inline">\hat p=0.56</span></li>
<li><span class="math inline">\mathrm{SE}\approx 0.050</span></li>
<li>Wald 95% CI <span class="math inline">\approx [0.46,\,0.66]</span>.</li>
</ul>
<p>If <span class="math inline">\hat p=0.56</span> but <span class="math inline">n=1000</span>, then <span class="math inline">\mathrm{SE}\approx 0.0157</span> and the 95% CI shrinks to <span class="math inline">[0.529,\,0.591]</span>.</p>
</section>
<section id="simulation-sampling-variability-and-coverage" class="level3">
<h3 class="anchored" data-anchor-id="simulation-sampling-variability-and-coverage">Simulation: Sampling Variability and Coverage</h3>
<p>The following code simulates 30 independent samples (10 trials each) and plots their 95% CIs. By default it uses the <strong>Wilson</strong> interval, which has better small-sample coverage than the quick Wald interval.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb114"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb114-1"><a href="#cb114-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb114-2"><a href="#cb114-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb114-3"><a href="#cb114-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(purrr)</span>
<span id="cb114-4"><a href="#cb114-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tibble)</span>
<span id="cb114-5"><a href="#cb114-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-6"><a href="#cb114-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1234</span>)</span>
<span id="cb114-7"><a href="#cb114-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-8"><a href="#cb114-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Choose interval method: "wilson" (recommended for small n) or "wald" (quick approximation)</span></span>
<span id="cb114-9"><a href="#cb114-9" aria-hidden="true" tabindex="-1"></a>method <span class="ot">&lt;-</span> <span class="st">"wilson"</span></span>
<span id="cb114-10"><a href="#cb114-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-11"><a href="#cb114-11" aria-hidden="true" tabindex="-1"></a>m <span class="ot">&lt;-</span> <span class="dv">30</span>      <span class="co"># number of repeated samples</span></span>
<span id="cb114-12"><a href="#cb114-12" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span>      <span class="co"># trials per sample</span></span>
<span id="cb114-13"><a href="#cb114-13" aria-hidden="true" tabindex="-1"></a>p_true <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb114-14"><a href="#cb114-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-15"><a href="#cb114-15" aria-hidden="true" tabindex="-1"></a>x     <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(m, <span class="at">size =</span> n, <span class="at">prob =</span> p_true)</span>
<span id="cb114-16"><a href="#cb114-16" aria-hidden="true" tabindex="-1"></a>phat  <span class="ot">&lt;-</span> x <span class="sc">/</span> n</span>
<span id="cb114-17"><a href="#cb114-17" aria-hidden="true" tabindex="-1"></a>z     <span class="ot">&lt;-</span> <span class="fl">1.96</span></span>
<span id="cb114-18"><a href="#cb114-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-19"><a href="#cb114-19" aria-hidden="true" tabindex="-1"></a>wald_ci <span class="ot">&lt;-</span> <span class="cf">function</span>(p, n, <span class="at">z =</span> <span class="fl">1.96</span>){</span>
<span id="cb114-20"><a href="#cb114-20" aria-hidden="true" tabindex="-1"></a>  se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(p <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p) <span class="sc">/</span> n)</span>
<span id="cb114-21"><a href="#cb114-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">lower =</span> p <span class="sc">-</span> z <span class="sc">*</span> se, <span class="at">upper =</span> p <span class="sc">+</span> z <span class="sc">*</span> se)</span>
<span id="cb114-22"><a href="#cb114-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb114-23"><a href="#cb114-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-24"><a href="#cb114-24" aria-hidden="true" tabindex="-1"></a>wilson_ci <span class="ot">&lt;-</span> <span class="cf">function</span>(p, n, <span class="at">z =</span> <span class="fl">1.96</span>){</span>
<span id="cb114-25"><a href="#cb114-25" aria-hidden="true" tabindex="-1"></a>  z2     <span class="ot">&lt;-</span> z<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb114-26"><a href="#cb114-26" aria-hidden="true" tabindex="-1"></a>  denom  <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">+</span> z2 <span class="sc">/</span> n</span>
<span id="cb114-27"><a href="#cb114-27" aria-hidden="true" tabindex="-1"></a>  center <span class="ot">&lt;-</span> (p <span class="sc">+</span> z2 <span class="sc">/</span> (<span class="dv">2</span> <span class="sc">*</span> n)) <span class="sc">/</span> denom</span>
<span id="cb114-28"><a href="#cb114-28" aria-hidden="true" tabindex="-1"></a>  half   <span class="ot">&lt;-</span> (z <span class="sc">/</span> denom) <span class="sc">*</span> <span class="fu">sqrt</span>( (p <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p) <span class="sc">/</span> n) <span class="sc">+</span> z2 <span class="sc">/</span> (<span class="dv">4</span> <span class="sc">*</span> n<span class="sc">^</span><span class="dv">2</span>) )</span>
<span id="cb114-29"><a href="#cb114-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">lower =</span> center <span class="sc">-</span> half, <span class="at">upper =</span> center <span class="sc">+</span> half)</span>
<span id="cb114-30"><a href="#cb114-30" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb114-31"><a href="#cb114-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-32"><a href="#cb114-32" aria-hidden="true" tabindex="-1"></a>ci_fun <span class="ot">&lt;-</span> <span class="cf">switch</span>(<span class="fu">tolower</span>(method),</span>
<span id="cb114-33"><a href="#cb114-33" aria-hidden="true" tabindex="-1"></a>  <span class="st">"wilson"</span> <span class="ot">=</span> wilson_ci,</span>
<span id="cb114-34"><a href="#cb114-34" aria-hidden="true" tabindex="-1"></a>  <span class="st">"wald"</span>   <span class="ot">=</span> wald_ci,</span>
<span id="cb114-35"><a href="#cb114-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stop</span>(<span class="st">"method must be 'wilson' or 'wald'"</span>)</span>
<span id="cb114-36"><a href="#cb114-36" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb114-37"><a href="#cb114-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-38"><a href="#cb114-38" aria-hidden="true" tabindex="-1"></a>cis <span class="ot">&lt;-</span> <span class="fu">map_dfr</span>(<span class="fu">seq_along</span>(phat), <span class="cf">function</span>(i){</span>
<span id="cb114-39"><a href="#cb114-39" aria-hidden="true" tabindex="-1"></a>  out <span class="ot">&lt;-</span> <span class="fu">ci_fun</span>(phat[i], n, z)</span>
<span id="cb114-40"><a href="#cb114-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">sample_id =</span> i, <span class="at">phat =</span> phat[i]) <span class="sc">%&gt;%</span> <span class="fu">bind_cols</span>(out)</span>
<span id="cb114-41"><a href="#cb114-41" aria-hidden="true" tabindex="-1"></a>}) <span class="sc">%&gt;%</span></span>
<span id="cb114-42"><a href="#cb114-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">lower =</span> <span class="fu">pmax</span>(<span class="dv">0</span>, lower), <span class="at">upper =</span> <span class="fu">pmin</span>(<span class="dv">1</span>, upper),      <span class="co"># clip to [0,1]</span></span>
<span id="cb114-43"><a href="#cb114-43" aria-hidden="true" tabindex="-1"></a>         <span class="at">cover =</span> (lower <span class="sc">&lt;=</span> p_true <span class="sc">&amp;</span> p_true <span class="sc">&lt;=</span> upper))</span>
<span id="cb114-44"><a href="#cb114-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb114-45"><a href="#cb114-45" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(cis, <span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">reorder</span>(<span class="fu">factor</span>(sample_id), phat))) <span class="sc">+</span></span>
<span id="cb114-46"><a href="#cb114-46" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbarh</span>(<span class="fu">aes</span>(<span class="at">xmin =</span> lower, <span class="at">xmax =</span> upper, <span class="at">color =</span> cover), <span class="at">height =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb114-47"><a href="#cb114-47" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x =</span> phat, <span class="at">color =</span> cover)) <span class="sc">+</span></span>
<span id="cb114-48"><a href="#cb114-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> p_true, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb114-49"><a href="#cb114-49" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"Estimated proportion (p̂)"</span>,</span>
<span id="cb114-50"><a href="#cb114-50" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Sample"</span>,</span>
<span id="cb114-51"><a href="#cb114-51" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">"Interval covers 0.5?"</span>,</span>
<span id="cb114-52"><a href="#cb114-52" aria-hidden="true" tabindex="-1"></a>       <span class="at">title =</span> <span class="fu">paste</span>(<span class="st">"95% confidence intervals ("</span>, <span class="fu">toupper</span>(method), <span class="st">")"</span>, <span class="at">sep =</span> <span class="st">""</span>),</span>
<span id="cb114-53"><a href="#cb114-53" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste</span>(m, <span class="st">"independent samples; n ="</span>, n, <span class="st">"per sample"</span>)) <span class="sc">+</span></span>
<span id="cb114-54"><a href="#cb114-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">xlim</span>(<span class="dv">0</span>, <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chapter1_files/figure-html/coin-demo-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Sampling variability: 30 repeated samples, n = 10 each. Horizontal bars are 95% CIs; dashed line is the true p = 0.5.</figcaption>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Operational meaning of “95%”.</strong> It is a <strong>long-run frequency</strong> statement: if we were to repeat the entire sampling and interval-construction procedure many times, approximately 95% of the resulting intervals would contain the true <span class="math inline">p</span>.</p>
<p>Let <span class="math inline">B</span> be the number of intervals constructed with a method whose true coverage is <span class="math inline">c</span>. Then the number that cover, <span class="math inline">K</span>, satisfies</p>
<p><span class="math display">
K \sim \mathrm{Binomial}(B,\,c), \qquad \mathbb{E}[K]=Bc,\quad \mathrm{SD}(K)=\sqrt{Bc(1-c)}.
</span></p>
<p>For <span class="math inline">B=30</span> and <span class="math inline">c=0.95</span>, <span class="math inline">\mathbb{E}[K]=28.5</span>, <span class="math inline">\mathrm{SD}\approx 1.19</span>; seeing 26–30 covers is entirely plausible.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Small-sample caveat.</strong> The Wald interval <span class="math inline">\hat p \pm 1.96\,\mathrm{SE}</span> often <strong>under-covers</strong> when <span class="math inline">n</span> is small or <span class="math inline">p</span> is near 0 or 1. Prefer <strong>Wilson</strong> (or Agresti–Coull) for small–moderate <span class="math inline">n</span>, or increase <span class="math inline">n</span>.</p>
</div>
</div>
</section>
<section id="what-a-95-ci-doesand-does-notsay" class="level3">
<h3 class="anchored" data-anchor-id="what-a-95-ci-doesand-does-notsay">What a 95% CI Does—and Does Not—Say</h3>
<ul>
<li><strong>Long-run reliability, not a single-case probability.</strong> For a given dataset, an interval either contains <span class="math inline">p</span> or it does not; “95%” refers to the method’s performance across repetitions, not to the probability that this specific interval contains <span class="math inline">p</span>.</li>
<li><strong>Batch variability is expected.</strong> In a finite batch of intervals, the count that cover will vary randomly around its expectation.</li>
<li><strong>Method matters.</strong> Coverage depends on the interval procedure (e.g., Wilson vs.&nbsp;Wald) and on <span class="math inline">n</span> and <span class="math inline">p</span>.</li>
</ul>
</section>
<section id="understanding-confidence-intervals-through-simulation" class="level3">
<h3 class="anchored" data-anchor-id="understanding-confidence-intervals-through-simulation">Understanding Confidence Intervals Through Simulation</h3>
<p>The following simulation demonstrates the true meaning of “95% confidence”:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb115"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb115-1"><a href="#cb115-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate taking many polls to see how often CIs work</span></span>
<span id="cb115-2"><a href="#cb115-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb115-3"><a href="#cb115-3" aria-hidden="true" tabindex="-1"></a>true_prop <span class="ot">&lt;-</span> <span class="fl">0.52</span>    <span class="co"># The true population proportion</span></span>
<span id="cb115-4"><a href="#cb115-4" aria-hidden="true" tabindex="-1"></a>n_polls <span class="ot">&lt;-</span> <span class="dv">100</span>       <span class="co"># Number of simulated polls</span></span>
<span id="cb115-5"><a href="#cb115-5" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="dv">1000</span>  <span class="co"># Each poll surveys 1000 people</span></span>
<span id="cb115-6"><a href="#cb115-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-7"><a href="#cb115-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate the polls</span></span>
<span id="cb115-8"><a href="#cb115-8" aria-hidden="true" tabindex="-1"></a>sample_props <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_polls, sample_size, true_prop) <span class="sc">/</span> sample_size</span>
<span id="cb115-9"><a href="#cb115-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-10"><a href="#cb115-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate confidence interval for each poll</span></span>
<span id="cb115-11"><a href="#cb115-11" aria-hidden="true" tabindex="-1"></a>se <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(sample_props <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> sample_props) <span class="sc">/</span> sample_size)</span>
<span id="cb115-12"><a href="#cb115-12" aria-hidden="true" tabindex="-1"></a>ci_lower <span class="ot">&lt;-</span> sample_props <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se</span>
<span id="cb115-13"><a href="#cb115-13" aria-hidden="true" tabindex="-1"></a>ci_upper <span class="ot">&lt;-</span> sample_props <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se</span>
<span id="cb115-14"><a href="#cb115-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-15"><a href="#cb115-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Check which intervals contain the true value</span></span>
<span id="cb115-16"><a href="#cb115-16" aria-hidden="true" tabindex="-1"></a>ci_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb115-17"><a href="#cb115-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">poll_id =</span> <span class="dv">1</span><span class="sc">:</span>n_polls,</span>
<span id="cb115-18"><a href="#cb115-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">estimate =</span> sample_props,</span>
<span id="cb115-19"><a href="#cb115-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">ci_lower =</span> ci_lower,</span>
<span id="cb115-20"><a href="#cb115-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">ci_upper =</span> ci_upper,</span>
<span id="cb115-21"><a href="#cb115-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">contains_truth =</span> (ci_lower <span class="sc">&lt;=</span> true_prop) <span class="sc">&amp;</span> (true_prop <span class="sc">&lt;=</span> ci_upper)</span>
<span id="cb115-22"><a href="#cb115-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb115-23"><a href="#cb115-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb115-24"><a href="#cb115-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Count how many intervals contain the truth</span></span>
<span id="cb115-25"><a href="#cb115-25" aria-hidden="true" tabindex="-1"></a>coverage <span class="ot">&lt;-</span> <span class="fu">mean</span>(ci_data<span class="sc">$</span>contains_truth) <span class="sc">*</span> <span class="dv">100</span></span>
<span id="cb115-26"><a href="#cb115-26" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">"Percentage of CIs containing true value:"</span>, coverage, <span class="st">"%</span><span class="sc">\n</span><span class="st">"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Percentage of CIs containing true value: 93 %</code></pre>
</div>
<div class="sourceCode cell-code" id="cb117"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb117-1"><a href="#cb117-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualize first 30 polls</span></span>
<span id="cb117-2"><a href="#cb117-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(ci_data[<span class="dv">1</span><span class="sc">:</span><span class="dv">30</span>, ], <span class="fu">aes</span>(<span class="at">x =</span> poll_id, <span class="at">y =</span> estimate, </span>
<span id="cb117-3"><a href="#cb117-3" aria-hidden="true" tabindex="-1"></a>                             <span class="at">color =</span> contains_truth)) <span class="sc">+</span></span>
<span id="cb117-4"><a href="#cb117-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb117-5"><a href="#cb117-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> ci_lower, <span class="at">ymax =</span> ci_upper), </span>
<span id="cb117-6"><a href="#cb117-6" aria-hidden="true" tabindex="-1"></a>                <span class="at">width =</span> <span class="fl">0.3</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb117-7"><a href="#cb117-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> true_prop, <span class="at">color =</span> <span class="st">"black"</span>, </span>
<span id="cb117-8"><a href="#cb117-8" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"solid"</span>, <span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb117-9"><a href="#cb117-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"FALSE"</span> <span class="ot">=</span> <span class="st">"red"</span>, <span class="st">"TRUE"</span> <span class="ot">=</span> <span class="st">"blue"</span>),</span>
<span id="cb117-10"><a href="#cb117-10" aria-hidden="true" tabindex="-1"></a>                     <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Misses truth"</span>, <span class="st">"Contains truth"</span>)) <span class="sc">+</span></span>
<span id="cb117-11"><a href="#cb117-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb117-12"><a href="#cb117-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"30 Polls with 95% Confidence Intervals"</span>,</span>
<span id="cb117-13"><a href="#cb117-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">"Black line shows true value. About 95% of intervals should contain it."</span>,</span>
<span id="cb117-14"><a href="#cb117-14" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"</span><span class="sc">\n</span><span class="st">In this simulation:"</span>, <span class="fu">sum</span>(ci_data<span class="sc">$</span>contains_truth[<span class="dv">1</span><span class="sc">:</span><span class="dv">30</span>]), </span>
<span id="cb117-15"><a href="#cb117-15" aria-hidden="true" tabindex="-1"></a>                     <span class="st">"out of 30 contain the true value."</span>),</span>
<span id="cb117-16"><a href="#cb117-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Poll Number"</span>,</span>
<span id="cb117-17"><a href="#cb117-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Estimated Support"</span>,</span>
<span id="cb117-18"><a href="#cb117-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Interval Status"</span></span>
<span id="cb117-19"><a href="#cb117-19" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb117-20"><a href="#cb117-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">percent_format</span>(),</span>
<span id="cb117-21"><a href="#cb117-21" aria-hidden="true" tabindex="-1"></a>                     <span class="at">limits =</span> <span class="fu">c</span>(<span class="fl">0.4</span>, <span class="fl">0.6</span>)) <span class="sc">+</span></span>
<span id="cb117-22"><a href="#cb117-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb117-23"><a href="#cb117-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/confidence-interval-simulation-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Interpretation of Results</strong>:</p>
<ul>
<li>Each horizontal line segment represents one poll’s confidence interval</li>
<li>Blue intervals contain the true value (black line)</li>
<li>Red intervals miss the true value</li>
<li>Over many polls, approximately 95% of intervals contain the truth</li>
<li>For any single poll, we cannot determine whether our interval captures the true value</li>
</ul>
</section>
<section id="factors-affecting-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="factors-affecting-uncertainty">Factors Affecting Uncertainty</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb118"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb118-1"><a href="#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show how sample size affects margin of error</span></span>
<span id="cb118-2"><a href="#cb118-2" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">250</span>, <span class="dv">500</span>, <span class="dv">1000</span>, <span class="dv">2000</span>, <span class="dv">4000</span>, <span class="dv">10000</span>)</span>
<span id="cb118-3"><a href="#cb118-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fl">0.5</span>  <span class="co"># Use 0.5 as worst-case (maximum uncertainty)</span></span>
<span id="cb118-4"><a href="#cb118-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-5"><a href="#cb118-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate margin of error for each sample size</span></span>
<span id="cb118-6"><a href="#cb118-6" aria-hidden="true" tabindex="-1"></a>margins <span class="ot">&lt;-</span> <span class="fl">1.96</span> <span class="sc">*</span> <span class="fu">sqrt</span>(p <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> p) <span class="sc">/</span> sample_sizes)</span>
<span id="cb118-7"><a href="#cb118-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-8"><a href="#cb118-8" aria-hidden="true" tabindex="-1"></a>margin_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb118-9"><a href="#cb118-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">n =</span> sample_sizes,</span>
<span id="cb118-10"><a href="#cb118-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">margin =</span> margins <span class="sc">*</span> <span class="dv">100</span>  <span class="co"># Convert to percentage</span></span>
<span id="cb118-11"><a href="#cb118-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb118-12"><a href="#cb118-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb118-13"><a href="#cb118-13" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(margin_data, <span class="fu">aes</span>(<span class="at">x =</span> n, <span class="at">y =</span> margin)) <span class="sc">+</span></span>
<span id="cb118-14"><a href="#cb118-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"darkblue"</span>, <span class="at">linewidth =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb118-15"><a href="#cb118-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"darkblue"</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb118-16"><a href="#cb118-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">3</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, </span>
<span id="cb118-17"><a href="#cb118-17" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb118-18"><a href="#cb118-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_log10</span>(<span class="at">breaks =</span> sample_sizes,</span>
<span id="cb118-19"><a href="#cb118-19" aria-hidden="true" tabindex="-1"></a>                <span class="at">labels =</span> scales<span class="sc">::</span>comma) <span class="sc">+</span></span>
<span id="cb118-20"><a href="#cb118-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb118-21"><a href="#cb118-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"How Sample Size Affects Precision"</span>,</span>
<span id="cb118-22"><a href="#cb118-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Larger samples yield smaller margins of error (note logarithmic x-axis)"</span>,</span>
<span id="cb118-23"><a href="#cb118-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Sample Size"</span>,</span>
<span id="cb118-24"><a href="#cb118-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Margin of Error (%)"</span></span>
<span id="cb118-25"><a href="#cb118-25" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb118-26"><a href="#cb118-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb118-27"><a href="#cb118-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">5000</span>, <span class="at">y =</span> <span class="fl">3.3</span>, </span>
<span id="cb118-28"><a href="#cb118-28" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="st">"±3% (common target)"</span>, </span>
<span id="cb118-29"><a href="#cb118-29" aria-hidden="true" tabindex="-1"></a>           <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb118-30"><a href="#cb118-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">100</span>, <span class="at">y =</span> <span class="fl">10.5</span>, </span>
<span id="cb118-31"><a href="#cb118-31" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"n=100: ±"</span>, <span class="fu">round</span>(margins[<span class="dv">1</span>]<span class="sc">*</span><span class="dv">100</span>, <span class="dv">1</span>), <span class="st">"%"</span>), </span>
<span id="cb118-32"><a href="#cb118-32" aria-hidden="true" tabindex="-1"></a>           <span class="at">size =</span> <span class="dv">3</span>, <span class="at">hjust =</span> <span class="dv">0</span>) <span class="sc">+</span></span>
<span id="cb118-33"><a href="#cb118-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="dv">10000</span>, <span class="at">y =</span> <span class="fl">1.5</span>, </span>
<span id="cb118-34"><a href="#cb118-34" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"n=10,000: ±"</span>, <span class="fu">round</span>(margins[<span class="dv">7</span>]<span class="sc">*</span><span class="dv">100</span>, <span class="dv">1</span>), <span class="st">"%"</span>), </span>
<span id="cb118-35"><a href="#cb118-35" aria-hidden="true" tabindex="-1"></a>           <span class="at">size =</span> <span class="dv">3</span>, <span class="at">hjust =</span> <span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/sample-size-effect-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Key Mathematical Relationships</strong>:</p>
<ul>
<li>Doubling the sample size does not halve the margin of error</li>
<li>To reduce the margin of error by half requires quadrupling the sample size</li>
<li>Diminishing returns: The reduction from n=100 to n=1,000 is more substantial than from n=1,000 to n=10,000</li>
</ul>
</section>
<section id="practical-guidelines-for-working-with-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="practical-guidelines-for-working-with-uncertainty">Practical Guidelines for Working with Uncertainty</h3>
<p><strong>When interpreting results with uncertainty:</strong></p>
<ol type="1">
<li><p><strong>Report confidence intervals alongside point estimates</strong></p>
<ul>
<li>Insufficient: “52% support the candidate”</li>
<li>Appropriate: “52% support the candidate (95% CI: 49%-55%)”</li>
</ul></li>
<li><p><strong>Assess whether differences exceed sampling variability</strong></p>
<ul>
<li>If Poll A shows 52% and Poll B shows 51%, the difference may reflect sampling variation</li>
<li>Examine whether confidence intervals overlap</li>
</ul></li>
<li><p><strong>Acknowledge unmeasured sources of error</strong></p>
<ul>
<li>Confidence intervals capture only sampling error</li>
<li>They do not account for question bias, coverage errors, or response inaccuracies</li>
</ul></li>
<li><p><strong>Prioritize study quality over sample size</strong></p>
<ul>
<li>A well-designed study with 1,000 respondents surpasses a biased study with 100,000</li>
<li>Methodological rigor matters more than sample size alone</li>
</ul></li>
</ol>
</section>
<section id="summary-2" class="level3">
<h3 class="anchored" data-anchor-id="summary-2">Summary</h3>
<p>Statistical uncertainty is an inherent feature of empirical research in political science. Key principles include:</p>
<ul>
<li><strong>Sampling error</strong> is predictable, quantifiable, and decreases with larger samples</li>
<li><strong>Non-sampling errors</strong> pose greater threats because they persist regardless of sample size</li>
<li><strong>Standard error</strong> measures the typical variation in estimates across samples</li>
<li><strong>Confidence intervals</strong> provide ranges of plausible values with specified coverage probabilities</li>
<li>Uncertainty quantification should always accompany statistical estimates to enable proper interpretation</li>
</ul>
</section>
</section>
<section id="appendix-c-randomness-the-foundation-of-statistical-inference" class="level2" data-number="2.19">
<h2 data-number="2.19" class="anchored" data-anchor-id="appendix-c-randomness-the-foundation-of-statistical-inference"><span class="header-section-number">2.19</span> Appendix C: Randomness: The Foundation of Statistical Inference (*)</h2>
<section id="what-is-randomness-1" class="level3">
<h3 class="anchored" data-anchor-id="what-is-randomness-1">What is Randomness?</h3>
<p>In statistics, <strong>randomness</strong> means <em>structured uncertainty</em>: single outcomes are uncertain, but their <strong>long‑run frequencies</strong> follow known probabilities.</p>
<p>Two core properties:</p>
<ol type="1">
<li><strong>Single‑case unpredictability</strong> — we can’t say whether a particular voter will turn out.</li>
<li><strong>Aggregate regularity</strong> — we can say that about 60% of voters will turn out (with quantifiable uncertainty).</li>
</ol>
</section>
<section id="predictable-frequencies-law-of-large-numbers" class="level3">
<h3 class="anchored" data-anchor-id="predictable-frequencies-law-of-large-numbers">Predictable Frequencies (Law of Large Numbers)</h3>
<p>An individual random event is unpredictable. If we know the <strong>probability distribution</strong>, the pattern across many trials is predictable.</p>
<ul>
<li><strong>Example (two dice)</strong>: any one throw is uncertain, but sums follow a fixed distribution: 4 has 3/36 outcomes (≈8.3%), 7 has 6/36 (≈16.7%). Over many throws, 7 appears about twice as often as 4. The <strong>law of large numbers</strong> drives empirical frequencies toward these probabilities.</li>
</ul>
<blockquote class="blockquote">
<p><strong>Key idea:</strong> Randomness ≠ mess. Each trial is uncertain, yet the <strong>distribution is stable</strong> in the long run.</p>
</blockquote>
</section>
<section id="shannon-entropy-measuring-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="shannon-entropy-measuring-uncertainty">Shannon Entropy: Measuring Uncertainty</h3>
<section id="what-is-shannon-entropy" class="level4">
<h4 class="anchored" data-anchor-id="what-is-shannon-entropy">What is Shannon Entropy?</h4>
<p><strong>Shannon entropy</strong> quantifies how much uncertainty or “surprise” exists in a random process. It measures the average amount of information needed to describe an outcome.</p>
<p>The formula for Shannon entropy <span class="math inline">H</span> is:</p>
<p><span class="math display">H = -\sum_{i} p_i \log_2(p_i)</span></p>
<p>where <span class="math inline">p_i</span> is the probability of outcome <span class="math inline">i</span>, and we measure entropy in <strong>bits</strong>.</p>
</section>
<section id="simple-dice-examples" class="level4">
<h4 class="anchored" data-anchor-id="simple-dice-examples">Simple Dice Examples</h4>
<p><strong>Example 1: Fair Die</strong> - Six equally likely outcomes: each has probability <span class="math inline">p = 1/6</span> - Entropy: <span class="math inline">H = -6 \times \frac{1}{6} \log_2(\frac{1}{6}) = \log_2(6) \approx 2.58</span> bits - <strong>Interpretation</strong>: Maximum uncertainty—we need about 2.58 bits of information to describe each roll</p>
<p><strong>Example 2: Loaded Die (Always Shows 6)</strong> - One outcome with probability 1, others with probability 0 - Entropy: <span class="math inline">H = -1 \times \log_2(1) = 0</span> bits - <strong>Interpretation</strong>: No uncertainty—we already know the outcome!</p>
<p><strong>Example 3: Partially Loaded Die</strong> - Suppose: 6 appears 50% of the time, other faces each 10% - <span class="math inline">H = -0.5 \log_2(0.5) - 5 \times 0.1 \log_2(0.1)</span> - <span class="math inline">H = 0.5 + 5 \times 0.332 = 2.16</span> bits - <strong>Interpretation</strong>: Less uncertainty than a fair die, but more than the fully loaded die</p>
<blockquote class="blockquote">
<p><strong>Student Tip:</strong> Higher entropy = more uncertainty = harder to predict. A fair die has maximum entropy; a rigged die has lower entropy.</p>
</blockquote>
</section>
<section id="polling-example-measuring-electoral-uncertainty" class="level4">
<h4 class="anchored" data-anchor-id="polling-example-measuring-electoral-uncertainty">Polling Example: Measuring Electoral Uncertainty</h4>
<p>Consider three different polling scenarios for a two-candidate race:</p>
<p><strong>Scenario A: Dead Heat</strong> - Candidate 1: 50%, Candidate 2: 50% - <span class="math inline">H = -0.5 \log_2(0.5) - 0.5 \log_2(0.5) = 1</span> bit - <strong>Maximum uncertainty</strong> for a binary choice</p>
<p><strong>Scenario B: Clear Leader</strong> - Candidate 1: 70%, Candidate 2: 30% - <span class="math inline">H = -0.7 \log_2(0.7) - 0.3 \log_2(0.3) \approx 0.88</span> bits - Less uncertainty—the outcome is more predictable</p>
<p><strong>Scenario C: Landslide</strong> - Candidate 1: 95%, Candidate 2: 5% - <span class="math inline">H = -0.95 \log_2(0.95) - 0.05 \log_2(0.05) \approx 0.29</span> bits - Very low uncertainty—the outcome is nearly certain</p>
</section>
<section id="entropy-in-multi-candidate-races" class="level4">
<h4 class="anchored" data-anchor-id="entropy-in-multi-candidate-races">Entropy in Multi-Candidate Races</h4>
<p><strong>Example: Three-way race with different distributions</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 17%">
<col style="width: 18%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Distribution Type</th>
<th style="text-align: left;">Candidate A</th>
<th style="text-align: left;">Candidate B</th>
<th style="text-align: left;">Candidate C</th>
<th style="text-align: left;">Entropy (bits)</th>
<th style="text-align: left;">Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Equal split</strong></td>
<td style="text-align: left;">33.3%</td>
<td style="text-align: left;">33.3%</td>
<td style="text-align: left;">33.3%</td>
<td style="text-align: left;">1.58</td>
<td style="text-align: left;">Maximum uncertainty</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Two-way race</strong></td>
<td style="text-align: left;">45%</td>
<td style="text-align: left;">45%</td>
<td style="text-align: left;">10%</td>
<td style="text-align: left;">1.36</td>
<td style="text-align: left;">High uncertainty</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Clear favorite</strong></td>
<td style="text-align: left;">60%</td>
<td style="text-align: left;">25%</td>
<td style="text-align: left;">15%</td>
<td style="text-align: left;">1.30</td>
<td style="text-align: left;">Moderate uncertainty</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Dominant leader</strong></td>
<td style="text-align: left;">80%</td>
<td style="text-align: left;">15%</td>
<td style="text-align: left;">5%</td>
<td style="text-align: left;">0.88</td>
<td style="text-align: left;">Low uncertainty</td>
</tr>
</tbody>
</table>
</section>
<section id="why-entropy-matters-in-statistics" class="level4">
<h4 class="anchored" data-anchor-id="why-entropy-matters-in-statistics">Why Entropy Matters in Statistics</h4>
<ol type="1">
<li><strong>Survey Design</strong>: Higher entropy in responses means we need larger samples for the same precision</li>
<li><strong>Information Gain</strong>: In decision trees and machine learning, we choose variables that maximize entropy reduction</li>
<li><strong>Communication Efficiency</strong>: Entropy tells us the theoretical minimum bits needed to encode messages</li>
<li><strong>Uncertainty Quantification</strong>: Provides a single number summarizing distributional spread</li>
</ol>
</section>
<section id="interactive-intuition-the-20-questions-game" class="level4">
<h4 class="anchored" data-anchor-id="interactive-intuition-the-20-questions-game">Interactive Intuition: The 20 Questions Game</h4>
<p>Shannon entropy connects to the “20 Questions” game: - For a fair die (entropy ≈ 2.58 bits): You need about 3 yes/no questions on average - For a coin flip (entropy = 1 bit): You need exactly 1 question - For a loaded die that always shows 6 (entropy = 0): You need 0 questions!</p>
<blockquote class="blockquote">
<p><strong>Practice Problem:</strong> A weather forecast gives: Sunny (60%), Cloudy (30%), Rainy (10%). Calculate the Shannon entropy. What does this tell you about the predictability of tomorrow’s weather?</p>
</blockquote>
</section>
</section>
<section id="randomness-chaos-entropy-haphazardness-at-a-glance" class="level3">
<h3 class="anchored" data-anchor-id="randomness-chaos-entropy-haphazardness-at-a-glance">Randomness, Chaos, Entropy, Haphazardness (at a glance)</h3>
<table class="caption-top table">
<colgroup>
<col style="width: 10%">
<col style="width: 36%">
<col style="width: 27%">
<col style="width: 25%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Concept</th>
<th style="text-align: left;">What it is</th>
<th style="text-align: left;">Why it can look unpredictable</th>
<th style="text-align: left;">Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><strong>Randomness</strong></td>
<td style="text-align: left;">Outcomes uncertain; probabilities known</td>
<td style="text-align: left;">Individual draws vary; frequencies stabilize</td>
<td style="text-align: left;">Dice, coin flips</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Chaos</strong></td>
<td style="text-align: left;">Deterministic dynamics, <em>sensitive</em> to initial conditions</td>
<td style="text-align: left;">Tiny changes → big divergences</td>
<td style="text-align: left;">Weather, double pendulum</td>
</tr>
<tr class="odd">
<td style="text-align: left;"><strong>Entropy</strong></td>
<td style="text-align: left;"><strong>Measure</strong> of uncertainty/disorder (info/thermo)</td>
<td style="text-align: left;">Higher when outcomes are more spread</td>
<td style="text-align: left;">Shannon entropy of a fair vs.&nbsp;loaded die</td>
</tr>
<tr class="even">
<td style="text-align: left;"><strong>Haphazardness</strong></td>
<td style="text-align: left;">Informal appearance of disorder</td>
<td style="text-align: left;">May lack any governing model</td>
<td style="text-align: left;">Clutter on a desk</td>
</tr>
</tbody>
</table>
</section>
<section id="why-randomness-matters-1" class="level3">
<h3 class="anchored" data-anchor-id="why-randomness-matters-1">Why Randomness Matters</h3>
<ul>
<li><p><strong>Random sampling</strong></p>
<ul>
<li>Limits systematic bias in surveys</li>
<li>Lets us compute margins of error and confidence intervals</li>
</ul></li>
<li><p><strong>Random assignment (experiments)</strong></p>
<ul>
<li>Balances observed and unobserved factors on average</li>
<li>Enables credible <strong>causal</strong> inference</li>
</ul></li>
</ul>
</section>
<section id="the-power-of-random-sampling-quick-demo-1" class="level3">
<h3 class="anchored" data-anchor-id="the-power-of-random-sampling-quick-demo-1">The Power of Random Sampling (quick demo)</h3>
<p>If we randomly sample 1,000 voters and estimate 55% support, statistics tells us:</p>
<ul>
<li>The population support is likely close to 55%,</li>
<li>We can quantify “how close” (often ≈ ±3 pp at 95%),</li>
<li>Because large‑sample randomness follows predictable patterns.</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb119"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb119-1"><a href="#cb119-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Self-contained demo (no external packages beyond ggplot2)</span></span>
<span id="cb119-2"><a href="#cb119-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb119-3"><a href="#cb119-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-4"><a href="#cb119-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a synthetic "population" with a known proportion</span></span>
<span id="cb119-5"><a href="#cb119-5" aria-hidden="true" tabindex="-1"></a>population_support <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"A"</span>, <span class="dv">5200</span>), <span class="fu">rep</span>(<span class="st">"B"</span>, <span class="dv">4800</span>))</span>
<span id="cb119-6"><a href="#cb119-6" aria-hidden="true" tabindex="-1"></a>true_support_A <span class="ot">&lt;-</span> <span class="fu">mean</span>(population_support <span class="sc">==</span> <span class="st">"A"</span>)</span>
<span id="cb119-7"><a href="#cb119-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-8"><a href="#cb119-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Function: take a simple random sample and compute support for A</span></span>
<span id="cb119-9"><a href="#cb119-9" aria-hidden="true" tabindex="-1"></a>sample_support <span class="ot">&lt;-</span> <span class="cf">function</span>(n) {</span>
<span id="cb119-10"><a href="#cb119-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mean</span>(<span class="fu">sample</span>(population_support, n) <span class="sc">==</span> <span class="st">"A"</span>)</span>
<span id="cb119-11"><a href="#cb119-11" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb119-12"><a href="#cb119-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-13"><a href="#cb119-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample sizes and repeated draws</span></span>
<span id="cb119-14"><a href="#cb119-14" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>)</span>
<span id="cb119-15"><a href="#cb119-15" aria-hidden="true" tabindex="-1"></a>results_list <span class="ot">&lt;-</span> <span class="fu">lapply</span>(sample_sizes, <span class="cf">function</span>(n) {</span>
<span id="cb119-16"><a href="#cb119-16" aria-hidden="true" tabindex="-1"></a>  est <span class="ot">&lt;-</span> <span class="fu">replicate</span>(<span class="dv">100</span>, <span class="fu">sample_support</span>(n))</span>
<span id="cb119-17"><a href="#cb119-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">data.frame</span>(<span class="at">sample_size =</span> <span class="fu">factor</span>(n), <span class="at">estimate =</span> est, <span class="at">true_value =</span> true_support_A)</span>
<span id="cb119-18"><a href="#cb119-18" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb119-19"><a href="#cb119-19" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">do.call</span>(rbind, results_list)</span>
<span id="cb119-20"><a href="#cb119-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-21"><a href="#cb119-21" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb119-22"><a href="#cb119-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb119-23"><a href="#cb119-23" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(results, <span class="fu">aes</span>(<span class="at">x =</span> sample_size, <span class="at">y =</span> estimate)) <span class="sc">+</span></span>
<span id="cb119-24"><a href="#cb119-24" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">fill =</span> <span class="st">"lightblue"</span>) <span class="sc">+</span></span>
<span id="cb119-25"><a href="#cb119-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> true_support_A, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">linewidth =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb119-26"><a href="#cb119-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb119-27"><a href="#cb119-27" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Random Sampling Converges to the Truth as n Increases"</span>,</span>
<span id="cb119-28"><a href="#cb119-28" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Red dashed line = true population value (52%)"</span>,</span>
<span id="cb119-29"><a href="#cb119-29" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Sample size"</span>,</span>
<span id="cb119-30"><a href="#cb119-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Estimated support for A"</span>,</span>
<span id="cb119-31"><a href="#cb119-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">"Each box summarizes 100 random samples"</span></span>
<span id="cb119-32"><a href="#cb119-32" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb119-33"><a href="#cb119-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span><span class="fu">percent_format</span>())</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/random-sampling-demo-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Reading the figure.</strong> Boxes show the middle 50% of estimates; the line is the median. As <strong>n</strong> grows, the boxes narrow: variability from randomness shrinks, and estimates settle near the true value.</p>
</div>
</div>
<p><strong>Bottom line:</strong> Randomness underpins statistical inference: it turns uncertainty in individual outcomes into <strong>predictable distributions</strong> for estimates, letting us measure error, build intervals, and test hypotheses.</p>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="Preface">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preface</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./rozdzial1.html" class="pagination-link" aria-label="Wprowadzenie do statystyki i analizy danych dla politologii">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Wprowadzenie do statystyki i analizy danych dla politologii</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>