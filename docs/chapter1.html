<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; Foundations of Statistics and Demography – Statistics: An Introduction (PL: Wprowadzenie do Statystyki)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./rozdzial1.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-ffd282cb318059e0bcb130885a47f5dc.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter1.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Foundations of Statistics and Demography</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistics: An Introduction (PL: Wprowadzenie do Statystyki)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter1.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Foundations of Statistics and Demography</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Podstawy Statystyki i Demografii</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Understanding Data Types in Social Sciences</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Typy Danych w Naukach Społecznych</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Fundamentals of Univariate Descriptive Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Podstawy Jednowymiarowej Statystyki Opisowej</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Visualization: with examples in R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Wizualizacja Danych: z przykładami w R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correg_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Correlation and Regression Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correg_pl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Wprowadzenie do Analizy Korelacji i Regresji</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1.1</span> Introduction</a></li>
  <li><a href="#what-is-statistics" id="toc-what-is-statistics" class="nav-link" data-scroll-target="#what-is-statistics"><span class="header-section-number">1.2</span> What is Statistics?</a>
  <ul class="collapse">
  <li><a href="#descriptive-statistics" id="toc-descriptive-statistics" class="nav-link" data-scroll-target="#descriptive-statistics">Descriptive Statistics</a></li>
  <li><a href="#inferential-statistics" id="toc-inferential-statistics" class="nav-link" data-scroll-target="#inferential-statistics">Inferential Statistics</a></li>
  <li><a href="#statistical-thinking" id="toc-statistical-thinking" class="nav-link" data-scroll-target="#statistical-thinking">Statistical Thinking</a></li>
  <li><a href="#from-error-to-understanding-modern-polling" id="toc-from-error-to-understanding-modern-polling" class="nav-link" data-scroll-target="#from-error-to-understanding-modern-polling">From Error to Understanding: Modern Polling</a></li>
  </ul></li>
  <li><a href="#data-and-distributions" id="toc-data-and-distributions" class="nav-link" data-scroll-target="#data-and-distributions"><span class="header-section-number">1.3</span> Data and Distributions</a>
  <ul class="collapse">
  <li><a href="#types-of-data" id="toc-types-of-data" class="nav-link" data-scroll-target="#types-of-data">Types of Data</a></li>
  <li><a href="#data-distribution" id="toc-data-distribution" class="nav-link" data-scroll-target="#data-distribution">Data Distribution</a></li>
  <li><a href="#frequency-distribution" id="toc-frequency-distribution" class="nav-link" data-scroll-target="#frequency-distribution">Frequency Distribution</a></li>
  </ul></li>
  <li><a href="#populations-and-samples" id="toc-populations-and-samples" class="nav-link" data-scroll-target="#populations-and-samples"><span class="header-section-number">1.4</span> Populations and Samples</a>
  <ul class="collapse">
  <li><a href="#population" id="toc-population" class="nav-link" data-scroll-target="#population">Population</a></li>
  <li><a href="#sample" id="toc-sample" class="nav-link" data-scroll-target="#sample">Sample</a></li>
  </ul></li>
  <li><a href="#superpopulation-and-data-generating-process-dgp" id="toc-superpopulation-and-data-generating-process-dgp" class="nav-link" data-scroll-target="#superpopulation-and-data-generating-process-dgp"><span class="header-section-number">1.5</span> Superpopulation and Data Generating Process (DGP) (*)</a>
  <ul class="collapse">
  <li><a href="#superpopulation" id="toc-superpopulation" class="nav-link" data-scroll-target="#superpopulation"><strong>Superpopulation</strong></a></li>
  <li><a href="#data-generating-process-the-true-recipe" id="toc-data-generating-process-the-true-recipe" class="nav-link" data-scroll-target="#data-generating-process-the-true-recipe"><strong>Data Generating Process: The True Recipe</strong></a></li>
  <li><a href="#two-approaches-to-statistical-inference" id="toc-two-approaches-to-statistical-inference" class="nav-link" data-scroll-target="#two-approaches-to-statistical-inference"><strong>Two Approaches to Statistical Inference</strong></a></li>
  <li><a href="#practical-example-analyzing-state-education-spending" id="toc-practical-example-analyzing-state-education-spending" class="nav-link" data-scroll-target="#practical-example-analyzing-state-education-spending"><strong>Practical Example: Analyzing State Education Spending</strong></a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><strong>Summary</strong></a></li>
  </ul></li>
  <li><a href="#variables-and-measurement-scales" id="toc-variables-and-measurement-scales" class="nav-link" data-scroll-target="#variables-and-measurement-scales"><span class="header-section-number">1.6</span> Variables and Measurement Scales</a>
  <ul class="collapse">
  <li><a href="#measurement-transforming-concepts-into-numbers" id="toc-measurement-transforming-concepts-into-numbers" class="nav-link" data-scroll-target="#measurement-transforming-concepts-into-numbers">Measurement: Transforming Concepts into Numbers</a></li>
  <li><a href="#types-of-variables" id="toc-types-of-variables" class="nav-link" data-scroll-target="#types-of-variables">Types of Variables</a></li>
  <li><a href="#measurement-scales" id="toc-measurement-scales" class="nav-link" data-scroll-target="#measurement-scales">Measurement Scales</a></li>
  </ul></li>
  <li><a href="#parameters-statistics-and-estimation" id="toc-parameters-statistics-and-estimation" class="nav-link" data-scroll-target="#parameters-statistics-and-estimation"><span class="header-section-number">1.7</span> Parameters, Statistics, and Estimation</a>
  <ul class="collapse">
  <li><a href="#parameter" id="toc-parameter" class="nav-link" data-scroll-target="#parameter">Parameter</a></li>
  <li><a href="#statistic" id="toc-statistic" class="nav-link" data-scroll-target="#statistic">Statistic</a></li>
  <li><a href="#the-relationship-between-parameters-and-statistics" id="toc-the-relationship-between-parameters-and-statistics" class="nav-link" data-scroll-target="#the-relationship-between-parameters-and-statistics">The Relationship Between Parameters and Statistics</a></li>
  <li><a href="#estimator" id="toc-estimator" class="nav-link" data-scroll-target="#estimator">Estimator</a></li>
  <li><a href="#estimand" id="toc-estimand" class="nav-link" data-scroll-target="#estimand">Estimand</a></li>
  <li><a href="#estimate" id="toc-estimate" class="nav-link" data-scroll-target="#estimate">Estimate</a></li>
  </ul></li>
  <li><a href="#statistical-error" id="toc-statistical-error" class="nav-link" data-scroll-target="#statistical-error"><span class="header-section-number">1.8</span> Statistical Error</a></li>
  <li><a href="#random-error" id="toc-random-error" class="nav-link" data-scroll-target="#random-error">Random Error</a></li>
  <li><a href="#systematic-error" id="toc-systematic-error" class="nav-link" data-scroll-target="#systematic-error">Systematic Error</a></li>
  <li><a href="#sampling-and-sampling-methods" id="toc-sampling-and-sampling-methods" class="nav-link" data-scroll-target="#sampling-and-sampling-methods"><span class="header-section-number">1.18</span> Sampling and Sampling Methods</a>
  <ul class="collapse">
  <li><a href="#the-sampling-frame" id="toc-the-sampling-frame" class="nav-link" data-scroll-target="#the-sampling-frame">The Sampling Frame</a></li>
  <li><a href="#probability-sampling-methods" id="toc-probability-sampling-methods" class="nav-link" data-scroll-target="#probability-sampling-methods">Probability Sampling Methods</a></li>
  <li><a href="#non-probability-sampling-methods" id="toc-non-probability-sampling-methods" class="nav-link" data-scroll-target="#non-probability-sampling-methods">Non-Probability Sampling Methods</a></li>
  </ul></li>
  <li><a href="#measures-of-uncertainty" id="toc-measures-of-uncertainty" class="nav-link" data-scroll-target="#measures-of-uncertainty"><span class="header-section-number">1.19</span> Measures of Uncertainty</a>
  <ul class="collapse">
  <li><a href="#standard-error" id="toc-standard-error" class="nav-link" data-scroll-target="#standard-error">Standard Error</a></li>
  <li><a href="#margin-of-error" id="toc-margin-of-error" class="nav-link" data-scroll-target="#margin-of-error">Margin of Error</a></li>
  <li><a href="#confidence-interval" id="toc-confidence-interval" class="nav-link" data-scroll-target="#confidence-interval">Confidence Interval</a></li>
  </ul></li>
  <li><a href="#probability-concepts-for-statistical-analysis" id="toc-probability-concepts-for-statistical-analysis" class="nav-link" data-scroll-target="#probability-concepts-for-statistical-analysis"><span class="header-section-number">1.24</span> Probability Concepts for Statistical Analysis</a>
  <ul class="collapse">
  <li><a href="#basic-probability" id="toc-basic-probability" class="nav-link" data-scroll-target="#basic-probability">Basic Probability</a></li>
  <li><a href="#conditional-probability" id="toc-conditional-probability" class="nav-link" data-scroll-target="#conditional-probability">Conditional Probability</a></li>
  <li><a href="#independence" id="toc-independence" class="nav-link" data-scroll-target="#independence">Independence</a></li>
  <li><a href="#law-of-large-numbers" id="toc-law-of-large-numbers" class="nav-link" data-scroll-target="#law-of-large-numbers">Law of Large Numbers</a></li>
  <li><a href="#visualizing-the-law-of-large-numbers-coin-flips" id="toc-visualizing-the-law-of-large-numbers-coin-flips" class="nav-link" data-scroll-target="#visualizing-the-law-of-large-numbers-coin-flips">Visualizing the Law of Large Numbers: Coin Flips</a></li>
  <li><a href="#the-mathematical-statement" id="toc-the-mathematical-statement" class="nav-link" data-scroll-target="#the-mathematical-statement">The Mathematical Statement</a></li>
  <li><a href="#examples-in-different-contexts" id="toc-examples-in-different-contexts" class="nav-link" data-scroll-target="#examples-in-different-contexts">Examples in Different Contexts</a></li>
  <li><a href="#why-this-matters-for-statistics" id="toc-why-this-matters-for-statistics" class="nav-link" data-scroll-target="#why-this-matters-for-statistics">Why This Matters for Statistics</a></li>
  <li><a href="#central-limit-theorem" id="toc-central-limit-theorem" class="nav-link" data-scroll-target="#central-limit-theorem">Central Limit Theorem</a></li>
  </ul></li>
  <li><a href="#statistical-significance-a-quick-start-guide" id="toc-statistical-significance-a-quick-start-guide" class="nav-link" data-scroll-target="#statistical-significance-a-quick-start-guide"><span class="header-section-number">1.26</span> Statistical Significance: A Quick Start Guide</a></li>
  <li><a href="#the-framework-think-like-a-judge-not-a-prosecutor" id="toc-the-framework-think-like-a-judge-not-a-prosecutor" class="nav-link" data-scroll-target="#the-framework-think-like-a-judge-not-a-prosecutor"><span class="header-section-number">1.27</span> The Framework: Think Like a Judge (Not a Prosecutor!)</a>
  <ul class="collapse">
  <li><a href="#the-courtroom-analogy" id="toc-the-courtroom-analogy" class="nav-link" data-scroll-target="#the-courtroom-analogy">The Courtroom Analogy</a></li>
  <li><a href="#start-with-skepticism-presumption-of-innocence" id="toc-start-with-skepticism-presumption-of-innocence" class="nav-link" data-scroll-target="#start-with-skepticism-presumption-of-innocence">Start with Skepticism (Presumption of Innocence)</a></li>
  </ul></li>
  <li><a href="#the-p-value-your-surprise-meter" id="toc-the-p-value-your-surprise-meter" class="nav-link" data-scroll-target="#the-p-value-your-surprise-meter"><span class="header-section-number">1.28</span> The p-value: Your “Surprise Meter”</a>
  <ul class="collapse">
  <li><a href="#three-ways-to-think-about-p-values" id="toc-three-ways-to-think-about-p-values" class="nav-link" data-scroll-target="#three-ways-to-think-about-p-values">Three Ways to Think About p-values</a></li>
  </ul></li>
  <li><a href="#the-prosecutor-fallacy-a-critical-warning" id="toc-the-prosecutor-fallacy-a-critical-warning" class="nav-link" data-scroll-target="#the-prosecutor-fallacy-a-critical-warning"><span class="header-section-number">1.29</span> The Prosecutor Fallacy: A Critical Warning</a>
  <ul class="collapse">
  <li><a href="#the-fallacy-explained" id="toc-the-fallacy-explained" class="nav-link" data-scroll-target="#the-fallacy-explained">The Fallacy Explained</a></li>
  <li><a href="#the-statistical-version" id="toc-the-statistical-version" class="nav-link" data-scroll-target="#the-statistical-version">The Statistical Version</a></li>
  <li><a href="#why-this-matters-a-concrete-example" id="toc-why-this-matters-a-concrete-example" class="nav-link" data-scroll-target="#why-this-matters-a-concrete-example">Why This Matters: A Concrete Example</a></li>
  </ul></li>
  <li><a href="#introduction-to-regression-analysis-modeling-relationships-between-variables" id="toc-introduction-to-regression-analysis-modeling-relationships-between-variables" class="nav-link" data-scroll-target="#introduction-to-regression-analysis-modeling-relationships-between-variables"><span class="header-section-number">1.30</span> Introduction to Regression Analysis: Modeling Relationships Between Variables</a>
  <ul class="collapse">
  <li><a href="#what-is-regression-analysis" id="toc-what-is-regression-analysis" class="nav-link" data-scroll-target="#what-is-regression-analysis">What is Regression Analysis?</a></li>
  <li><a href="#the-basic-idea-drawing-the-best-line-through-points" id="toc-the-basic-idea-drawing-the-best-line-through-points" class="nav-link" data-scroll-target="#the-basic-idea-drawing-the-best-line-through-points">The Basic Idea: Drawing the Best Line Through Points</a></li>
  <li><a href="#understanding-relationships-vs.-proving-causation" id="toc-understanding-relationships-vs.-proving-causation" class="nav-link" data-scroll-target="#understanding-relationships-vs.-proving-causation">Understanding Relationships vs.&nbsp;Proving Causation</a></li>
  <li><a href="#multiple-regression-controlling-for-other-factors" id="toc-multiple-regression-controlling-for-other-factors" class="nav-link" data-scroll-target="#multiple-regression-controlling-for-other-factors">Multiple Regression: Controlling for Other Factors</a></li>
  <li><a href="#types-of-variables-in-regression" id="toc-types-of-variables-in-regression" class="nav-link" data-scroll-target="#types-of-variables-in-regression">Types of Variables in Regression</a></li>
  <li><a href="#different-types-of-regression-for-different-outcomes" id="toc-different-types-of-regression-for-different-outcomes" class="nav-link" data-scroll-target="#different-types-of-regression-for-different-outcomes">Different Types of Regression for Different Outcomes</a></li>
  <li><a href="#interpreting-regression-results" id="toc-interpreting-regression-results" class="nav-link" data-scroll-target="#interpreting-regression-results">Interpreting Regression Results</a></li>
  <li><a href="#assumptions-and-limitations" id="toc-assumptions-and-limitations" class="nav-link" data-scroll-target="#assumptions-and-limitations">Assumptions and Limitations</a></li>
  <li><a href="#practical-applications-in-demography" id="toc-practical-applications-in-demography" class="nav-link" data-scroll-target="#practical-applications-in-demography">Practical Applications in Demography</a></li>
  <li><a href="#common-pitfalls-and-how-to-avoid-them" id="toc-common-pitfalls-and-how-to-avoid-them" class="nav-link" data-scroll-target="#common-pitfalls-and-how-to-avoid-them">Common Pitfalls and How to Avoid Them</a></li>
  <li><a href="#making-regression-intuitive" id="toc-making-regression-intuitive" class="nav-link" data-scroll-target="#making-regression-intuitive">Making Regression Intuitive</a></li>
  <li><a href="#the-power-and-responsibility-of-regression" id="toc-the-power-and-responsibility-of-regression" class="nav-link" data-scroll-target="#the-power-and-responsibility-of-regression">The Power and Responsibility of Regression</a></li>
  <li><a href="#regression-in-practice-a-complete-example" id="toc-regression-in-practice-a-complete-example" class="nav-link" data-scroll-target="#regression-in-practice-a-complete-example">Regression in Practice: A Complete Example</a></li>
  <li><a href="#moving-forward-with-regression" id="toc-moving-forward-with-regression" class="nav-link" data-scroll-target="#moving-forward-with-regression">Moving Forward with Regression</a></li>
  </ul></li>
  <li><a href="#data-quality-and-sources" id="toc-data-quality-and-sources" class="nav-link" data-scroll-target="#data-quality-and-sources"><span class="header-section-number">1.33</span> Data Quality and Sources</a>
  <ul class="collapse">
  <li><a href="#dimensions-of-data-quality" id="toc-dimensions-of-data-quality" class="nav-link" data-scroll-target="#dimensions-of-data-quality">Dimensions of Data Quality</a></li>
  <li><a href="#common-data-sources-in-demography" id="toc-common-data-sources-in-demography" class="nav-link" data-scroll-target="#common-data-sources-in-demography">Common Data Sources in Demography</a></li>
  <li><a href="#data-quality-issues-specific-to-demography" id="toc-data-quality-issues-specific-to-demography" class="nav-link" data-scroll-target="#data-quality-issues-specific-to-demography">Data Quality Issues Specific to Demography</a></li>
  </ul></li>
  <li><a href="#ethical-considerations-in-statistical-demographics" id="toc-ethical-considerations-in-statistical-demographics" class="nav-link" data-scroll-target="#ethical-considerations-in-statistical-demographics"><span class="header-section-number">1.34</span> Ethical Considerations in Statistical Demographics</a>
  <ul class="collapse">
  <li><a href="#informed-consent" id="toc-informed-consent" class="nav-link" data-scroll-target="#informed-consent">Informed Consent</a></li>
  <li><a href="#confidentiality-and-privacy" id="toc-confidentiality-and-privacy" class="nav-link" data-scroll-target="#confidentiality-and-privacy">Confidentiality and Privacy</a></li>
  <li><a href="#representation-and-fairness" id="toc-representation-and-fairness" class="nav-link" data-scroll-target="#representation-and-fairness">Representation and Fairness</a></li>
  <li><a href="#misuse-of-statistics" id="toc-misuse-of-statistics" class="nav-link" data-scroll-target="#misuse-of-statistics">Misuse of Statistics</a></li>
  <li><a href="#responsible-reporting" id="toc-responsible-reporting" class="nav-link" data-scroll-target="#responsible-reporting">Responsible Reporting</a></li>
  </ul></li>
  <li><a href="#common-misconceptions-in-statistics" id="toc-common-misconceptions-in-statistics" class="nav-link" data-scroll-target="#common-misconceptions-in-statistics"><span class="header-section-number">1.35</span> Common Misconceptions in Statistics</a>
  <ul class="collapse">
  <li><a href="#misconception-1-statistics-can-prove-anything" id="toc-misconception-1-statistics-can-prove-anything" class="nav-link" data-scroll-target="#misconception-1-statistics-can-prove-anything">Misconception 1: “Statistics Can Prove Anything”</a></li>
  <li><a href="#misconception-2-larger-samples-are-always-better" id="toc-misconception-2-larger-samples-are-always-better" class="nav-link" data-scroll-target="#misconception-2-larger-samples-are-always-better">Misconception 2: “Larger Samples Are Always Better”</a></li>
  <li><a href="#misconception-3-statistical-significance-practical-importance" id="toc-misconception-3-statistical-significance-practical-importance" class="nav-link" data-scroll-target="#misconception-3-statistical-significance-practical-importance">Misconception 3: “Statistical Significance = Practical Importance”</a></li>
  <li><a href="#misconception-4-correlation-implies-causation" id="toc-misconception-4-correlation-implies-causation" class="nav-link" data-scroll-target="#misconception-4-correlation-implies-causation">Misconception 4: “Correlation Implies Causation”</a></li>
  <li><a href="#misconception-5-random-means-haphazard" id="toc-misconception-5-random-means-haphazard" class="nav-link" data-scroll-target="#misconception-5-random-means-haphazard">Misconception 5: “Random Means Haphazard”</a></li>
  <li><a href="#misconception-6-average-represents-everyone" id="toc-misconception-6-average-represents-everyone" class="nav-link" data-scroll-target="#misconception-6-average-represents-everyone">Misconception 6: “Average Represents Everyone”</a></li>
  <li><a href="#misconception-7-past-patterns-guarantee-future-results" id="toc-misconception-7-past-patterns-guarantee-future-results" class="nav-link" data-scroll-target="#misconception-7-past-patterns-guarantee-future-results">Misconception 7: “Past Patterns Guarantee Future Results”</a></li>
  </ul></li>
  <li><a href="#applications-in-demography" id="toc-applications-in-demography" class="nav-link" data-scroll-target="#applications-in-demography"><span class="header-section-number">1.36</span> Applications in Demography</a>
  <ul class="collapse">
  <li><a href="#population-estimation-and-projection" id="toc-population-estimation-and-projection" class="nav-link" data-scroll-target="#population-estimation-and-projection">Population Estimation and Projection</a></li>
  <li><a href="#demographic-rate-calculation" id="toc-demographic-rate-calculation" class="nav-link" data-scroll-target="#demographic-rate-calculation">Demographic Rate Calculation</a></li>
  <li><a href="#life-table-analysis" id="toc-life-table-analysis" class="nav-link" data-scroll-target="#life-table-analysis">Life Table Analysis</a></li>
  <li><a href="#fertility-analysis-1" id="toc-fertility-analysis-1" class="nav-link" data-scroll-target="#fertility-analysis-1">Fertility Analysis</a></li>
  <li><a href="#migration-analysis" id="toc-migration-analysis" class="nav-link" data-scroll-target="#migration-analysis">Migration Analysis</a></li>
  <li><a href="#population-health-metrics" id="toc-population-health-metrics" class="nav-link" data-scroll-target="#population-health-metrics">Population Health Metrics</a></li>
  </ul></li>
  <li><a href="#software-and-tools" id="toc-software-and-tools" class="nav-link" data-scroll-target="#software-and-tools"><span class="header-section-number">1.37</span> Software and Tools</a>
  <ul class="collapse">
  <li><a href="#statistical-software-packages" id="toc-statistical-software-packages" class="nav-link" data-scroll-target="#statistical-software-packages">Statistical Software Packages</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">1.38</span> Conclusion</a></li>
  <li><a href="#key-terms-summary" id="toc-key-terms-summary" class="nav-link" data-scroll-target="#key-terms-summary"><span class="header-section-number">1.39</span> Key Terms Summary</a></li>
  <li><a href="#practice-exercises" id="toc-practice-exercises" class="nav-link" data-scroll-target="#practice-exercises"><span class="header-section-number">1.40</span> Practice Exercises</a>
  <ul class="collapse">
  <li><a href="#conceptual-understanding" id="toc-conceptual-understanding" class="nav-link" data-scroll-target="#conceptual-understanding">Conceptual Understanding</a></li>
  <li><a href="#calculations" id="toc-calculations" class="nav-link" data-scroll-target="#calculations">Calculations</a></li>
  <li><a href="#application-problems" id="toc-application-problems" class="nav-link" data-scroll-target="#application-problems">Application Problems</a></li>
  <li><a href="#critical-thinking" id="toc-critical-thinking" class="nav-link" data-scroll-target="#critical-thinking">Critical Thinking</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Foundations of Statistics and Demography</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<hr>
<section id="introduction" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1.1</span> Introduction</h2>
<p><strong>Statistics</strong> is the science of learning from data under uncertainty.</p>
<p>Statistics is a way to learn about the world from data when results vary and are uncertain. It teaches how to collect data wisely, spot patterns, estimate population quantities, and make predictions—always stating how wrong we might be.</p>
<p><strong>Demography</strong> is the scientific study of human populations, focusing on their size, structure, distribution, and changes over time. It’s essentially the statistical analysis of people - who they are, where they live, how many there are, and how these characteristics evolve.</p>
<hr>
<p>Statistics and demography are interconnected disciplines that provide powerful tools for understanding populations, their characteristics, and the patterns that emerge from data. In an era where data drives decision-making from local community planning to global policy initiatives, understanding statistical principles is not just academic—it’s essential for informed citizenship and professional practice.</p>
<p>Consider a practical example: When news reports state that “unemployment has decreased by 2%,” what does this really mean? Is this change meaningful or could it be due to random variation? How was this measured? Who was included in the study? These questions illustrate why statistical literacy is crucial for interpreting the demographic information that shapes our world.</p>
<p>Statistics serves as the mathematical backbone of demographic analysis, enabling us to move beyond simple description to understanding complex population dynamics, making predictions, and informing policy decisions.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Rounding and Scientific Notation in Statistics
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Main Rule:</strong> Unless otherwise specified, round the <strong>decimal parts</strong> of decimal numbers to <strong>at least 2 significant figures</strong>. In statistics, we often work with long decimal parts and very small numbers — don’t round excessively in intermediate steps, round <strong>at the end</strong> of calculations.</p>
<section id="rounding-in-statistical-context" class="level3">
<h3 class="anchored" data-anchor-id="rounding-in-statistical-context">Rounding in Statistical Context</h3>
<p>The <strong>decimal part</strong> consists of digits after the decimal point. In statistics, it’s particularly important to maintain appropriate precision:</p>
<p><strong>Descriptive statistics:</strong></p>
<ul>
<li>Mean: <span class="math inline">\bar{x} = 15.847693... \rightarrow 15.85</span></li>
<li>Standard deviation: <span class="math inline">s = 2.7488... \rightarrow 2.75</span></li>
<li>Correlation coefficient: <span class="math inline">r = 0.78432... \rightarrow 0.78</span></li>
</ul>
<p><strong>Very small numbers (p-values, probabilities):</strong></p>
<ul>
<li><span class="math inline">p = 0.000347... \rightarrow 0.00035</span> or <span class="math inline">3.5 \times 10^{-4}</span></li>
<li><span class="math inline">P(X &gt; 2) = 0.0000891... \rightarrow 0.000089</span> or <span class="math inline">8.9 \times 10^{-5}</span></li>
</ul>
</section>
<section id="significant-figures-in-decimal-parts" class="level3">
<h3 class="anchored" data-anchor-id="significant-figures-in-decimal-parts">Significant Figures in Decimal Parts</h3>
<p>In the decimal part, significant figures are all digits except leading zeros:</p>
<ul>
<li><span class="math inline">.78432</span> has 5 significant figures → round to <span class="math inline">.78</span> (2 s.f.)</li>
<li><span class="math inline">.000347</span> has 3 significant figures → round to <span class="math inline">.00035</span> (2 s.f.)</li>
<li><span class="math inline">.050600</span> has 4 significant figures → round to <span class="math inline">.051</span> (2 s.f.)</li>
</ul>
</section>
<section id="rounding-rules-in-statistics" class="level3">
<h3 class="anchored" data-anchor-id="rounding-rules-in-statistics">Rounding Rules in Statistics</h3>
<ol type="1">
<li><strong>Round only the decimal part</strong> to at least 2 significant figures</li>
<li><strong>The integer part</strong> remains unchanged</li>
<li><strong>In long calculations</strong> keep 3-4 digits in the decimal part until the final step</li>
<li><strong>NEVER round to zero</strong> - small values have interpretive significance</li>
<li><strong>For very small numbers</strong> use scientific notation when it improves readability</li>
<li><strong>P-values</strong> often require greater precision — keep 2-3 significant figures</li>
</ol>
<p>⚠️ WARNING: Don’t round to zero!</p>
</section>
<section id="scientific-notation-in-statistics" class="level3">
<h3 class="anchored" data-anchor-id="scientific-notation-in-statistics">Scientific Notation in Statistics</h3>
<p>In statistics, we often encounter very small numbers. Use scientific notation when it improves readability:</p>
<p><strong>P-values and probabilities:</strong></p>
<ul>
<li><span class="math inline">p = 0.000347 = 3.47 \times 10^{-4}</span> (better: <span class="math inline">3.5 \times 10^{-4}</span>)</li>
<li><span class="math inline">P(Z &gt; 3.5) = 0.000233 = 2.33 \times 10^{-4}</span></li>
</ul>
<p><strong>Very small standard deviations:</strong></p>
<ul>
<li><span class="math inline">\sigma = 0.000892 = 8.92 \times 10^{-4}</span></li>
</ul>
<p><strong>Large numbers (rare in basic statistics):</strong></p>
<ul>
<li><span class="math inline">N = 1\,234\,567 = 1.23 \times 10^6</span></li>
</ul>
<p><strong>When in doubt:</strong> Better to keep an extra digit than to round too aggressively</p>
</section>
</div>
</div>
</section>
<section id="what-is-statistics" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="what-is-statistics"><span class="header-section-number">1.2</span> What is Statistics?</h2>
<p><strong>Statistics</strong> is the science of collecting, organizing, analyzing, interpreting, and presenting data. It encompasses both the methods for working with data and the theoretical foundations that justify these methods. But statistics is more than just numbers and formulas—it’s a way of thinking about uncertainty and variation in the world around us.</p>
<p>Imagine you want to understand the average age at first marriage in your country. You cannot possibly ask every single person when they first married (if at all). Statistics provides the tools to:</p>
<ul>
<li>Select a representative group of people to survey</li>
<li>Calculate meaningful summaries from their responses</li>
<li>Estimate the likely average for the entire population</li>
<li>Quantify how confident you can be in your estimate</li>
<li>Test whether the average age is changing over time</li>
</ul>
<p>The field of statistics can be broadly divided into two complementary branches:</p>
<section id="descriptive-statistics" class="level3">
<h3 class="anchored" data-anchor-id="descriptive-statistics">Descriptive Statistics</h3>
<p><strong>Descriptive Statistics</strong> involves methods for summarizing and presenting data in meaningful ways. This includes:</p>
<p><strong>Measures of Central Tendency</strong> - Where is the center of your data?</p>
<ul>
<li><strong>Mean</strong>: The arithmetic average. If the total household income in a village of 100 households is $5,000,000, the mean income is $50,000. However, if one household is extremely wealthy, this might not represent the typical household well.</li>
<li><strong>Median</strong>: The middle value when data is ordered. If most households earn between $20,000-$40,000 but one earns $2,000,000, the median better represents the typical household.</li>
<li><strong>Mode</strong>: The most frequent value. In studying family size, if most families have 2 children, 2 is the mode, even if the mean is 2.3 children.</li>
</ul>
<p><strong>Measures of Variability</strong> - How spread out is your data?</p>
<ul>
<li><strong>Range</strong>: The difference between maximum and minimum values. If ages in a community range from 0 to 95 years, the range is 95 years.</li>
<li><strong>Variance</strong>: The average squared deviation from the mean. Measures how far values typically fall from the center.</li>
<li><strong>Standard Deviation</strong>: The square root of variance, in the same units as the original data. If the mean age is 35 years with a standard deviation of 20 years, most people are between 15 and 55 years old.</li>
</ul>
<p><strong>Visual Representations</strong></p>
<ul>
<li><strong>Population Pyramids</strong>: Show age and sex distribution, revealing demographic history. A wide base indicates high birth rates; a narrow base suggests declining fertility.</li>
<li><strong>Life Tables</strong>: Summarize mortality patterns, showing the probability of surviving to each age.</li>
<li><strong>Time Series Graphs</strong>: Display trends over time, such as changing fertility rates across decades.</li>
</ul>
</section>
<section id="inferential-statistics" class="level3">
<h3 class="anchored" data-anchor-id="inferential-statistics">Inferential Statistics</h3>
<p><strong>Inferential Statistics</strong> encompasses techniques for drawing conclusions about populations based on sample data. This branch allows us to move beyond what we observe to what we can reasonably conclude.</p>
<p><img src="stat_imgs/random-sample.svg" class="img-fluid"></p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
A Practical Analogy: Soup-Tasting
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="stat_imgs/soup-svgrepo-com.svg" class="img-fluid" style="width:30.0%"></p>
<p>Consider a chef preparing soup for 100 people who needs to assess its flavor without consuming the entire batch:</p>
<p><strong>Population</strong>: The entire pot of soup (100 servings)<br>
<strong>Sample</strong>: A single spoonful for tasting<br>
<strong>Population Parameter</strong>: The true average saltiness of the complete pot (unknown)<br>
<strong>Sample Statistic</strong>: The saltiness level detected in the spoonful (observable)<br>
<strong>Statistical Inference</strong>: Using the spoonful’s characteristics to draw conclusions about the entire pot</p>
<section id="key-principles" class="level3">
<h3 class="anchored" data-anchor-id="key-principles">Key Principles</h3>
<p><strong>1. Random sampling is essential</strong>: The chef must thoroughly stir the soup before sampling. Consistently sampling from the surface might miss seasoning that has settled, introducing systematic bias.</p>
<p><strong>2. Sample size affects precision</strong>: A larger spoonful provides more reliable information about overall flavor than a small sip, though practical constraints limit sample size.</p>
<p><strong>3. Uncertainty is inherent</strong>: Even with proper sampling technique, the spoonful might not perfectly represent the entire pot’s characteristics.</p>
<p><strong>4. Systematic bias undermines inference</strong>: If someone secretly adds salt only to the sampling area, conclusions about the whole pot become invalid—illustrating how sampling bias distorts statistical inference.</p>
<p><strong>5. Inference has scope limitations</strong>: The sample can estimate average saltiness but cannot reveal whether some portions are saltier than others, highlighting the limits of what samples can tell us about population variability.</p>
<p>This analogy captures the essence of statistical reasoning: using carefully selected samples to learn about larger populations while explicitly acknowledging and quantifying the inherent uncertainty in this process.</p>
</section>
</div>
</div>
<p>For example, if a survey of 1,000 households finds that 23% include three generations living together, inferential statistics helps us:</p>
<ul>
<li>Estimate that between 20% and 26% of all households in the population likely have this structure (confidence interval)</li>
<li>Test whether this percentage has increased compared to a decade ago (hypothesis testing)</li>
<li>Examine whether multigenerational living is more common in certain ethnic groups (comparison of groups)</li>
<li>Predict future trends based on current patterns (regression and forecasting)</li>
</ul>
<hr>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Fundamental Principle</strong>: Statistics does not eliminate uncertainty—it helps us measure, manage, and communicate it effectively.</p>
</div>
</div>
</section>
<section id="statistical-thinking" class="level3">
<h3 class="anchored" data-anchor-id="statistical-thinking">Statistical Thinking</h3>
<p><strong>Research Question</strong>: What proportion of students support keeping the library open 24/7?</p>
<p><strong>The Challenge</strong>:</p>
<ul>
<li>Population: 20,000 students at the university</li>
<li>Practical constraint: Can only survey 100 students<br>
</li>
<li>Problem: Different samples will yield different results</li>
</ul>
<p><strong>Without Statistical Thinking</strong>: “60 out of 100 students said yes, therefore exactly 60% support it.”</p>
<p><strong>With Statistical Thinking</strong>: “We estimate 60% support with a margin of error of ±10%. We can be reasonably confident the true support lies between 50% and 70%.”</p>
<p>The difference is <strong>acknowledging and quantifying uncertainty</strong> rather than pretending it doesn’t exist.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Historical Example: The 1936 Literary Digest Poll
</div>
</div>
<div class="callout-body-container callout-body">
<p>The Literary Digest conducted one of the largest polls in history with <strong>2.4 million responses</strong>, predicting Alf Landon would defeat Franklin D. Roosevelt in the 1936 presidential election. Despite the massive sample size:</p>
<p><strong>Prediction</strong>: Landon 57%, Roosevelt 43%<br>
<strong>Actual Result</strong>: Roosevelt 62%, Landon 38%<br>
<strong>Error</strong>: 25 percentage points!</p>
<p><strong>What went wrong?</strong> The poll suffered from systematic bias:</p>
<p><strong>Selection bias in sampling frame</strong>:</p>
<ul>
<li>Sources: telephone directories, automobile registrations, club memberships</li>
<li>Problem: In 1936, these sources overrepresented wealthy Americans who favored Landon</li>
<li>Result: The sample systematically excluded Roosevelt supporters</li>
</ul>
<p><strong>Non-response bias</strong>:</p>
<ul>
<li>Only 24% of those contacted responded</li>
<li>Likely respondents: those with strong anti-Roosevelt opinions</li>
<li>Non-respondents: many Roosevelt supporters didn’t feel compelled to participate</li>
</ul>
<p><strong>Key Lessons</strong>:</p>
<ol type="1">
<li><strong>A large biased sample is worse than a small representative sample</strong></li>
<li><strong>Standard errors only measure random error, not bias</strong><br>
</li>
<li><strong>Sample size cannot fix fundamental sampling problems</strong></li>
<li><strong>Representative sampling matters more than sample size</strong></li>
</ol>
<p>This disaster led to major improvements in polling methodology, including the development of probability sampling and response rate tracking.</p>
</div>
</div>
</section>
<section id="from-error-to-understanding-modern-polling" class="level3">
<h3 class="anchored" data-anchor-id="from-error-to-understanding-modern-polling">From Error to Understanding: Modern Polling</h3>
<p>Today’s polls, while much smaller than the Literary Digest’s 2.4 million responses, are far more accurate because they focus on:</p>
<p><strong>Representative sampling</strong>: Using probability-based methods to ensure all groups have known chances of selection</p>
<p><strong>Bias detection and correction</strong>: Monitoring response rates across demographics and adjusting for known biases</p>
<p><strong>Uncertainty quantification</strong>: Reporting margins of error that honestly communicate the limits of what we know</p>
<p><strong>Example</strong>: A modern poll of 1,000 randomly selected voters with a 3% margin of error is far more reliable than the Literary Digest’s massive but biased survey.</p>
<hr>
</section>
</section>
<section id="data-and-distributions" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="data-and-distributions"><span class="header-section-number">1.3</span> Data and Distributions</h2>
<p><strong>Data</strong>: Information collected during research – this includes survey responses, experimental results, economic indicators, social media content, or any other measurable observations.</p>
<p>Understanding data types and distributions is fundamental to choosing appropriate analyses and interpreting results correctly.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding Different Types of Data Sets and Their Formats
</div>
</div>
<div class="callout-body-container callout-body">
<section id="cross-sectional-data" class="level3">
<h3 class="anchored" data-anchor-id="cross-sectional-data">Cross-sectional Data</h3>
<p>Observations for variables (columns in a database) collected at a single point in time across multiple entities/individuals:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Individual</th>
<th>Age</th>
<th>Income</th>
<th>Education</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>25</td>
<td>50000</td>
<td>Bachelor’s</td>
</tr>
<tr class="even">
<td>2</td>
<td>35</td>
<td>75000</td>
<td>Master’s</td>
</tr>
<tr class="odd">
<td>3</td>
<td>45</td>
<td>90000</td>
<td>PhD</td>
</tr>
</tbody>
</table>
</section>
<section id="time-series-data" class="level3">
<h3 class="anchored" data-anchor-id="time-series-data">Time Series Data</h3>
<p>Observations of a single entity tracked over multiple time points:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Year</th>
<th>GDP (in billions)</th>
<th>Unemployment Rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2018</td>
<td>20,580</td>
<td>3.9%</td>
</tr>
<tr class="even">
<td>2019</td>
<td>21,433</td>
<td>3.7%</td>
</tr>
<tr class="odd">
<td>2020</td>
<td>20,933</td>
<td>8.1%</td>
</tr>
</tbody>
</table>
</section>
<section id="panel-data-longitudinal-data" class="level3">
<h3 class="anchored" data-anchor-id="panel-data-longitudinal-data">Panel Data (Longitudinal Data)</h3>
<p>Observations of multiple entities tracked over time:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Country</th>
<th>Year</th>
<th>GDP per capita</th>
<th>Life Expectancy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>USA</td>
<td>2018</td>
<td>62,794</td>
<td>78.7</td>
</tr>
<tr class="even">
<td>USA</td>
<td>2019</td>
<td>65,118</td>
<td>78.8</td>
</tr>
<tr class="odd">
<td>Canada</td>
<td>2018</td>
<td>46,194</td>
<td>81.9</td>
</tr>
<tr class="even">
<td>Canada</td>
<td>2019</td>
<td>46,194</td>
<td>82.0</td>
</tr>
</tbody>
</table>
</section>
<section id="time-series-cross-sectional-tscs-data" class="level3">
<h3 class="anchored" data-anchor-id="time-series-cross-sectional-tscs-data">Time-series Cross-sectional (TSCS) Data</h3>
<p>A special case of panel data where:</p>
<ul>
<li>Number of time points &gt; Number of entities</li>
<li>Similar structure to panel data but with emphasis on temporal depth</li>
<li>Common in political science and economics research</li>
</ul>
</section>
<section id="data-formats" class="level3">
<h3 class="anchored" data-anchor-id="data-formats">Data Formats</h3>
<section id="wide-format" class="level4">
<h4 class="anchored" data-anchor-id="wide-format">Wide Format</h4>
<p>Each row represents an entity; columns represent variables/time points:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Country</th>
<th>GDP_2018</th>
<th>GDP_2019</th>
<th>LE_2018</th>
<th>LE_2019</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>USA</td>
<td>62,794</td>
<td>65,118</td>
<td>78.7</td>
<td>78.8</td>
</tr>
<tr class="even">
<td>Canada</td>
<td>46,194</td>
<td>46,194</td>
<td>81.9</td>
<td>82.0</td>
</tr>
</tbody>
</table>
</section>
<section id="long-format" class="level4">
<h4 class="anchored" data-anchor-id="long-format">Long Format</h4>
<p>Each row represents a unique entity-time-variable combination:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Country</th>
<th>Year</th>
<th>Variable</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>USA</td>
<td>2018</td>
<td>GDP per capita</td>
<td>62,794</td>
</tr>
<tr class="even">
<td>USA</td>
<td>2019</td>
<td>GDP per capita</td>
<td>65,118</td>
</tr>
<tr class="odd">
<td>USA</td>
<td>2018</td>
<td>Life Expectancy</td>
<td>78.7</td>
</tr>
<tr class="even">
<td>USA</td>
<td>2019</td>
<td>Life Expectancy</td>
<td>78.8</td>
</tr>
<tr class="odd">
<td>Canada</td>
<td>2018</td>
<td>GDP per capita</td>
<td>46,194</td>
</tr>
<tr class="even">
<td>Canada</td>
<td>2019</td>
<td>GDP per capita</td>
<td>46,194</td>
</tr>
<tr class="odd">
<td>Canada</td>
<td>2018</td>
<td>Life Expectancy</td>
<td>81.9</td>
</tr>
<tr class="even">
<td>Canada</td>
<td>2019</td>
<td>Life Expectancy</td>
<td>82.0</td>
</tr>
</tbody>
</table>
<p><strong>Note:</strong> Long format is generally preferred for:</p>
<ul>
<li>Data manipulation in R and Python</li>
<li>Statistical analysis</li>
<li>Data visualization</li>
<li>Mixed-effects modeling</li>
<li>Repeated measures analyses</li>
</ul>
</section>
</section>
</div>
</div>
<section id="types-of-data" class="level3">
<h3 class="anchored" data-anchor-id="types-of-data">Types of Data</h3>
<p><strong>Data</strong> consists of collected observations or measurements. The type of data determines what operations are meaningful and what statistical methods apply.</p>
<section id="quantitative-data" class="level4">
<h4 class="anchored" data-anchor-id="quantitative-data">Quantitative Data</h4>
<p><strong>Continuous Data</strong> can take any value within a range:</p>
<p><strong>Examples with Demographic Relevance:</strong></p>
<ul>
<li><strong>Age</strong>: Can be 25.5 years, 25.51 years, 25.514 years (precision limited only by measurement)</li>
<li><strong>Income</strong>: $45,234.67 (can have any cent value)</li>
<li><strong>Body Mass Index</strong>: 23.7 kg/m²</li>
<li><strong>Fertility Rate</strong>: 1.73 children per woman</li>
<li><strong>Population Density</strong>: 4,521.3 people per km²</li>
</ul>
<p><strong>Properties:</strong></p>
<ul>
<li>Can perform all arithmetic operations</li>
<li>Can calculate means, standard deviations</li>
<li>Often follow known probability distributions</li>
</ul>
<p><strong>Discrete Data</strong> can only take specific values:</p>
<p><strong>Examples:</strong></p>
<ul>
<li><strong>Number of Children</strong>: 0, 1, 2, 3… (can’t have 2.5 children)</li>
<li><strong>Number of Marriages</strong>: 0, 1, 2, 3…</li>
<li><strong>Household Size</strong>: 1, 2, 3, 4… people</li>
<li><strong>Number of Doctor Visits</strong>: 0, 1, 2, 3… per year</li>
</ul>
<p><strong>Key Distinction</strong>: Discrete data comes from counting; continuous from measuring.</p>
</section>
<section id="qualitative-data" class="level4">
<h4 class="anchored" data-anchor-id="qualitative-data">Qualitative Data</h4>
<p><strong>Nominal Data</strong> represents categories with no inherent order:</p>
<p><strong>Examples:</strong></p>
<ul>
<li><strong>Country of Birth</strong>: USA, China, India, Brazil…</li>
<li><strong>Religion</strong>: Christian, Muslim, Hindu, Buddhist, None…</li>
<li><strong>Marital Status</strong>: Single, Married, Divorced, Widowed</li>
<li><strong>Cause of Death</strong>: Heart disease, Cancer, Accident, Stroke…</li>
<li><strong>Blood Type</strong>: A, B, AB, O</li>
</ul>
<p><strong>What We Can Do:</strong></p>
<ul>
<li>Count frequencies</li>
<li>Calculate proportions</li>
<li>Find mode</li>
<li>Test for independence</li>
</ul>
<p><strong>What We Cannot Do:</strong></p>
<ul>
<li>Calculate mean (average religion makes no sense)</li>
<li>Order categories meaningfully</li>
<li>Compute distances between categories</li>
</ul>
<p><strong>Ordinal Data</strong> represents ordered categories:</p>
<p><strong>Examples:</strong></p>
<ul>
<li><strong>Education Level</strong>: None &lt; Primary &lt; Secondary &lt; Tertiary</li>
<li><strong>Socioeconomic Status</strong>: Low &lt; Middle &lt; High</li>
<li><strong>Self-Rated Health</strong>: Poor &lt; Fair &lt; Good &lt; Excellent</li>
<li><strong>Agreement Scale</strong>: Strongly Disagree &lt; Disagree &lt; Neutral &lt; Agree &lt; Strongly Agree</li>
</ul>
<p><strong>The Challenge</strong>: Intervals between categories aren’t necessarily equal. The “distance” from Poor to Fair health may not equal the distance from Good to Excellent.</p>
</section>
</section>
<section id="data-distribution" class="level3">
<h3 class="anchored" data-anchor-id="data-distribution">Data Distribution</h3>
<p>A <strong>data distribution</strong> describes how values spread across possible outcomes (what values and how often a variable takes). Distributions tell us what values are common, what values are rare, and what patterns exist in our data.</p>
<section id="describing-distributions" class="level4">
<h4 class="anchored" data-anchor-id="describing-distributions">Describing Distributions</h4>
<p><strong>Shape Characteristics:</strong></p>
<p><strong>Symmetry vs.&nbsp;Skewness:</strong></p>
<ul>
<li><strong>Symmetric</strong>: Mirror image around center (example: heights in homogeneous population)</li>
<li><strong>Right-skewed (positive skew)</strong>: Long tail to right (example: income, wealth)</li>
<li><strong>Left-skewed (negative skew)</strong>: Long tail to left (example: age at death in developed countries)</li>
</ul>
<p><strong>Example of Skewness Impact:</strong></p>
<p>Income distribution in the U.S.:</p>
<ul>
<li>Median household income: ~$70,000</li>
<li>Mean household income: ~$100,000</li>
<li>Mean &gt; Median indicates right skew</li>
<li>A few very high incomes pull the mean up</li>
</ul>
<p><strong>Modality:</strong></p>
<ul>
<li><strong>Unimodal</strong>: One peak (example: test scores)</li>
<li><strong>Bimodal</strong>: Two peaks (example: height when mixing males and females)</li>
<li><strong>Multimodal</strong>: Multiple peaks (example: age distribution in a college town—peaks at college age and middle age)</li>
</ul>
<p><strong>Important Probability Distributions:</strong></p>
<p><strong>Normal (Gaussian) Distribution:</strong></p>
<ul>
<li>Bell-shaped, symmetric</li>
<li>Characterized by mean (<span class="math inline">\mu</span>) and standard deviation (<span class="math inline">\sigma</span>)</li>
<li>About 68% of values within <span class="math inline">\mu \pm \sigma</span></li>
<li>About 95% within <span class="math inline">\mu \pm 2\sigma</span></li>
<li>About 99.7% within <span class="math inline">\mu \pm 3\sigma</span></li>
</ul>
<p><em>Demographic Applications:</em></p>
<ul>
<li>Heights within homogeneous populations</li>
<li>Measurement errors</li>
<li>Sampling distributions of means (Central Limit Theorem)</li>
</ul>
<p><strong>Binomial Distribution:</strong></p>
<ul>
<li>Number of successes in <span class="math inline">n</span> independent trials</li>
<li>Each trial has probability <span class="math inline">p</span> of success</li>
<li>Mean = <span class="math inline">np</span>, Variance = <span class="math inline">np(1-p)</span></li>
</ul>
<p><em>Example</em>: Number of male births out of 100 births (<span class="math inline">p \approx 0.512</span>)</p>
<p><strong>Poisson Distribution:</strong></p>
<ul>
<li>Count of events in fixed time/space</li>
<li>Mean = Variance = <span class="math inline">\lambda</span></li>
<li>Good for rare events</li>
</ul>
<p><em>Demographic Applications:</em></p>
<ul>
<li>Number of deaths per day in small town</li>
<li>Number of births per hour in hospital</li>
<li>Number of accidents at intersection per month</li>
</ul>
</section>
</section>
<section id="frequency-distribution" class="level3">
<h3 class="anchored" data-anchor-id="frequency-distribution">Frequency Distribution</h3>
<p>A <strong>frequency distribution</strong> shows how often each value occurs in a dataset. It’s often the first step in understanding your data.</p>
<section id="components-of-frequency-distributions" class="level4">
<h4 class="anchored" data-anchor-id="components-of-frequency-distributions">Components of Frequency Distributions</h4>
<p><strong>Absolute Frequency</strong>: The count of observations for each value.</p>
<p><strong>Relative Frequency</strong>: The proportion in each category. <span class="math display">\text{Relative Frequency} = \frac{\text{Count}}{\text{Total}}</span></p>
<p><strong>Cumulative Frequency</strong>: Running total up to each value.</p>
<p><strong>Detailed Example</strong>: Age distribution in a community health survey of 200 people:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
<col style="width: 20%">
</colgroup>
<thead>
<tr class="header">
<th>Age Group</th>
<th>Absolute Frequency</th>
<th>Relative Frequency</th>
<th>Cumulative Frequency</th>
<th>Cumulative %</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0-9</td>
<td>24</td>
<td>0.12</td>
<td>24</td>
<td>12%</td>
</tr>
<tr class="even">
<td>10-19</td>
<td>28</td>
<td>0.14</td>
<td>52</td>
<td>26%</td>
</tr>
<tr class="odd">
<td>20-29</td>
<td>35</td>
<td>0.175</td>
<td>87</td>
<td>43.5%</td>
</tr>
<tr class="even">
<td>30-39</td>
<td>32</td>
<td>0.16</td>
<td>119</td>
<td>59.5%</td>
</tr>
<tr class="odd">
<td>40-49</td>
<td>30</td>
<td>0.15</td>
<td>149</td>
<td>74.5%</td>
</tr>
<tr class="even">
<td>50-59</td>
<td>25</td>
<td>0.125</td>
<td>174</td>
<td>87%</td>
</tr>
<tr class="odd">
<td>60-69</td>
<td>16</td>
<td>0.08</td>
<td>190</td>
<td>95%</td>
</tr>
<tr class="even">
<td>70+</td>
<td>10</td>
<td>0.05</td>
<td>200</td>
<td>100%</td>
</tr>
</tbody>
</table>
<p><strong>What This Tells Us:</strong></p>
<ul>
<li>Mode: 20-29 age group (highest frequency)</li>
<li>Median: In 30-39 group (cumulative passes 50% here)</li>
<li>Young population: 43.5% under 30</li>
<li>Working age (20-59): 60.5% of population</li>
</ul>
</section>
<section id="visualizing-frequency-distributions" class="level4">
<h4 class="anchored">Visualizing Frequency Distributions</h4>
<p><strong>Histogram</strong>: For continuous data, shows frequency with bar heights.</p>
<ul>
<li>X-axis: Value ranges (bins)</li>
<li>Y-axis: Frequency or density</li>
<li>No gaps between bars (continuous data)</li>
<li>Bin width affects appearance</li>
</ul>
<p><strong>Bar Chart</strong>: For categorical data, shows frequency with separated bars.</p>
<ul>
<li>X-axis: Categories</li>
<li>Y-axis: Frequency</li>
<li>Gaps between bars (discrete categories)</li>
<li>Order may or may not matter</li>
</ul>
<p><strong>Cumulative Distribution Function (CDF)</strong>: Shows proportion of values ≤ each point of data.</p>
<ul>
<li>Always increases (or stays flat)</li>
<li>Starts at 0, ends at 1</li>
<li>Steep slopes indicate common values</li>
<li>Flat areas indicate rare values</li>
</ul>
<p><strong>Box Plot (Box-and-Whisker Plot)</strong>: A visual summary that displays the distribution’s key statistics using five key values.</p>
<p><strong>The Five-Number Summary:</strong></p>
<ul>
<li><strong>Minimum</strong>: Leftmost whisker end (excluding outliers)</li>
<li><strong>Q1 (First Quartile)</strong>: Left edge of the box (25th percentile)</li>
<li><strong>Median (Q2)</strong>: Line inside the box (50th percentile)<br>
</li>
<li><strong>Q3 (Third Quartile)</strong>: Right edge of the box (75th percentile)</li>
<li><strong>Maximum</strong>: Rightmost whisker end (excluding outliers)</li>
</ul>
<p><strong>What It Reveals:</strong> - <strong>Skewness</strong>: If median line is off-center in the box, or whiskers are unequal - <strong>Spread</strong>: Wider boxes and longer whiskers indicate more variability - <strong>Outliers</strong>: Immediately visible as separate points - <strong>Symmetry</strong>: Equal whisker lengths and centered median suggest normal distribution</p>
<p><strong>Quick Interpretation:</strong> - Narrow box = consistent data - Long whiskers = wide range of values<br>
- Many outliers = potential data quality issues or interesting extreme cases - Median closer to Q1 = right-skewed data (tail extends right) - Median closer to Q3 = left-skewed data (tail extends left)</p>
<p>Box plots are especially useful for comparing multiple groups side-by-side!</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Frequency vs.&nbsp;Density: connecting the dots
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Idea:</strong> A histogram divides the x-axis into <strong>bins</strong>.<br>
- <strong>Frequency</strong> = how many observations fall in each bin (a <strong>count</strong>).<br>
- <strong>Density</strong> rescales those counts so that the <strong>total area = 1</strong>. This makes areas ≈ <strong>probabilities</strong>.</p>
<section id="the-key-formula-plain-english" class="level3">
<h3 class="anchored" data-anchor-id="the-key-formula-plain-english">The key formula (plain English)</h3>
<p>For a bin of width <strong>h</strong> that contains <strong>count</strong> observations out of <strong>n</strong> total:</p>
<p><span class="math display">
\textbf{density height in that bin} \;\approx\; \frac{\text{count}}{n \cdot h}
</span></p>
<ul>
<li>If you multiply this <strong>height</strong> by the <strong>bin width</strong> (<strong>h</strong>), you get the <strong>area</strong> of that bar:<br>
<span class="math inline">\text{area} = \frac{\text{count}}{n \cdot h} \times h = \frac{\text{count}}{n}</span> = <strong>relative frequency (probability) in that bin</strong>.</li>
<li>Summing areas over all bins gives 1.</li>
</ul>
<p><strong>Discrete analogy:</strong><br>
If your data are discrete and you use <strong>unit-width bins (h = 1)</strong> centered on the discrete values, then<br>
<span class="math inline">\text{density height} = \frac{\text{count}}{n \cdot 1} = \frac{\text{count}}{n}</span> — i.e., <strong>density height = relative frequency</strong>.<br>
For other bin widths, density is <strong>relative frequency per unit of x</strong>.</p>
<p><strong>Continuous analogy:</strong><br>
For continuous variables, the probability of any <strong>exact</strong> value is 0. We talk about the probability of an <strong>interval</strong>. A histogram’s bar height is the <strong>probability per unit of x</strong> (so that <strong>height × width ≈ probability</strong> of that interval). That’s why densities carry units like “per cm” or “per kg”.</p>
</section>
<section id="minimal-example-in-r" class="level3">
<h3 class="anchored" data-anchor-id="minimal-example-in-r">Minimal example in R</h3>
<section id="a-frequency-histogram-counts" class="level4">
<h4 class="anchored" data-anchor-id="a-frequency-histogram-counts">A) Frequency histogram (counts)</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(heights, <span class="fu">aes</span>(<span class="at">x =</span> height)) <span class="sc">+</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="dv">5</span>, <span class="at">boundary =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Frequency histogram"</span>, <span class="at">x =</span> <span class="st">"Height (cm)"</span>, <span class="at">y =</span> <span class="st">"Frequency (count)"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chapter1_files/figure-html/hist-frequency-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Histogram with frequency (counts) on the y-axis</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="b-density-histogram-area-1-smooth-curve" class="level4">
<h4 class="anchored" data-anchor-id="b-density-histogram-area-1-smooth-curve">B) Density histogram (area = 1) + smooth curve</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(heights, <span class="fu">aes</span>(<span class="at">x =</span> height)) <span class="sc">+</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), <span class="at">binwidth =</span> <span class="dv">5</span>, <span class="at">boundary =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">linewidth =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Density histogram (area = 1) + smooth density curve"</span>, <span class="at">x =</span> <span class="st">"Height (cm)"</span>, <span class="at">y =</span> <span class="st">"Density"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chapter1_files/figure-html/hist-density-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption>Histogram scaled to density; area of all bars sums to 1</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="c-verify-the-formula-density-count-n-bin-width" class="level4">
<h4 class="anchored" data-anchor-id="c-verify-the-formula-density-count-n-bin-width">C) Verify the formula: density ≈ count / (n × bin width)</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>bw <span class="ot">&lt;-</span> <span class="dv">5</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>brks <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fu">floor</span>(<span class="fu">min</span>(heights<span class="sc">$</span>height)<span class="sc">/</span>bw)<span class="sc">*</span>bw, <span class="fu">ceiling</span>(<span class="fu">max</span>(heights<span class="sc">$</span>height)<span class="sc">/</span>bw)<span class="sc">*</span>bw, <span class="at">by =</span> bw)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>tab <span class="ot">&lt;-</span> heights <span class="sc">%&gt;%</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">bin =</span> <span class="fu">cut</span>(height, <span class="at">breaks =</span> brks, <span class="at">right =</span> <span class="cn">FALSE</span>, <span class="at">include.lowest =</span> <span class="cn">TRUE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">count</span>(bin, <span class="at">name =</span> <span class="st">"count"</span>) <span class="sc">%&gt;%</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">width =</span> bw,</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">n_total =</span> <span class="fu">nrow</span>(heights),</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">rel_freq =</span> count <span class="sc">/</span> n_total,</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">density_height =</span> rel_freq <span class="sc">/</span> width,            <span class="co"># count / (n * h)</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">area =</span> density_height <span class="sc">*</span> width) <span class="sc">%&gt;%</span>            <span class="co"># should equal rel_freq</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">arrange</span>(bin)</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(tab, <span class="dv">5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 5 × 7
  bin       count width n_total rel_freq density_height  area
  &lt;fct&gt;     &lt;int&gt; &lt;dbl&gt;   &lt;int&gt;    &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;
1 [135,140)     1     5     500    0.002         0.0004 0.002
2 [140,145)     2     5     500    0.004         0.0008 0.004
3 [145,150)    10     5     500    0.02          0.004  0.02 
4 [150,155)    20     5     500    0.04          0.008  0.04 
5 [155,160)    44     5     500    0.088         0.0176 0.088</code></pre>
</div>
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(tab<span class="sc">$</span>area)  <span class="co"># ≈ 1 (up to rounding)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1</code></pre>
</div>
</div>
</section>
</section>
<section id="quick-takeaways" class="level3">
<h3 class="anchored" data-anchor-id="quick-takeaways">Quick takeaways</h3>
<ul>
<li><strong>Density height = relative frequency ÷ bin width.</strong></li>
<li><strong>Area</strong> of a bin ≈ <strong>probability</strong> of that interval.</li>
<li>For <strong>unit-width</strong> bins on discrete data, <strong>density height = relative frequency</strong>.</li>
<li>Density enables <strong>fair comparisons</strong> across samples of different sizes.</li>
</ul>
</section>
</div>
</div>
<hr>
</section>
</section>
</section>
<section id="populations-and-samples" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="populations-and-samples"><span class="header-section-number">1.4</span> Populations and Samples</h2>
<p>Understanding the distinction between populations and samples is crucial for proper statistical analysis. This distinction affects every aspect of our analysis, from planning data collection to interpreting results.</p>
<section id="population" class="level3">
<h3 class="anchored" data-anchor-id="population">Population</h3>
<p>A <strong>population</strong> is the complete set of individuals, objects, or measurements about which we wish to draw conclusions. The key word here is “complete”—a population includes every single member of the group we’re studying.</p>
<p><strong>Examples of Populations in Demography:</strong></p>
<ul>
<li><strong>All residents of India as of January 1, 2024</strong>: This includes every person living in India on that specific date—approximately 1.4 billion people.</li>
<li><strong>All births in Sweden during 2023</strong>: Every baby born within Swedish borders during that calendar year—roughly 100,000 births.</li>
<li><strong>All households in Tokyo</strong>: Every residential unit where people live, cook, and sleep separately from others—about 7 million households.</li>
<li><strong>All deaths from COVID-19 worldwide in 2020</strong>: Every death where COVID-19 was listed as a cause—several million deaths.</li>
</ul>
<p>Populations can be:</p>
<p><strong>Finite</strong>: Having a countable number of members (all current U.S. citizens, all Polish municipalities in 2024)</p>
<p><strong>Infinite</strong>: Theoretical or uncountably large (all possible future births)</p>
<p><strong>Fixed</strong>: Defined at a specific point in time (all residents on census day)</p>
<p><strong>Dynamic</strong>: Changing over time (the population of a city that experiences births, deaths, and migration daily)</p>
</section>
<section id="sample" class="level3">
<h3 class="anchored" data-anchor-id="sample">Sample</h3>
<p>A <strong>sample</strong> is a subset of the population that is actually observed or measured. We study samples because examining entire populations is often impossible, impractical, or unnecessary.</p>
<p><strong>Why We Use Samples:</strong></p>
<p><strong>Practical Impossibility</strong>: Imagine testing every person in China for a disease. By the time you finished testing 1.4 billion people, the disease situation would have changed completely, and some people tested early would need retesting.</p>
<p><strong>Cost Considerations</strong>: The 2020 U.S. Census cost approximately $16 billion. Conducting such complete enumerations frequently would be prohibitively expensive. A well-designed sample survey can provide accurate estimates at a fraction of the cost.</p>
<p><strong>Time Constraints</strong>: Policy makers often need information quickly. A sample survey of 10,000 people can be completed in weeks, while a census takes years to plan, execute, and process.</p>
<p><strong>Destructive Measurement</strong>: Some measurements destroy what’s being measured. Testing the lifespan of light bulbs or the breaking point of materials requires using samples.</p>
<p><strong>Greater Accuracy</strong>: Surprisingly, samples can sometimes be more accurate than complete enumerations. With a sample, you can afford better training for interviewers, more careful data collection, and more thorough quality checks.</p>
<p><strong>Example of Sample vs.&nbsp;Population:</strong></p>
<p>Let’s say we want to know the average household size in New York City:</p>
<ul>
<li><strong>Population</strong>: All 3.2 million households in NYC</li>
<li><strong>Census approach</strong>: Attempt to contact every household (expensive, time-consuming, some will be missed)</li>
<li><strong>Sample approach</strong>: Randomly select 5,000 households, carefully measure their sizes, and use this to estimate the average for all households</li>
<li><strong>Result</strong>: The sample might find an average of 2.43 people per household with a margin of error of ±0.05, meaning we’re confident the true population average is between 2.38 and 2.48</li>
</ul>
<hr>
</section>
</section>
<section id="superpopulation-and-data-generating-process-dgp" class="level2 calout-note" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="superpopulation-and-data-generating-process-dgp"><span class="header-section-number">1.5</span> Superpopulation and Data Generating Process (DGP) (*)</h2>
<hr>
<section id="superpopulation" class="level3">
<h3 class="anchored" data-anchor-id="superpopulation"><strong>Superpopulation</strong></h3>
<p>A <strong>superpopulation</strong> is a theoretical infinite population from which your finite population is considered to be one random sample.</p>
<p><strong>Think of it in three levels:</strong></p>
<ol type="1">
<li><strong>Superpopulation</strong>: An infinite collection of possible values (theoretical)</li>
<li><strong>Finite population</strong>: The actual population you could theoretically census (e.g., all 50 US states, all 10,000 firms in an industry)</li>
<li><strong>Sample</strong>: The subset you actually observe (e.g., 30 states, 500 firms)</li>
</ol>
<p><strong>Why do we need this concept?</strong></p>
<p>Consider the 50 US states. You might measure unemployment rate for all 50 states—a complete census, no sampling needed. But you still want to:</p>
<ul>
<li>Test if unemployment is related to education levels</li>
<li>Predict next year’s unemployment rates</li>
<li>Determine if differences between states are “statistically significant”</li>
</ul>
<p>Without the superpopulation concept, you’re stuck—you have all the data, so what’s left to infer? The answer: treat this year’s 50 values as one draw from an infinite superpopulation of possible values that could occur under similar conditions.</p>
<p><strong>Mathematical representation:</strong></p>
<ul>
<li>Finite population value: <span class="math inline">Y_i</span> (state i’s unemployment rate)</li>
<li>Superpopulation model: <span class="math inline">Y_i = \mu + \epsilon_i</span> where <span class="math inline">\epsilon_i \sim (0, \sigma^2)</span></li>
<li>The 50 observed values are one realization of this process</li>
</ul>
<hr>
</section>
<section id="data-generating-process-the-true-recipe" class="level3">
<h3 class="anchored" data-anchor-id="data-generating-process-the-true-recipe"><strong>Data Generating Process: The True Recipe</strong></h3>
<p>The <strong>Data Generating Process (DGP)</strong> is the actual mechanism that creates your data—including all factors, relationships, and random elements.</p>
<p><strong>An intuitive example:</strong> Suppose student test scores are truly generated by:</p>
<p><span class="math display">\text{Score}_i = 50 + 2(\text{StudyHours}_i) + 3(\text{SleepHours}_i) - 5(\text{Stress}_i) + 1.5(\text{Breakfast}_i) + \epsilon_i</span></p>
<p>This is the TRUE DGP. But you don’t know this! You might estimate:</p>
<p><span class="math display">\text{Score}_i = \alpha + \beta(\text{StudyHours}_i) + u_i</span></p>
<p>Your model is simpler than reality. You’re missing variables (sleep, stress, breakfast), so your estimates might be biased. The <span class="math inline">u_i</span> term captures everything you missed.</p>
<p><strong>Key insight</strong>: We never know the true DGP. Our statistical models are always approximations, trying to capture the most important parts of the unknown, complex truth.</p>
<hr>
</section>
<section id="two-approaches-to-statistical-inference" class="level3">
<h3 class="anchored" data-anchor-id="two-approaches-to-statistical-inference"><strong>Two Approaches to Statistical Inference</strong></h3>
<p>When analyzing data, especially from surveys or samples, we can take two philosophical approaches:</p>
<section id="design-based-inference" class="level4">
<h4 class="anchored" data-anchor-id="design-based-inference"><strong>1. Design-Based Inference</strong></h4>
<ul>
<li><strong>Philosophy</strong>: The population values are fixed numbers. Randomness comes ONLY from which units we happened to sample.</li>
<li><strong>Focus</strong>: How we selected the sample (simple random, stratified, cluster sampling, etc.)</li>
<li><strong>Example</strong>: The mean income of California counties is a fixed number. We sample 10 counties. Our uncertainty comes from which 10 we randomly selected.</li>
<li><strong>No models needed</strong>: We don’t assume anything about the population values’ distribution</li>
</ul>
</section>
<section id="model-based-inference" class="level4">
<h4 class="anchored" data-anchor-id="model-based-inference"><strong>2. Model-Based Inference</strong></h4>
<ul>
<li><strong>Philosophy</strong>: The population values themselves are realizations from some probability model (superpopulation)</li>
<li><strong>Focus</strong>: The statistical model generating the population values</li>
<li><strong>Example</strong>: Each California county’s income is drawn from: <span class="math inline">Y_i = \mu + \epsilon_i</span> where <span class="math inline">\epsilon_i \sim N(0, \sigma^2)</span></li>
<li><strong>Models required</strong>: We make assumptions about how the data were generated</li>
</ul>
<p><strong>Which is better?</strong></p>
<ul>
<li><strong>Large populations, good random samples</strong>: Design-based works well</li>
<li><strong>Small populations (like 50 states)</strong>: Model-based often necessary</li>
<li><strong>Complete enumeration</strong>: Only model-based allows inference</li>
<li><strong>Modern practice</strong>: Often combines both approaches</li>
</ul>
<hr>
</section>
</section>
<section id="practical-example-analyzing-state-education-spending" class="level3">
<h3 class="anchored" data-anchor-id="practical-example-analyzing-state-education-spending"><strong>Practical Example: Analyzing State Education Spending</strong></h3>
<p>Suppose you collect education spending per pupil for all 50 US states.</p>
<p><strong>Without superpopulation thinking:</strong></p>
<ul>
<li>You have all 50 values—that’s it</li>
<li>The mean is the mean, no uncertainty</li>
<li>You can’t test hypotheses or make predictions</li>
</ul>
<p><strong>With superpopulation thinking:</strong></p>
<ul>
<li>This year’s 50 values are one realization from a superpopulation</li>
<li>Model: <span class="math inline">\text{Spending}_i = \mu + \beta(\text{StateIncome}_i) + \epsilon_i</span></li>
<li>Now you can:
<ul>
<li>Test if spending relates to state income (<span class="math inline">\beta \neq 0</span>?)</li>
<li>Predict next year’s values</li>
<li>Calculate confidence intervals</li>
</ul></li>
</ul>
<p><strong>The key insight</strong>: Even with complete data, the superpopulation framework enables statistical inference by treating observed values as one possible outcome from an underlying stochastic process.</p>
<hr>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary"><strong>Summary</strong></h3>
<ul>
<li><p><strong>Superpopulation</strong>: Treats your finite population as one draw from an infinite possibility space—essential when your finite population is small or completely observed</p></li>
<li><p><strong>DGP</strong>: The true (unknown) process creating your data—your models try to approximate it</p></li>
</ul>
</section>
</section>
<hr>
<section id="variables-and-measurement-scales" class="level2" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="variables-and-measurement-scales"><span class="header-section-number">1.6</span> Variables and Measurement Scales</h2>
<p>Before diving deeper into populations and samples, we must understand the types of variables we work with and how we measure them.</p>
<blockquote class="blockquote">
<p>A <strong>variable</strong> is any characteristic that can take different values across units of observation.</p>
</blockquote>
<section id="measurement-transforming-concepts-into-numbers" class="level3">
<h3 class="anchored" data-anchor-id="measurement-transforming-concepts-into-numbers">Measurement: Transforming Concepts into Numbers</h3>
<section id="the-political-world-is-full-of-data" class="level4">
<h4 class="anchored">The Political World is Full of Data</h4>
<p>Political science has evolved from a primarily theoretical discipline to one that increasingly relies on empirical evidence. Whether we’re studying:</p>
<ul>
<li><strong>Election outcomes</strong>: Why do people vote the way they do?</li>
<li><strong>Public opinion</strong>: What shapes attitudes toward immigration or climate policy?</li>
<li><strong>International relations</strong>: What factors predict conflict between nations?</li>
<li><strong>Policy effectiveness</strong>: Did a new education policy actually improve outcomes?</li>
</ul>
<p>We need systematic ways to analyze data and draw conclusions that go beyond anecdotes and personal impressions.</p>
<blockquote class="blockquote">
<p>Consider this question: “Does democracy lead to economic growth?”</p>
</blockquote>
<p>Your intuition might suggest yes—democratic countries tend to be wealthier. But is this causation or correlation? Are there exceptions? How confident can we be in our conclusions?</p>
<p>Statistics provides the tools to move from hunches to evidence-based answers, helping us distinguish between what seems true and what actually is true.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
🔍 Correlation ≠ Causation: Understanding Spurious Relationships
</div>
</div>
<div class="callout-body-container callout-body">
<section id="the-fundamental-distinction" class="level3">
<h3 class="anchored" data-anchor-id="the-fundamental-distinction"><strong>The Fundamental Distinction</strong></h3>
<p><strong>Correlation</strong> measures how two variables move together: - Positive: Both increase together (study hours ↑, grades ↑) - Negative: One increases while other decreases (TV hours ↑, grades ↓) - Measured by correlation coefficient: <span class="math inline">r \in [-1, 1]</span></p>
<p><strong>Causation</strong> means one variable directly influences another: - <span class="math inline">X \rightarrow Y</span>: Changes in X directly cause changes in Y - Requires: (1) correlation, (2) temporal precedence, (3) no alternative explanations</p>
</section>
<section id="the-danger-spurious-correlation" class="level3">
<h3 class="anchored" data-anchor-id="the-danger-spurious-correlation"><strong>The Danger: Spurious Correlation</strong></h3>
<p>A <strong>spurious correlation</strong> occurs when two variables appear related but are actually both influenced by a third variable (a <strong>confounder</strong>).</p>
<p><strong>Classic Example:</strong> - <strong>Observed</strong>: Ice cream sales correlate with drowning deaths - <strong>Spurious conclusion</strong>: Ice cream causes drowning (❌) - <strong>Reality</strong>: Summer weather (confounder) causes both: - Summer → More ice cream sales - Summer → More swimming → More drownings</p>
<p><strong>Mathematical representation:</strong> - Observed correlation: <span class="math inline">\text{Cor}(X,Y) \neq 0</span> - But the true model: <span class="math inline">X = \alpha Z + \epsilon_1</span> and <span class="math inline">Y = \beta Z + \epsilon_2</span> - Where <span class="math inline">Z</span> is the confounding variable causing both</p>
</section>
<section id="confounding-the-hidden-influence" class="level3">
<h3 class="anchored" data-anchor-id="confounding-the-hidden-influence"><strong>Confounding: The Hidden Influence</strong></h3>
<p>A <strong>confounding variable</strong> (confounder): 1. Affects both the presumed cause and effect 2. Creates an illusion of direct causation 3. Must be controlled for valid causal inference</p>
<p><strong>Research Example:</strong> - <strong>Observed</strong>: Coffee consumption correlates with heart disease - <strong>Potential confounder</strong>: Smoking (coffee drinkers more likely to smoke) - <strong>True relationships</strong>: - Smoking → Heart disease (causal) - Smoking → Coffee consumption (association) - Coffee → Heart disease (spurious without controlling for smoking)</p>
</section>
<section id="how-to-identify-causal-relationships" class="level3">
<h3 class="anchored" data-anchor-id="how-to-identify-causal-relationships"><strong>How to Identify Causal Relationships</strong></h3>
<ol type="1">
<li><strong>Randomized Controlled Trials (RCTs)</strong>: Random assignment breaks confounding</li>
<li><strong>Natural Experiments</strong>: External events create “as-if” random variation</li>
<li><strong>Statistical Control</strong>: Include confounders in regression models</li>
<li><strong>Instrumental Variables</strong>: Find variables affecting X but not Y directly</li>
</ol>
</section>
<section id="key-takeaway" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaway"><strong>Key Takeaway</strong></h3>
<p>Finding correlation is easy. Establishing causation is hard. Always ask: “What else could explain this relationship?”</p>
<p><strong>Remember</strong>: The most dangerous phrase in empirical research is “our data shows that X causes Y” when all you’ve measured is correlation.</p>
</section>
</div>
</div>
<hr>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
📊 Quick Test: Correlation or Causation?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For each scenario, identify whether the relationship is likely causal or spurious:</p>
<ol type="1">
<li><strong>Cities with more churches have more crime</strong>
<ul>
<li>Answer: Spurious (confounder: population size)</li>
</ul></li>
<li><strong>Smoking leads to lung cancer</strong>
<ul>
<li>Answer: Causal (established through multiple study designs)</li>
</ul></li>
<li><strong>Students with more books at home get better grades</strong>
<ul>
<li>Answer: Likely spurious (confounders: parental education, income)</li>
</ul></li>
<li><strong>Countries with higher chocolate consumption have more Nobel laureates</strong>
<ul>
<li>Answer: Spurious (confounder: wealth/development level)</li>
</ul></li>
</ol>
</div>
</div>
</div>
</section>
<section id="the-challenge-of-measurement-in-social-sciences" class="level4">
<h4 class="anchored" data-anchor-id="the-challenge-of-measurement-in-social-sciences">The Challenge of Measurement in Social Sciences</h4>
<p>In social sciences, we often struggle with the fact that key concepts do not translate directly into numbers:</p>
<ul>
<li>How do we measure “democracy”?</li>
<li>What number captures “political ideology”?</li>
<li>How do we quantify “institutional strength”?</li>
<li>How do we measure “political participation”?</li>
</ul>
<hr>
</section>
</section>
<section id="types-of-variables" class="level3">
<h3 class="anchored" data-anchor-id="types-of-variables">Types of Variables</h3>
<p><strong>Quantitative Variables</strong> represent amounts or quantities and can be:</p>
<p><strong>Continuous Variables</strong>: Can take any value within a range, limited only by measurement precision.</p>
<ul>
<li>Age (22.5 years, 22.51 years, 22.514 years…)</li>
<li>Income ($45,234.67)</li>
<li>Height (175.3 cm)</li>
<li>Population density (432.7 people per square kilometer)</li>
</ul>
<p><strong>Discrete Variables</strong>: Can only take specific values, usually counts.</p>
<ul>
<li>Number of children in a family (0, 1, 2, 3…)</li>
<li>Number of marriages (0, 1, 2…)</li>
<li>Number of rooms in a dwelling (1, 2, 3…)</li>
<li>Number of migrants entering a country per year</li>
</ul>
<p><strong>Qualitative Variables</strong> represent categories or qualities and can be:</p>
<p><strong>Nominal Variables</strong>: Categories with no inherent order.</p>
<ul>
<li>Country of birth (USA, Mexico, Canada…)</li>
<li>Religion (Christian, Muslim, Hindu, Buddhist…)</li>
<li>Blood type (A, B, AB, O)</li>
<li>Cause of death (heart disease, cancer, accident…)</li>
</ul>
<p><strong>Ordinal Variables</strong>: Categories with a meaningful order but unequal intervals.</p>
<ul>
<li>Education level (no schooling, primary, secondary, tertiary)</li>
<li>Satisfaction with healthcare (very dissatisfied, dissatisfied, neutral, satisfied, very satisfied)</li>
<li>Socioeconomic status (low, middle, high)</li>
<li>Self-rated health (poor, fair, good, excellent)</li>
</ul>
</section>
<section id="measurement-scales" class="level3">
<h3 class="anchored" data-anchor-id="measurement-scales">Measurement Scales</h3>
<p>Understanding measurement scales is crucial because they determine which statistical methods are appropriate:</p>
<p><strong>Nominal Scale</strong>: Categories only—we can count frequencies but cannot order or perform arithmetic. Example: We can say 45% of residents were born locally, but we cannot calculate an “average birthplace.”</p>
<p><strong>Ordinal Scale</strong>: Order matters but differences between values are not necessarily equal. Example: The difference between “poor” and “fair” health may not equal the difference between “good” and “excellent” health.</p>
<p><strong>Interval Scale</strong>: Equal intervals between values but no true zero point. Example: Temperature in Celsius—the difference between 20°C and 30°C equals the difference between 30°C and 40°C, but 0°C doesn’t mean “no temperature.”</p>
<p><strong>Ratio Scale</strong>: Equal intervals with a true zero point, allowing all mathematical operations. Example: Income—$40,000 is twice as much as $20,000, and $0 means no income.</p>
<hr>
</section>
</section>
<section id="parameters-statistics-and-estimation" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="parameters-statistics-and-estimation"><span class="header-section-number">1.7</span> Parameters, Statistics, and Estimation</h2>
<p>These concepts form the core of statistical inference—how we learn about populations from samples. Understanding the relationships between these terms is essential for proper statistical reasoning.</p>
<section id="parameter" class="level3">
<h3 class="anchored" data-anchor-id="parameter">Parameter</h3>
<p>A <strong>parameter</strong> is a numerical characteristic of a population. Parameters are typically unknown because we cannot measure the entire population. They are fixed values (not random) but unknown to us. We denote parameters with Greek letters.</p>
<p><strong>Common Demographic Parameters:</strong></p>
<ul>
<li><span class="math inline">\mu</span> (mu): Population mean age. For example, the true average age of all Europeans.</li>
<li><span class="math inline">\sigma^2</span> (sigma squared): Population variance in income across all households in Brazil.</li>
<li><span class="math inline">p</span>: Population proportion. For example, the true proportion of all adults in Japan who are married.</li>
<li><span class="math inline">\beta</span> (beta): Regression coefficient. The true relationship between education and fertility in a population.</li>
<li><span class="math inline">\lambda</span> (lambda): Rate parameter. The true rate of migration from rural to urban areas.</li>
</ul>
<p><strong>Example</strong>: The true mean age at first birth for all women in France who gave birth in 2023 is a parameter. Let’s call it <span class="math inline">\mu = 31.2</span> years. We don’t know this value without measuring every single birth.</p>
</section>
<section id="statistic" class="level3">
<h3 class="anchored" data-anchor-id="statistic">Statistic</h3>
<p>A <strong>statistic</strong> is a numerical characteristic calculated from sample data. Statistics are random variables—their values vary from sample to sample. We use Roman letters for statistics.</p>
<p><strong>Common Sample Statistics:</strong></p>
<ul>
<li><span class="math inline">\bar{x}</span> (x-bar): Sample mean age from a survey of 1,000 people</li>
<li><span class="math inline">s^2</span>: Sample variance in income from 500 surveyed households</li>
<li><span class="math inline">\hat{p}</span> (p-hat): Sample proportion married from a survey</li>
<li><span class="math inline">r</span>: Sample correlation between education and income</li>
<li><span class="math inline">b</span>: Sample regression coefficient</li>
</ul>
<p><strong>Example</strong>: From a sample of 500 births in France, we calculate a sample mean age at first birth of <span class="math inline">\bar{x} = 30.9</span> years. This is our statistic. A different sample might yield <span class="math inline">\bar{x} = 31.4</span> years.</p>
</section>
<section id="the-relationship-between-parameters-and-statistics" class="level3">
<h3 class="anchored" data-anchor-id="the-relationship-between-parameters-and-statistics">The Relationship Between Parameters and Statistics</h3>
<p>Think of this relationship like trying to understand the depth of a lake:</p>
<ul>
<li><strong>Parameter</strong>: The true average depth of the lake (unknown, fixed)</li>
<li><strong>Statistic</strong>: The average depth from several measurement points (known, varies with different samples)</li>
<li><strong>Estimation</strong>: Using our measurements to guess the true average depth</li>
</ul>
</section>
<section id="estimator" class="level3">
<h3 class="anchored" data-anchor-id="estimator">Estimator</h3>
<p>An <strong>estimator</strong> is a rule or formula for calculating an estimate of a population parameter from sample data. An estimator is a function that maps sample data to parameter estimates. It’s the recipe, not the cake.</p>
<p><strong>Properties of Good Estimators:</strong></p>
<p><strong>Unbiasedness</strong>: On average, the estimator equals the true parameter value. If we repeated sampling many times, the average of all our estimates would equal the true parameter.</p>
<p><strong>Example</strong>: The sample mean <span class="math inline">\bar{x}</span> is an unbiased estimator of population mean <span class="math inline">\mu</span>. If we took 1,000 different samples and calculated 1,000 sample means, their average would be very close to <span class="math inline">\mu</span>.</p>
<p><strong>Consistency</strong>: As sample size increases, the estimator converges to the true parameter value.</p>
<p>Example: With <span class="math inline">n=10</span>, our estimate of average income might be off by $5,000. With <span class="math inline">n=1,000</span>, we might be off by only $500. With <span class="math inline">n=100,000</span>, we might be off by only $50.</p>
<p><strong>Efficiency</strong>: Among unbiased estimators, the one with the smallest variance. The sample mean is more efficient than the sample median for estimating the population mean of a normal distribution.</p>
<p><strong>Common Estimators:</strong></p>
<ul>
<li>Sample mean as estimator of population mean: <span class="math inline">\bar{x} = \frac{\sum x_i}{n}</span></li>
<li>Sample proportion as estimator of population proportion: <span class="math inline">\hat{p} = \frac{x}{n}</span> (where <span class="math inline">x</span> is the count of successes)</li>
<li>Sample variance as estimator of population variance: <span class="math inline">s^2 = \frac{\sum(x_i - \bar{x})^2}{n-1}</span></li>
</ul>
<p>Note: We divide by <span class="math inline">(n-1)</span> not <span class="math inline">n</span> for sample variance to make it unbiased—this is called Bessel’s correction.</p>
</section>
<section id="estimand" class="level3">
<h3 class="anchored" data-anchor-id="estimand">Estimand</h3>
<p>The <strong>estimand</strong> is the specific population parameter we aim to estimate. It’s the target of our estimation procedure. Clear specification of the estimand is crucial for proper statistical inference and avoiding misinterpretation.</p>
<p><strong>Examples of Clearly Defined Estimands:</strong></p>
<ul>
<li>“The median household income for all households in California as of January 1, 2024”</li>
<li>“The difference in life expectancy between males and females born in Sweden in 2023”</li>
<li>“The proportion of all adults aged 25-34 in urban areas who completed tertiary education”</li>
</ul>
<p><strong>Why Precise Estimand Definition Matters:</strong></p>
<p>Consider studying “unemployment rate.” The estimand must specify:</p>
<ul>
<li>Who counts as unemployed? (Actively seeking work? Discouraged workers?)</li>
<li>What age range? (15+? 16-64?)</li>
<li>What geographic area?</li>
<li>What time period?</li>
</ul>
<p>Different definitions lead to different numbers. The U.S. Bureau of Labor Statistics publishes six different unemployment rates (U-1 through U-6) based on different definitions.</p>
</section>
<section id="estimate" class="level3">
<h3 class="anchored" data-anchor-id="estimate">Estimate</h3>
<p>An <strong>estimate</strong> is the specific numerical value calculated by applying an estimator to observed data. It’s our best guess at the true parameter value based on available information.</p>
<p><strong>Example of the Complete Process:</strong></p>
<ol type="1">
<li><strong>Estimand</strong> (target): The proportion of all U.S. adults who approve of the president’s performance</li>
<li><strong>Parameter</strong> (true unknown value): <span class="math inline">p = 0.42</span> (42%, but we don’t know this)</li>
<li><strong>Estimator</strong> (method): Sample proportion <span class="math inline">\hat{p} = \frac{x}{n}</span> where <span class="math inline">x</span> is approvals and <span class="math inline">n</span> is sample size</li>
<li><strong>Sample</strong>: Survey 1,500 randomly selected adults, 650 approve</li>
<li><strong>Estimate</strong> (calculated value): <span class="math inline">\hat{p} = \frac{650}{1,500} = 0.433</span> (43.3%)</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Estimands: What Exactly Are We Trying to Estimate?
</div>
</div>
<div class="callout-body-container callout-body">
<p>An <strong>estimand</strong> is the specific quantity we aim to estimate—what we’re targeting with our statistical analysis. While this is often a population parameter, estimands can be more complex.</p>
<p><strong>Examples of different estimands</strong>:</p>
<p><strong>Simple parameter estimand</strong>: The population mean income (<span class="math inline">\mu</span>)<br>
<strong>Comparative estimand</strong>: The difference in mean income between two groups (<span class="math inline">\mu_1 - \mu_2</span>)<br>
<strong>Causal estimand</strong>: The average treatment effect of a job training program on earnings<br>
<strong>Conditional estimand</strong>: Expected voter turnout given specific weather conditions</p>
<section id="the-complete-framework" class="level3">
<h3 class="anchored" data-anchor-id="the-complete-framework">The Complete Framework</h3>
<p>Understanding statistical inference requires distinguishing between these related but distinct concepts:</p>
<ul>
<li><strong>Population Parameter</strong>: The true characteristic of the population (e.g., <span class="math inline">\mu</span>)</li>
<li><strong>Estimand</strong>: The specific quantity we want to estimate (often, but not always, a parameter)</li>
<li><strong>Estimator</strong>: The method for computing our estimate (e.g., sample mean)<br>
</li>
<li><strong>Estimate</strong>: The actual number we calculate from our data</li>
</ul>
<p><strong>Example in context</strong>:</p>
<ul>
<li><strong>Parameter</strong>: True mean voter turnout in all elections (<span class="math inline">\mu</span>)</li>
<li><strong>Estimand</strong>: Expected turnout difference between rainy vs.&nbsp;sunny election days (<span class="math inline">\mu_{\text{rainy}} - \mu_{\text{sunny}}</span>)</li>
<li><strong>Estimator</strong>: Difference between sample means from rainy and sunny elections</li>
<li><strong>Estimate</strong>: 3.2 percentage points lower turnout on rainy days</li>
</ul>
<p>This framework helps clarify exactly what question we’re answering and ensures our methods align with our research goals.</p>
<hr>
</section>
</div>
</div>
</section>
</section>
<section id="statistical-error" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="statistical-error"><span class="header-section-number">1.8</span> Statistical Error</h2>
<p>No measurement or estimate is perfect. Understanding different types of error is crucial for interpreting results and improving study design.</p>
</section>
<div class="callou-note">
<section id="opinion-polls-why-one-number-isnt-enough" class="level2" data-number="1.9">
<h2 data-number="1.9" class="anchored" data-anchor-id="opinion-polls-why-one-number-isnt-enough"><span class="header-section-number">1.9</span> Opinion Polls: Why One Number Isn’t Enough</h2>
<p>Polls use <strong>samples</strong> of people rather than surveying the entire population, so results naturally <strong>vary</strong>. A result like “Candidate A: 52%, Candidate B: 48%” is <strong>incomplete</strong> without expressing the uncertainty inherent in sampling.</p>
</section>
<section id="the-golden-rule-of-polling" class="level2" data-number="1.10">
<h2 data-number="1.10" class="anchored" data-anchor-id="the-golden-rule-of-polling"><span class="header-section-number">1.10</span> The Golden Rule of Polling</h2>
<p>With approximately <strong>1,000</strong> randomly selected respondents, the <strong>95% margin of sampling error</strong> is roughly <strong>±3 percentage points</strong> in the worst-case scenario. When a poll reports “52%,” the true population support likely falls <strong>between 49% and 55%</strong> — assuming no other sources of error.</p>
</section>
<section id="understanding-95-confidence" class="level2" data-number="1.11">
<h2 data-number="1.11" class="anchored" data-anchor-id="understanding-95-confidence"><span class="header-section-number">1.11</span> Understanding 95% Confidence</h2>
<p>Consider repeating the same poll 100 times with different random samples of 1,000 people. Each time, you calculate the ±3% range around your result. <strong>Approximately 95 of those 100 ranges would contain the true population value.</strong></p>
<p>The remaining 5 times represent sampling variation—occasions when the random sample happens to differ substantially from the population.</p>
</section>
<section id="why-choose-95" class="level2" data-number="1.12">
<h2 data-number="1.12" class="anchored" data-anchor-id="why-choose-95"><span class="header-section-number">1.12</span> Why Choose 95%?</h2>
<p>The confidence level represents a trade-off between precision and reliability:</p>
<ul>
<li><strong>90% confidence</strong> → narrower intervals, but incorrect more frequently</li>
<li><strong>95% confidence</strong> → moderate width (most common choice)<br>
</li>
<li><strong>99% confidence</strong> → wider intervals, but incorrect less frequently</li>
</ul>
<p>Higher confidence requires wider intervals, reducing precision.</p>
</section>
<section id="small-differences-and-uncertainty" class="level2" data-number="1.13">
<h2 data-number="1.13" class="anchored" data-anchor-id="small-differences-and-uncertainty"><span class="header-section-number">1.13</span> Small Differences and Uncertainty</h2>
<p>The <strong>difference</strong> between candidates carries more uncertainty than individual percentages. With n≈1,000, a 4-percentage-point lead may be <strong>within the margin of sampling error</strong> when accounting for random sampling variation.</p>
</section>
<section id="the-mathematical-foundation" class="level2" data-number="1.14">
<h2 data-number="1.14" class="anchored" data-anchor-id="the-mathematical-foundation"><span class="header-section-number">1.14</span> The Mathematical Foundation</h2>
<p>For a sample proportion <span class="math inline">\hat{p}</span> from <span class="math inline">n</span> respondents, the <strong>margin of sampling error</strong> is:</p>
<p><span class="math display">\text{Margin of sampling error (95\%)} \approx 1.96 \times \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</span></p>
<section id="understanding-the-1.96-multiplier" class="level3">
<h3 class="anchored" data-anchor-id="understanding-the-1.96-multiplier">Understanding the 1.96 Multiplier</h3>
<p>The value 1.96 represents a mathematical constant that ensures 95% coverage. Here is the conceptual explanation:</p>
<p>When drawing many samples from a population, the sample results form a predictable pattern around the true value. To capture the middle 95% of all possible sample results, statisticians have determined that the interval must extend <strong>1.96 times the typical variation</strong> in each direction from the sample result.</p>
<p>This multiplier ensures that if you repeated the polling process many times, approximately 95% of your calculated intervals would contain the true population parameter.</p>
</section>
<section id="worst-case-calculation" class="level3">
<h3 class="anchored" data-anchor-id="worst-case-calculation">Worst-Case Calculation</h3>
<p>The margin of sampling error reaches its maximum when <span class="math inline">\hat{p} = 0.5</span> (a 50-50 split):</p>
<p><span class="math display">\text{Margin of sampling error} \approx 1.96 \times \sqrt{\frac{0.5 \times 0.5}{n}} = \frac{0.98}{\sqrt{n}}</span></p>
<p>With <span class="math inline">n = 1,000</span>: <span class="math inline">\frac{0.98}{\sqrt{1000}} \approx 0.031 = 3.1\%</span></p>
</section>
</section>
<section id="essential-poll-information" class="level2" data-number="1.15">
<h2 data-number="1.15" class="anchored" data-anchor-id="essential-poll-information"><span class="header-section-number">1.15</span> Essential Poll Information</h2>
<p>Quality polls should report:</p>
<ul>
<li><strong>Field dates</strong> when interviews occurred</li>
<li><strong>Sample definition</strong> (adults, registered voters, likely voters) and <strong>sample size</strong> (<span class="math inline">n</span>)</li>
<li><strong>Treatment of undecided responses</strong> and third-party candidates</li>
<li><strong>Margin of sampling error</strong> for individual candidates</li>
<li><strong>Uncertainty in vote margins</strong> when possible</li>
</ul>
</section>
<section id="key-principles-1" class="level2" data-number="1.16">
<h2 data-number="1.16" class="anchored" data-anchor-id="key-principles-1"><span class="header-section-number">1.16</span> Key Principles</h2>
<p><strong>Primary rule:</strong> Differences smaller than the margin of sampling error may represent <strong>random sampling variation rather than meaningful differences</strong>.</p>
<p><strong>Critical limitation:</strong> The margin of sampling error addresses only <strong>random variation from sampling</strong>. It does <strong>not</strong> account for systematic errors, which are often larger and more consequential:</p>
<ul>
<li><strong>Non-response bias</strong> (certain groups declining to participate)</li>
<li><strong>Coverage bias</strong> (certain groups absent from contact lists)<br>
</li>
<li><strong>Question wording effects</strong> and response order</li>
<li><strong>Social desirability bias</strong> (respondents giving socially acceptable answers)</li>
<li><strong>Timing effects</strong> and current events influence</li>
</ul>
<p>These systematic errors can cause polls to miss the true value by much more than ±3%, yet they are invisible in the reported margin of sampling error.</p>
<p><strong>Rule of thumb</strong>: Don’t over-interpret differences smaller than the margin of error—they might just be noise.</p>
<section id="random-error-vs.-systematic-error" class="level4">
<h4 class="anchored" data-anchor-id="random-error-vs.-systematic-error">Random Error vs.&nbsp;Systematic Error</h4>
<p><strong>Random error</strong> is the unpredictable variability that occurs in any sample-based study. The larger the sample, the smaller the random error. This is what the margin of error accounts for.</p>
<p><strong>Systematic error (bias)</strong> is a consistent shift in results in one direction. It can result from:</p>
<ul>
<li>Unrepresentative samples (e.g., polling only landline phones)</li>
<li>Leading questions (“Do you support wasting taxpayer money on program X?”)</li>
<li>Non-response from certain groups (e.g., young people less likely to answer calls)</li>
</ul>
<p><strong>Key difference</strong>: A larger sample reduces random error but <strong>does not</strong> eliminate systematic error. A poll of 10,000 people with systematic bias can be less accurate than a poll of 1,000 people without such bias.</p>
<p><strong>Key idea:</strong> A large <strong>biased</strong> sample gives a <strong>precisely wrong</strong> answer. Increase <span class="math inline">n</span> to reduce <strong>random error</strong>; improve design/measurement to reduce <strong>bias</strong>.</p>
</section>
</section>
<section id="biasvariance-mse-decomposition" class="level2" data-number="1.17">
<h2 data-number="1.17" class="anchored" data-anchor-id="biasvariance-mse-decomposition"><span class="header-section-number">1.17</span> Bias–Variance (MSE) Decomposition</h2>
<p>For an estimator <span class="math inline">\hat\theta</span>:</p>
<p><span class="math display">
\mathrm{MSE}(\hat\theta) \;=\; \underbrace{\mathrm{Var}(\hat\theta)}_{\text{random error}} \;+\; \underbrace{\big(\mathrm{Bias}(\hat\theta)\big)^2}_{\text{systematic error}}.
</span></p>
<ul>
<li><strong>Variance</strong>: How much the estimate would bounce around the true value of the unknown parameter if you repeated the study many times (random error).</li>
<li><strong>Bias</strong>: How far the average estimate is from the truth (systematic error).</li>
<li><strong>Goal</strong>: Keep <strong>both</strong> small. More data lowers variance; better design lowers bias.</li>
</ul>
<p><img src="stat_imgs/bias-variance-targets.svg" class="img-fluid"></p>
</section>
</div>
<section id="random-error" class="level3">
<h3 class="anchored" data-anchor-id="random-error">Random Error</h3>
<p><strong>Random error</strong> (also called sampling error) arises from natural variability in sampling. It’s the error that occurs because we observe a sample rather than the entire population.</p>
<p><strong>Characteristics of Random Error:</strong></p>
<ul>
<li><strong>Unpredictable Direction</strong>: Sometimes our estimate is too high, sometimes too low</li>
<li><strong>Decreases with Sample Size</strong>: Larger samples have less random error</li>
<li><strong>Quantifiable</strong>: We can calculate the likely magnitude using probability theory</li>
<li><strong>Averages to Zero</strong>: With many repeated samples, overestimates and underestimates balance out</li>
</ul>
<p><strong>Example of Random Error:</strong></p>
<p>Imagine estimating the proportion of households with internet access by surveying 100 random households:</p>
<ul>
<li>Sample 1: 73 have internet (estimate: 73%)</li>
<li>Sample 2: 68 have internet (estimate: 68%)</li>
<li>Sample 3: 71 have internet (estimate: 71%)</li>
<li>True population value: 70%</li>
</ul>
<p>The variation around 70% is random error. With larger samples (say 1,000 households), estimates would cluster more tightly around 70%.</p>
<p><strong>Quantifying Random Error:</strong></p>
<p>For a proportion, the standard error (which measures random error) is: <span class="math display">SE = \sqrt{\frac{p(1-p)}{n}}</span></p>
<p>If true proportion <span class="math inline">p = 0.7</span> and <span class="math inline">n = 100</span>: <span class="math display">SE = \sqrt{\frac{0.7 \times 0.3}{100}} = 0.046</span></p>
<p>This means our estimate typically varies by about <span class="math inline">\pm 4.6</span> percentage points due to random error alone.</p>
</section>
<section id="systematic-error" class="level3">
<h3 class="anchored" data-anchor-id="systematic-error">Systematic Error</h3>
<p><strong>Systematic error</strong> (also called bias) represents consistent deviation from true values in a particular direction. Unlike random error, it doesn’t average out with repeated sampling.</p>
<p><strong>Sources of Systematic Error:</strong></p>
<p><strong>Selection Bias</strong>: When the sampling method systematically excludes certain groups.</p>
<p><em>Example</em>: A telephone survey about employment conducted only during business hours will underrepresent employed people, biasing unemployment estimates upward.</p>
<p><strong>Measurement Bias</strong>: When the measurement instrument consistently over- or under-measures.</p>
<p><em>Example</em>: Asking “How old were you at your first marriage?” may yield different results than “In what year were you first married?” due to recall differences.</p>
<p><strong>Response Bias</strong>: When respondents systematically misreport.</p>
<p><em>Example</em>: People tend to underreport alcohol consumption and overreport voting behavior. Income is often underreported at high levels and overreported at low levels.</p>
<p><strong>Non-response Bias</strong>: When those who don’t respond differ systematically from those who do.</p>
<p><em>Example</em>: In health surveys, very sick and very healthy people are less likely to respond, biasing health estimates toward the middle.</p>
<p><strong>Survivorship Bias</strong>: When we only observe “survivors” of some process.</p>
<p><em>Example</em>: Studying factors associated with longevity by interviewing 90-year-olds misses those with the same factors who died younger.</p>
<p><strong>Example Comparing Random and Systematic Error:</strong></p>
<p>A scale that always reads 2 pounds heavy has systematic error. If you weigh yourself 100 times:</p>
<ul>
<li>Without systematic error but with random error: Readings vary around your true weight</li>
<li>With systematic error but no random error: All readings are exactly 2 pounds too heavy</li>
<li>With both: Readings vary around a value that’s 2 pounds too heavy</li>
</ul>
<p><strong>Dealing with Different Types of Error:</strong></p>
<ul>
<li><strong>Random Error</strong>: Increase sample size, improve measurement precision, use better sampling designs</li>
<li><strong>Systematic Error</strong>: Careful study design, calibration of instruments, validation studies, statistical adjustments</li>
</ul>
</section>
<section id="sampling-and-sampling-methods" class="level2" data-number="1.18">
<h2 data-number="1.18" class="anchored" data-anchor-id="sampling-and-sampling-methods"><span class="header-section-number">1.18</span> Sampling and Sampling Methods</h2>
<p><strong>Sampling</strong> is the process of selecting a subset of individuals from a population to estimate characteristics of the whole population. The way we sample profoundly affects what we can conclude from our data.</p>
<section id="the-sampling-frame" class="level3">
<h3 class="anchored" data-anchor-id="the-sampling-frame">The Sampling Frame</h3>
<p>Before discussing methods, we must understand the <strong>sampling frame</strong>—the list or device from which we draw our sample. The frame should ideally include every population member exactly once.</p>
<p><strong>Common Sampling Frames:</strong></p>
<ul>
<li>Electoral rolls (for adult citizens)</li>
<li>Telephone directories (increasingly problematic due to mobile phones and unlisted numbers)</li>
<li>Address lists from postal services</li>
<li>Birth registrations (for newborns)</li>
<li>School enrollment lists (for children)</li>
<li>Tax records (for income earners)</li>
<li>Satellite imagery (for dwellings in remote areas)</li>
</ul>
<p><strong>Frame Problems:</strong></p>
<ul>
<li><strong>Undercoverage</strong>: Frame missing population members (homeless individuals not on address lists)</li>
<li><strong>Overcoverage</strong>: Frame includes non-population members (deceased people still on voter rolls)</li>
<li><strong>Duplication</strong>: Same unit appears multiple times (people with multiple phone numbers)</li>
<li><strong>Clustering</strong>: Multiple population members per frame unit (multiple families at one address)</li>
</ul>
</section>
<section id="probability-sampling-methods" class="level3">
<h3 class="anchored" data-anchor-id="probability-sampling-methods">Probability Sampling Methods</h3>
<p><strong>Probability sampling</strong> gives every population member a known, non-zero probability of selection. This allows us to make statistical inferences about the population.</p>
<section id="simple-random-sampling-srs" class="level4">
<h4 class="anchored" data-anchor-id="simple-random-sampling-srs">Simple Random Sampling (SRS)</h4>
<p>Every possible sample of size <span class="math inline">n</span> has equal probability of selection. It’s the gold standard for statistical theory but often impractical for large populations.</p>
<p><strong>How It Works:</strong></p>
<ol type="1">
<li>Number every unit in the population from 1 to <span class="math inline">N</span></li>
<li>Use random numbers to select <span class="math inline">n</span> units</li>
<li>Each unit has probability <span class="math inline">n/N</span> of selection</li>
</ol>
<p><strong>Example</strong>: To sample 50 students from a school of 1,000:</p>
<ul>
<li>Assign each student a number from 1 to 1,000</li>
<li>Generate 50 random numbers between 1 and 1,000</li>
<li>Select students with those numbers</li>
</ul>
<p><strong>Advantages:</strong></p>
<ul>
<li>Statistically optimal</li>
<li>Easy to analyze</li>
<li>No need for additional information about population</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Requires complete sampling frame</li>
<li>Can be expensive (selected units might be far apart)</li>
<li>May not represent important subgroups well by chance</li>
</ul>
</section>
<section id="systematic-sampling" class="level4">
<h4 class="anchored" data-anchor-id="systematic-sampling">Systematic Sampling</h4>
<p>Select every <span class="math inline">k</span>th element from an ordered sampling frame, where <span class="math inline">k = N/n</span> (the sampling interval).</p>
<p><strong>How It Works:</strong></p>
<ol type="1">
<li>Calculate sampling interval <span class="math inline">k = N/n</span></li>
<li>Randomly select starting point between 1 and <span class="math inline">k</span></li>
<li>Select every <span class="math inline">k</span>th unit thereafter</li>
</ol>
<p><strong>Example</strong>: To sample 100 houses from 5,000 on a street listing:</p>
<ul>
<li><span class="math inline">k = 5,000/100 = 50</span></li>
<li>Random start: 23</li>
<li>Sample houses: 23, 73, 123, 173, 223…</li>
</ul>
<p><strong>Advantages:</strong></p>
<ul>
<li>Simple to implement in field</li>
<li>Spreads sample throughout population</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Can introduce bias if there’s periodicity in the frame</li>
</ul>
<p><strong>Hidden Periodicity Example</strong>: Sampling every 10th apartment in buildings where corner apartments (numbers ending in 0) are all larger. This would bias our estimate of average apartment size.</p>
</section>
<section id="stratified-sampling" class="level4">
<h4 class="anchored" data-anchor-id="stratified-sampling">Stratified Sampling</h4>
<p>Divide population into homogeneous subgroups (strata) before sampling. Sample independently within each stratum.</p>
<p><strong>How It Works:</strong></p>
<ol type="1">
<li>Divide population into non-overlapping strata</li>
<li>Sample independently from each stratum</li>
<li>Combine results with appropriate weights</li>
</ol>
<p><strong>Example</strong>: Studying income in a city with distinct neighborhoods:</p>
<ul>
<li>Stratum 1: High-income neighborhood (10% of population) - sample 100</li>
<li>Stratum 2: Middle-income neighborhood (60% of population) - sample 600</li>
<li>Stratum 3: Low-income neighborhood (30% of population) - sample 300</li>
</ul>
<p><strong>Types of Allocation:</strong></p>
<p><strong>Proportional</strong>: Sample size in each stratum proportional to stratum size</p>
<ul>
<li>If stratum has 20% of population, it gets 20% of sample</li>
</ul>
<p><strong>Optimal (Neyman)</strong>: Larger samples from more variable strata</p>
<ul>
<li>If income varies more in high-income areas, sample more there</li>
</ul>
<p><strong>Equal</strong>: Same sample size per stratum regardless of population size</p>
<ul>
<li>Useful when comparing strata is primary goal</li>
</ul>
<p><strong>Advantages:</strong></p>
<ul>
<li>Ensures representation of all subgroups</li>
<li>Can increase precision substantially</li>
<li>Allows different sampling methods per stratum</li>
<li>Provides estimates for each stratum</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Requires information to create strata</li>
<li>Can be complex to analyze</li>
</ul>
</section>
<section id="cluster-sampling" class="level4">
<h4 class="anchored" data-anchor-id="cluster-sampling">Cluster Sampling</h4>
<p>Select groups (clusters) rather than individuals. Often used when population is naturally grouped or when creating a complete frame is difficult.</p>
<p><strong>Single-Stage Cluster Sampling:</strong></p>
<ol type="1">
<li>Divide population into clusters</li>
<li>Randomly select some clusters</li>
<li>Include all units from selected clusters</li>
</ol>
<p><strong>Two-Stage Cluster Sampling:</strong></p>
<ol type="1">
<li>Randomly select clusters (Primary Sampling Units)</li>
<li>Within selected clusters, randomly select individuals (Secondary Sampling Units)</li>
</ol>
<p><strong>Example</strong>: Surveying rural households in a large country:</p>
<ul>
<li>Stage 1: Randomly select 50 villages from 1,000 villages</li>
<li>Stage 2: Within each selected village, randomly select 20 households</li>
<li>Total sample: 50 × 20 = 1,000 households</li>
</ul>
<p><strong>Multi-Stage Example</strong>: National health survey:</p>
<ul>
<li>Stage 1: Select states</li>
<li>Stage 2: Select counties within selected states</li>
<li>Stage 3: Select census blocks within selected counties</li>
<li>Stage 4: Select households within selected blocks</li>
<li>Stage 5: Select one adult within selected households</li>
</ul>
<p><strong>Advantages:</strong></p>
<ul>
<li>Doesn’t require complete population list</li>
<li>Reduces travel costs (units clustered geographically)</li>
<li>Can use different methods at different stages</li>
<li>Natural for hierarchical populations</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Less statistically efficient than SRS</li>
<li>Complex variance estimation</li>
<li>Larger samples needed for same precision</li>
</ul>
<p><strong>Design Effect</strong>: Cluster sampling typically requires larger samples than SRS. The design effect (DEFF) quantifies this:</p>
<p><span class="math display">\text{DEFF} = \frac{\text{Variance(cluster sample)}}{\text{Variance(SRS)}}</span></p>
<p>If DEFF = 2, you need twice the sample size to achieve the same precision as SRS.</p>
</section>
</section>
<section id="non-probability-sampling-methods" class="level3">
<h3 class="anchored" data-anchor-id="non-probability-sampling-methods">Non-Probability Sampling Methods</h3>
<p><strong>Non-probability sampling</strong> doesn’t guarantee known selection probabilities. While limiting statistical inference, these methods may be necessary or useful in certain situations.</p>
<section id="convenience-sampling" class="level4">
<h4 class="anchored" data-anchor-id="convenience-sampling">Convenience Sampling</h4>
<p>Selection based purely on ease of access. No attempt at representation.</p>
<p><strong>Examples:</strong></p>
<ul>
<li>Surveying students in your class about study habits</li>
<li>Interviewing people at a shopping mall about consumer preferences</li>
<li>Online polls where anyone can participate</li>
<li>Medical studies using volunteers who respond to advertisements</li>
</ul>
<p><strong>When It Might Be Acceptable:</strong></p>
<ul>
<li>Pilot studies to test survey instruments</li>
<li>Exploratory research to identify issues</li>
<li>When studying processes believed to be universal</li>
</ul>
<p><strong>Major Problems:</strong></p>
<ul>
<li>No basis for inference to population</li>
<li>Severe selection bias likely</li>
<li>Results may be completely misleading</li>
</ul>
<p><strong>Real Example</strong>: Literary Digest’s 1936 U.S. presidential poll surveyed 2.4 million people (huge sample!) but used telephone directories and club memberships as frames during the Depression, dramatically overrepresenting wealthy voters and incorrectly predicting Landon would defeat Roosevelt.</p>
</section>
<section id="purposive-judgmental-sampling" class="level4">
<h4 class="anchored" data-anchor-id="purposive-judgmental-sampling">Purposive (Judgmental) Sampling</h4>
<p>Deliberate selection of specific cases based on researcher judgment about what’s “typical” or “interesting.”</p>
<p><strong>Examples:</strong></p>
<ul>
<li>Selecting “typical” villages to represent rural areas</li>
<li>Choosing specific age groups for a developmental study</li>
<li>Selecting extreme cases to understand range of variation</li>
<li>Picking information-rich cases for in-depth study</li>
</ul>
<p><strong>Types of Purposive Sampling:</strong></p>
<p><strong>Typical Case</strong>: Choose average or normal examples</p>
<ul>
<li>Studying “typical” American suburbs</li>
</ul>
<p><strong>Extreme/Deviant Case</strong>: Choose unusual examples</p>
<ul>
<li>Studying villages with unusually low infant mortality to understand success factors</li>
</ul>
<p><strong>Maximum Variation</strong>: Deliberately pick diverse cases</p>
<ul>
<li>Selecting diverse schools (urban/rural, rich/poor, large/small) for education research</li>
</ul>
<p><strong>Critical Case</strong>: Choose cases that will be definitive</p>
<ul>
<li>“If it doesn’t work here, it won’t work anywhere”</li>
</ul>
<p><strong>When It’s Useful:</strong></p>
<ul>
<li>Qualitative research focusing on depth over breadth</li>
<li>When studying rare populations</li>
<li>Resource constraints limit sample size severely</li>
<li>Exploratory phases of research</li>
</ul>
<p><strong>Problems:</strong></p>
<ul>
<li>Entirely dependent on researcher judgment</li>
<li>No statistical inference possible</li>
<li>Different researchers might select different “typical” cases</li>
</ul>
</section>
<section id="quota-sampling" class="level4">
<h4 class="anchored" data-anchor-id="quota-sampling">Quota Sampling</h4>
<p>Selection to match population proportions on key characteristics. Like stratified sampling but without random selection within groups.</p>
<p><strong>How Quota Sampling Works:</strong></p>
<ol type="1">
<li>Identify key characteristics (age, sex, race, education)</li>
<li>Determine population proportions for these characteristics</li>
<li>Set quotas for each combination</li>
<li>Interviewers fill quotas using convenience methods</li>
</ol>
<p><strong>Detailed Example</strong>: Political poll with quotas:</p>
<p>Population proportions:</p>
<ul>
<li>Male 18-34: 15%</li>
<li>Male 35-54: 20%</li>
<li>Male 55+: 15%</li>
<li>Female 18-34: 16%</li>
<li>Female 35-54: 19%</li>
<li>Female 55+: 15%</li>
</ul>
<p>For a sample of 1,000:</p>
<ul>
<li>Interview 150 males aged 18-34</li>
<li>Interview 200 males aged 35-54</li>
<li>And so on…</li>
</ul>
<p>Interviewers might stand on street corners approaching people who appear to fit needed categories until quotas are filled.</p>
<p><strong>Why It’s Popular in Market Research:</strong></p>
<ul>
<li>Faster than probability sampling</li>
<li>Cheaper (no callbacks for specific individuals)</li>
<li>Ensures demographic representation</li>
<li>No sampling frame needed</li>
</ul>
<p><strong>Why It’s Problematic for Statistical Inference:</strong></p>
<p><strong>Hidden Selection Bias</strong>: Interviewers approach people who look approachable, speak the language well, aren’t in a hurry—systematically excluding certain types within each quota cell.</p>
<p><strong>Example of Bias</strong>: An interviewer filling a quota for “women 18-34” might approach women at a shopping mall on Tuesday afternoon, systematically missing:</p>
<ul>
<li>Women who work during weekdays</li>
<li>Women who can’t afford to shop at malls</li>
<li>Women with young children who avoid malls</li>
<li>Women who shop online</li>
</ul>
<p>Even though the final sample has the “right” proportion of young women, they’re not representative of all young women.</p>
<p><strong>No Measure of Sampling Error</strong>: Without selection probabilities, we can’t calculate standard errors or confidence intervals.</p>
<p><strong>Historical Cautionary Tale</strong>: Quota sampling was standard in polling until the 1948 U.S. presidential election, when polls using quota sampling incorrectly predicted Dewey would defeat Truman. The failure led to adoption of probability sampling in polling.</p>
</section>
<section id="snowball-sampling" class="level4">
<h4 class="anchored" data-anchor-id="snowball-sampling">Snowball Sampling</h4>
<p>Participants recruit additional subjects from their acquaintances. The sample grows like a rolling snowball.</p>
<p><strong>How It Works:</strong></p>
<ol type="1">
<li>Identify initial participants (seeds)</li>
<li>Ask them to refer others with required characteristics</li>
<li>Ask new participants for further referrals</li>
<li>Continue until sample size reached or referrals exhausted</li>
</ol>
<p><strong>Example</strong>: Studying undocumented immigrants:</p>
<ul>
<li>Start with 5 immigrants you can identify</li>
<li>Each refers 3 others they know</li>
<li>Those 15 each refer 2-3 others</li>
<li>Continue until you have 100+ participants</li>
</ul>
<p><strong>When It’s Valuable:</strong></p>
<p><strong>Hidden Populations</strong>: Groups without sampling frames</p>
<ul>
<li>Drug users</li>
<li>Homeless individuals</li>
<li>People with rare diseases</li>
<li>Members of underground movements</li>
</ul>
<p><strong>Socially Connected Populations</strong>: When relationships matter</p>
<ul>
<li>Studying social network effects</li>
<li>Researching community transmission of diseases</li>
<li>Understanding information diffusion</li>
</ul>
<p><strong>Trust-Dependent Research</strong>: When referrals increase participation</p>
<ul>
<li>Sensitive topics where trust is essential</li>
<li>Closed communities suspicious of outsiders</li>
</ul>
<p><strong>Major Limitations:</strong></p>
<ul>
<li>Samples biased toward cooperative, well-connected individuals</li>
<li>Isolated members of population missed entirely</li>
<li>Statistical inference generally impossible</li>
<li>Can reinforce social divisions (chains rarely cross social boundaries)</li>
</ul>
<p><strong>Advanced Version - Respondent-Driven Sampling (RDS):</strong></p>
<p>Attempts to make snowball sampling more rigorous by:</p>
<ul>
<li>Tracking who recruited whom</li>
<li>Limiting number of referrals per person</li>
<li>Weighting based on network size</li>
<li>Using mathematical models to adjust for bias</li>
</ul>
<p>Still controversial whether RDS truly allows valid inference.</p>
</section>
</section>
</section>
<section id="measures-of-uncertainty" class="level2" data-number="1.19">
<h2 data-number="1.19" class="anchored" data-anchor-id="measures-of-uncertainty"><span class="header-section-number">1.19</span> Measures of Uncertainty</h2>
<p>When we make estimates from samples, we need to quantify how uncertain those estimates are. These measures are fundamental to honest reporting of results.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Point estimate</strong>: The single value calculated from sample data (e.g., <span class="math inline">\hat{p} = 0.60</span>)</p>
<p><strong>Standard error (SE)</strong>: Typical variability in the estimate across repeated samples</p>
<p><strong>Margin of error</strong>: Range added around point estimate to account for sampling uncertainty</p>
<p><strong>Confidence interval</strong>: Point estimate ± margin of error (e.g., 60% ± 3%)</p>
<p>When 60 out of 100 surveyed students support a proposal, <span class="math inline">\hat{p} = 0.60</span> is your <strong>point estimate</strong>—the best single approximation of the population parameter from your sample.</p>
<section id="sample-size-and-precision" class="level2" data-number="1.20">
<h2 data-number="1.20" class="anchored" data-anchor-id="sample-size-and-precision"><span class="header-section-number">1.20</span> Sample Size and Precision</h2>
<p>Sample size directly controls estimate precision. For binary outcomes near 50% with simple random sampling:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Sample Size</th>
<th>Margin of Error (95%)</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n = 100</td>
<td>± 10%</td>
<td>Broad direction only</td>
</tr>
<tr class="even">
<td>n = 400</td>
<td>± 5%</td>
<td>General trends</td>
</tr>
<tr class="odd">
<td>n = 1,000</td>
<td>± 3%</td>
<td>Actionable precision</td>
</tr>
<tr class="even">
<td>n = 2,500</td>
<td>± 2%</td>
<td>High precision</td>
</tr>
<tr class="odd">
<td>n = 10,000</td>
<td>± 1%</td>
<td>Very high precision</td>
</tr>
</tbody>
</table>
<p><strong>Key insight</strong>: To halve the margin of error, you need <strong>four times</strong> the sample size (law of diminishing returns).</p>
<p><strong>Mathematical basis</strong>: Since <span class="math inline">\text{MoE} \propto \frac{1}{\sqrt{n}}</span>, precision improvements require quadratic increases in sample size.</p>
</section>
<section id="mathematical-foundations" class="level2" data-number="1.21">
<h2 data-number="1.21" class="anchored" data-anchor-id="mathematical-foundations"><span class="header-section-number">1.21</span> Mathematical Foundations</h2>
<section id="standard-formulas" class="level3">
<h3 class="anchored" data-anchor-id="standard-formulas">Standard Formulas</h3>
<p><strong>Margin of error relationship</strong>: <span class="math inline">\text{MoE} \approx 2 \times \text{SE}</span> (for 95% confidence)</p>
<p><strong>Standard errors</strong>: - Proportion: <span class="math inline">\text{SE}(\hat{p}) = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</span> - Mean: <span class="math inline">\text{SE}(\bar{x}) = \frac{s}{\sqrt{n}}</span></p>
<p><strong>Rule of thumb</strong>: For proportions near 50%, <span class="math inline">\text{MoE} \approx \frac{1}{\sqrt{n}}</span></p>
</section>
<section id="the-1.96-multiplier" class="level3">
<h3 class="anchored" data-anchor-id="the-1.96-multiplier">The 1.96 Multiplier</h3>
<p>For 95% confidence intervals, we multiply the standard error by 1.96. This value ensures that if you repeated the process many times, approximately 95% of your calculated intervals would contain the true population parameter.</p>
</section>
</section>
<section id="summary-1" class="level2" data-number="1.22">
<h2 data-number="1.22" class="anchored" data-anchor-id="summary-1"><span class="header-section-number">1.22</span> Summary</h2>
<p><strong>Margin of error</strong> quantifies uncertainty from studying a sample rather than the entire population. <strong>Standard error</strong> measures typical sampling variability. <strong>95% confidence intervals</strong> use methods that capture the true parameter 95% of the time across repeated applications.</p>
<p><strong>Key insight</strong>: These measures help distinguish meaningful differences from sampling noise, but remember they address only one source of uncertainty—random sampling variation.</p>
</section>
<section id="visualizing-sampling-variability" class="level2" data-number="1.23">
<h2 data-number="1.23" class="anchored" data-anchor-id="visualizing-sampling-variability"><span class="header-section-number">1.23</span> Visualizing Sampling Variability</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>n_polls      <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>n_people     <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>true_support <span class="ot">&lt;-</span> <span class="fl">0.50</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate independent polls (binomial counts -&gt; proportions)</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>support <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_polls, n_people, true_support) <span class="sc">/</span> n_people</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Per-poll standard error for a proportion (plug-in using that poll's estimate)</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>se   <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(support <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> support) <span class="sc">/</span> n_people)</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a><span class="co"># "95%" margin of error ≈ 2 × SE (plain-English multiplier, no distribution jargon)</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>moe  <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> se</span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Clamp intervals to [0, 1] to avoid plotting outside the parameter space</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>lower <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="dv">0</span>, support <span class="sc">-</span> moe)</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>upper <span class="ot">&lt;-</span> <span class="fu">pmin</span>(<span class="dv">1</span>, support <span class="sc">+</span> moe)</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Does the interval cover the true value?</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>covers <span class="ot">&lt;-</span> (lower <span class="sc">&lt;=</span> true_support) <span class="sc">&amp;</span> (upper <span class="sc">&gt;=</span> true_support)</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>n_cover <span class="ot">&lt;-</span> <span class="fu">sum</span>(covers)</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>n_miss  <span class="ot">&lt;-</span> n_polls <span class="sc">-</span> n_cover</span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">poll =</span> <span class="fu">seq_len</span>(n_polls),</span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>  support, se, moe, lower, upper, covers</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(results, <span class="fu">aes</span>(<span class="at">x =</span> poll, <span class="at">y =</span> support, <span class="at">color =</span> covers)) <span class="sc">+</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper), <span class="at">width =</span> <span class="fl">0.3</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> true_support, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"TRUE"</span> <span class="ot">=</span> <span class="st">"forestgreen"</span>, <span class="st">"FALSE"</span> <span class="ot">=</span> <span class="st">"darkorange"</span>),</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"TRUE"</span> <span class="ot">=</span> <span class="st">"Covers truth"</span>, <span class="st">"FALSE"</span> <span class="ot">=</span> <span class="st">"Misses truth"</span>),</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">name   =</span> <span class="cn">NULL</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_cartesian</span>(<span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">title    =</span> <span class="st">"Sampling Variability in 20 Independent Polls"</span>,</span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">paste0</span>(</span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>      <span class="st">"Each poll surveys "</span>, n_people, <span class="st">" different people.  Truth = "</span>,</span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>      scales<span class="sc">::</span><span class="fu">percent</span>(true_support),</span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>      <span class="st">". Intervals covering truth: "</span>, n_cover, <span class="st">"/"</span>, n_polls,</span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>      <span class="st">" ("</span>, <span class="fu">round</span>(<span class="dv">100</span> <span class="sc">*</span> n_cover <span class="sc">/</span> n_polls), <span class="st">"%)."</span></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Poll Number"</span>,</span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Estimated Proportion"</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">13</span>) <span class="sc">+</span></span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">"top"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Key observation</strong>: Each sample yields a different result, but most estimates—and their intervals—cluster around the true value; a few “miss” purely due to the randomness of sampling.</p>
</section>
</div>
</div>
<section id="standard-error" class="level3">
<h3 class="anchored" data-anchor-id="standard-error">Standard Error</h3>
<p>The <strong>standard error</strong> (SE) quantifies the variability of a statistic across different possible samples. Think of it as measuring how much our estimate would bounce around if we repeated our study many times.</p>
<p><strong>Understanding Standard Error Through Simulation:</strong></p>
<p>Imagine we want to estimate average height in a population where <span class="math inline">\mu = 170</span> cm and <span class="math inline">\sigma = 10</span> cm.</p>
<p>If we took 1,000 different samples of <span class="math inline">n = 100</span> people:</p>
<ul>
<li>Sample 1 mean: 169.2 cm</li>
<li>Sample 2 mean: 170.8 cm</li>
<li>Sample 3 mean: 169.7 cm</li>
<li>…</li>
<li>Sample 1,000 mean: 170.4 cm</li>
</ul>
<p>The standard deviation of these 1,000 sample means would be approximately 1 cm. This is the standard error.</p>
<p><strong>Formulas for Common Standard Errors:</strong></p>
<p><strong>For a mean</strong>: <span class="math inline">SE(\bar{x}) = \frac{\sigma}{\sqrt{n}}</span></p>
<ul>
<li>Population with <span class="math inline">\sigma = 10</span>, sample of <span class="math inline">n = 100</span>: <span class="math inline">SE = \frac{10}{\sqrt{100}} = 1</span></li>
<li>Double the sample to <span class="math inline">n = 400</span>: <span class="math inline">SE = \frac{10}{\sqrt{400}} = 0.5</span></li>
<li>To halve the SE, need <span class="math inline">4\times</span> the sample size</li>
</ul>
<p><strong>For a proportion</strong>: <span class="math inline">SE(\hat{p}) = \sqrt{\frac{p(1-p)}{n}}</span></p>
<ul>
<li>True proportion <span class="math inline">p = 0.3</span>, sample <span class="math inline">n = 1,000</span>: <span class="math inline">SE = \sqrt{\frac{0.3 \times 0.7}{1,000}} = 0.0145</span></li>
<li>This means our estimate typically varies by about <span class="math inline">\pm 1.45</span> percentage points</li>
</ul>
<p><strong>For difference between two means</strong>: <span class="math inline">SE(\bar{x}_1 - \bar{x}_2) = \sqrt{\frac{\sigma_1^2}{n_1} + \frac{\sigma_2^2}{n_2}}</span></p>
<p><strong>Important Properties:</strong></p>
<ul>
<li>Standard error decreases with √n (diminishing returns)</li>
<li>To reduce SE by half, need 4× larger sample</li>
<li>To reduce SE by 90%, need 100× larger sample</li>
<li>Standard error depends on population variability (σ)</li>
</ul>
<p><strong>Standard Error vs.&nbsp;Standard Deviation:</strong></p>
<p>Students often confuse these:</p>
<ul>
<li><strong>Standard Deviation</strong>: Measures spread of individual observations</li>
<li><strong>Standard Error</strong>: Measures precision of an estimate</li>
</ul>
<p>Example with exam scores:</p>
<ul>
<li>Standard deviation = 15 points (individual scores vary from the mean (average) by ±15 points)</li>
<li>Standard error of mean with n = 100: SE = 15/√100 = 1.5 points</li>
<li>The class average is precise to ±1.5 points, even though individuals vary on average by ±15 points</li>
</ul>
</section>
<section id="margin-of-error" class="level3">
<h3 class="anchored" data-anchor-id="margin-of-error">Margin of Error</h3>
<p>The <strong>margin of error</strong> represents the maximum expected difference between a sample estimate and the true population parameter at a specified confidence level. It’s what you see reported in polls: “Support is 52% with a margin of error of ±3%.”</p>
<p><strong>Calculating Margin of Error:</strong></p>
<p><span class="math inline">\text{MOE} = \text{Critical Value} \times \text{Standard Error}</span></p>
<p>For 95% confidence with normal approximation: <span class="math inline">\text{MOE} = 1.96 \times SE</span></p>
<p>For 99% confidence: <span class="math inline">\text{MOE} = 2.576 \times SE</span></p>
<p><strong>Example with Political Polling:</strong></p>
<p>Survey of 1,000 voters finds 52% support a candidate.</p>
<ol type="1">
<li>Standard error: <span class="math inline">SE = \sqrt{\frac{0.52 \times 0.48}{1,000}} = 0.0158</span></li>
<li>Margin of error (95%): <span class="math inline">\text{MOE} = 1.96 \times 0.0158 = 0.031</span></li>
<li>Report: “52% support with margin of error <span class="math inline">\pm 3.1%</span>”</li>
</ol>
<p><strong>What Margin of Error Does and Doesn’t Tell Us:</strong></p>
<p><strong>Does Tell Us:</strong></p>
<ul>
<li>Range of likely values due to sampling variation</li>
<li>Precision of our estimate</li>
<li>How sample size affects precision</li>
</ul>
<p><strong>Doesn’t Tell Us:</strong></p>
<ul>
<li>Anything about bias or systematic error</li>
<li>Whether our sample represents the population</li>
<li>Measurement quality</li>
</ul>
<p>A biased sample with small margin of error is precisely wrong!</p>
<p><strong>Factors Affecting Margin of Error:</strong></p>
<ol type="1">
<li><strong>Sample Size</strong>: Larger n → smaller MOE</li>
<li><strong>Confidence Level</strong>: Higher confidence → larger MOE</li>
<li><strong>Population Variability</strong>: More variable population → larger MOE</li>
<li><strong>Proportion Being Estimated</strong>: Proportions near 50% have largest MOE</li>
</ol>
<p><strong>Common Misinterpretations:</strong></p>
<ul>
<li>“The true value is definitely within the margin of error” (No—there’s still a 5% chance it’s outside with 95% confidence)</li>
<li>“MOE covers all error” (Only covers sampling error, not bias)</li>
</ul>
</section>
<section id="confidence-interval" class="level3">
<h3 class="anchored" data-anchor-id="confidence-interval">Confidence Interval</h3>
<p>A <strong>confidence interval</strong> provides a range of plausible values for a population parameter. It’s more informative than a point estimate alone.</p>
<p><strong>Construction:</strong></p>
<p><span class="math inline">\text{CI} = \text{Estimate} \pm (\text{Critical Value} \times \text{Standard Error})</span></p>
<p>For 95% CI of a mean: <span class="math inline">\text{CI} = \bar{x} \pm 1.96 \times \frac{\sigma}{\sqrt{n}}</span></p>
<p><strong>Detailed Example:</strong></p>
<p>Estimating average household size from a sample:</p>
<ul>
<li>Sample mean: <span class="math inline">\bar{x} = 2.43</span> people</li>
<li>Sample standard deviation: <span class="math inline">s = 1.2</span> people</li>
<li>Sample size: <span class="math inline">n = 400</span></li>
<li>Standard error: <span class="math inline">SE = \frac{1.2}{\sqrt{400}} = 0.06</span></li>
<li>95% CI: <span class="math inline">2.43 \pm (1.96 \times 0.06) = 2.43 \pm 0.118 = [2.31, 2.55]</span></li>
</ul>
<p>Interpretation: The 95% confidence interval for the mean household size is [2.31, 2.55]. If we repeatedly drew similar random samples and built intervals the same way, about 95% of those intervals would contain the true population mean. This specific interval is one such interval.</p>
<p>With 95% confidence, we estimate the population mean household size to lie between 2.31 and 2.55 (assuming random sampling and no systematic bias).</p>
<p><strong>What Confidence Level Means:</strong></p>
<p>The 95% confidence level means that if we repeated our sampling procedure 100 times:</p>
<ul>
<li>About 95 of the intervals would contain the true parameter</li>
<li>About 5 would miss it</li>
<li>We don’t know if our specific interval is one of the 95 or one of the 5</li>
</ul>
<p><strong>Common Confidence Levels:</strong></p>
<ul>
<li>90%: z = 1.645 (less certain, narrower interval)</li>
<li>95%: z = 1.96 (standard in most fields)</li>
<li>99%: z = 2.576 (more certain, wider interval)</li>
<li>99.9%: z = 3.291 (very certain, much wider interval)</li>
</ul>
<p><strong>Factors Affecting CI Width:</strong></p>
<ol type="1">
<li><strong>Sample size</strong>: Larger n → narrower CI (more precision)</li>
<li><strong>Variability</strong>: Larger σ → wider CI (less precision)</li>
<li><strong>Confidence level</strong>: Higher confidence → wider CI (more certainty requires wider range)</li>
</ol>
<p><strong>Confidence Intervals for Different Parameters:</strong></p>
<p><strong>Proportion</strong>: <span class="math inline">\hat{p} \pm z\sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</span></p>
<p>Example: 230 out of 1,000 adults smoke</p>
<ul>
<li><span class="math inline">\hat{p} = 0.23</span></li>
<li><span class="math inline">SE = \sqrt{\frac{0.23 \times 0.77}{1,000}} = 0.0133</span></li>
<li>95% CI: <span class="math inline">0.23 \pm 1.96 \times 0.0133 = [0.204, 0.256]</span></li>
</ul>
<p><strong>Difference Between Proportions</strong>: <span class="math display">(\hat{p}_1 - \hat{p}_2) \pm z\sqrt{\frac{\hat{p}_1(1-\hat{p}_1)}{n_1} + \frac{\hat{p}_2(1-\hat{p}_2)}{n_2}}</span></p>
<hr>
</section>
</section>
<section id="probability-concepts-for-statistical-analysis" class="level2" data-number="1.24">
<h2 data-number="1.24" class="anchored" data-anchor-id="probability-concepts-for-statistical-analysis"><span class="header-section-number">1.24</span> Probability Concepts for Statistical Analysis</h2>
<p>While this is primarily a statistics course, understanding basic probability is essential for statistical inference.</p>
<section id="basic-probability" class="level3">
<h3 class="anchored" data-anchor-id="basic-probability">Basic Probability</h3>
<p><strong>Probability</strong> quantifies uncertainty on a scale from 0 (impossible) to 1 (certain).</p>
<p><strong>Classical Probability</strong>: <span class="math display">P(\text{event}) = \frac{\text{Number of favorable outcomes}}{\text{Total possible outcomes}}</span></p>
<p>Example: Probability a randomly selected person is female <span class="math inline">\approx 0.5</span></p>
<p><strong>Empirical Probability</strong>: Based on observed frequencies</p>
<p>Example: In a village, 423 of 1,000 residents are female, so <span class="math inline">P(\text{female}) \approx 0.423</span></p>
</section>
<section id="conditional-probability" class="level3">
<h3 class="anchored" data-anchor-id="conditional-probability">Conditional Probability</h3>
<p><strong>Conditional Probability</strong> is the probability of event A given that event B has occurred: <span class="math inline">P(A|B)</span></p>
<p><strong>Demographic Example</strong>: Probability of dying within a year given current age:</p>
<ul>
<li><span class="math inline">P(\text{death within year} | \text{age 30}) \approx 0.001</span></li>
<li><span class="math inline">P(\text{death within year} | \text{age 80}) \approx 0.05</span></li>
</ul>
<p>These conditional probabilities form the basis of life tables.</p>
</section>
<section id="independence" class="level3">
<h3 class="anchored" data-anchor-id="independence">Independence</h3>
<p>Events A and B are <strong>independent</strong> if <span class="math inline">P(A|B) = P(A)</span>.</p>
<p><strong>Testing Independence in Demographic Data:</strong></p>
<p>Are education and fertility independent?</p>
<ul>
<li><span class="math inline">P(\text{3+ children}) = 0.3</span> overall</li>
<li><span class="math inline">P(\text{3+ children} | \text{college degree}) = 0.15</span></li>
<li>Different probabilities indicate dependence</li>
</ul>
</section>
<section id="law-of-large-numbers" class="level3">
<h3 class="anchored" data-anchor-id="law-of-large-numbers">Law of Large Numbers</h3>
<p>As sample size increases, sample statistics converge to population parameters.</p>
<p><strong>Demonstration</strong>: Estimating sex ratio at birth:</p>
<ul>
<li>10 births: 7 males (70% - very unstable)</li>
<li>100 births: 53 males (53% - getting closer to ~51.2%)</li>
<li>1,000 births: 515 males (51.5% - quite close)</li>
<li>10,000 births: 5,118 males (51.18% - very close)</li>
</ul>
</section>
<section id="visualizing-the-law-of-large-numbers-coin-flips" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-law-of-large-numbers-coin-flips">Visualizing the Law of Large Numbers: Coin Flips</h3>
<p>Let’s see this in action with coin flips. A fair coin has a 50% chance of landing heads, but individual flips are unpredictable.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate coin flips and show convergence</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>n_flips <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>flips <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_flips, <span class="dv">1</span>, <span class="fl">0.5</span>)  <span class="co"># 1 = heads, 0 = tails</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate cumulative proportion of heads</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>cumulative_prop <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(flips) <span class="sc">/</span> <span class="fu">seq_along</span>(flips)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data frame for plotting</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>lln_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">flip_number =</span> <span class="dv">1</span><span class="sc">:</span>n_flips,</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">cumulative_proportion =</span> cumulative_prop</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the convergence</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(lln_data, <span class="fu">aes</span>(<span class="at">x =</span> flip_number, <span class="at">y =</span> cumulative_proportion)) <span class="sc">+</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="fl">0.45</span>, <span class="fl">0.55</span>), <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Law of Large Numbers: Coin Flip Proportions Converge to 0.5"</span>,</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Number of coin flips"</span>,</span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Cumulative proportion of heads"</span>,</span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">"Red dashed line = true probability (0.5)</span><span class="sc">\n</span><span class="st">Dotted lines = ±5% range"</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.7</span>), <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="fl">0.3</span>, <span class="fl">0.7</span>, <span class="fl">0.1</span>)) <span class="sc">+</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/lln-demo-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p><strong>What this shows:</strong></p>
<ul>
<li>Early flips show wild variation (first 10 flips might be 70% or 30% heads)</li>
<li>As we add more flips, the proportion stabilizes around 50%</li>
<li>The “noise” of individual outcomes averages out over time</li>
</ul>
</section>
<section id="the-mathematical-statement" class="level3">
<h3 class="anchored" data-anchor-id="the-mathematical-statement">The Mathematical Statement</h3>
<p>Let <span class="math inline">A</span> denote an event of interest (e.g., “heads on a coin flip”, “vote for party X”, “sum of dice equals 7”). If <span class="math inline">P(A) = p</span> and we observe <span class="math inline">n</span> <strong>independent trials with the same distribution</strong> (i.i.d.), then the <strong>sample frequency of</strong> <span class="math inline">A</span>:</p>
<p><span class="math display">\hat{p}_n = \frac{\text{number of occurrences of } A}{n}</span></p>
<p><strong>converges to</strong> <span class="math inline">p</span> as <span class="math inline">n</span> increases.</p>
</section>
<section id="examples-in-different-contexts" class="level3">
<h3 class="anchored" data-anchor-id="examples-in-different-contexts">Examples in Different Contexts</h3>
<p><strong>Dice example</strong>: The event “sum = 7” with two dice has probability <span class="math inline">6/36 ≈ 16.7\%</span>, while “sum = 4” has <span class="math inline">3/36 ≈ 8.3\%</span>. Over many throws, a sum of 7 appears about twice as often as a sum of 4.</p>
<p><strong>Election polling</strong>: If population support for a party equals <span class="math inline">p</span>, then under random sampling of size <span class="math inline">n</span>, the observed frequency <span class="math inline">\hat{p}_n</span> will approach <span class="math inline">p</span> as <span class="math inline">n</span> grows (assuming random sampling and independence).</p>
<p><strong>Quality control</strong>: If 2% of products are defective, then in large batches, approximately 2% will be found defective (assuming independent production).</p>
</section>
<section id="why-this-matters-for-statistics" class="level3">
<h3 class="anchored">Why This Matters for Statistics</h3>
<p><strong>Bottom line</strong>: Randomness underpins statistical inference by turning uncertainty in individual outcomes into <strong>predictable distributions</strong> for estimates. The Law of Large Numbers guarantees that the “noise” of individual outcomes averages out, allowing us to:</p>
<ul>
<li>Predict long-run frequencies</li>
<li>Quantify uncertainty (margins of error)<br>
</li>
<li>Draw reliable inferences from samples</li>
<li>Make probabilistic statements about populations</li>
</ul>
<p>This principle works in surveys, experiments, and even quantum phenomena (in the frequentist interpretation).</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is randomness? (*)
</div>
</div>
<div class="callout-body-container callout-body">
<p>In statistics, <strong>randomness</strong> is an orderly way to describe uncertainty: individual outcomes are unpredictable, yet in <strong>long sequences of repetitions</strong> stable regularities emerge (e.g., frequencies, means).</p>
<p><strong>Two perspectives</strong></p>
<ol type="1">
<li><strong>Single realisation</strong> — we cannot determine how a specific voter will vote at a given moment.<br>
</li>
<li><strong>Aggregate</strong> — we can describe the share of voters supporting a party and quantify the associated estimation uncertainty.</li>
</ol>
<p><strong>Epistemic vs.&nbsp;ontological randomness</strong></p>
<ul>
<li><p><strong>Epistemic</strong> (due to incomplete knowledge): we treat an outcome as random because not all determinants are observed or conditions are not controlled.</p>
<p><strong>Examples:</strong></p>
<ul>
<li>the decision of an individual respondent in a poll (we do not know the full set of motivations),</li>
<li>measurement error in a survey (limited precision, item nonresponse),</li>
<li>a coin toss modeled as random because minute, unobserved differences in initial conditions determine the outcome.</li>
</ul></li>
<li><p><strong>Ontological</strong> (intrinsic indeterminacy): even complete knowledge does not remove outcome uncertainty.</p>
<p><strong>Examples:</strong></p>
<ul>
<li>the time to radioactive decay of an atom.</li>
</ul></li>
</ul>
<section id="why-randomness-matters" class="level3">
<h3 class="anchored" data-anchor-id="why-randomness-matters">Why Randomness Matters</h3>
<ul>
<li><p><strong>Random sampling</strong></p>
<ul>
<li>Reduces systematic selection bias so the sample resembles the target population (in expectation).</li>
<li>Makes uncertainty <strong>quantifiable</strong> (e.g., margins of error; later we’ll name these “confidence intervals”), assuming genuinely random selection and good coverage.</li>
</ul></li>
<li><p><strong>Random assignment (experiments)</strong></p>
<ul>
<li>Breaks the link between treatment and other factors, making groups comparable <strong>on average</strong> (both observed and unobserved).</li>
<li>Supports credible <strong>cause-and-effect</strong> claims (identifies average treatment effects under standard conditions).</li>
</ul></li>
</ul>
</section>
<section id="the-power-of-random-sampling" class="level3">
<h3 class="anchored" data-anchor-id="the-power-of-random-sampling">The Power of Random Sampling</h3>
<p>Suppose we take a <strong>random sample</strong> of <span class="math inline">n=1000</span> voters and observe <span class="math inline">\hat p = 0.55</span> (i.e., 55% support). Then:</p>
<ul>
<li><p>Our best single-number estimate of the population share is <span class="math inline">\hat p = 0.55</span>.</p></li>
<li><p>A typical “<span class="math inline">95\%</span> range of plausible values” around <span class="math inline">\hat p</span> can be approximated by <span class="math display">
\hat p \;\pm\; 2\sqrt{\frac{\hat p(1-\hat p)}{n}}
\;=\;
0.55 \;\pm\; 2\sqrt{\frac{0.55\cdot 0.45}{1000}}
\approx
0.55 \pm 0.031,
</span> i.e., roughly <span class="math inline">52\%\text{–}58\%</span> (about <span class="math inline">\pm 3.1</span> percentage points).</p></li>
<li><p>The width of this range shrinks predictably with sample size: <span class="math display">
\text{width} \;\propto\; \frac{1}{\sqrt{n}}.
</span> For example, increasing <span class="math inline">n</span> from <span class="math inline">1000</span> to <span class="math inline">4000</span> cuts the range by about half.</p></li>
</ul>
</section>
<section id="understanding-different-types-of-unpredictability" class="level2" data-number="1.25">
<h2 data-number="1.25" class="anchored" data-anchor-id="understanding-different-types-of-unpredictability"><span class="header-section-number">1.25</span> Understanding Different Types of Unpredictability</h2>
<p>Not all uncertainty is the same. Understanding different sources of unpredictability helps us choose appropriate statistical methods and interpret results correctly.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 23%">
<col style="width: 29%">
<col style="width: 23%">
<col style="width: 23%">
</colgroup>
<thead>
<tr class="header">
<th>Concept</th>
<th>What is it?</th>
<th>Source of unpredictability</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Randomness</strong></td>
<td>Individual outcomes are uncertain, but the <strong>probability distribution</strong> is known or modeled.</td>
<td>Fluctuations across realizations; lack of information about a specific outcome.</td>
<td>Dice roll, coin toss, polling sample</td>
</tr>
<tr class="even">
<td><strong>Chaos</strong></td>
<td><strong>Deterministic</strong> dynamics <strong>highly sensitive</strong> to initial conditions (butterfly effect).</td>
<td>Tiny initial differences grow rapidly → large trajectory divergences.</td>
<td>Weather forecasting, double pendulum, population dynamics</td>
</tr>
<tr class="odd">
<td><strong>Entropy</strong></td>
<td>A <strong>measure</strong> of uncertainty/dispersion (information-theoretic or thermodynamic).</td>
<td>Larger when outcomes are more evenly distributed (less predictive information).</td>
<td>Shannon entropy in data compression</td>
</tr>
<tr class="even">
<td><strong>“Haphazardness”</strong> (colloquial)</td>
<td>A felt lack of order without an explicit model; a mixture of mechanisms.</td>
<td>No structured description or stable rules; overlapping processes.</td>
<td>Traffic patterns, social media trends</td>
</tr>
<tr class="odd">
<td><strong>Quantum randomness</strong></td>
<td>A single outcome is <strong>not determined</strong>; only the distribution is specified (Born rule).</td>
<td><strong>Fundamental (ontological)</strong> indeterminacy of individual measurements.</td>
<td>Electron spin measurement, photon polarization</td>
</tr>
</tbody>
</table>
<section id="key-distinctions-for-statistical-practice" class="level3">
<h3 class="anchored" data-anchor-id="key-distinctions-for-statistical-practice">Key Distinctions for Statistical Practice</h3>
<p><strong>Deterministic chaos ≠ statistical randomness</strong>: A chaotic system is fully deterministic yet practically unpredictable due to extreme sensitivity to initial conditions. Statistical randomness, by contrast, models uncertainty via probability distributions where individual outcomes are genuinely uncertain.</p>
<p><strong>Why this matters</strong>: In statistics, we typically model phenomena as random processes, assuming we can specify probability distributions even when individual outcomes are unpredictable. This assumption underlies most statistical inference.</p>
</section>
<section id="quantum-mechanics-and-fundamental-randomness" class="level3">
<h3 class="anchored" data-anchor-id="quantum-mechanics-and-fundamental-randomness">Quantum Mechanics and Fundamental Randomness</h3>
<p>In the Copenhagen interpretation, randomness is <strong>fundamental (ontological)</strong>: a <strong>single</strong> outcome cannot be predicted, but the <strong>probability distribution</strong> is given by the Born rule.</p>
<p>This represents true randomness at the most basic level of nature, not just our ignorance of determining factors.</p>
</section>
</section>
</div>
</div>
</section>
<section id="central-limit-theorem" class="level3">
<h3 class="anchored" data-anchor-id="central-limit-theorem">Central Limit Theorem</h3>
<p>The distribution of sample means approaches normal distribution as sample size increases, regardless of the population distribution.</p>
<p><strong>Why This Matters</strong>: Even if income is highly skewed, the average income from samples of 100+ people follows approximately normal distribution, allowing us to use normal-based confidence intervals.</p>
<hr>
</section>
</section>
<section id="statistical-significance-a-quick-start-guide" class="level2" data-number="1.26">
<h2 data-number="1.26" class="anchored" data-anchor-id="statistical-significance-a-quick-start-guide"><span class="header-section-number">1.26</span> Statistical Significance: A Quick Start Guide</h2>
<p>Imagine you flip a coin 10 times and get 8 heads. Is the coin biased, or did you just get lucky? This is the core question statistical significance helps us answer.</p>
<p><strong>Statistical significance</strong> tells us whether patterns in our data likely reflect something real or could have happened by pure chance.</p>
</section>
<section id="the-framework-think-like-a-judge-not-a-prosecutor" class="level2" data-number="1.27">
<h2 data-number="1.27" class="anchored" data-anchor-id="the-framework-think-like-a-judge-not-a-prosecutor"><span class="header-section-number">1.27</span> The Framework: Think Like a Judge (Not a Prosecutor!)</h2>
<section id="the-courtroom-analogy" class="level3">
<h3 class="anchored" data-anchor-id="the-courtroom-analogy">The Courtroom Analogy</h3>
<p>Statistical hypothesis testing works like a criminal trial:</p>
<ul>
<li><strong>Null Hypothesis (</strong><span class="math inline">H_0</span>): The defendant is innocent (no effect exists)</li>
<li><strong>Alternative Hypothesis (</strong><span class="math inline">H_1</span>): The defendant is guilty (an effect exists)</li>
<li><strong>The Evidence</strong>: Your data and test results</li>
<li><strong>The Verdict</strong>: “Guilty” (reject <span class="math inline">H_0</span>) or “Not Guilty” (fail to reject <span class="math inline">H_0</span>)</li>
</ul>
<p><strong>Crucial distinction</strong>: “Not guilty” ≠ “Innocent”</p>
<ul>
<li>A “not guilty” verdict means insufficient evidence to convict</li>
<li>Similarly, “not statistically significant” means insufficient evidence for an effect, NOT proof of no effect</li>
</ul>
</section>
<section id="start-with-skepticism-presumption-of-innocence" class="level3">
<h3 class="anchored" data-anchor-id="start-with-skepticism-presumption-of-innocence">Start with Skepticism (Presumption of Innocence)</h3>
<p>In statistics, we always start by assuming nothing special is happening:</p>
<ul>
<li><strong>Null Hypothesis (</strong><span class="math inline">H_0</span>): “There’s no effect”
<ul>
<li>The coin is fair</li>
<li>The new drug doesn’t work</li>
<li>Study time doesn’t affect grades</li>
</ul></li>
<li><strong>Alternative Hypothesis (</strong><span class="math inline">H_1</span>): “There IS an effect”
<ul>
<li>The coin is biased</li>
<li>The drug works</li>
<li>More study time improves grades</li>
</ul></li>
</ul>
<p><strong>Key principle</strong>: We maintain the null hypothesis (innocence) unless our data provides strong evidence against it—“beyond a reasonable doubt” in legal terms, or “p &lt; 0.05” in statistical terms.</p>
</section>
</section>
<section id="the-p-value-your-surprise-meter" class="level2" data-number="1.28">
<h2 data-number="1.28" class="anchored" data-anchor-id="the-p-value-your-surprise-meter"><span class="header-section-number">1.28</span> The p-value: Your “Surprise Meter”</h2>
<p>The <strong>p-value</strong> answers one specific question:</p>
<blockquote class="blockquote">
<p>“If nothing special were happening (null hypothesis is true), how surprising would our results be?”</p>
</blockquote>
<section id="three-ways-to-think-about-p-values" class="level3">
<h3 class="anchored" data-anchor-id="three-ways-to-think-about-p-values">Three Ways to Think About p-values</h3>
<section id="the-surprise-scale" class="level4">
<h4 class="anchored" data-anchor-id="the-surprise-scale">1. The Surprise Scale</h4>
<ul>
<li><strong>p &lt; 0.01</strong>: Very surprising! (Strong evidence against <span class="math inline">H_0</span>)</li>
<li><strong>p &lt; 0.05</strong>: Pretty surprising (Moderate evidence against <span class="math inline">H_0</span>)</li>
<li><strong>p &gt; 0.05</strong>: Not that surprising (Insufficient evidence against <span class="math inline">H_0</span>)</li>
</ul>
</section>
<section id="concrete-example-the-suspicious-coin" class="level4">
<h4 class="anchored" data-anchor-id="concrete-example-the-suspicious-coin">2. Concrete Example: The Suspicious Coin</h4>
<p>You flip a coin 10 times and get 8 heads. What’s the p-value?</p>
<p><strong>The calculation</strong>: If the coin were fair, the probability of getting 8 or more heads is: <span class="math display">p = P(≥8 \text{ heads in 10 flips}) \approx 0.055 \approx 5.5\%</span></p>
<p><span class="math display">P(X \geq 8) = \sum_{k=8}^{10} \binom{10}{k} 0,5^{10} = \frac{56}{1024} \approx 0,0547</span></p>
<p><strong>Interpretation</strong>: There’s a 5.5% chance of getting results this extreme with a fair coin. That’s somewhat unusual but not shocking.</p>
</section>
<section id="the-formal-definition" class="level4">
<h4 class="anchored" data-anchor-id="the-formal-definition">3. The Formal Definition</h4>
<p>A p-value is the probability of getting results at least as extreme as what you observed, <strong>assuming the null hypothesis is true</strong>.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Common Mistake</strong>: The p-value is NOT the probability that the null hypothesis is true! It assumes the null is true and tells you how unusual your data would be in that world.</p>
</div>
</div>
</section>
</section>
</section>
<section id="the-prosecutor-fallacy-a-critical-warning" class="level2" data-number="1.29">
<h2 data-number="1.29" class="anchored" data-anchor-id="the-prosecutor-fallacy-a-critical-warning"><span class="header-section-number">1.29</span> The Prosecutor Fallacy: A Critical Warning</h2>
<section id="the-fallacy-explained" class="level3">
<h3 class="anchored" data-anchor-id="the-fallacy-explained">The Fallacy Explained</h3>
<p>Imagine this courtroom scenario:</p>
<p><strong>Prosecutor</strong>: “If the defendant were innocent, there’s only a 1% chance we’d find his DNA at the crime scene. We found his DNA. Therefore, there’s a 99% chance he’s guilty!”</p>
<p><strong>This is WRONG!</strong> The prosecutor confused: - P(Evidence | Innocent) = 0.01 ← What we know - P(Innocent | Evidence) = ? ← What we want to know (but can’t get from the p-value alone!)</p>
</section>
<section id="the-statistical-version" class="level3">
<h3 class="anchored" data-anchor-id="the-statistical-version">The Statistical Version</h3>
<p>When we get p = 0.01, it’s tempting to think:</p>
<p>❌ <strong>WRONG</strong>: “There’s only a 1% chance the null hypothesis is true” ❌ <strong>WRONG</strong>: “There’s a 99% chance our treatment works”</p>
<p>✅ <strong>CORRECT</strong>: “If the null hypothesis were true, there’s only a 1% chance we’d see data this extreme”</p>
</section>
<section id="why-this-matters-a-concrete-example" class="level3">
<h3 class="anchored" data-anchor-id="why-this-matters-a-concrete-example">Why This Matters: A Concrete Example</h3>
<p>Suppose you’re testing 1000 potential cancer drugs, and in reality, only 10 actually work.</p>
<ul>
<li>You test all 1000 with α = 0.05</li>
<li>Of the 990 that don’t work: ~50 will show “significant” results (false positives)</li>
<li>Of the 10 that do work: ~8 will show “significant” results (true positives)</li>
<li><strong>Total “significant” results</strong>: ~58</li>
</ul>
<p>If your drug shows a significant result, the probability it actually works is only 8/58 ≈ 14%, not 95%!</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Remember</strong>: A p-value tells you P(Data | Null is true), not P(Null is true | Data). These are as different as P(Wet ground | Rain) and P(Rain | Wet ground)—the ground could be wet from a sprinkler!</p>
</div>
</div>
<hr>
</section>
</section>
<section id="introduction-to-regression-analysis-modeling-relationships-between-variables" class="level2" data-number="1.30">
<h2 data-number="1.30" class="anchored" data-anchor-id="introduction-to-regression-analysis-modeling-relationships-between-variables"><span class="header-section-number">1.30</span> Introduction to Regression Analysis: Modeling Relationships Between Variables</h2>
<p>One of the most powerful tools in statistical analysis is <strong>regression analysis</strong>—a method for understanding and quantifying relationships between variables. While the mathematics can become complex, the core idea is beautifully simple: How does one thing relate to another, and can we use that relationship to make predictions?</p>
<blockquote class="blockquote">
<p><strong>The One-Sentence Summary:</strong> Regression helps us understand how things relate to each other in a messy, complicated world where everything affects everything else.</p>
</blockquote>
<section id="what-is-regression-analysis" class="level3">
<h3 class="anchored">What is Regression Analysis?</h3>
<p>Imagine you’re curious about the relationship between education and income. You notice that people with more education tend to earn more money, but you want to understand this relationship more precisely:</p>
<ul>
<li>How much does each additional year of education increase income, on average?</li>
<li>How strong is this relationship?</li>
<li>Are there other factors we should consider?</li>
<li>Can we predict someone’s likely income if we know their education level?</li>
</ul>
<p>Regression analysis provides systematic answers to these questions. It’s like finding the “best-fitting story” that describes how variables relate to each other.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p><strong>The One-Sentence Summary:</strong> Regression helps us understand how things relate to each other in a messy, complicated world where everything affects everything else.</p>
</blockquote>
<p>Consider a typical pre-election news headline: “Candidate Smith’s approval rating reaches 68%.” Your immediate inference likely suggests favorable electoral prospects for Smith—not guaranteed victory, but a strong position.</p>
<p>This intuitive assessment exemplifies the essence of regression analysis. You utilized one piece of information (approval rating) to predict another outcome (electoral success), automatically recognizing that higher approval ratings correlate with better electoral performance, despite an imperfect relationship.</p>
<p>Regression analysis systematizes this intuitive process, enabling researchers to:</p>
<ul>
<li>Generate predictions based on available information</li>
<li>Identify which factors matter most</li>
<li>Quantify uncertainty in predictions</li>
<li>Test theoretical propositions with empirical data</li>
</ul>
<section id="variables-and-variation" class="level2" data-number="1.31">
<h2 data-number="1.31" class="anchored" data-anchor-id="variables-and-variation"><span class="header-section-number">1.31</span> Variables and Variation</h2>
<section id="defining-variables" class="level3">
<h3 class="anchored" data-anchor-id="defining-variables">Defining Variables</h3>
<p>A <strong>variable</strong> is any characteristic that can take different values across units of observation. In political science:</p>
<ul>
<li><strong>Units of analysis</strong>: Countries, individuals, elections, policies, years</li>
<li><strong>Variables</strong>: GDP, voting preference, democracy score, conflict occurrence</li>
</ul>
<blockquote class="blockquote">
<p><strong>💡 In Plain English:</strong> A variable is anything that changes. If everyone voted the same way, “voting preference” wouldn’t be a variable—it would be a constant. We study variables because we want to understand why things differ.</p>
</blockquote>
</section>
</section>
<section id="what-is-regression" class="level2" data-number="1.32">
<h2 data-number="1.32" class="anchored" data-anchor-id="what-is-regression"><span class="header-section-number">1.32</span> What is Regression?</h2>
<p>Regression analysis constitutes the foundational statistical tool in political science. It models relationships between variables and operationalizes our fundamental statistical model.</p>
<section id="the-fundamental-model" class="level3">
<h3 class="anchored" data-anchor-id="the-fundamental-model">The Fundamental Model</h3>
<p>A model represents an object, person, or system in an informative way. Models divide into physical representations (such as architectural models) and abstract representations (such as mathematical equations describing atmospheric dynamics).</p>
<p>The core of statistical thinking can be expressed as:</p>
<p><span class="math display">Y = f(X) + \text{error}</span></p>
<p>This equation states that our outcome (<span class="math inline">Y</span>) equals some function of our predictors (<span class="math inline">X</span>), plus unpredictable variation.</p>
<p><strong>Components</strong>:</p>
<ul>
<li><span class="math inline">Y</span> = Dependent variable (the phenomenon we seek to explain)</li>
<li><span class="math inline">X</span> = Independent variable(s) (explanatory factors)</li>
<li><span class="math inline">f()</span> = The functional relationship (often assumed linear)</li>
<li>error (<span class="math inline">\epsilon</span>) = Unexplained variation</li>
</ul>
<blockquote class="blockquote">
<p><strong>💡 What This Really Means:</strong> Think of it like a recipe. Your grade in a class (<span class="math inline">Y</span>) depends on study hours (<span class="math inline">X</span>), but not perfectly. Two students studying 10 hours might get different grades because of test anxiety, prior knowledge, or just luck (the error term). Regression finds the average relationship.</p>
</blockquote>
<p>This model provides the foundation for all statistical analysis—from simple correlations to complex machine learning algorithms.</p>
<p>Regression helps answer fundamental questions such as:</p>
<ul>
<li>How much does education increase political participation?</li>
<li>What factors predict electoral success?</li>
<li>Do democratic institutions promote economic growth?</li>
</ul>
</section>
</section>
</div>
</div>
</section>
<section id="the-basic-idea-drawing-the-best-line-through-points" class="level3">
<h3 class="anchored" data-anchor-id="the-basic-idea-drawing-the-best-line-through-points">The Basic Idea: Drawing the Best Line Through Points</h3>
<section id="simple-linear-regression" class="level4">
<h4 class="anchored" data-anchor-id="simple-linear-regression">Simple Linear Regression</h4>
<p>Let’s start with the simplest case: the relationship between two variables. Suppose we plot education (years of schooling) on the x-axis and annual income on the y-axis for 100 people. We’d see a cloud of points, and regression finds the straight line that best represents the pattern in these points.</p>
<p><strong>What makes a line “best”?</strong> The regression line minimizes the total squared vertical distances from all points to the line. Think of it as finding the line that makes the smallest total prediction error.</p>
<p>The equation of this line is: <span class="math display">Y = a + bX + \text{error}</span></p>
<p>Or in our example: <span class="math display">\text{Income} = a + b \times \text{Education} + \text{error}</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">a</span> (intercept) = predicted income with zero education</li>
<li><span class="math inline">b</span> (slope) = change in income per additional year of education</li>
<li>error = difference between actual and predicted income</li>
</ul>
<p><strong>Interpreting the Results:</strong></p>
<p>If our analysis finds: <span class="math display">\text{Income} = 15,000 + 4,000 \times \text{Education}</span></p>
<p>This tells us:</p>
<ul>
<li>Someone with 0 years of education is predicted to earn $15,000</li>
<li>Each additional year of education is associated with $4,000 more income</li>
<li>Someone with 12 years of education is predicted to earn: $15,000 + (4,000 ) = $63,000</li>
<li>Someone with 16 years (bachelor’s degree) is predicted to earn: $15,000 + (4,000 ) = $79,000</li>
</ul>
</section>
</section>
<section id="understanding-relationships-vs.-proving-causation" class="level3">
<h3 class="anchored" data-anchor-id="understanding-relationships-vs.-proving-causation">Understanding Relationships vs.&nbsp;Proving Causation</h3>
<p>A crucial distinction: regression shows <strong>association</strong>, not necessarily <strong>causation</strong>. Our education-income regression shows they’re related, but doesn’t prove education causes higher income. Other explanations are possible:</p>
<ul>
<li><strong>Reverse causation</strong>: Maybe wealthier families can afford more education for their children</li>
<li><strong>Common cause</strong>: Perhaps intelligence or motivation affects both education and income</li>
<li><strong>Coincidence</strong>: In small samples, patterns can appear by chance</li>
</ul>
<p><strong>Example of Spurious Correlation</strong>: A regression might show that ice cream sales strongly predict drowning deaths. Does ice cream cause drowning? No! Both increase in summer (the common cause).</p>
</section>
<section id="multiple-regression-controlling-for-other-factors" class="level3">
<h3 class="anchored" data-anchor-id="multiple-regression-controlling-for-other-factors">Multiple Regression: Controlling for Other Factors</h3>
<p>Real life is complicated—many factors influence outcomes simultaneously. <strong>Multiple regression</strong> lets us examine one relationship while “controlling for” or “holding constant” other variables.</p>
<section id="the-power-of-statistical-control" class="level4">
<h4 class="anchored" data-anchor-id="the-power-of-statistical-control">The Power of Statistical Control</h4>
<p>Returning to education and income, we might wonder: Is the education effect just because educated people tend to be younger, from wealthier families, or live in cities? Multiple regression can separate these effects:</p>
<p><span class="math display">\text{Income} = a + b_1 \times \text{Education} + b_2 \times \text{Age} + b_3 \times \text{Urban} + b_4 \times \text{Parent Income} + \text{error}</span></p>
<p>Now <span class="math inline">b_1</span> represents the education effect <em>after accounting for</em> age, location, and family background. If <span class="math inline">b_1 = 3,000</span>, it means: “Comparing people of the same age, location, and family background, each additional year of education is associated with $3,000 more income.”</p>
<p><strong>Real Demographic Example</strong>: Fertility and Women’s Education</p>
<p>Researchers studying fertility might find: <span class="math display">\text{Children} = 4.5 - 0.3 \times \text{Education}</span></p>
<p>This suggests each year of women’s education is associated with 0.3 fewer children. But is education the cause, or are educated women different in other ways? Adding controls:</p>
<p><span class="math display">\text{Children} = a - 0.15 \times \text{Education} - 0.2 \times \text{Urban} + 0.1 \times \text{Husband Education} - 0.4 \times \text{Contraceptive Access}</span></p>
<p>Now we see education’s association is weaker (-0.15 instead of -0.3) after accounting for urban residence and contraceptive access. This suggests part of education’s apparent effect operates through these other pathways.</p>
</section>
</section>
<section id="types-of-variables-in-regression" class="level3">
<h3 class="anchored" data-anchor-id="types-of-variables-in-regression">Types of Variables in Regression</h3>
<section id="outcome-dependent-variable" class="level4">
<h4 class="anchored" data-anchor-id="outcome-dependent-variable">Outcome (Dependent) Variable</h4>
<p>This is what we’re trying to understand or predict:</p>
<ul>
<li>Income in our first example</li>
<li>Number of children in our fertility example</li>
<li>Life expectancy in health studies</li>
<li>Migration probability in population studies</li>
</ul>
</section>
<section id="predictor-independent-variables" class="level4">
<h4 class="anchored" data-anchor-id="predictor-independent-variables">Predictor (Independent) Variables</h4>
<p>These are factors we think might influence the outcome:</p>
<ul>
<li><strong>Continuous</strong>: Age, years of education, income, distance</li>
<li><strong>Categorical</strong>: Gender, race, marital status, region</li>
<li><strong>Binary (Dummy)</strong>: Urban/rural, employed/unemployed, married/unmarried</li>
</ul>
<p><strong>Handling Categorical Variables</strong>: We can’t directly put “religion” into an equation. Instead, we create binary variables:</p>
<ul>
<li>Christian = 1 if Christian, 0 otherwise</li>
<li>Muslim = 1 if Muslim, 0 otherwise</li>
<li>Hindu = 1 if Hindu, 0 otherwise</li>
<li>(One category becomes the reference group)</li>
</ul>
</section>
</section>
<section id="different-types-of-regression-for-different-outcomes" class="level3">
<h3 class="anchored" data-anchor-id="different-types-of-regression-for-different-outcomes">Different Types of Regression for Different Outcomes</h3>
<p>The basic regression idea adapts to many situations:</p>
<section id="linear-regression" class="level4">
<h4 class="anchored" data-anchor-id="linear-regression">Linear Regression</h4>
<p>For continuous outcomes (income, height, blood pressure): <span class="math display">Y = a + b_1X_1 + b_2X_2 + … + \text{error}</span></p>
</section>
<section id="logistic-regression" class="level4">
<h4 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h4>
<p>For binary outcomes (died/survived, migrated/stayed, married/unmarried):</p>
<p>Instead of predicting the outcome directly, we predict the probability: <span class="math display">\log\left(\frac{p}{1-p}\right) = a + b_1X_1 + b_2X_2 + …</span></p>
<p>Where <span class="math inline">p</span> is the probability of the event occurring.</p>
<p><strong>Example</strong>: Predicting migration probability based on age, education, and marital status. The model might find young, educated, unmarried people have 40% probability of migrating, while older, less educated, married people have only 5% probability.</p>
</section>
<section id="poisson-regression" class="level4">
<h4 class="anchored" data-anchor-id="poisson-regression">Poisson Regression</h4>
<p>For count outcomes (number of children, number of doctor visits): <span class="math display">\log(\text{expected count}) = a + b_1X_1 + b_2X_2 + …</span></p>
<p><strong>Example</strong>: Modeling number of children based on women’s characteristics. Useful because it ensures predictions are never negative (can’t have -0.5 children!).</p>
</section>
<section id="survival-cox-modelhazard-regression" class="level4">
<h4 class="anchored" data-anchor-id="survival-cox-modelhazard-regression">Survival (Cox model)/Hazard Regression</h4>
<p><strong>What it’s for:</strong> Predicting <em>when</em> something will happen, not just <em>if</em> it will happen.</p>
<p><strong>The challenge:</strong> Imagine you’re studying how long marriages last. You follow 1,000 couples for 10 years, but by the end of your study:</p>
<ul>
<li>400 couples divorced (you know exactly when)</li>
<li>600 couples are still married (you don’t know if/when they’ll divorce)</li>
</ul>
<p>Regular regression can’t handle this “incomplete story” problem—those 600 ongoing marriages contain valuable information, but we don’t know their endpoints yet.</p>
<p><strong>How Cox models help:</strong> Instead of trying to predict the exact timing, they focus on <em>relative risk</em>—who’s more likely to experience the event sooner. Think of it like asking “At any given moment, who’s at higher risk?” rather than “Exactly when will this happen?”</p>
<p><strong>Real-world applications:</strong></p>
<ul>
<li>Medical research: Who responds to treatment faster?</li>
<li>Business: Which customers cancel subscriptions sooner?</li>
<li>Social science: What factors make life events happen earlier/later?</li>
</ul>
</section>
</section>
<section id="interpreting-regression-results" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-regression-results">Interpreting Regression Results</h3>
<section id="coefficients" class="level4">
<h4 class="anchored" data-anchor-id="coefficients">Coefficients</h4>
<p>The coefficient tells us the expected change in outcome for a one-unit increase in the predictor, holding other variables constant.</p>
<p><strong>Examples of Interpretation:</strong></p>
<p>Linear regression for income:</p>
<ul>
<li>“Each additional year of education is associated with $3,500 higher annual income, controlling for age and experience”</li>
</ul>
<p>Logistic regression for infant mortality:</p>
<ul>
<li>“Each additional prenatal visit is associated with 15% lower odds of infant death, controlling for mother’s age and education”</li>
</ul>
<p>Multiple regression for life expectancy:</p>
<ul>
<li>“Each $1,000 increase in per-capita GDP is associated with 0.4 years longer life expectancy, after controlling for education and healthcare access”</li>
</ul>
</section>
<section id="statistical-significance" class="level4">
<h4 class="anchored" data-anchor-id="statistical-significance">Statistical Significance</h4>
<p>The regression also tests whether relationships could be due to chance:</p>
<ul>
<li><strong>p-value &lt; 0.05</strong>: Relationship unlikely due to chance (statistically significant)</li>
<li><strong>p-value &gt; 0.05</strong>: Relationship could plausibly be random variation</li>
</ul>
<p>But remember: Statistical significance ≠ practical importance. With large samples, tiny effects become “significant.”</p>
</section>
<section id="confidence-intervals-for-coefficients" class="level4">
<h4 class="anchored" data-anchor-id="confidence-intervals-for-coefficients">Confidence Intervals for Coefficients</h4>
<p>Just as we have confidence intervals for means, we have them for regression coefficients:</p>
<p>“The effect of education on income is $3,500 per year, 95% CI: [$2,800, $4,200]”</p>
<p>This means we’re 95% confident the true effect is between $2,800 and $4,200.</p>
</section>
<section id="r-squared-how-well-does-the-model-fit" class="level4">
<h4 class="anchored" data-anchor-id="r-squared-how-well-does-the-model-fit">R-squared: How Well Does the Model Fit?</h4>
<p><span class="math inline">R^2</span> (R-squared) measures the proportion of variation in the outcome explained by the predictors:</p>
<ul>
<li><span class="math inline">R^2 = 0</span>: Predictors explain nothing</li>
<li><span class="math inline">R^2 = 1</span>: Predictors explain everything</li>
<li><span class="math inline">R^2 = 0.3</span>: Predictors explain 30% of variation</li>
</ul>
<p><strong>Example</strong>: A model of income with only education might have <span class="math inline">R^2 = 0.15</span> (education explains 15% of income variation). Adding age, experience, and location might increase <span class="math inline">R^2</span> to 0.35 (together they explain 35%).</p>
</section>
</section>
<section id="assumptions-and-limitations" class="level3">
<h3 class="anchored" data-anchor-id="assumptions-and-limitations">Assumptions and Limitations</h3>
<p>Regression makes assumptions that may not hold:</p>
<section id="linearity" class="level4">
<h4 class="anchored" data-anchor-id="linearity">Linearity</h4>
<p>Assumes straight-line relationships. But what if education’s effect on income is stronger at higher levels? We can add polynomial terms: <span class="math display">\text{Income} = a + b_1 \times \text{Education} + b_2 \times \text{Education}^2</span></p>
</section>
<section id="independence-1" class="level4">
<h4 class="anchored" data-anchor-id="independence-1">Independence</h4>
<p>Assumes observations are independent. But family members might be similar, repeated measures on the same person are related, and neighbors might influence each other. Special methods handle these dependencies.</p>
</section>
<section id="homoscedasticity" class="level4">
<h4 class="anchored" data-anchor-id="homoscedasticity">Homoscedasticity</h4>
<p>Assumes error variance is constant. But prediction errors might be larger for high-income people than low-income people. Diagnostic plots help detect this.</p>
</section>
<section id="normality" class="level4">
<h4 class="anchored" data-anchor-id="normality">Normality</h4>
<p>Assumes errors follow normal distribution. Important for small samples, less critical for large samples.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Common Statistical Pitfalls
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><strong>Ecological fallacy</strong>: Assuming group-level patterns apply to individuals</li>
<li><strong>Selection bias</strong>: Non-random samples that systematically exclude certain groups<br>
</li>
<li><strong>Confounding</strong>: Failing to account for variables that affect both X and Y</li>
<li><strong>P-hacking</strong>: Testing multiple hypotheses until finding significance</li>
<li><strong>Overgeneralization</strong>: Extending findings beyond the studied population</li>
</ol>
</div>
</div>
<hr>
</section>
</section>
<section id="practical-applications-in-demography" class="level3">
<h3 class="anchored" data-anchor-id="practical-applications-in-demography">Practical Applications in Demography</h3>
<section id="fertility-analysis" class="level4">
<h4 class="anchored" data-anchor-id="fertility-analysis">Fertility Analysis</h4>
<p>Understanding what factors influence fertility decisions: <span class="math display">\text{Children} = f(\text{Education, Income, Urban, Religion, Contraception, …})</span></p>
<p>Helps identify policy levers for countries concerned about high or low fertility.</p>
<p><strong>Policy levers</strong> are the tools and methods that governments and organizations use to influence events and achieve specific goals by affecting behavior and outcomes.</p>
</section>
<section id="mortality-modeling" class="level4">
<h4 class="anchored" data-anchor-id="mortality-modeling">Mortality Modeling</h4>
<p>Predicting life expectancy or mortality risk: <span class="math display">\text{Mortality Risk} = f(\text{Age, Sex, Smoking, Education, Healthcare Access, …})</span></p>
<p>Used by insurance companies, public health officials, and researchers.</p>
</section>
<section id="migration-prediction" class="level4">
<h4 class="anchored" data-anchor-id="migration-prediction">Migration Prediction</h4>
<p>Understanding who migrates and why: <span class="math display">P(\text{Migration}) = f(\text{Age, Education, Employment, Family Ties, Distance, …})</span></p>
<p>Helps predict population flows and plan for demographic change.</p>
</section>
<section id="marriage-and-divorce" class="level4">
<h4 class="anchored" data-anchor-id="marriage-and-divorce">Marriage and Divorce</h4>
<p>Analyzing union formation and dissolution: <span class="math display">P(\text{Divorce}) = f(\text{Age at Marriage, Education Match, Income, Children, Duration, …})</span></p>
<p>Informs social policy and support services.</p>
</section>
</section>
<section id="common-pitfalls-and-how-to-avoid-them" class="level3">
<h3 class="anchored" data-anchor-id="common-pitfalls-and-how-to-avoid-them">Common Pitfalls and How to Avoid Them</h3>
<section id="overfitting" class="level4">
<h4 class="anchored" data-anchor-id="overfitting">Overfitting</h4>
<p>Including too many predictors can make the model fit perfectly in your sample but fail with new data. Like memorizing exam answers instead of understanding concepts.</p>
<p><strong>Solution</strong>: Use simpler models, cross-validation, or reserve some data for testing.</p>
</section>
<section id="multicollinearity" class="level4">
<h4 class="anchored" data-anchor-id="multicollinearity">Multicollinearity</h4>
<p>When predictors are highly correlated (e.g., years of education and degree level), the model can’t separate their effects.</p>
<p><strong>Solution</strong>: Choose one variable or combine them into an index.</p>
</section>
<section id="omitted-variable-bias" class="level4">
<h4 class="anchored" data-anchor-id="omitted-variable-bias">Omitted Variable Bias</h4>
<p>Leaving out important variables can make other effects appear stronger or weaker than they really are.</p>
<p><strong>Example</strong>: The relationship between ice cream sales and crime rates disappears when you control for temperature.</p>
</section>
<section id="extrapolation" class="level4">
<h4 class="anchored" data-anchor-id="extrapolation">Extrapolation</h4>
<p>Using the model outside the range of observed data.</p>
<p><strong>Example</strong>: If your data includes education from 0-20 years, don’t predict income for someone with 30 years of education.</p>
</section>
</section>
<section id="making-regression-intuitive" class="level3">
<h3 class="anchored" data-anchor-id="making-regression-intuitive">Making Regression Intuitive</h3>
<p>Think of regression as a sophisticated averaging technique:</p>
<ul>
<li><strong>Simple average</strong>: “The average income is $50,000”</li>
<li><strong>Conditional average</strong>: “The average income for college graduates is $70,000”</li>
<li><strong>Regression</strong>: “The average income for 35-year-old college graduates in urban areas is $78,000”</li>
</ul>
<p>Each added variable makes our prediction more specific and (hopefully) more accurate.</p>
</section>
<section id="the-power-and-responsibility-of-regression" class="level3">
<h3 class="anchored" data-anchor-id="the-power-and-responsibility-of-regression">The Power and Responsibility of Regression</h3>
<p>Regression analysis is powerful—it influences policy decisions, business strategies, and scientific understanding. But with power comes responsibility:</p>
<p><strong>Do:</strong></p>
<ul>
<li>Clearly state what variables you’re controlling for</li>
<li>Acknowledge uncertainty with confidence intervals</li>
<li>Consider alternative explanations</li>
<li>Check assumptions with diagnostic plots</li>
<li>Be cautious about causal interpretation</li>
</ul>
<p><strong>Don’t:</strong></p>
<ul>
<li>Claim causation without strong justification</li>
<li>Ignore practical significance for statistical significance</li>
<li>Extrapolate beyond your data</li>
<li>Add variables without thinking</li>
<li>Hide unfavorable results</li>
</ul>
</section>
<section id="regression-in-practice-a-complete-example" class="level3">
<h3 class="anchored" data-anchor-id="regression-in-practice-a-complete-example">Regression in Practice: A Complete Example</h3>
<p><strong>Research Question</strong>: What factors influence age at first birth?</p>
<p><strong>Data</strong>: Survey of 1,000 women who have had at least one child</p>
<p><strong>Variables</strong>:</p>
<ul>
<li>Outcome: Age at first birth (years)</li>
<li>Predictors: Education (years), Urban (0/1), Income (thousands), Religious (0/1)</li>
</ul>
<p><strong>Simple Regression Result</strong>: <span class="math display">\text{Age at First Birth} = 18 + 0.8 \times \text{Education}</span></p>
<p>Interpretation: Each year of education associated with 0.8 years later first birth.</p>
<p><strong>Multiple Regression Result</strong>: <span class="math display">\text{Age at First Birth} = 16 + 0.5 \times \text{Education} + 2 \times \text{Urban} + 0.03 \times \text{Income} - 1.5 \times \text{Religious}</span></p>
<p>Interpretation:</p>
<ul>
<li>Education effect reduced but still positive (0.5 years per education year)</li>
<li>Urban women have first births 2 years later</li>
<li>Each $1,000 income associated with 0.03 years (11 days) later</li>
<li>Religious women have first births 1.5 years earlier</li>
<li><span class="math inline">R^2 = 0.42</span> (model explains 42% of variation)</li>
</ul>
<p>This richer model helps us understand that education’s effect partly operates through urban residence and income.</p>
</section>
<section id="moving-forward-with-regression" class="level3">
<h3 class="anchored" data-anchor-id="moving-forward-with-regression">Moving Forward with Regression</h3>
<p>Regression is a gateway to advanced statistical modeling. Once you understand the basic concept—using variables to predict outcomes and quantifying relationships—you can explore:</p>
<ul>
<li><strong>Interaction effects</strong>: When one variable’s effect depends on another</li>
<li><strong>Non-linear relationships</strong>: Curves, thresholds, and complex patterns</li>
<li><strong>Multilevel models</strong>: Accounting for grouped data (students in schools, people in neighborhoods)</li>
<li><strong>Time series regression</strong>: Analyzing change over time</li>
<li><strong>Machine learning extensions</strong>: Random forests, neural networks, and more</li>
</ul>
<p>The key insight remains: We’re trying to understand how things relate to each other in a systematic, quantifiable way.</p>
</section>
</section>
<section id="data-quality-and-sources" class="level2" data-number="1.33">
<h2 data-number="1.33" class="anchored" data-anchor-id="data-quality-and-sources"><span class="header-section-number">1.33</span> Data Quality and Sources</h2>
<p>No analysis is better than the data it’s based on. Understanding data quality issues is crucial for demographic research.</p>
<section id="dimensions-of-data-quality" class="level3">
<h3 class="anchored" data-anchor-id="dimensions-of-data-quality">Dimensions of Data Quality</h3>
<p><strong>Accuracy</strong>: How close are measurements to true values?</p>
<p>Example: Age reporting often shows “heaping” at round numbers (30, 40, 50) because people round their ages.</p>
<p><strong>Completeness</strong>: What proportion of the population is covered?</p>
<p>Example: Birth registration completeness varies widely:</p>
<ul>
<li>Developed countries: &gt;99%</li>
<li>Some developing countries: &lt;50%</li>
</ul>
<p><strong>Timeliness</strong>: How current is the data?</p>
<p>Example: Census conducted every 10 years becomes increasingly outdated, especially in rapidly changing areas.</p>
<p><strong>Consistency</strong>: Are definitions and methods stable over time and space?</p>
<p>Example: Definition of “urban” varies by country, making international comparisons difficult.</p>
<p><strong>Accessibility</strong>: Can researchers and policy makers actually use the data?</p>
</section>
<section id="common-data-sources-in-demography" class="level3">
<h3 class="anchored" data-anchor-id="common-data-sources-in-demography">Common Data Sources in Demography</h3>
<p><strong>Census</strong>: Complete enumeration of population</p>
<p><em>Advantages:</em></p>
<ul>
<li>Complete coverage (in theory)</li>
<li>Small area data available</li>
<li>Baseline for other estimates</li>
</ul>
<p><em>Disadvantages:</em></p>
<ul>
<li>Expensive and infrequent</li>
<li>Some populations hard to count</li>
<li>Limited variables collected</li>
</ul>
<p><strong>Vital Registration</strong>: Continuous recording of births, deaths, marriages</p>
<p><em>Advantages:</em></p>
<ul>
<li>Continuous and timely</li>
<li>Legal requirement ensures compliance</li>
<li>Medical cause of death information</li>
</ul>
<p><em>Disadvantages:</em></p>
<ul>
<li>Coverage varies by development level</li>
<li>Quality of cause-of-death coding varies</li>
<li>Delayed registration common in some areas</li>
</ul>
<p><strong>Sample Surveys</strong>: Detailed data from population subset</p>
<p><em>Examples:</em></p>
<ul>
<li>Demographic and Health Surveys (DHS)</li>
<li>American Community Survey (ACS)</li>
<li>Labour Force Surveys</li>
</ul>
<p><em>Advantages:</em></p>
<ul>
<li>Can collect detailed information</li>
<li>More frequent than census</li>
<li>Can focus on specific topics</li>
</ul>
<p><em>Disadvantages:</em></p>
<ul>
<li>Sampling error present</li>
<li>Small areas not represented</li>
<li>Response burden may reduce quality</li>
</ul>
<p><strong>Administrative Records</strong>: Data collected for non-statistical purposes</p>
<p><em>Examples:</em></p>
<ul>
<li>Tax records</li>
<li>School enrollment</li>
<li>Health insurance claims</li>
<li>Mobile phone data</li>
</ul>
<p><em>Advantages:</em></p>
<ul>
<li>Already collected (no additional burden)</li>
<li>Often complete for covered population</li>
<li>Continuously updated</li>
</ul>
<p><em>Disadvantages:</em></p>
<ul>
<li>Coverage may be selective</li>
<li>Definitions may not match research needs</li>
<li>Access often restricted</li>
</ul>
</section>
<section id="data-quality-issues-specific-to-demography" class="level3">
<h3 class="anchored" data-anchor-id="data-quality-issues-specific-to-demography">Data Quality Issues Specific to Demography</h3>
<p><strong>Age Heaping</strong>: Tendency to report ages ending in 0 or 5</p>
<p><em>Detection</em>: Calculate Whipple’s Index or Myers’ Index</p>
<p><em>Impact</em>: Affects age-specific rates and projections</p>
<p><strong>Digit Preference</strong>: Reporting certain final digits more than others</p>
<p><em>Example</em>: Birth weights often reported as 3,000g, 3,500g rather than precise values</p>
<p><strong>Recall Bias</strong>: Difficulty remembering past events accurately</p>
<p><em>Example</em>: “How many times did you visit a doctor last year?” Often underreported for frequent visitors, overreported for rare visitors.</p>
<p><strong>Proxy Reporting</strong>: Information provided by someone else</p>
<p><em>Challenge</em>: Household head reporting for all members may not know everyone’s exact age or education</p>
</section>
</section>
<section id="ethical-considerations-in-statistical-demographics" class="level2" data-number="1.34">
<h2 data-number="1.34" class="anchored" data-anchor-id="ethical-considerations-in-statistical-demographics"><span class="header-section-number">1.34</span> Ethical Considerations in Statistical Demographics</h2>
<p>Statistics isn’t just about numbers—it involves real people and has real consequences.</p>
<section id="informed-consent" class="level3">
<h3 class="anchored" data-anchor-id="informed-consent">Informed Consent</h3>
<p>Participants should understand:</p>
<ul>
<li>Purpose of data collection</li>
<li>How data will be used</li>
<li>Risks and benefits</li>
<li>Their right to refuse or withdraw</li>
</ul>
<p><strong>Challenge in Demographics</strong>: Census participation is often mandatory, raising ethical questions about consent.</p>
</section>
<section id="confidentiality-and-privacy" class="level3">
<h3 class="anchored" data-anchor-id="confidentiality-and-privacy">Confidentiality and Privacy</h3>
<p><strong>Statistical Disclosure Control</strong>: Protecting individual identity in published data</p>
<p>Methods include:</p>
<ul>
<li>Suppressing small cells (e.g., “&lt;5” instead of “2”)</li>
<li>Adding random noise</li>
<li>Geographic aggregation</li>
<li>Top/bottom coding of extreme values</li>
</ul>
<p><strong>Example</strong>: In a table of occupation by age by sex for a small town, there might be only one female doctor aged 60-65, making her identifiable.</p>
</section>
<section id="representation-and-fairness" class="level3">
<h3 class="anchored" data-anchor-id="representation-and-fairness">Representation and Fairness</h3>
<p><strong>Who’s Counted?</strong>: Decisions about who to include affect representation</p>
<ul>
<li>Prisoners: Where are they counted—prison location or home address?</li>
<li>Homeless: How to ensure coverage?</li>
<li>Undocumented immigrants: Include or exclude?</li>
</ul>
<p><strong>Differential Privacy</strong>: Mathematical framework for privacy protection while maintaining statistical utility</p>
<p>Trade-off: More privacy protection = less accurate statistics</p>
</section>
<section id="misuse-of-statistics" class="level3">
<h3 class="anchored" data-anchor-id="misuse-of-statistics">Misuse of Statistics</h3>
<p><strong>Cherry-Picking</strong>: Selecting only favorable results</p>
<p>Example: Reporting decline in teen pregnancy from peak year rather than showing full trend</p>
<p><strong>P-Hacking</strong>: Manipulating analysis to achieve statistical significance</p>
<p><strong>Ecological Fallacy</strong>: Inferring individual relationships from group data</p>
<p>Example: Counties with more immigrants have higher average incomes ≠ immigrants have higher incomes</p>
</section>
<section id="responsible-reporting" class="level3">
<h3 class="anchored" data-anchor-id="responsible-reporting">Responsible Reporting</h3>
<p><strong>Uncertainty Communication</strong>: Always report confidence intervals or margins of error</p>
<p><strong>Context Provision</strong>: Include relevant comparison groups and historical trends</p>
<p><strong>Limitation Acknowledgment</strong>: Clearly state what data can and cannot show</p>
</section>
</section>
<section id="common-misconceptions-in-statistics" class="level2" data-number="1.35">
<h2 data-number="1.35" class="anchored" data-anchor-id="common-misconceptions-in-statistics"><span class="header-section-number">1.35</span> Common Misconceptions in Statistics</h2>
<p>Understanding what statistics is NOT is as important as understanding what it is.</p>
<section id="misconception-1-statistics-can-prove-anything" class="level3">
<h3 class="anchored" data-anchor-id="misconception-1-statistics-can-prove-anything">Misconception 1: “Statistics Can Prove Anything”</h3>
<p><strong>Reality</strong>: Statistics can only provide evidence, never absolute proof. And proper statistics, honestly applied, constrains conclusions significantly.</p>
<p><strong>Example</strong>: A study finds correlation between ice cream sales and drowning deaths. Statistics doesn’t “prove” ice cream causes drowning—both are related to summer weather.</p>
</section>
<section id="misconception-2-larger-samples-are-always-better" class="level3">
<h3 class="anchored" data-anchor-id="misconception-2-larger-samples-are-always-better">Misconception 2: “Larger Samples Are Always Better”</h3>
<p><strong>Reality</strong>: Beyond a certain point, larger samples add little precision but may add bias.</p>
<p><strong>Example</strong>: Online survey with 1 million responses may be less accurate than probability sample of 1,000 due to self-selection bias.</p>
<p><strong>Diminishing Returns</strong>:</p>
<ul>
<li><span class="math inline">n = 100</span>: Margin of error <span class="math inline">\approx 10%</span></li>
<li><span class="math inline">n = 1,000</span>: Margin of error <span class="math inline">\approx 3.2%</span></li>
<li><span class="math inline">n = 10,000</span>: Margin of error <span class="math inline">\approx 1%</span></li>
<li><span class="math inline">n = 100,000</span>: Margin of error <span class="math inline">\approx 0.32%</span></li>
</ul>
<p>The jump from 10,000 to 100,000 barely improves precision but costs <span class="math inline">10\times</span> more.</p>
</section>
<section id="misconception-3-statistical-significance-practical-importance" class="level3">
<h3 class="anchored" data-anchor-id="misconception-3-statistical-significance-practical-importance">Misconception 3: “Statistical Significance = Practical Importance”</h3>
<p><strong>Reality</strong>: With large samples, tiny differences become “statistically significant” even if meaningless.</p>
<p><strong>Example</strong>: Study of 100,000 people finds men are 0.1 cm taller on average (p &lt; 0.001). Statistically significant but practically irrelevant.</p>
</section>
<section id="misconception-4-correlation-implies-causation" class="level3">
<h3 class="anchored" data-anchor-id="misconception-4-correlation-implies-causation">Misconception 4: “Correlation Implies Causation”</h3>
<p><strong>Reality</strong>: Correlation is necessary but not sufficient for causation.</p>
<p><strong>Classic Examples</strong>:</p>
<ul>
<li>Cities with more churches have more crime (both correlate with population size)</li>
<li>Countries with more TV sets have longer life expectancy (both correlate with development)</li>
</ul>
</section>
<section id="misconception-5-random-means-haphazard" class="level3">
<h3 class="anchored" data-anchor-id="misconception-5-random-means-haphazard">Misconception 5: “Random Means Haphazard”</h3>
<p><strong>Reality</strong>: Statistical randomness is carefully controlled and systematic.</p>
<p><strong>Example</strong>: Random sampling requires careful procedure, not just grabbing whoever is convenient.</p>
</section>
<section id="misconception-6-average-represents-everyone" class="level3">
<h3 class="anchored" data-anchor-id="misconception-6-average-represents-everyone">Misconception 6: “Average Represents Everyone”</h3>
<p><strong>Reality</strong>: Averages can be misleading when distributions are skewed or multimodal.</p>
<p><strong>Example</strong>: Average income of bar patrons is $50,000. Bill Gates walks in. Now average is $1 million. Nobody’s actual income changed.</p>
</section>
<section id="misconception-7-past-patterns-guarantee-future-results" class="level3">
<h3 class="anchored" data-anchor-id="misconception-7-past-patterns-guarantee-future-results">Misconception 7: “Past Patterns Guarantee Future Results”</h3>
<p><strong>Reality</strong>: Extrapolation assumes conditions remain constant.</p>
<p><strong>Example</strong>: Linear population growth projection from 1950-2000 would badly overestimate 2050 population because it misses fertility decline.</p>
</section>
</section>
<section id="applications-in-demography" class="level2" data-number="1.36">
<h2 data-number="1.36" class="anchored" data-anchor-id="applications-in-demography"><span class="header-section-number">1.36</span> Applications in Demography</h2>
<p>These statistical foundations enable sophisticated demographic analyses. Let’s explore key applications.</p>
<section id="population-estimation-and-projection" class="level3">
<h3 class="anchored" data-anchor-id="population-estimation-and-projection">Population Estimation and Projection</h3>
<p><strong>Intercensal Estimates</strong>: Estimating population between censuses</p>
<p>Components Method: <span class="math display">P(t+1) = P(t) + B - D + I - E</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">P(t)</span> = Population at time <span class="math inline">t</span></li>
<li><span class="math inline">B</span> = Births</li>
<li><span class="math inline">D</span> = Deaths</li>
<li><span class="math inline">I</span> = Immigration</li>
<li><span class="math inline">E</span> = Emigration</li>
</ul>
<p>Each component estimated from different sources with different error structures.</p>
<p><strong>Population Projections</strong>: Forecasting future population</p>
<p>Cohort Component Method:</p>
<ol type="1">
<li>Project survival rates by age</li>
<li>Project fertility rates</li>
<li>Project migration rates</li>
<li>Apply to base population</li>
<li>Aggregate results</li>
</ol>
<p>Uncertainty increases with projection horizon.</p>
</section>
<section id="demographic-rate-calculation" class="level3">
<h3 class="anchored" data-anchor-id="demographic-rate-calculation">Demographic Rate Calculation</h3>
<p><strong>Crude Rates</strong>: Events per 1,000 population</p>
<p><span class="math display">\text{Crude Birth Rate} = \frac{\text{Births}}{\text{Mid-year Population}} \times 1,000</span></p>
<p><strong>Age-Specific Rates</strong>: Control for age structure</p>
<p><span class="math display">\text{Age-Specific Fertility Rate} = \frac{\text{Births to women aged } x}{\text{Women aged } x} \times 1,000</span></p>
<p><strong>Standardization</strong>: Compare populations with different structures</p>
<p>Direct Standardization: Apply population’s rates to standard age structure Indirect Standardization: Apply standard rates to population’s age structure</p>
</section>
<section id="life-table-analysis" class="level3">
<h3 class="anchored" data-anchor-id="life-table-analysis">Life Table Analysis</h3>
<p>Life tables summarize mortality experience of a population.</p>
<p>Key Columns:</p>
<ul>
<li><span class="math inline">q_x</span>: Probability of dying between age <span class="math inline">x</span> and <span class="math inline">x+1</span></li>
<li><span class="math inline">l_x</span>: Number surviving to age <span class="math inline">x</span> (from 100,000 births)</li>
<li><span class="math inline">d_x</span>: Deaths between age <span class="math inline">x</span> and <span class="math inline">x+1</span></li>
<li><span class="math inline">L_x</span>: Person-years lived between age <span class="math inline">x</span> and <span class="math inline">x+1</span></li>
<li><span class="math inline">e_x</span>: Life expectancy at age <span class="math inline">x</span></li>
</ul>
<p><strong>Example Interpretation</strong>: If <span class="math inline">q_{65} = 0.015</span>, then 1.5% of 65-year-olds die before reaching 66. If <span class="math inline">e_{65} = 18.5</span>, then 65-year-olds average 18.5 more years of life.</p>
</section>
<section id="fertility-analysis-1" class="level3">
<h3 class="anchored" data-anchor-id="fertility-analysis-1">Fertility Analysis</h3>
<p><strong>Total Fertility Rate (TFR)</strong>: Average children per woman given current age-specific rates</p>
<p><span class="math display">\text{TFR} = \sum (\text{ASFR} \times \text{age interval width})</span></p>
<p><strong>Example</strong>: If each 5-year age group from 15-49 has ASFR = 20 per 1,000: <span class="math display">\text{TFR} = 7 \text{ age groups} \times \frac{20}{1,000} \times 5 \text{ years} = 0.7 \text{ children per woman}</span></p>
<p>This very low TFR indicates below-replacement fertility.</p>
</section>
<section id="migration-analysis" class="level3">
<h3 class="anchored" data-anchor-id="migration-analysis">Migration Analysis</h3>
<p><strong>Net Migration Rate</strong>: <span class="math display">\text{NMR} = \frac{\text{Immigrants} - \text{Emigrants}}{\text{Population}} \times 1,000</span></p>
<p><strong>Migration Effectiveness Index</strong>: <span class="math display">\text{MEI} = \frac{|\text{In} - \text{Out}|}{\text{In} + \text{Out}}</span></p>
<ul>
<li>Values near 0: High turnover, little net change</li>
<li>Values near 1: Mostly one-way flow</li>
</ul>
</section>
<section id="population-health-metrics" class="level3">
<h3 class="anchored" data-anchor-id="population-health-metrics">Population Health Metrics</h3>
<p><strong>Disability-Adjusted Life Years (DALYs)</strong>: Years of healthy life lost</p>
<p>DALY = Years of Life Lost (YLL) + Years Lived with Disability (YLD)</p>
<p><strong>Healthy Life Expectancy</strong>: Expected years in good health</p>
<p>Combines mortality and morbidity information.</p>
</section>
</section>
<section id="software-and-tools" class="level2" data-number="1.37">
<h2 data-number="1.37" class="anchored" data-anchor-id="software-and-tools"><span class="header-section-number">1.37</span> Software and Tools</h2>
<p>Modern demographic statistics relies heavily on computational tools.</p>
<section id="statistical-software-packages" class="level3">
<h3 class="anchored" data-anchor-id="statistical-software-packages">Statistical Software Packages</h3>
<p><strong>R</strong>: Free, open-source, extensive demographic packages</p>
<ul>
<li>Packages: demography, popReconstruct, bayesPop</li>
<li>Advantages: Reproducible research, cutting-edge methods</li>
<li>Disadvantages: Steep learning curve</li>
</ul>
<p><strong>Stata</strong>: Widely used in social sciences</p>
<ul>
<li>Strengths: Survey data analysis, panel data</li>
<li>Common in: Economics, epidemiology</li>
</ul>
<p><strong>SPSS</strong>: User-friendly interface</p>
<ul>
<li>Strengths: Point-and-click interface</li>
<li>Common in: Social sciences, market research</li>
</ul>
<p><strong>Python</strong>: General programming language with statistical libraries</p>
<ul>
<li>Libraries: pandas, numpy, scipy, statsmodels</li>
<li>Advantages: Integration with other applications</li>
</ul>
</section>
</section>
<section id="conclusion" class="level2" data-number="1.38">
<h2 data-number="1.38" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">1.38</span> Conclusion</h2>
<p>This chapter has introduced the fundamental statistical concepts essential for demographic analysis. We’ve covered the distinction between description and inference, populations and samples, parameters and statistics, and the various ways we quantify uncertainty in our estimates.</p>
<p>Key takeaways:</p>
<ol type="1">
<li><strong>Statistics is about understanding variation and uncertainty</strong>, not about proving absolute truths.</li>
<li><strong>Good data collection is fundamental</strong>—no analysis can overcome fundamentally flawed data.</li>
<li><strong>Different sampling methods serve different purposes</strong>—choose based on your research goals and constraints.</li>
<li><strong>Always quantify uncertainty</strong>—point estimates without confidence intervals are incomplete.</li>
<li><strong>Context matters</strong>—statistical significance doesn’t equal practical importance.</li>
<li><strong>Ethical considerations are paramount</strong>—we study human populations, not just numbers.</li>
</ol>
<p>As we progress through this course, we will build upon these concepts to explore more sophisticated statistical methods and their applications to real-world demographic questions. The interplay between statistical theory and demographic practice will remain central, emphasizing both mathematical rigor and practical relevance.</p>
<p>Remember: Statistics is both an art and a science. While formulas and theorems provide the structure, judgment and experience guide their application. Every number represents people—their births, deaths, movements, and life experiences. Use these tools thoughtfully and responsibly.</p>
</section>
<section id="key-terms-summary" class="level2" data-number="1.39">
<h2 data-number="1.39" class="anchored" data-anchor-id="key-terms-summary"><span class="header-section-number">1.39</span> Key Terms Summary</h2>
<p><strong>Statistics</strong>: The science of collecting, organizing, analyzing, interpreting, and presenting data to understand phenomena and support decision-making</p>
<p><strong>Descriptive Statistics</strong>: Methods for summarizing and presenting data in meaningful ways without extending conclusions beyond the observed data</p>
<p><strong>Inferential Statistics</strong>: Techniques for drawing conclusions about populations from samples, including estimation and hypothesis testing</p>
<p><strong>Population</strong>: The complete set of individuals, objects, or measurements about which conclusions are to be drawn</p>
<p><strong>Sample</strong>: A subset of the population that is actually observed or measured to make inferences about the population</p>
<p><strong>Superpopulation</strong>: A theoretical infinite population from which observed finite populations are considered to be samples</p>
<p><strong>Parameter</strong>: A numerical characteristic of a population (usually unknown and denoted by Greek letters)</p>
<p><strong>Statistic</strong>: A numerical characteristic calculated from sample data (known and denoted by Roman letters)</p>
<p><strong>Estimator</strong>: A rule or formula for calculating estimates of population parameters from sample data</p>
<p><strong>Estimand</strong>: The specific population parameter targeted for estimation</p>
<p><strong>Estimate</strong>: The numerical value produced by applying an estimator to observed data</p>
<p><strong>Random Error (Sampling Error)</strong>: Unpredictable variation arising from the sampling process that decreases with larger samples</p>
<p><strong>Systematic Error (Bias)</strong>: Consistent deviation from true values that cannot be reduced by increasing sample size</p>
<p><strong>Sampling</strong>: The process of selecting a subset of units from a population for measurement</p>
<p><strong>Sampling Frame</strong>: The list or device from which a sample is drawn, ideally containing all population members</p>
<p><strong>Probability Sampling</strong>: Sampling methods where every population member has a known, non-zero probability of selection</p>
<p><strong>Simple Random Sampling</strong>: Every possible sample of size n has equal probability of selection</p>
<p><strong>Systematic Sampling</strong>: Selection of every kth element from an ordered sampling frame</p>
<p><strong>Stratified Sampling</strong>: Division of population into homogeneous subgroups before sampling within each</p>
<p><strong>Cluster Sampling</strong>: Selection of groups (clusters) rather than individuals</p>
<p><strong>Non-probability Sampling</strong>: Sampling methods without guaranteed known selection probabilities</p>
<p><strong>Convenience Sampling</strong>: Selection based purely on ease of access</p>
<p><strong>Purposive Sampling</strong>: Deliberate selection based on researcher judgment</p>
<p><strong>Quota Sampling</strong>: Selection to match population proportions on key characteristics without random selection</p>
<p><strong>Snowball Sampling</strong>: Participants recruit additional subjects from their acquaintances</p>
<p><strong>Standard Error</strong>: The standard deviation of the sampling distribution of a statistic</p>
<p><strong>Margin of Error</strong>: Maximum expected difference between estimate and parameter at specified confidence</p>
<p><strong>Confidence Interval</strong>: Range of plausible values for a parameter at specified confidence level</p>
<p><strong>Confidence Level</strong>: Probability that the confidence interval method produces intervals containing the parameter</p>
<p><strong>Data</strong>: Collected observations or measurements</p>
<p><strong>Quantitative Data</strong>: Numerical measurements (continuous or discrete)</p>
<p><strong>Qualitative Data</strong>: Categorical information (nominal or ordinal)</p>
<p><strong>Data Distribution</strong>: Description of how values spread across possible outcomes</p>
<p><strong>Frequency Distribution</strong>: Summary showing how often each value occurs in data</p>
<p><strong>Absolute Frequency</strong>: Count of observations for each value</p>
<p><strong>Relative Frequency</strong>: Proportion of observations in each category</p>
<p><strong>Cumulative Frequency</strong>: Running total of frequencies up to each value</p>
</section>
<section id="practice-exercises" class="level2" data-number="1.40">
<h2 data-number="1.40" class="anchored" data-anchor-id="practice-exercises"><span class="header-section-number">1.40</span> Practice Exercises</h2>
<section id="conceptual-understanding" class="level3">
<h3 class="anchored" data-anchor-id="conceptual-understanding">Conceptual Understanding</h3>
<ol type="1">
<li><strong>Distinguishing Concepts</strong>: For each pair, explain the key difference and provide a demographic example:</li>
</ol>
<ul>
<li>Parameter vs.&nbsp;Statistic</li>
<li>Population vs.&nbsp;Sample</li>
<li>Random error vs.&nbsp;Systematic error</li>
<li>Descriptive vs.&nbsp;Inferential statistics</li>
<li>Discrete vs.&nbsp;Continuous data</li>
</ul>
<ol type="1">
<li><strong>Identifying Bias</strong>: A telephone survey about internet usage conducted from 9 AM to 5 PM on weekdays finds that 95% of respondents have high-speed internet. Identify at least three sources of potential bias and explain how each might affect the estimate.</li>
<li><strong>Sampling Design</strong>: You need to estimate the prevalence of diabetes in a city of 500,000 people. Design a sampling strategy, explaining:</li>
</ol>
<ul>
<li>What sampling method you would use and why</li>
<li>How you would construct your sampling frame</li>
<li>What sample size you would target</li>
<li>What potential sources of error you anticipate</li>
</ul>
</section>
<section id="calculations" class="level3">
<h3 class="anchored" data-anchor-id="calculations">Calculations</h3>
<ol type="1">
<li><strong>Standard Error and Confidence Intervals</strong>: A survey of 400 households finds a mean household size of 3.2 people with a standard deviation of 1.8 people.</li>
</ol>
<ul>
<li>Calculate the standard error of the mean</li>
<li>Construct a 95% confidence interval</li>
<li>Interpret your interval in plain language</li>
<li>How large a sample would you need to halve the margin of error?</li>
</ul>
<ol type="1">
<li><strong>Proportion Estimation</strong>: In a random sample of 1,500 adults, 345 report being current smokers.</li>
</ol>
<ul>
<li>Calculate the point estimate for smoking prevalence</li>
<li>Calculate the standard error</li>
<li>Construct a 95% confidence interval</li>
<li>What sample size would be needed to estimate the proportion within ±1 percentage point?</li>
</ul>
<ol type="1">
<li><strong>Frequency Distribution</strong>: Given the following data on household sizes in a neighborhood: 2, 4, 1, 3, 2, 5, 3, 2, 4, 1, 3, 3, 2, 6, 4, 2, 3, 1, 2, 3, 4, 2, 3, 2, 5</li>
</ol>
<ul>
<li>Create a frequency distribution table</li>
<li>Calculate relative and cumulative frequencies</li>
<li>Find the mode, median, and mean</li>
<li>Describe the shape of the distribution</li>
</ul>
</section>
<section id="application-problems" class="level3">
<h3 class="anchored" data-anchor-id="application-problems">Application Problems</h3>
<ol type="1">
<li><strong>Life Table Interpretation</strong>: From a life table, you find: <span class="math inline">l_{65} = 84,532</span> and <span class="math inline">l_{66} = 83,421</span></li>
</ol>
<ul>
<li>Calculate <span class="math inline">q_{65}</span>, the probability of dying between 65 and 66</li>
<li>If there are 100,000 people aged 65 in your city, approximately how many will die before reaching 66?</li>
<li>What assumptions are you making in this calculation?</li>
</ul>
<ol type="1">
<li><strong>Comparing Populations</strong>: City A: 50,000 people, 500 deaths per year, median age = 28 City B: 50,000 people, 750 deaths per year, median age = 42</li>
</ol>
<ul>
<li>Calculate crude death rates for both cities</li>
<li>Explain why direct comparison might be misleading</li>
<li>What additional information would you need for fair comparison?</li>
</ul>
<ol type="1">
<li><strong>Survey Design Challenge</strong>: You need to estimate the average age at first marriage for women in a country where:</li>
</ol>
<ul>
<li><p>Rural areas have limited phone/internet access</p></li>
<li><p>Some regions have security concerns</p></li>
<li><p>Women in some areas may be reluctant to discuss marriage</p></li>
<li><p>The population is 60% rural, 40% urban</p>
<p>Design a feasible sampling strategy addressing these challenges.</p></li>
</ul>
</section>
<section id="critical-thinking" class="level3">
<h3 class="anchored" data-anchor-id="critical-thinking">Critical Thinking</h3>
<ol type="1">
<li><strong>Interpreting News Reports</strong>: A news headline states: “Unemployment falls to 3.5%!” The fine print mentions: “Survey of 60,000 households, margin of error ±0.2 percentage points.”</li>
</ol>
<ul>
<li>What additional information would you want to know?</li>
<li>How might the unemployment rate differ if measured differently?</li>
<li>Draft a more complete and accurate headline</li>
</ul>
<ol type="1">
<li><strong>Ethical Considerations</strong>: A government wants to add a citizenship question to the census. Discuss:</li>
</ol>
<ul>
<li>Potential impacts on data quality</li>
<li>Ethical considerations</li>
<li>Trade-offs between different data needs</li>
<li>How you would evaluate the decision statistically</li>
</ul>
<ol type="1">
<li><strong>Real-World Application</strong>: Your local health department reports: “COVID-19 positivity rate is 5% based on 10,000 tests last week.”</li>
</ol>
<ul>
<li>What factors might affect whether this represents the true population prevalence?</li>
<li>How would you design a study to estimate true prevalence?</li>
<li>What additional data would help interpret this number?</li>
</ul>
<hr>
<p><em>End of Chapter 1: Foundations of Statistics and Demography</em></p>
<hr>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="do">## ============================================</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Visualizations for Statistics &amp; Demography</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Chapter 1: Foundations</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="do">## ============================================</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load required libraries</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(scales)</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)  <span class="co"># for combining plots</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Set theme for all plots</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">12</span>))</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Color palette for consistency</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>colors <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"#2E86AB"</span>, <span class="st">"#A23B72"</span>, <span class="st">"#F18F01"</span>, <span class="st">"#C73E1D"</span>, <span class="st">"#6A994E"</span>)</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. POPULATION vs SAMPLE VISUALIZATION</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a population and sample visualization</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate population data (e.g., ages of 10,000 people)</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>population <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>,</span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">10000</span>, <span class="at">mean =</span> <span class="dv">40</span>, <span class="at">sd =</span> <span class="dv">15</span>))</span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>population<span class="sc">$</span>age[population<span class="sc">$</span>age <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>population<span class="sc">$</span>age[population<span class="sc">$</span>age <span class="sc">&gt;</span> <span class="dv">100</span>] <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a random sample</span></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>sample_data <span class="ot">&lt;-</span> population[<span class="fu">sample</span>(<span class="fu">nrow</span>(population), sample_size), ]</span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(population, <span class="fu">aes</span>(<span class="at">x =</span> age)) <span class="sc">+</span></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="dv">5</span>, <span class="at">fill =</span> colors[<span class="dv">1</span>], <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(population<span class="sc">$</span>age), </span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> colors[<span class="dv">2</span>], <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Population Distribution (N = 10,000)"</span>,</span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">"Population mean (μ) ="</span>, <span class="fu">round</span>(<span class="fu">mean</span>(population<span class="sc">$</span>age), <span class="dv">2</span>), <span class="st">"years"</span>),</span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Age (years)"</span>, <span class="at">y =</span> <span class="st">"Frequency"</span>) <span class="sc">+</span></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>))</span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sample_data, <span class="fu">aes</span>(<span class="at">x =</span> age)) <span class="sc">+</span></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="dv">5</span>, <span class="at">fill =</span> colors[<span class="dv">3</span>], <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(sample_data<span class="sc">$</span>age), </span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> colors[<span class="dv">4</span>], <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">paste</span>(<span class="st">"Sample Distribution (n ="</span>, sample_size, <span class="st">")"</span>),</span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">"Sample mean (x̄) ="</span>, <span class="fu">round</span>(<span class="fu">mean</span>(sample_data<span class="sc">$</span>age), <span class="dv">2</span>), <span class="st">"years"</span>),</span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Age (years)"</span>, <span class="at">y =</span> <span class="st">"Frequency"</span>) <span class="sc">+</span></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>))</span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine plots</span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>population_sample_plot <span class="ot">&lt;-</span> p1 <span class="sc">/</span> p2</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(population_sample_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. TYPES OF DATA DISTRIBUTIONS</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate different distribution types</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">5000</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Normal distribution</span></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>normal_data <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Right-skewed distribution (income-like)</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>right_skewed <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(n, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">scale =</span> <span class="dv">15</span>)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Left-skewed distribution (age at death in developed country)</span></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>left_skewed <span class="ot">&lt;-</span> <span class="dv">90</span> <span class="sc">-</span> <span class="fu">rgamma</span>(n, <span class="at">shape =</span> <span class="dv">3</span>, <span class="at">scale =</span> <span class="dv">5</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>left_skewed[left_skewed <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Bimodal distribution (e.g., height of mixed male/female population)</span></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>n2  <span class="ot">&lt;-</span> <span class="dv">20000</span></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>nf <span class="ot">&lt;-</span> n2 <span class="sc">%/%</span> <span class="dv">2</span>; nm <span class="ot">&lt;-</span> n2 <span class="sc">-</span> nf</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>bimodal <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(nf, <span class="at">mean =</span> <span class="dv">164</span>, <span class="at">sd =</span> <span class="dv">5</span>),</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>             <span class="fu">rnorm</span>(nm, <span class="at">mean =</span> <span class="dv">182</span>, <span class="at">sd =</span> <span class="dv">5</span>))</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data frame</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>distributions_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">Normal =</span> normal_data,</span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Right Skewed</span><span class="st">`</span> <span class="ot">=</span> right_skewed,</span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Left Skewed</span><span class="st">`</span> <span class="ot">=</span> left_skewed,</span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">Bimodal =</span> bimodal</span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>(), <span class="at">names_to =</span> <span class="st">"Distribution"</span>, <span class="at">values_to =</span> <span class="st">"Value"</span>)</span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot distributions</span></span>
<span id="cb10-36"><a href="#cb10-36" aria-hidden="true" tabindex="-1"></a>distributions_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(distributions_df, <span class="fu">aes</span>(<span class="at">x =</span> Value, <span class="at">fill =</span> Distribution)) <span class="sc">+</span></span>
<span id="cb10-37"><a href="#cb10-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb10-38"><a href="#cb10-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>Distribution, <span class="at">scales =</span> <span class="st">"free"</span>, <span class="at">nrow =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb10-39"><a href="#cb10-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> colors[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]) <span class="sc">+</span></span>
<span id="cb10-40"><a href="#cb10-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Types of Data Distributions"</span>,</span>
<span id="cb10-41"><a href="#cb10-41" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Common patterns in demographic data"</span>,</span>
<span id="cb10-42"><a href="#cb10-42" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Value"</span>, <span class="at">y =</span> <span class="st">"Frequency"</span>) <span class="sc">+</span></span>
<span id="cb10-43"><a href="#cb10-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>),</span>
<span id="cb10-44"><a href="#cb10-44" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="st">"none"</span>)</span>
<span id="cb10-45"><a href="#cb10-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-46"><a href="#cb10-46" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(distributions_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-2-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. NORMAL DISTRIBUTION WITH 68-95-99.7 RULE</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate normal distribution data</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">789</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>mean_val <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>sd_val <span class="ot">&lt;-</span> <span class="dv">15</span></span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(mean_val <span class="sc">-</span> <span class="dv">4</span><span class="sc">*</span>sd_val, mean_val <span class="sc">+</span> <span class="dv">4</span><span class="sc">*</span>sd_val, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> mean_val, <span class="at">sd =</span> sd_val)</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>df_norm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot</span></span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>normal_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_norm, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Fill areas under the curve</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">data =</span> <span class="fu">subset</span>(df_norm, x <span class="sc">&gt;=</span> mean_val <span class="sc">-</span> sd_val <span class="sc">&amp;</span> x <span class="sc">&lt;=</span> mean_val <span class="sc">+</span> sd_val),</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">fill =</span> colors[<span class="dv">1</span>], <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">data =</span> <span class="fu">subset</span>(df_norm, x <span class="sc">&gt;=</span> mean_val <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>sd_val <span class="sc">&amp;</span> x <span class="sc">&lt;=</span> mean_val <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>sd_val),</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">fill =</span> colors[<span class="dv">2</span>], <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">data =</span> <span class="fu">subset</span>(df_norm, x <span class="sc">&gt;=</span> mean_val <span class="sc">-</span> <span class="dv">3</span><span class="sc">*</span>sd_val <span class="sc">&amp;</span> x <span class="sc">&lt;=</span> mean_val <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>sd_val),</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">fill =</span> colors[<span class="dv">3</span>], <span class="at">alpha =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add the curve</span></span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add vertical lines for standard deviations</span></span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mean_val, <span class="at">linetype =</span> <span class="st">"solid"</span>, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(mean_val <span class="sc">-</span> sd_val, mean_val <span class="sc">+</span> sd_val), </span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">0.8</span>, <span class="at">color =</span> colors[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(mean_val <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>sd_val, mean_val <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>sd_val), </span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">0.8</span>, <span class="at">color =</span> colors[<span class="dv">2</span>]) <span class="sc">+</span></span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(mean_val <span class="sc">-</span> <span class="dv">3</span><span class="sc">*</span>sd_val, mean_val <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>sd_val), </span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">0.8</span>, <span class="at">color =</span> colors[<span class="dv">3</span>]) <span class="sc">+</span></span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add labels</span></span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_val, <span class="at">y =</span> <span class="fu">max</span>(y) <span class="sc">*</span> <span class="fl">0.5</span>, <span class="at">label =</span> <span class="st">"68%"</span>, </span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>           <span class="at">size =</span> <span class="dv">5</span>, <span class="at">fontface =</span> <span class="st">"bold"</span>, <span class="at">color =</span> colors[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_val, <span class="at">y =</span> <span class="fu">max</span>(y) <span class="sc">*</span> <span class="fl">0.3</span>, <span class="at">label =</span> <span class="st">"95%"</span>, </span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>           <span class="at">size =</span> <span class="dv">5</span>, <span class="at">fontface =</span> <span class="st">"bold"</span>, <span class="at">color =</span> colors[<span class="dv">2</span>]) <span class="sc">+</span></span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_val, <span class="at">y =</span> <span class="fu">max</span>(y) <span class="sc">*</span> <span class="fl">0.1</span>, <span class="at">label =</span> <span class="st">"99.7%"</span>, </span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>           <span class="at">size =</span> <span class="dv">5</span>, <span class="at">fontface =</span> <span class="st">"bold"</span>, <span class="at">color =</span> colors[<span class="dv">3</span>]) <span class="sc">+</span></span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Labels</span></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">c</span>(mean_val <span class="sc">-</span> <span class="dv">3</span><span class="sc">*</span>sd_val, mean_val <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>sd_val, </span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>                                mean_val <span class="sc">-</span> sd_val, mean_val, </span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>                                mean_val <span class="sc">+</span> sd_val, mean_val <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>sd_val, </span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>                                mean_val <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>sd_val),</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>                     <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"μ-3σ"</span>, <span class="st">"μ-2σ"</span>, <span class="st">"μ-σ"</span>, <span class="st">"μ"</span>, <span class="st">"μ+σ"</span>, <span class="st">"μ+2σ"</span>, <span class="st">"μ+3σ"</span>)) <span class="sc">+</span></span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Normal Distribution: The 68-95-99.7 Rule"</span>,</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Proportion of data within standard deviations from the mean"</span>,</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Value"</span>, <span class="at">y =</span> <span class="st">"Probability Density"</span>) <span class="sc">+</span></span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>))</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(normal_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-2-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. SIMPLE LINEAR REGRESSION</span></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load required libraries</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(scales)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define color palette (this was missing in original code)</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>colors <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"#2E86AB"</span>, <span class="st">"#A23B72"</span>, <span class="st">"#F18F01"</span>, <span class="st">"#C73E1D"</span>, <span class="st">"#592E83"</span>)</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data for regression example (Education vs Income)</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2024</span>)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>n_reg <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>education <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(n_reg, <span class="at">mean =</span> <span class="dv">14</span>, <span class="at">sd =</span> <span class="dv">3</span>))</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>education[education <span class="sc">&lt;</span> <span class="dv">8</span>] <span class="ot">&lt;-</span> <span class="dv">8</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>education[education <span class="sc">&gt;</span> <span class="dv">22</span>] <span class="ot">&lt;-</span> <span class="dv">22</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create income with linear relationship plus noise</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>income <span class="ot">&lt;-</span> <span class="dv">15000</span> <span class="sc">+</span> <span class="dv">4000</span> <span class="sc">*</span> education <span class="sc">+</span> <span class="fu">rnorm</span>(n_reg, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">8000</span>)</span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>income[income <span class="sc">&lt;</span> <span class="dv">10000</span>] <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>reg_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">education =</span> education, <span class="at">income =</span> income)</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(income <span class="sc">~</span> education, <span class="at">data =</span> reg_data)</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subset of data for residual lines</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a>subset_indices <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(reg_data), <span class="dv">20</span>)</span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a>subset_data <span class="ot">&lt;-</span> reg_data[subset_indices, ]</span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>subset_data<span class="sc">$</span>predicted <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_model, <span class="at">newdata =</span> subset_data)</span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Create regression plot</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>regression_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(reg_data, <span class="fu">aes</span>(<span class="at">x =</span> education, <span class="at">y =</span> income)) <span class="sc">+</span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add points</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">size =</span> <span class="dv">2</span>, <span class="at">color =</span> colors[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add regression line with confidence interval</span></span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">TRUE</span>, <span class="at">color =</span> colors[<span class="dv">2</span>], <span class="at">fill =</span> colors[<span class="dv">2</span>], <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add residual lines for a subset of points to show the concept</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">data =</span> subset_data,</span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>               <span class="fu">aes</span>(<span class="at">x =</span> education, <span class="at">xend =</span> education, </span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>                   <span class="at">y =</span> income, <span class="at">yend =</span> predicted),</span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>               <span class="at">color =</span> colors[<span class="dv">4</span>], <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add equation to plot (adjusted position based on data range)</span></span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="fu">min</span>(reg_data<span class="sc">$</span>education) <span class="sc">+</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="fu">max</span>(reg_data<span class="sc">$</span>income) <span class="sc">*</span> <span class="fl">0.9</span>, </span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"Income = $"</span>, <span class="fu">format</span>(<span class="fu">round</span>(<span class="fu">coef</span>(lm_model)[<span class="dv">1</span>]), <span class="at">big.mark =</span> <span class="st">","</span>), </span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>                        <span class="st">" + $"</span>, <span class="fu">format</span>(<span class="fu">round</span>(<span class="fu">coef</span>(lm_model)[<span class="dv">2</span>]), <span class="at">big.mark =</span> <span class="st">","</span>), <span class="st">" × Education"</span>,</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"</span><span class="sc">\n</span><span class="st">R² = "</span>, <span class="fu">round</span>(<span class="fu">summary</span>(lm_model)<span class="sc">$</span>r.squared, <span class="dv">3</span>), <span class="at">sep =</span> <span class="st">""</span>),</span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>           <span class="at">hjust =</span> <span class="dv">0</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">fontface =</span> <span class="st">"italic"</span>) <span class="sc">+</span></span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Labels and formatting</span></span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> <span class="fu">dollar_format</span>()) <span class="sc">+</span></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Simple Linear Regression: Education and Income"</span>,</span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Each year of education associated with higher income"</span>,</span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Years of Education"</span>, </span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Annual Income"</span>) <span class="sc">+</span></span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>))</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-63"><a href="#cb12-63" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(regression_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. SAMPLING ERROR AND SAMPLE SIZE</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Show how standard error decreases with sample size</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">111</span>)</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">250</span>, <span class="dv">500</span>, <span class="dv">1000</span>, <span class="dv">2500</span>, <span class="dv">5000</span>)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>n_simulations <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># True population parameters</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>true_mean <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>true_sd <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Run simulations for each sample size</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>se_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> sample_sizes) {</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>  sample_means <span class="ot">&lt;-</span> <span class="fu">replicate</span>(n_simulations, <span class="fu">mean</span>(<span class="fu">rnorm</span>(n, true_mean, true_sd)))</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>  se_results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(se_results, </span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">data.frame</span>(<span class="at">n =</span> n, </span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>                                <span class="at">se_empirical =</span> <span class="fu">sd</span>(sample_means),</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>                                <span class="at">se_theoretical =</span> true_sd <span class="sc">/</span> <span class="fu">sqrt</span>(n)))</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>se_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(se_results, <span class="fu">aes</span>(<span class="at">x =</span> n)) <span class="sc">+</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> se_empirical, <span class="at">color =</span> <span class="st">"Empirical SE"</span>), <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> se_empirical, <span class="at">color =</span> <span class="st">"Empirical SE"</span>), <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb13-28"><a href="#cb13-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> se_theoretical, <span class="at">color =</span> <span class="st">"Theoretical SE"</span>), </span>
<span id="cb13-29"><a href="#cb13-29" aria-hidden="true" tabindex="-1"></a>            <span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb13-30"><a href="#cb13-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_log10</span>(<span class="at">breaks =</span> sample_sizes) <span class="sc">+</span></span>
<span id="cb13-31"><a href="#cb13-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Empirical SE"</span> <span class="ot">=</span> colors[<span class="dv">1</span>], </span>
<span id="cb13-32"><a href="#cb13-32" aria-hidden="true" tabindex="-1"></a>                               <span class="st">"Theoretical SE"</span> <span class="ot">=</span> colors[<span class="dv">2</span>])) <span class="sc">+</span></span>
<span id="cb13-33"><a href="#cb13-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Standard Error Decreases with Sample Size"</span>,</span>
<span id="cb13-34"><a href="#cb13-34" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"The precision of estimates improves with larger samples"</span>,</span>
<span id="cb13-35"><a href="#cb13-35" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Size (log scale)"</span>, </span>
<span id="cb13-36"><a href="#cb13-36" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Standard Error"</span>,</span>
<span id="cb13-37"><a href="#cb13-37" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb13-38"><a href="#cb13-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>),</span>
<span id="cb13-39"><a href="#cb13-39" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb13-40"><a href="#cb13-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-41"><a href="#cb13-41" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(se_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. CONFIDENCE INTERVALS VISUALIZATION</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate multiple samples and their confidence intervals</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">999</span>)</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>n_samples <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>sample_size_ci <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>true_mean_ci <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>true_sd_ci <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate samples and calculate CIs</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>ci_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_samples) {</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>  sample_i <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(sample_size_ci, true_mean_ci, true_sd_ci)</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>  mean_i <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample_i)</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>  se_i <span class="ot">&lt;-</span> <span class="fu">sd</span>(sample_i) <span class="sc">/</span> <span class="fu">sqrt</span>(sample_size_ci)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>  ci_lower <span class="ot">&lt;-</span> mean_i <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se_i</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>  ci_upper <span class="ot">&lt;-</span> mean_i <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se_i</span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>  contains_true <span class="ot">&lt;-</span> (true_mean_ci <span class="sc">&gt;=</span> ci_lower) <span class="sc">&amp;</span> (true_mean_ci <span class="sc">&lt;=</span> ci_upper)</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>  ci_data <span class="ot">&lt;-</span> <span class="fu">rbind</span>(ci_data,</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">data.frame</span>(<span class="at">sample =</span> i, <span class="at">mean =</span> mean_i, </span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>                             <span class="at">lower =</span> ci_lower, <span class="at">upper =</span> ci_upper,</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>                             <span class="at">contains =</span> contains_true))</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create CI plot</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>ci_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ci_data, <span class="fu">aes</span>(<span class="at">x =</span> sample, <span class="at">y =</span> mean)) <span class="sc">+</span></span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> true_mean_ci, <span class="at">color =</span> <span class="st">"red"</span>, </span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper, <span class="at">color =</span> contains), </span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>                <span class="at">width =</span> <span class="fl">0.3</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> contains), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"TRUE"</span> <span class="ot">=</span> colors[<span class="dv">1</span>], <span class="st">"FALSE"</span> <span class="ot">=</span> colors[<span class="dv">4</span>]),</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>                    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Misses true value"</span>, <span class="st">"Contains true value"</span>)) <span class="sc">+</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"95% Confidence Intervals from 20 Different Samples"</span>,</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">"True population mean = "</span>, true_mean_ci, </span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>                       <span class="st">" (red dashed line)"</span>, <span class="at">sep =</span> <span class="st">""</span>),</span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Number"</span>, </span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Sample Mean with 95% CI"</span>,</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>),</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(ci_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-4-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. SAMPLING DISTRIBUTIONS (CENTRAL LIMIT THEOREM)</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- Setup ----</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">13</span>))</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Skewed population (Gamma); change if you want another DGP</span></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>Npop <span class="ot">&lt;-</span> <span class="dv">100000</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>population <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(Npop, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">scale =</span> <span class="dv">10</span>)  <span class="co"># skewed right</span></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> <span class="fu">mean</span>(population)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">sd</span>(population)</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- CLT: sampling distribution of the mean ----</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">30</span>, <span class="dv">100</span>)</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">2000</span>  <span class="co"># resamples per n</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>clt_df <span class="ot">&lt;-</span> purrr<span class="sc">::</span><span class="fu">map_dfr</span>(sample_sizes, \(n) {</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">n =</span> n,</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>         <span class="at">mean =</span> <span class="fu">replicate</span>(B, <span class="fu">mean</span>(<span class="fu">sample</span>(population, n, <span class="at">replace =</span> <span class="cn">TRUE</span>))))</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Normal overlays: N(mu, sigma/sqrt(n))</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>clt_range <span class="ot">&lt;-</span> clt_df <span class="sc">|&gt;</span></span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(n) <span class="sc">|&gt;</span></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">min_x =</span> <span class="fu">min</span>(mean), <span class="at">max_x =</span> <span class="fu">max</span>(mean), <span class="at">.groups =</span> <span class="st">"drop"</span>)</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>normal_df <span class="ot">&lt;-</span> clt_range <span class="sc">|&gt;</span></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">x =</span> <span class="fu">list</span>(<span class="fu">seq</span>(min_x, max_x, <span class="at">length.out =</span> <span class="dv">200</span>))) <span class="sc">|&gt;</span></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(x) <span class="sc">|&gt;</span></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">density =</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)))</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>clt_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(clt_df, <span class="fu">aes</span>(mean)) <span class="sc">+</span></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density), <span class="at">fill =</span> <span class="fu">factor</span>(n)),</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>                 <span class="at">bins =</span> <span class="dv">30</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> normal_df, <span class="fu">aes</span>(x, density), <span class="at">linewidth =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mu, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> n, <span class="at">scales =</span> <span class="st">"free"</span>, <span class="at">ncol =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"CLT: Sampling distribution of the mean → Normal(μ, σ/√n)"</span>,</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">sprintf</span>(<span class="st">"Skewed population: Gamma(shape=2, scale=10).  μ≈%.2f, σ≈%.2f; B=%d resamples each."</span>, mu, sigma, B),</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Sample mean"</span>, <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">fill =</span> <span class="st">"none"</span>)</span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>clt_plot</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 8. TYPES OF SAMPLING ERROR</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data to show random vs systematic error</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>n_measurements <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>true_value <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Random error only</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>random_error <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_measurements, <span class="at">mean =</span> true_value, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Systematic error (bias) only</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>systematic_error <span class="ot">&lt;-</span> <span class="fu">rep</span>(true_value <span class="sc">+</span> <span class="dv">10</span>, n_measurements) <span class="sc">+</span> <span class="fu">rnorm</span>(n_measurements, <span class="dv">0</span>, <span class="fl">0.5</span>)</span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Both errors</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>both_errors <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_measurements, <span class="at">mean =</span> true_value <span class="sc">+</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>error_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">measurement =</span> <span class="dv">1</span><span class="sc">:</span>n_measurements,</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Random Error Only</span><span class="st">`</span> <span class="ot">=</span> random_error,</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Systematic Error Only</span><span class="st">`</span> <span class="ot">=</span> systematic_error,</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Both Errors</span><span class="st">`</span> <span class="ot">=</span> both_errors</span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>measurement, <span class="at">names_to =</span> <span class="st">"Error_Type"</span>, <span class="at">values_to =</span> <span class="st">"Value"</span>)</span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Create error visualization</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>error_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(error_data, <span class="fu">aes</span>(<span class="at">x =</span> measurement, <span class="at">y =</span> Value, <span class="at">color =</span> Error_Type)) <span class="sc">+</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> true_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>Error_Type, <span class="at">nrow =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> colors[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]) <span class="sc">+</span></span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Random Error vs Systematic Error (Bias)"</span>,</span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">"True value = "</span>, true_value, <span class="st">" (black dashed line)"</span>, <span class="at">sep =</span> <span class="st">""</span>),</span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Measurement Number"</span>, </span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Measured Value"</span>) <span class="sc">+</span></span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>),</span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="st">"none"</span>)</span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(error_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 9. DEMOGRAPHIC PYRAMID</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create age pyramid data</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">777</span>)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>age_groups <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"0-4"</span>, <span class="st">"5-9"</span>, <span class="st">"10-14"</span>, <span class="st">"15-19"</span>, <span class="st">"20-24"</span>, <span class="st">"25-29"</span>, </span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>               <span class="st">"30-34"</span>, <span class="st">"35-39"</span>, <span class="st">"40-44"</span>, <span class="st">"45-49"</span>, <span class="st">"50-54"</span>, </span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>               <span class="st">"55-59"</span>, <span class="st">"60-64"</span>, <span class="st">"65-69"</span>, <span class="st">"70-74"</span>, <span class="st">"75-79"</span>, <span class="st">"80+"</span>)</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data for a developing country pattern</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>male_pop <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">12</span>, <span class="fl">11.5</span>, <span class="dv">11</span>, <span class="fl">10.5</span>, <span class="dv">10</span>, <span class="fl">9.5</span>, <span class="dv">9</span>, <span class="fl">8.5</span>, <span class="dv">8</span>, <span class="fl">7.5</span>, <span class="dv">7</span>, </span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>             <span class="dv">6</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="fl">1.5</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>female_pop <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">11.8</span>, <span class="fl">11.3</span>, <span class="fl">10.8</span>, <span class="fl">10.3</span>, <span class="fl">9.8</span>, <span class="fl">9.3</span>, <span class="fl">8.8</span>, <span class="fl">8.3</span>, <span class="fl">7.8</span>, </span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>               <span class="fl">7.3</span>, <span class="fl">6.8</span>, <span class="fl">5.8</span>, <span class="fl">4.8</span>, <span class="fl">3.8</span>, <span class="fl">2.8</span>, <span class="fl">2.2</span>, <span class="dv">2</span>)</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>pyramid_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">Age =</span> <span class="fu">factor</span>(<span class="fu">rep</span>(age_groups, <span class="dv">2</span>), <span class="at">levels =</span> <span class="fu">rev</span>(age_groups)),</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">Population =</span> <span class="fu">c</span>(<span class="sc">-</span>male_pop, female_pop),  <span class="co"># Negative for males</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">Sex =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Male"</span>, <span class="fu">length</span>(male_pop)), <span class="fu">rep</span>(<span class="st">"Female"</span>, <span class="fu">length</span>(female_pop)))</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Create population pyramid</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>pyramid_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(pyramid_data, <span class="fu">aes</span>(<span class="at">x =</span> Age, <span class="at">y =</span> Population, <span class="at">fill =</span> Sex)) <span class="sc">+</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">width =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> <span class="cf">function</span>(x) <span class="fu">paste0</span>(<span class="fu">abs</span>(x), <span class="st">"%"</span>)) <span class="sc">+</span></span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Male"</span> <span class="ot">=</span> colors[<span class="dv">1</span>], <span class="st">"Female"</span> <span class="ot">=</span> colors[<span class="dv">3</span>])) <span class="sc">+</span></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Population Pyramid"</span>,</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Age and sex distribution (typical developing country pattern)"</span>,</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Age Group"</span>, </span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Percentage of Population"</span>) <span class="sc">+</span></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>),</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pyramid_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-6-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 10. REGRESSION RESIDUALS AND DIAGNOSTICS</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the previous regression model for diagnostics</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>reg_diagnostics <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">fitted =</span> <span class="fu">fitted</span>(lm_model),</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">residuals =</span> <span class="fu">residuals</span>(lm_model),</span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">standardized_residuals =</span> <span class="fu">rstandard</span>(lm_model),</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">education =</span> reg_data<span class="sc">$</span>education,</span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">income =</span> reg_data<span class="sc">$</span>income</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create diagnostic plots</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Residuals vs Fitted</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>p_resid_fitted <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(reg_diagnostics, <span class="fu">aes</span>(<span class="at">x =</span> fitted, <span class="at">y =</span> residuals)) <span class="sc">+</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">color =</span> colors[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">se =</span> <span class="cn">TRUE</span>, <span class="at">color =</span> colors[<span class="dv">2</span>], <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Residuals vs Fitted Values"</span>,</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Check for homoscedasticity"</span>,</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Fitted Values"</span>, <span class="at">y =</span> <span class="st">"Residuals"</span>)</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Q-Q plot</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>p_qq <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(reg_diagnostics, <span class="fu">aes</span>(<span class="at">sample =</span> standardized_residuals)) <span class="sc">+</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq</span>(<span class="at">color =</span> colors[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq_line</span>(<span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Normal Q-Q Plot"</span>,</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Check for normality of residuals"</span>,</span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Theoretical Quantiles"</span>, <span class="at">y =</span> <span class="st">"Standardized Residuals"</span>)</span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Histogram of residuals</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>p_hist_resid <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(reg_diagnostics, <span class="fu">aes</span>(<span class="at">x =</span> residuals)) <span class="sc">+</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>, <span class="at">fill =</span> colors[<span class="dv">3</span>], <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Distribution of Residuals"</span>,</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Should be approximately normal"</span>,</span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Residuals"</span>, <span class="at">y =</span> <span class="st">"Frequency"</span>)</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Residuals vs Predictor</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>p_resid_x <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(reg_diagnostics, <span class="fu">aes</span>(<span class="at">x =</span> education, <span class="at">y =</span> residuals)) <span class="sc">+</span></span>
<span id="cb18-42"><a href="#cb18-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">color =</span> colors[<span class="dv">4</span>]) <span class="sc">+</span></span>
<span id="cb18-43"><a href="#cb18-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb18-44"><a href="#cb18-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">se =</span> <span class="cn">TRUE</span>, <span class="at">color =</span> colors[<span class="dv">2</span>], <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb18-45"><a href="#cb18-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Residuals vs Predictor"</span>,</span>
<span id="cb18-46"><a href="#cb18-46" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Check for patterns"</span>,</span>
<span id="cb18-47"><a href="#cb18-47" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Education (years)"</span>, <span class="at">y =</span> <span class="st">"Residuals"</span>)</span>
<span id="cb18-48"><a href="#cb18-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-49"><a href="#cb18-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine diagnostic plots</span></span>
<span id="cb18-50"><a href="#cb18-50" aria-hidden="true" tabindex="-1"></a>diagnostic_plots <span class="ot">&lt;-</span> (p_resid_fitted <span class="sc">+</span> p_qq) <span class="sc">/</span> (p_hist_resid <span class="sc">+</span> p_resid_x)</span>
<span id="cb18-51"><a href="#cb18-51" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(diagnostic_plots)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-6-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 11. SAVE ALL PLOTS (Optional)</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment to save plots as high-resolution images</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("population_sample.png", population_sample_plot, width = 10, height = 8, dpi = 300)</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("distributions.png", distributions_plot, width = 12, height = 8, dpi = 300)</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("normal_distribution.png", normal_plot, width = 10, height = 6, dpi = 300)</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("regression.png", regression_plot, width = 10, height = 7, dpi = 300)</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("standard_error.png", se_plot, width = 10, height = 6, dpi = 300)</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("confidence_intervals.png", ci_plot, width = 10, height = 8, dpi = 300)</span></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("central_limit_theorem.png", clt_plot, width = 14, height = 5, dpi = 300)</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("error_types.png", error_plot, width = 14, height = 5, dpi = 300)</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("population_pyramid.png", pyramid_plot, width = 8, height = 8, dpi = 300)</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("regression_diagnostics.png", diagnostic_plots, width = 12, height = 10, dpi = 300)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="Preface">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preface</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./rozdzial1.html" class="pagination-link" aria-label="Podstawy Statystyki i Demografii">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Podstawy Statystyki i Demografii</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>