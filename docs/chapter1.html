<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>1&nbsp; Foundations of Statistics and Demography – Statistics: An Introduction (PL: Wprowadzenie do Statystyki)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./rozdzial1.html" rel="next">
<link href="./index.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-ffd282cb318059e0bcb130885a47f5dc.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css">

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter1.html"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Foundations of Statistics and Demography</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistics: An Introduction (PL: Wprowadzenie do Statystyki)</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter1.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Foundations of Statistics and Demography</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Podstawy Statystyki i Demografii</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Understanding Data Types in Social Sciences</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Typy Danych w Naukach Społecznych</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Fundamentals of Univariate Descriptive Statistics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Podstawy Jednowymiarowej Statystyki Opisowej</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Data Visualization: with examples in R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./rozdzial6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Wizualizacja Danych: z przykładami w R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correg_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Introduction to Correlation and Regression Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correg_pl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Wprowadzenie do Analizy Korelacji i Regresji</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Introduction to Probability</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./probability_pl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Wprowadzenie do Prawdopodobieństwa</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_en.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Introduction to Statistical Inference: The Logic of Statistical Hypothesis Testing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference_pl.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Wprowadzenie do Wnioskowania Statystycznego: Logika Testowania Hipotez Statystycznych</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">1.1</span> Introduction</a></li>
  <li><a href="#exploratory-data-analysis-eda" id="toc-exploratory-data-analysis-eda" class="nav-link" data-scroll-target="#exploratory-data-analysis-eda"><span class="header-section-number">1.2</span> Exploratory Data Analysis (EDA)</a>
  <ul class="collapse">
  <li><a href="#simple-tools-for-exploring-data" id="toc-simple-tools-for-exploring-data" class="nav-link" data-scroll-target="#simple-tools-for-exploring-data">Simple Tools for Exploring Data</a></li>
  </ul></li>
  <li><a href="#inferential-statistics" id="toc-inferential-statistics" class="nav-link" data-scroll-target="#inferential-statistics"><span class="header-section-number">1.3</span> Inferential Statistics</a>
  <ul class="collapse">
  <li><a href="#statistical-thinking" id="toc-statistical-thinking" class="nav-link" data-scroll-target="#statistical-thinking">Statistical Thinking</a></li>
  </ul></li>
  <li><a href="#understanding-randomness" id="toc-understanding-randomness" class="nav-link" data-scroll-target="#understanding-randomness"><span class="header-section-number">1.4</span> Understanding Randomness</a>
  <ul class="collapse">
  <li><a href="#types-of-randomness" id="toc-types-of-randomness" class="nav-link" data-scroll-target="#types-of-randomness">Types of Randomness</a></li>
  <li><a href="#related-concepts" id="toc-related-concepts" class="nav-link" data-scroll-target="#related-concepts">Related Concepts</a></li>
  </ul></li>
  <li><a href="#populations-and-samples" id="toc-populations-and-samples" class="nav-link" data-scroll-target="#populations-and-samples"><span class="header-section-number">1.5</span> Populations and Samples</a>
  <ul class="collapse">
  <li><a href="#population" id="toc-population" class="nav-link" data-scroll-target="#population">Population</a></li>
  <li><a href="#sample" id="toc-sample" class="nav-link" data-scroll-target="#sample">Sample</a></li>
  </ul></li>
  <li><a href="#superpopulation-and-data-generating-process-dgp" id="toc-superpopulation-and-data-generating-process-dgp" class="nav-link" data-scroll-target="#superpopulation-and-data-generating-process-dgp"><span class="header-section-number">1.6</span> Superpopulation and Data Generating Process (DGP) (*)</a>
  <ul class="collapse">
  <li><a href="#superpopulation" id="toc-superpopulation" class="nav-link" data-scroll-target="#superpopulation"><strong>Superpopulation</strong></a></li>
  <li><a href="#data-generating-process-the-true-recipe" id="toc-data-generating-process-the-true-recipe" class="nav-link" data-scroll-target="#data-generating-process-the-true-recipe"><strong>Data Generating Process: The True Recipe</strong></a></li>
  <li><a href="#two-approaches-to-statistical-inference" id="toc-two-approaches-to-statistical-inference" class="nav-link" data-scroll-target="#two-approaches-to-statistical-inference"><strong>Two Approaches to Statistical Inference</strong></a></li>
  <li><a href="#practical-example-analyzing-state-education-spending" id="toc-practical-example-analyzing-state-education-spending" class="nav-link" data-scroll-target="#practical-example-analyzing-state-education-spending"><strong>Practical Example: Analyzing State Education Spending</strong></a></li>
  <li><a href="#summary" id="toc-summary" class="nav-link" data-scroll-target="#summary"><strong>Summary</strong></a></li>
  </ul></li>
  <li><a href="#data-and-distributions" id="toc-data-and-distributions" class="nav-link" data-scroll-target="#data-and-distributions"><span class="header-section-number">1.7</span> Data and Distributions</a>
  <ul class="collapse">
  <li><a href="#types-of-data" id="toc-types-of-data" class="nav-link" data-scroll-target="#types-of-data">Types of Data</a></li>
  <li><a href="#data-distribution" id="toc-data-distribution" class="nav-link" data-scroll-target="#data-distribution">Data Distribution</a></li>
  </ul></li>
  <li><a href="#variables-and-measurement-scales" id="toc-variables-and-measurement-scales" class="nav-link" data-scroll-target="#variables-and-measurement-scales"><span class="header-section-number">1.8</span> Variables and Measurement Scales</a>
  <ul class="collapse">
  <li><a href="#measurement-transforming-concepts-into-numbers" id="toc-measurement-transforming-concepts-into-numbers" class="nav-link" data-scroll-target="#measurement-transforming-concepts-into-numbers">Measurement: Transforming Concepts into Numbers</a></li>
  <li><a href="#types-of-variables" id="toc-types-of-variables" class="nav-link" data-scroll-target="#types-of-variables">Types of Variables</a></li>
  <li><a href="#measurement-scales" id="toc-measurement-scales" class="nav-link" data-scroll-target="#measurement-scales">Measurement Scales</a></li>
  </ul></li>
  <li><a href="#parameters-statistics-and-estimation" id="toc-parameters-statistics-and-estimation" class="nav-link" data-scroll-target="#parameters-statistics-and-estimation"><span class="header-section-number">1.9</span> Parameters, Statistics, and Estimation</a>
  <ul class="collapse">
  <li><a href="#parameter" id="toc-parameter" class="nav-link" data-scroll-target="#parameter">Parameter</a></li>
  <li><a href="#statistic" id="toc-statistic" class="nav-link" data-scroll-target="#statistic">Statistic</a></li>
  <li><a href="#the-relationship-between-parameters-and-statistics" id="toc-the-relationship-between-parameters-and-statistics" class="nav-link" data-scroll-target="#the-relationship-between-parameters-and-statistics">The Relationship Between Parameters and Statistics</a></li>
  <li><a href="#estimator" id="toc-estimator" class="nav-link" data-scroll-target="#estimator">Estimator</a></li>
  <li><a href="#estimand" id="toc-estimand" class="nav-link" data-scroll-target="#estimand">Estimand</a></li>
  <li><a href="#estimate" id="toc-estimate" class="nav-link" data-scroll-target="#estimate">Estimate</a></li>
  </ul></li>
  <li><a href="#statistical-error-and-uncertainty" id="toc-statistical-error-and-uncertainty" class="nav-link" data-scroll-target="#statistical-error-and-uncertainty"><span class="header-section-number">1.10</span> Statistical Error and Uncertainty</a>
  <ul class="collapse">
  <li><a href="#introduction-why-uncertainty-matters" id="toc-introduction-why-uncertainty-matters" class="nav-link" data-scroll-target="#introduction-why-uncertainty-matters">Introduction: Why Uncertainty Matters</a></li>
  </ul></li>
  <li><a href="#statistical-error-and-uncertainty-1" id="toc-statistical-error-and-uncertainty-1" class="nav-link" data-scroll-target="#statistical-error-and-uncertainty-1"><span class="header-section-number">1.11</span> Statistical Error and Uncertainty</a>
  <ul class="collapse">
  <li><a href="#introduction-why-uncertainty-matters-1" id="toc-introduction-why-uncertainty-matters-1" class="nav-link" data-scroll-target="#introduction-why-uncertainty-matters-1">Introduction: Why Uncertainty Matters</a></li>
  <li><a href="#types-of-error" id="toc-types-of-error" class="nav-link" data-scroll-target="#types-of-error">Types of Error</a></li>
  <li><a href="#quantifying-uncertainty" id="toc-quantifying-uncertainty" class="nav-link" data-scroll-target="#quantifying-uncertainty">Quantifying Uncertainty</a></li>
  <li><a href="#practical-application-opinion-polling" id="toc-practical-application-opinion-polling" class="nav-link" data-scroll-target="#practical-application-opinion-polling">Practical Application: Opinion Polling</a></li>
  <li><a href="#visualization-sampling-variability" id="toc-visualization-sampling-variability" class="nav-link" data-scroll-target="#visualization-sampling-variability">Visualization: Sampling Variability</a></li>
  <li><a href="#common-misconceptions" id="toc-common-misconceptions" class="nav-link" data-scroll-target="#common-misconceptions">Common Misconceptions</a></li>
  <li><a href="#real-world-example-polling-failures" id="toc-real-world-example-polling-failures" class="nav-link" data-scroll-target="#real-world-example-polling-failures">Real-World Example: Polling Failures</a></li>
  <li><a href="#key-takeaways" id="toc-key-takeaways" class="nav-link" data-scroll-target="#key-takeaways">Key Takeaways</a></li>
  </ul></li>
  <li><a href="#sampling-and-sampling-methods" id="toc-sampling-and-sampling-methods" class="nav-link" data-scroll-target="#sampling-and-sampling-methods"><span class="header-section-number">1.12</span> Sampling and Sampling Methods (*)</a>
  <ul class="collapse">
  <li><a href="#the-sampling-frame" id="toc-the-sampling-frame" class="nav-link" data-scroll-target="#the-sampling-frame">The Sampling Frame</a></li>
  <li><a href="#probability-sampling-methods" id="toc-probability-sampling-methods" class="nav-link" data-scroll-target="#probability-sampling-methods">Probability Sampling Methods</a></li>
  <li><a href="#non-probability-sampling-methods" id="toc-non-probability-sampling-methods" class="nav-link" data-scroll-target="#non-probability-sampling-methods">Non-Probability Sampling Methods</a></li>
  </ul></li>
  <li><a href="#probability-concepts-for-statistical-analysis" id="toc-probability-concepts-for-statistical-analysis" class="nav-link" data-scroll-target="#probability-concepts-for-statistical-analysis"><span class="header-section-number">1.13</span> Probability Concepts for Statistical Analysis</a>
  <ul class="collapse">
  <li><a href="#basic-probability" id="toc-basic-probability" class="nav-link" data-scroll-target="#basic-probability">Basic Probability</a></li>
  <li><a href="#conditional-probability" id="toc-conditional-probability" class="nav-link" data-scroll-target="#conditional-probability">Conditional Probability</a></li>
  <li><a href="#independence" id="toc-independence" class="nav-link" data-scroll-target="#independence">Independence</a></li>
  <li><a href="#law-of-large-numbers" id="toc-law-of-large-numbers" class="nav-link" data-scroll-target="#law-of-large-numbers">Law of Large Numbers</a></li>
  <li><a href="#visualizing-the-law-of-large-numbers-coin-flips" id="toc-visualizing-the-law-of-large-numbers-coin-flips" class="nav-link" data-scroll-target="#visualizing-the-law-of-large-numbers-coin-flips">Visualizing the Law of Large Numbers: Coin Flips</a></li>
  <li><a href="#the-mathematical-statement" id="toc-the-mathematical-statement" class="nav-link" data-scroll-target="#the-mathematical-statement">The Mathematical Statement</a></li>
  <li><a href="#examples-in-different-contexts" id="toc-examples-in-different-contexts" class="nav-link" data-scroll-target="#examples-in-different-contexts">Examples in Different Contexts</a></li>
  <li><a href="#why-this-matters-for-statistics" id="toc-why-this-matters-for-statistics" class="nav-link" data-scroll-target="#why-this-matters-for-statistics">Why This Matters for Statistics</a></li>
  <li><a href="#central-limit-theorem-clt" id="toc-central-limit-theorem-clt" class="nav-link" data-scroll-target="#central-limit-theorem-clt">Central Limit Theorem (CLT)</a></li>
  </ul></li>
  <li><a href="#statistical-significance-a-quick-start-guide" id="toc-statistical-significance-a-quick-start-guide" class="nav-link" data-scroll-target="#statistical-significance-a-quick-start-guide"><span class="header-section-number">1.14</span> Statistical Significance: A Quick Start Guide</a>
  <ul class="collapse">
  <li><a href="#the-courtroom-analogy" id="toc-the-courtroom-analogy" class="nav-link" data-scroll-target="#the-courtroom-analogy">The Courtroom Analogy</a></li>
  <li><a href="#start-with-skepticism-presumption-of-innocence" id="toc-start-with-skepticism-presumption-of-innocence" class="nav-link" data-scroll-target="#start-with-skepticism-presumption-of-innocence">Start with Skepticism (Presumption of Innocence)</a></li>
  </ul></li>
  <li><a href="#the-p-value-your-surprise-meter" id="toc-the-p-value-your-surprise-meter" class="nav-link" data-scroll-target="#the-p-value-your-surprise-meter"><span class="header-section-number">1.15</span> The p-value: Your “Surprise Meter”</a>
  <ul class="collapse">
  <li><a href="#three-ways-to-think-about-p-values" id="toc-three-ways-to-think-about-p-values" class="nav-link" data-scroll-target="#three-ways-to-think-about-p-values">Three Ways to Think About p-values</a></li>
  </ul></li>
  <li><a href="#the-prosecutor-fallacy-a-warning" id="toc-the-prosecutor-fallacy-a-warning" class="nav-link" data-scroll-target="#the-prosecutor-fallacy-a-warning"><span class="header-section-number">1.16</span> The Prosecutor Fallacy: A Warning</a></li>
  <li><a href="#the-prosecutor-fallacy-a-warning-1" id="toc-the-prosecutor-fallacy-a-warning-1" class="nav-link" data-scroll-target="#the-prosecutor-fallacy-a-warning-1"><span class="header-section-number">1.17</span> The Prosecutor Fallacy: A Warning</a>
  <ul class="collapse">
  <li><a href="#the-fallacy-explained" id="toc-the-fallacy-explained" class="nav-link" data-scroll-target="#the-fallacy-explained">The Fallacy Explained</a></li>
  <li><a href="#why-this-matters-a-simple-medical-testing-example" id="toc-why-this-matters-a-simple-medical-testing-example" class="nav-link" data-scroll-target="#why-this-matters-a-simple-medical-testing-example">Why This Matters: A Simple Medical Testing Example</a></li>
  <li><a href="#the-research-analogy" id="toc-the-research-analogy" class="nav-link" data-scroll-target="#the-research-analogy">The Research Analogy</a></li>
  </ul></li>
  <li><a href="#introduction-to-regression-analysis-modeling-relationships-between-variables" id="toc-introduction-to-regression-analysis-modeling-relationships-between-variables" class="nav-link" data-scroll-target="#introduction-to-regression-analysis-modeling-relationships-between-variables"><span class="header-section-number">1.18</span> Introduction to Regression Analysis: Modeling Relationships Between Variables</a>
  <ul class="collapse">
  <li><a href="#what-is-regression-analysis" id="toc-what-is-regression-analysis" class="nav-link" data-scroll-target="#what-is-regression-analysis">What is Regression Analysis?</a></li>
  <li><a href="#variables-and-variation" id="toc-variables-and-variation" class="nav-link" data-scroll-target="#variables-and-variation">Variables and Variation</a></li>
  <li><a href="#the-basic-idea-drawing-the-best-line-through-points" id="toc-the-basic-idea-drawing-the-best-line-through-points" class="nav-link" data-scroll-target="#the-basic-idea-drawing-the-best-line-through-points">The Basic Idea: Drawing the Best Line Through Points</a></li>
  <li><a href="#understanding-relationships-vs.-proving-causation" id="toc-understanding-relationships-vs.-proving-causation" class="nav-link" data-scroll-target="#understanding-relationships-vs.-proving-causation">Understanding Relationships vs.&nbsp;Proving Causation</a></li>
  <li><a href="#multiple-regression-controlling-for-other-factors" id="toc-multiple-regression-controlling-for-other-factors" class="nav-link" data-scroll-target="#multiple-regression-controlling-for-other-factors">Multiple Regression: Controlling for Other Factors</a></li>
  <li><a href="#types-of-variables-in-regression" id="toc-types-of-variables-in-regression" class="nav-link" data-scroll-target="#types-of-variables-in-regression">Types of Variables in Regression</a></li>
  <li><a href="#different-types-of-regression-for-different-outcomes" id="toc-different-types-of-regression-for-different-outcomes" class="nav-link" data-scroll-target="#different-types-of-regression-for-different-outcomes">Different Types of Regression for Different Outcomes</a></li>
  <li><a href="#interpreting-regression-results" id="toc-interpreting-regression-results" class="nav-link" data-scroll-target="#interpreting-regression-results">Interpreting Regression Results</a></li>
  <li><a href="#applications-in-demography" id="toc-applications-in-demography" class="nav-link" data-scroll-target="#applications-in-demography">Applications in Demography</a></li>
  <li><a href="#common-pitfalls-and-how-to-avoid-them" id="toc-common-pitfalls-and-how-to-avoid-them" class="nav-link" data-scroll-target="#common-pitfalls-and-how-to-avoid-them">Common Pitfalls and How to Avoid Them</a></li>
  <li><a href="#making-regression-intuitive" id="toc-making-regression-intuitive" class="nav-link" data-scroll-target="#making-regression-intuitive">Making Regression Intuitive</a></li>
  <li><a href="#regression-in-practice-a-complete-example" id="toc-regression-in-practice-a-complete-example" class="nav-link" data-scroll-target="#regression-in-practice-a-complete-example">Regression in Practice: A Complete Example</a></li>
  </ul></li>
  <li><a href="#data-quality-and-sources" id="toc-data-quality-and-sources" class="nav-link" data-scroll-target="#data-quality-and-sources"><span class="header-section-number">1.19</span> Data Quality and Sources</a>
  <ul class="collapse">
  <li><a href="#dimensions-of-data-quality" id="toc-dimensions-of-data-quality" class="nav-link" data-scroll-target="#dimensions-of-data-quality">Dimensions of Data Quality</a></li>
  <li><a href="#common-data-sources-in-demography" id="toc-common-data-sources-in-demography" class="nav-link" data-scroll-target="#common-data-sources-in-demography">Common Data Sources in Demography</a></li>
  <li><a href="#data-quality-issues-specific-to-demography" id="toc-data-quality-issues-specific-to-demography" class="nav-link" data-scroll-target="#data-quality-issues-specific-to-demography">Data Quality Issues Specific to Demography</a></li>
  </ul></li>
  <li><a href="#ethical-considerations-in-statistical-demographics" id="toc-ethical-considerations-in-statistical-demographics" class="nav-link" data-scroll-target="#ethical-considerations-in-statistical-demographics"><span class="header-section-number">1.20</span> Ethical Considerations in Statistical Demographics</a>
  <ul class="collapse">
  <li><a href="#informed-consent" id="toc-informed-consent" class="nav-link" data-scroll-target="#informed-consent">Informed Consent</a></li>
  <li><a href="#confidentiality-and-privacy" id="toc-confidentiality-and-privacy" class="nav-link" data-scroll-target="#confidentiality-and-privacy">Confidentiality and Privacy</a></li>
  <li><a href="#representation-and-fairness" id="toc-representation-and-fairness" class="nav-link" data-scroll-target="#representation-and-fairness">Representation and Fairness</a></li>
  <li><a href="#misuse-of-statistics" id="toc-misuse-of-statistics" class="nav-link" data-scroll-target="#misuse-of-statistics">Misuse of Statistics</a></li>
  <li><a href="#responsible-reporting" id="toc-responsible-reporting" class="nav-link" data-scroll-target="#responsible-reporting">Responsible Reporting</a></li>
  </ul></li>
  <li><a href="#common-misconceptions-in-statistics" id="toc-common-misconceptions-in-statistics" class="nav-link" data-scroll-target="#common-misconceptions-in-statistics"><span class="header-section-number">1.21</span> Common Misconceptions in Statistics</a>
  <ul class="collapse">
  <li><a href="#misconception-1-statistics-can-prove-anything" id="toc-misconception-1-statistics-can-prove-anything" class="nav-link" data-scroll-target="#misconception-1-statistics-can-prove-anything">Misconception 1: “Statistics Can Prove Anything”</a></li>
  <li><a href="#misconception-2-larger-samples-are-always-better" id="toc-misconception-2-larger-samples-are-always-better" class="nav-link" data-scroll-target="#misconception-2-larger-samples-are-always-better">Misconception 2: “Larger Samples Are Always Better”</a></li>
  <li><a href="#misconception-3-statistical-significance-practical-importance" id="toc-misconception-3-statistical-significance-practical-importance" class="nav-link" data-scroll-target="#misconception-3-statistical-significance-practical-importance">Misconception 3: “Statistical Significance = Practical Importance”</a></li>
  <li><a href="#misconception-4-correlation-implies-causation" id="toc-misconception-4-correlation-implies-causation" class="nav-link" data-scroll-target="#misconception-4-correlation-implies-causation">Misconception 4: “Correlation Implies Causation”</a></li>
  <li><a href="#misconception-5-random-means-haphazard" id="toc-misconception-5-random-means-haphazard" class="nav-link" data-scroll-target="#misconception-5-random-means-haphazard">Misconception 5: “Random Means Haphazard”</a></li>
  <li><a href="#misconception-6-average-represents-everyone" id="toc-misconception-6-average-represents-everyone" class="nav-link" data-scroll-target="#misconception-6-average-represents-everyone">Misconception 6: “Average Represents Everyone”</a></li>
  <li><a href="#misconception-7-past-patterns-guarantee-future-results" id="toc-misconception-7-past-patterns-guarantee-future-results" class="nav-link" data-scroll-target="#misconception-7-past-patterns-guarantee-future-results">Misconception 7: “Past Patterns Guarantee Future Results”</a></li>
  </ul></li>
  <li><a href="#applications-in-demography-1" id="toc-applications-in-demography-1" class="nav-link" data-scroll-target="#applications-in-demography-1"><span class="header-section-number">1.22</span> Applications in Demography</a>
  <ul class="collapse">
  <li><a href="#population-estimation-and-projection" id="toc-population-estimation-and-projection" class="nav-link" data-scroll-target="#population-estimation-and-projection">Population Estimation and Projection</a></li>
  <li><a href="#demographic-rate-calculation" id="toc-demographic-rate-calculation" class="nav-link" data-scroll-target="#demographic-rate-calculation">Demographic Rate Calculation</a></li>
  <li><a href="#life-table-analysis" id="toc-life-table-analysis" class="nav-link" data-scroll-target="#life-table-analysis">Life Table Analysis</a></li>
  <li><a href="#fertility-analysis-1" id="toc-fertility-analysis-1" class="nav-link" data-scroll-target="#fertility-analysis-1">Fertility Analysis</a></li>
  <li><a href="#migration-analysis" id="toc-migration-analysis" class="nav-link" data-scroll-target="#migration-analysis">Migration Analysis</a></li>
  <li><a href="#population-health-metrics" id="toc-population-health-metrics" class="nav-link" data-scroll-target="#population-health-metrics">Population Health Metrics</a></li>
  </ul></li>
  <li><a href="#software-and-tools" id="toc-software-and-tools" class="nav-link" data-scroll-target="#software-and-tools"><span class="header-section-number">1.23</span> Software and Tools</a>
  <ul class="collapse">
  <li><a href="#statistical-software-packages" id="toc-statistical-software-packages" class="nav-link" data-scroll-target="#statistical-software-packages">Statistical Software Packages</a></li>
  </ul></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">1.24</span> Conclusion</a>
  <ul class="collapse">
  <li><a href="#key-terms-summary" id="toc-key-terms-summary" class="nav-link" data-scroll-target="#key-terms-summary">Key Terms Summary</a></li>
  </ul></li>
  <li><a href="#appendix-a-visualizations-for-statistics-demography" id="toc-appendix-a-visualizations-for-statistics-demography" class="nav-link" data-scroll-target="#appendix-a-visualizations-for-statistics-demography"><span class="header-section-number">1.25</span> Appendix A: Visualizations for Statistics &amp; Demography</a></li>
  <li><a href="#appendix-b-central-limit-theorem-clt" id="toc-appendix-b-central-limit-theorem-clt" class="nav-link" data-scroll-target="#appendix-b-central-limit-theorem-clt"><span class="header-section-number">1.26</span> Appendix B: Central Limit Theorem (CLT)</a>
  <ul class="collapse">
  <li><a href="#key-insights-1" id="toc-key-insights-1" class="nav-link" data-scroll-target="#key-insights-1">Key Insights</a></li>
  </ul></li>
  <li><a href="#visual-demonstration-step-by-step-progression" id="toc-visual-demonstration-step-by-step-progression" class="nav-link" data-scroll-target="#visual-demonstration-step-by-step-progression"><span class="header-section-number">1.27</span> Visual Demonstration: Step-by-Step Progression</a>
  <ul class="collapse">
  <li><a href="#the-progressive-transformation" id="toc-the-progressive-transformation" class="nav-link" data-scroll-target="#the-progressive-transformation">The Progressive Transformation</a></li>
  <li><a href="#comparative-analysis" id="toc-comparative-analysis" class="nav-link" data-scroll-target="#comparative-analysis">Comparative Analysis</a></li>
  <li><a href="#superimposed-distributions" id="toc-superimposed-distributions" class="nav-link" data-scroll-target="#superimposed-distributions">Superimposed Distributions</a></li>
  <li><a href="#standard-error-convergence" id="toc-standard-error-convergence" class="nav-link" data-scroll-target="#standard-error-convergence">Standard Error Convergence</a></li>
  <li><a href="#numerical-summary" id="toc-numerical-summary" class="nav-link" data-scroll-target="#numerical-summary">Numerical Summary</a></li>
  </ul></li>
  <li><a href="#mathematical-foundation-1" id="toc-mathematical-foundation-1" class="nav-link" data-scroll-target="#mathematical-foundation-1"><span class="header-section-number">1.28</span> Mathematical Foundation</a></li>
  <li><a href="#key-takeaways-2" id="toc-key-takeaways-2" class="nav-link" data-scroll-target="#key-takeaways-2"><span class="header-section-number">1.29</span> Key Takeaways</a></li>
  <li><a href="#practical-significance" id="toc-practical-significance" class="nav-link" data-scroll-target="#practical-significance"><span class="header-section-number">1.30</span> Practical Significance</a></li>
  <li><a href="#appendix-c-standard-errors-and-margins-of-error-means-proportions-variance-and-covariance" id="toc-appendix-c-standard-errors-and-margins-of-error-means-proportions-variance-and-covariance" class="nav-link" data-scroll-target="#appendix-c-standard-errors-and-margins-of-error-means-proportions-variance-and-covariance"><span class="header-section-number">1.31</span> Appendix C: Standard Errors and Margins of Error: Means, Proportions, Variance, and Covariance</a>
  <ul class="collapse">
  <li><a href="#key-insight-a-proportion-is-a-mean" id="toc-key-insight-a-proportion-is-a-mean" class="nav-link" data-scroll-target="#key-insight-a-proportion-is-a-mean">Key Insight: A Proportion IS a Mean</a></li>
  <li><a href="#the-universal-formula-for-means" id="toc-the-universal-formula-for-means" class="nav-link" data-scroll-target="#the-universal-formula-for-means">The Universal Formula for Means</a></li>
  <li><a href="#calculating-se-and-moe-for-proportions" id="toc-calculating-se-and-moe-for-proportions" class="nav-link" data-scroll-target="#calculating-se-and-moe-for-proportions">Calculating SE and MoE for Proportions</a></li>
  <li><a href="#calculating-se-and-moe-for-typical-means" id="toc-calculating-se-and-moe-for-typical-means" class="nav-link" data-scroll-target="#calculating-se-and-moe-for-typical-means">Calculating SE and MoE for Typical Means</a></li>
  <li><a href="#why-proportions-often-require-larger-samples" id="toc-why-proportions-often-require-larger-samples" class="nav-link" data-scroll-target="#why-proportions-often-require-larger-samples">Why Proportions Often Require Larger Samples</a></li>
  <li><a href="#margin-of-error-and-sample-size-for-variance" id="toc-margin-of-error-and-sample-size-for-variance" class="nav-link" data-scroll-target="#margin-of-error-and-sample-size-for-variance">Margin of Error and Sample Size for Variance</a></li>
  <li><a href="#margin-of-error-and-sample-size-for-covariance" id="toc-margin-of-error-and-sample-size-for-covariance" class="nav-link" data-scroll-target="#margin-of-error-and-sample-size-for-covariance">Margin of Error and Sample Size for Covariance</a></li>
  <li><a href="#comparative-example-sample-size-requirements" id="toc-comparative-example-sample-size-requirements" class="nav-link" data-scroll-target="#comparative-example-sample-size-requirements">Comparative Example: Sample Size Requirements</a></li>
  <li><a href="#key-takeaways-3" id="toc-key-takeaways-3" class="nav-link" data-scroll-target="#key-takeaways-3">Key Takeaways</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Foundations of Statistics and Demography</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<hr>
<section id="introduction" class="level2" data-number="1.1">
<h2 data-number="1.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">1.1</span> Introduction</h2>
<blockquote class="blockquote">
<p><strong>Statistics</strong> is the science of learning from data under uncertainty.</p>
</blockquote>
<p>Statistics is a way to learn about the world from data. It teaches how to collect data wisely, spot patterns, estimate population parameters, and make predictions—stating how wrong we might be.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Statistics</strong> is the science of collecting, organizing, analyzing, interpreting, and presenting data. It encompasses both the methods for working with data and the theoretical foundations that justify these methods.</p>
<p>But statistics is more than just numbers and formulas—it’s a way of thinking about uncertainty and variation in the world around us.</p>
</div>
</div>
<hr>
<blockquote class="blockquote">
<p><strong>Demography</strong> is the scientific study of human populations, focusing on their size, structure, distribution, and changes over time. It’s essentially the statistical analysis of people - who they are, where they live, how many there are, and how these characteristics evolve.</p>
</blockquote>
<p><strong>Statistics and demography are interconnected disciplines</strong> that provide powerful tools for understanding populations, their characteristics, and the patterns that emerge from data.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Rounding and Scientific Notation
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Main Rule:</strong> Unless otherwise specified, round the <strong>decimal parts</strong> of decimal numbers to <strong>at least 2 significant figures</strong>. In statistics, we often work with long decimal parts and very small numbers — don’t round excessively in intermediate steps, round <strong>at the end</strong> of calculations.</p>
<section id="rounding-in-statistical-context" class="level3">
<h3 class="anchored" data-anchor-id="rounding-in-statistical-context">Rounding in Statistical Context</h3>
<p>The <strong>decimal part</strong> consists of digits after the decimal point. In statistics, it’s particularly important to maintain appropriate precision:</p>
<p><strong>Descriptive statistics:</strong></p>
<ul>
<li>Mean: <span class="math inline">\bar{x} = 15.847693... \rightarrow 15.85</span></li>
<li>Standard deviation: <span class="math inline">s = 2.7488... \rightarrow 2.75</span></li>
<li>Correlation coefficient: <span class="math inline">r = 0.78432... \rightarrow 0.78</span></li>
</ul>
<p><strong>Very small numbers (p-values, probabilities):</strong></p>
<ul>
<li><span class="math inline">p = 0.000347... \rightarrow 0.00035</span> or <span class="math inline">3.5 \times 10^{-4}</span></li>
<li><span class="math inline">P(X &gt; 2) = 0.0000891... \rightarrow 0.000089</span> or <span class="math inline">8.9 \times 10^{-5}</span></li>
</ul>
</section>
<section id="significant-figures-in-decimal-parts" class="level3">
<h3 class="anchored" data-anchor-id="significant-figures-in-decimal-parts">Significant Figures in Decimal Parts</h3>
<p>In the decimal part, significant figures are all digits except leading zeros:</p>
<ul>
<li><span class="math inline">.78432</span> has 5 significant figures → round to <span class="math inline">.78</span> (2 s.f.)</li>
<li><span class="math inline">.000347</span> has 3 significant figures → round to <span class="math inline">.00035</span> (2 s.f.)</li>
<li><span class="math inline">.050600</span> has 4 significant figures → round to <span class="math inline">.051</span> (2 s.f.)</li>
</ul>
</section>
<section id="rounding-rules-in-statistics" class="level3">
<h3 class="anchored" data-anchor-id="rounding-rules-in-statistics">Rounding Rules in Statistics</h3>
<ol type="1">
<li><strong>Round only the decimal part</strong> to at least 2 significant figures</li>
<li><strong>The integer part</strong> remains unchanged</li>
<li><strong>In long calculations</strong> keep 3-4 digits in the decimal part until the final step</li>
<li><strong>NEVER round to zero</strong> - small values have interpretive significance</li>
<li><strong>For very small numbers</strong> use scientific notation when it improves readability</li>
<li><strong>P-values</strong> often require greater precision — keep 2-3 significant figures</li>
</ol>
</section>
<section id="scientific-notation-in-statistics" class="level3">
<h3 class="anchored" data-anchor-id="scientific-notation-in-statistics">Scientific Notation in Statistics</h3>
<p>In statistics, we often encounter very small numbers. Use scientific notation when it improves readability:</p>
<p><strong>P-values and probabilities:</strong></p>
<ul>
<li><span class="math inline">p = 0.000347 = 3.47 \times 10^{-4}</span> (better: <span class="math inline">3.5 \times 10^{-4}</span>)</li>
<li><span class="math inline">P(Z &gt; 3.5) = 0.000233 = 2.33 \times 10^{-4}</span></li>
</ul>
<p><strong>Large numbers (rare in basic statistics):</strong></p>
<ul>
<li><span class="math inline">N = 1\,234\,567 = 1.23 \times 10^6</span></li>
</ul>
<p><strong>When in doubt:</strong> Better to keep an extra digit than to round too aggressively</p>
</section>
</div>
</div>
<hr>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What is Statistics For in Social and Political Science?
</div>
</div>
<div class="callout-body-container callout-body">
<p>Statistics is essential in social and political science for several key purposes:</p>
<p><strong>Understanding Social Phenomena</strong>: Measuring inequality, poverty, unemployment, political participation; describing demographic patterns and social trends; quantifying attitudes, beliefs, and behaviors in populations.</p>
<p><strong>Testing Theories</strong>: Political scientists theorize about democracy, voting behavior, conflict, and institutions. Sociologists develop theories about social mobility, inequality, and group dynamics. Statistics allows us to test whether these theories match reality.</p>
<p><strong>Causal Inference</strong>: Social scientists want to answer “why” questions—Does education increase income? Do democracies go to war less often? Does social media affect political polarization? Statistics helps separate causation from mere correlation.</p>
<p><strong>Policy Evaluation</strong>: Assessing whether interventions work—Does a job training program reduce unemployment? Did election reform increase voter turnout? Are anti-poverty programs effective? Statistics provides tools to evaluate what works and what doesn’t.</p>
<p><strong>Public Opinion Research</strong>: Election polls and forecasting; measuring public support for policies; understanding how opinions vary across demographic groups; tracking attitude changes over time.</p>
<p><strong>Making Generalizations</strong>: We can’t survey everyone, so we sample and use statistics to make inferences about entire populations. A poll of 1,000 people can tell us about a nation of millions (with known uncertainty).</p>
<p><strong>Dealing with Complexity</strong>: Human societies are messy—many factors influence outcomes simultaneously. Statistics helps us control for confounding variables, isolate specific effects, and make sense of multivariate relationships.</p>
<p><strong>The Uniqueness of Social Sciences</strong>: Unlike natural sciences, social sciences study human behavior, which is highly variable and context-dependent. Statistics provides the tools to find patterns and draw conclusions despite this inherent uncertainty.</p>
</div>
</div>
<hr>
<blockquote class="blockquote">
<p>When working with data, statisticians use two different approaches: <strong>exploration</strong> and <strong>confirmation/verification</strong> (<em>inferential statistics</em>). First, we examine the data to understand its characteristics and identify patterns. Then, we use formal methods to test specific hypotheses and draw conclusions.</p>
</blockquote>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Percent vs Percentage Points (pp)
</div>
</div>
<div class="callout-body-container callout-body">
<p>When news reports say “unemployment <strong>decreased by 2</strong>,” do they mean <strong>2 percentage points (pp)</strong> or <strong>2 percent</strong>?</p>
<p>These are <strong>not</strong> the same:</p>
<ul>
<li><strong>2 pp (absolute change):</strong> e.g., 10% → <strong>8%</strong> (−2 pp).</li>
<li><strong>2% (relative change):</strong> multiply the old rate by 0.98; e.g., 10% → <strong>9.8%</strong> (−0.2 pp).</li>
</ul>
<p><strong>Always ask:</strong></p>
<ol type="1">
<li>What is the <strong>baseline</strong> (earlier rate)?</li>
<li>Is the change <strong>absolute (pp)</strong> or <strong>relative (%)</strong>?</li>
<li>Could this be <strong>sampling error / random variation</strong>?</li>
<li><strong>How was unemployment measured</strong> (survey vs.&nbsp;administrative), <strong>when</strong>, and <strong>who’s included</strong>?</li>
</ol>
<p><strong>Rule of thumb</strong></p>
<ul>
<li>Use <strong>percentage points (pp)</strong> when comparing <strong>rates</strong> directly (unemployment, turnout).</li>
<li>Use <strong>percent (%)</strong> for <strong>relative</strong> changes (proportional to the starting value).</li>
</ul>
<p><strong>Tiny lookup table</strong></p>
<table class="caption-top table">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<thead>
<tr class="header">
<th>Starting rate</th>
<th>“Down <strong>2%</strong>” (relative)</th>
<th>“Down <strong>2 pp</strong>” (absolute)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>6%</td>
<td>6% × 0.98 = <strong>5.88%</strong> (−0.12 pp)</td>
<td><strong>4%</strong></td>
</tr>
<tr class="even">
<td>8%</td>
<td>8% × 0.98 = <strong>7.84%</strong> (−0.16 pp)</td>
<td><strong>6%</strong></td>
</tr>
<tr class="odd">
<td>10%</td>
<td>10% × 0.98 = <strong>9.8%</strong> (−0.2 pp)</td>
<td><strong>8%</strong></td>
</tr>
</tbody>
</table>
<p><em>Uwaga (PL): <strong>2%</strong> ≠ <strong>2 punkty procentowe (pp)</strong>.</em></p>
</div>
</div>
</section>
<section id="exploratory-data-analysis-eda" class="level2" data-number="1.2">
<h2 data-number="1.2" class="anchored" data-anchor-id="exploratory-data-analysis-eda"><span class="header-section-number">1.2</span> Exploratory Data Analysis (EDA)</h2>
<p><strong>What is EDA?</strong> Exploratory Data Analysis is the initial step where we examine data systematically to understand its structure and characteristics. This phase does not involve formal hypothesis testing—it focuses on discovering what the data contains.</p>
<p><strong>Why do we do EDA?</strong></p>
<ul>
<li>Find interesting patterns you didn’t expect</li>
<li>Spot mistakes or unusual values in your data</li>
<li>Get ideas about what questions to ask</li>
<li>Understand what your data looks like before doing formal tests (many statistical methods have specific requirements about the data to work properly. EDA helps check whether our data meets these requirements - e.g.&nbsp;1) some tests require data to have a normal distribution (bell-shaped), 2) we need to verify that the relationship between variables is actually linear, or 3) check homogeneity of variance and find outliers)</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The EDA Approach
</div>
</div>
<div class="callout-body-container callout-body">
<p>When conducting EDA, we begin without predetermined hypotheses. Instead, we examine data from multiple perspectives to discover patterns and generate questions for further investigation.</p>
</div>
</div>
<section id="simple-tools-for-exploring-data" class="level3">
<h3 class="anchored" data-anchor-id="simple-tools-for-exploring-data">Simple Tools for Exploring Data</h3>
<p><strong>1. Summary Numbers</strong> (<em>Descriptive Statistics</em>)</p>
<p>These are basic calculations that describe your data:</p>
<p><strong>Finding the “Typical” Value:</strong></p>
<ul>
<li><strong>Arithmetic Mean (Average)</strong>: Add up all values and divide by how many you have. Example: If 5 students scored 70, 80, 85, 90, and 100 on a test, the average is 85.</li>
<li><strong>Median (Middle)</strong>: The value in the middle when you line up all numbers from smallest to largest. In our test example, the median is also 85.</li>
<li><strong>Mode (Most Common)</strong>: The value that appears most often. If ten families have 1, 2, 2, 2, 2, 3, 3, 3, 4, and 5 children, the mode is 2 children.</li>
</ul>
<p><strong>Understanding Spread:</strong></p>
<ul>
<li><strong>Range</strong>: Just subtract the smallest number from the biggest. If students’ ages go from 18 to 24, the range is 6 years.</li>
<li><strong>Standard Deviation</strong>: Shows how spread out your data is from the average. A small standard deviation means most values are close to the average; a large one means they’re more spread out.</li>
</ul>
<p><strong>2. Visual Exploration</strong></p>
<p>Graphical methods help reveal patterns that numerical summaries alone might not show:</p>
<ul>
<li><strong>Population Pyramids</strong>: Show how many people are in each age group, split by males and females. Helps you see if a population is young or old.</li>
<li><strong>Box Plots</strong>: Show the middle of your data and help spot unusual values</li>
<li><strong>Scatter Plots</strong>: Display relationships between two variables (such as hours studied versus test scores)</li>
<li><strong>Time (Series) Graphs</strong>: Show how something changes over time (like temperature throughout the year)</li>
<li><strong>Histograms</strong>: A histogram is a graphical representation of data that shows the frequency distribution of a dataset. It consists of adjacent bars (with no gaps between them) where each bar represents a range of values (called a bin or class interval), and the height of the bar shows how many data points (what proportion of data points) fall within that range. Histograms are used to visualize the shape, spread, and central tendency of numerical data.</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="stat_imgs/Lodz_population_pyramid.svg" class="img-fluid figure-img"></p>
<figcaption>https://commons.wikimedia.org/wiki/File:%C5%81%C3%B3d%C5%BA_population_pyramid.svg</figcaption>
</figure>
</div>
<p><strong>3. Looking for Connections/Associations</strong>:</p>
<ul>
<li>Do two variables move together? (When one goes up, does the other go up too?)</li>
<li>Can you draw a line (<em>regression line</em>) that roughly fits your data points?</li>
<li>Do you see any clear patterns or trends?</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Using the Same Techniques for Different Purposes
</div>
</div>
<div class="callout-body-container callout-body">
<p>Many statistical techniques serve both exploratory and confirmatory functions:</p>
<p><strong>Exploring</strong>: We calculate correlations or fit regression lines to understand what relationships exist in the data. The focus is on discovering patterns.</p>
<p><strong>Confirming</strong>: We apply statistical tests to determine whether observed patterns are statistically significant or could have occurred by chance. The focus is on formal hypothesis testing.</p>
<p>The same technique can serve different purposes depending on the research phase.</p>
</div>
</div>
<p><strong>4. Good Questions to Ask While Exploring</strong>:</p>
<ul>
<li>What does the shape of my data look like?</li>
<li>Are there any weird or unusual values?</li>
<li>Do I see any patterns?</li>
<li>Is any data missing?</li>
<li>Do different groups show different patterns?</li>
</ul>
<hr>
</section>
</section>
<section id="inferential-statistics" class="level2" data-number="1.3">
<h2 data-number="1.3" class="anchored" data-anchor-id="inferential-statistics"><span class="header-section-number">1.3</span> Inferential Statistics</h2>
<p>After exploring, you might want to make formal conclusions. <strong>Inferential statistics</strong> helps you do this.</p>
<p><strong>The Basic Idea</strong>: You have data from some people (a sample), but you want to know about everyone (the population). Inferential statistics helps you make educated guesses about the bigger group based on your smaller group.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>A <strong>random sample</strong> requires that each member has a known, non-zero chance of being selected, not necessarily an equal chance.</p>
<p>When every member has an equal chance of selection, that’s specifically called a simple random sample - which is the most basic type.</p>
</div>
</div>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
A Soup-Tasting Analogy
</div>
</div>
<div class="callout-body-container callout-body">
<p><img src="stat_imgs/soup-svgrepo-com.svg" class="img-fluid" style="width:30.0%"></p>
<p>Consider a chef preparing soup for 100 people who needs to assess its flavor without consuming the entire batch:</p>
<p><strong>Population</strong>: The entire pot of soup (100 servings)<br>
<strong>Sample</strong>: A single spoonful for tasting<br>
<strong>Population Parameter</strong>: The true average saltiness of the complete pot (unknown)<br>
<strong>Sample Statistic</strong>: The saltiness level detected in the spoonful (observable, a point estimate)<br>
<strong>Statistical Inference</strong>: Using the spoonful’s characteristics to draw conclusions about the entire pot</p>
<section id="key-principles" class="level3">
<h3 class="anchored" data-anchor-id="key-principles">Key Principles</h3>
<p><strong>1. Random sampling is essential</strong>: The chef must thoroughly stir the soup before sampling. Consistently sampling from the surface might miss seasoning that has settled, introducing systematic bias.</p>
<p><strong>2. Sample size affects precision</strong>: A larger spoonful provides more reliable information about overall flavor than a small sip, though practical constraints (costs, time) limit sample size.</p>
<p><strong>3. Uncertainty is inherent</strong>: Even with proper sampling technique, the spoonful might not perfectly represent the entire pot’s characteristics.</p>
<p><strong>4. Systematic bias undermines inference</strong>: If someone secretly adds salt only to the sampling area, conclusions about the whole pot become invalid—illustrating how sampling bias distorts statistical inference.</p>
<p><strong>5. Inference has scope limitations</strong>: The sample can estimate average saltiness but cannot reveal whether some portions are saltier than others, highlighting the limits of what samples can tell us about population variability.</p>
<p>This analogy captures the essence of statistical reasoning: using carefully selected samples to learn about larger populations while explicitly acknowledging and quantifying the inherent uncertainty in this process.</p>
</section>
</div>
</div>
<hr>
<section id="statistical-thinking" class="level3">
<h3 class="anchored" data-anchor-id="statistical-thinking">Statistical Thinking</h3>
<p><img src="stat_imgs_2/FD134791-EDB7-41C0-A016-42D03015C243_1_105_c.jpeg" class="img-fluid"></p>
<p><img src="stat_imgs/sampling-estimators.svg" class="img-fluid"> <img src="stat_imgs/sampling-logic.001.png" class="img-fluid"></p>
<section id="the-scenario" class="level4">
<h4 class="anchored" data-anchor-id="the-scenario">The Scenario</h4>
<p>Your university is considering keeping the library open 24/7. The administration needs to know: <strong>What proportion of students support this change?</strong></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The Fundamental Challenge
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Ideal world</strong>: Ask all 20,000 students → Get the exact answer (<span class="math inline">\theta</span> parameter)<br>
<strong>Real world</strong>: Survey 100 students → Get an estimate (<span class="math inline">\hat{\theta}</span>) with uncertainty</p>
</div>
</div>
</section>
<section id="two-approaches-to-the-same-data" class="level4">
<h4 class="anchored" data-anchor-id="two-approaches-to-the-same-data">Two Approaches to the Same Data</h4>
<p>Imagine you survey 100 random students and find that 60 support the 24/7 library hours.</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>❌ Without Statistical Thinking</strong></p>
<p>“60 out of 100 students said yes.”</p>
<p><strong>Conclusion</strong>: “Exactly 60% of all students support it.”</p>
<p><strong>Decision</strong>: “Since it’s over 50%, we have clear majority support.”</p>
<p><strong>Problem</strong>: Ignores that a different sample might give 55% or 65%</p>
</div><div class="column" style="width:50%;">
<p><strong>✅ With Statistical Thinking</strong></p>
<p>“60 out of 100 students said yes.”</p>
<p><strong>Conclusion</strong>: “We estimate 60% support, with a margin of error of ±10 pp.”</p>
<p><strong>Decision</strong>: “True support is likely between 50% and 70%—we need more data to be certain of majority support.”</p>
<p><strong>Advantage</strong>: Acknowledges uncertainty and informs better decisions</p>
</div>
</div>
<hr>
</section>
<section id="the-sample-size-and-uncertainty-random-error" class="level4">
<h4 class="anchored" data-anchor-id="the-sample-size-and-uncertainty-random-error">The Sample Size and Uncertainty (<em>Random Error</em>)</h4>
<p>Suppose we take a <strong>random sample</strong> of <span class="math inline">n=1000</span> voters and observe <span class="math inline">\hat p = 0.55</span> (i.e., 55% support for a candidate in upcoming elections, 550 in 1000 sample). Then:</p>
<ul>
<li><p>Our best single-number estimate of the population share is <span class="math inline">\hat p = 0.55</span>.</p></li>
<li><p>A typical “range of plausible values” (for <span class="math inline">95\%</span> confidence level) around <span class="math inline">\hat p</span> can be approximated by <span class="math inline">\hat p \pm \text{Margin of (Random) Error}</span>, i.e., <span class="math display">
\hat p \;\pm\; 2\sqrt{\frac{\hat p(1-\hat p)}{n}}
\;=\;
0.55 \;\pm\; 2\sqrt{\frac{0.55\cdot 0.45}{1000}}
\approx
0.55 \pm 0.031,
</span> i.e., roughly <span class="math inline">52\%\text{–}58\%</span> (about <span class="math inline">\pm 3.1</span> percentage points).</p></li>
<li><p>The width of this range shrinks predictably with sample size: <span class="math display">
\text{MoE (width)} \;\propto\; \frac{1}{\sqrt{n}}.
</span> For example, increasing <span class="math inline">n</span> from <span class="math inline">1000</span> to <span class="math inline">4000</span> cuts the range by about half (<span class="math inline">0.0158</span>).</p></li>
</ul>
<hr>
<p>Here’s how sample size affects our confidence:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 14%">
<col style="width: 14%">
<col style="width: 30%">
<col style="width: 23%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th>Sample Size</th>
<th>Your Result</th>
<th>Margin of (Random) Error</th>
<th>Confidence Interval</th>
<th>Interpretation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n = 100</td>
<td>60%</td>
<td>±10 pp</td>
<td>50% to 70%</td>
<td>Uncertain about majority</td>
</tr>
<tr class="even">
<td>n = 400</td>
<td>60%</td>
<td>±5 pp</td>
<td>55% to 65%</td>
<td>Likely majority support</td>
</tr>
<tr class="odd">
<td>n = 1,000</td>
<td>60%</td>
<td>±3 pp</td>
<td>57% to 63%</td>
<td>Clear majority support</td>
</tr>
<tr class="even">
<td>n = 1,600</td>
<td>60%</td>
<td>±2.5 pp</td>
<td>57.5% to 62.5%</td>
<td>Strong majority support</td>
</tr>
<tr class="odd">
<td>n = 10,000</td>
<td>60%</td>
<td>±1 pp</td>
<td>59% to 61%</td>
<td>Very precise estimate</td>
</tr>
</tbody>
</table>
<p><strong>The Diminishing Returns Principle:</strong> Notice that going from 100 to 400 samples (4× increase) cuts the margin of error in half, but going from 1,600 to 10,000 samples (6× increase) only reduces it by 1.5 percentage points. To halve your margin of error, you must <strong>quadruple your sample size</strong>.</p>
<p>This is why most polls stop around 1,000-1,500 respondents—the gains in precision beyond that point rarely justify the additional cost and effort.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Remember
</div>
</div>
<div class="callout-body-container callout-body">
<p>Statistical thinking transforms “60 students said yes” from a precise-sounding but misleading statement into an honest assessment: “We’re reasonably confident that between 50% and 70% of all students support this.”</p>
<p><strong>This humility leads to better decisions.</strong></p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Fundamental Principle</strong>: Statistics does not eliminate uncertainty—it helps us measure, manage, and communicate it effectively.</p>
</div>
</div>
<hr>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Historical Example: the 1936 <em>Literary Digest</em> Poll
</div>
</div>
<div class="callout-body-container callout-body">
<p><em>Literary Digest</em> ran one of the largest polls in history — <strong>2.4 million responses</strong> — yet spectacularly failed to predict the 1936 U.S. presidential election:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Candidate</th>
<th>Prediction</th>
<th>Actual result</th>
<th>Error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Landon</td>
<td>57%</td>
<td>38%</td>
<td><strong>19 pp</strong></td>
</tr>
<tr class="even">
<td>Roosevelt</td>
<td>43%</td>
<td>62%</td>
<td><strong>19 pp</strong></td>
</tr>
</tbody>
</table>
<p><strong>What is systematic error?</strong></p>
<p>Imagine a bathroom scale that’s miscalibrated by +5 lbs for everyone:</p>
<ul>
<li><strong>Random error</strong> (no bias): Each time you step on, your stance changes slightly. Readings bounce around your true weight—say 149–151 lbs. Averaging many readings converges to the truth (≈150 lbs).</li>
<li><strong>Systematic error</strong> (bias): The zero point is wrong. Every reading is 5 lbs too high. Weigh yourself once: 155 lbs (wrong). Weigh yourself 1,000 times: still ~155 lbs (precisely wrong). More measurements <strong>don’t fix</strong> a bad instrument.</li>
</ul>
<p>That was <em>Literary Digest</em>’s fatal flaw: a <strong>miscalibrated “instrument”</strong> for measuring public opinion. Taking 2.4 million measurements with a biased device only produced <strong>false confidence</strong>.</p>
<p><strong>Where did the bias come from?</strong></p>
<p>Two biases pushed in the <em>same direction</em> (toward Landon):</p>
<ol type="1">
<li><strong>Selection (coverage) bias — who <em>could</em> be sampled</strong>
<ul>
<li>Sampling frames: telephone directories, automobile registrations, magazine subscriber lists, city directories.</li>
<li>Depression-era reality: these lists skewed <strong>wealthier</strong> than the electorate.</li>
<li>Result: systematic <strong>under-representation</strong> of working-class Roosevelt supporters.</li>
</ul></li>
<li><strong>Nonresponse bias — who <em>chose</em> to respond</strong>
<ul>
<li>Only about <strong>24%</strong> of contacted people responded.</li>
<li>More motivated (disproportionately anti-Roosevelt) voters were likelier to reply; satisfied voters were less inclined.</li>
</ul></li>
</ol>
<p>Together, these biases created large <strong>systematic error</strong> that <strong>no sample size</strong> could overcome.</p>
<p><strong>Why sample size couldn’t save the poll</strong></p>
<p>Drawing from biased frames is like using a scale calibrated for wealthy Americans to “weigh” all Americans. Contacting 2.4 million people from those lists yielded <strong>2.4 million biased measurements</strong>. The poll’s computed “margin of error” captured only <strong>random</strong> variation; if it had been a simple random sample, the 95% MOE at n = 2.4M would be about <strong>±0.06 percentage points</strong> — tiny, but irrelevant to the much larger bias.</p>
<p><strong>The crucial lesson:</strong> <strong>A large biased sample is worse than a small, representative one.</strong> It delivers spurious precision on the wrong answer.</p>
<p><strong>Modern polling: smaller, but smarter</strong></p>
<ul>
<li><strong>Probability sampling</strong>: Every voter has a known, non-zero selection chance.</li>
<li><strong>Demographic weighting/calibration</strong>: Adjust for groups that under-respond.</li>
<li><strong>Total survey error mindset</strong>: Design for coverage, nonresponse, measurement, and processing errors — not just sampling error.</li>
</ul>
<p>The <em>Literary Digest</em> fiasco taught pollsters that <strong>how</strong> you sample matters far more than <strong>how many</strong> you sample.</p>
</div>
</div>
<hr>
</section>
</section>
</section>
<section id="understanding-randomness" class="level2" data-number="1.4">
<h2 data-number="1.4" class="anchored" data-anchor-id="understanding-randomness"><span class="header-section-number">1.4</span> Understanding Randomness</h2>
<p>A <strong>random experiment</strong> is any process whose result cannot be predicted with certainty, such as tossing a coin or rolling a die.</p>
<p>An <strong>outcome</strong> is a single possible result of that experiment—for example, getting “heads” or rolling a “5”.</p>
<p>An <strong>event</strong> is a set of one or more outcomes that we’re interested in; it could be a simple event (like rolling exactly a 3) or a compound event (like rolling an even number, which includes the outcomes 2, 4, and 6).</p>
<blockquote class="blockquote">
<p><strong>Probability</strong> is a way of measuring how likely something is to happen. It’s a number between 0 and 1 (or 0% and 100%) that represents the chance of an event occurring.</p>
</blockquote>
<p>If something has a probability of 0, it’s impossible - it will never happen. If something has a probability of 1, it’s certain - it will definitely happen. Most things fall somewhere in between.</p>
<p>For example, when you flip a fair coin, there’s a 0.5 (or 50%) probability it will land on heads, because there are two equally likely outcomes and heads is one of them.</p>
<p>Probability helps us make sense of uncertainty and randomness in the world.</p>
<hr>
<blockquote class="blockquote">
<p>In statistics, <strong>randomness</strong> is an orderly way to describe uncertainty. While each individual outcome is unpredictable, <strong>stable patterns (more formally, empirical distributions of outcomes converge to probability distributions) emerge over many repetitions</strong>.</p>
</blockquote>
<p><strong>Example:</strong> Flip a fair coin:</p>
<ul>
<li><strong>Single flip</strong>: Completely unpredictable—you can’t know if it’ll be heads or tails</li>
<li><strong>100 flips</strong>: You’ll get close to 50% heads (maybe 48 or 53)</li>
<li><strong>10,000 flips</strong>: Almost certainly very close to 50% heads (perhaps 49.8%)</li>
</ul>
<p>The same applies to dice: you can’t predict your next roll, but roll 600 times and each number (1-6) will appear close to 100 times. This predictable long-run behavior from unpredictable individual events is the essence of statistical randomness.</p>
<section id="types-of-randomness" class="level3">
<h3 class="anchored" data-anchor-id="types-of-randomness">Types of Randomness</h3>
<p><strong>Epistemic vs.&nbsp;Ontological Randomness:</strong></p>
<ul>
<li><strong>Epistemic</strong> (due to incomplete knowledge): We treat an outcome as random because not all determinants are observed or conditions are not controlled.
<ul>
<li><em>Examples:</em> The decision of an individual respondent in a poll (we don’t know the full set of motivations); measurement error in a survey (limited precision, item nonresponse); a coin toss modeled as random because minute, unobserved differences in initial conditions determine the outcome.</li>
</ul></li>
<li><strong>Ontological</strong> (intrinsic indeterminacy): Even complete knowledge does not remove outcome uncertainty.
<ul>
<li><em>Examples:</em> The time to radioactive decay of an atom; quantum mechanical phenomena.</li>
</ul></li>
</ul>
</section>
<section id="related-concepts" class="level3">
<h3 class="anchored" data-anchor-id="related-concepts">Related Concepts</h3>
<p><strong>Randomness vs.&nbsp;Haphazardness:</strong> Statistical randomness has mathematical structure and follows probability laws—it’s orderly uncertainty. Haphazardness suggests complete disorder without underlying patterns or rules.</p>
<p><strong>Chaos</strong> is like a pinball machine: you know all the rules (physics), but the tiniest difference in where you release the ball—off by a fraction of a millimeter—leads to completely different outcomes. The system is deterministic and follows fixed laws, but errors compound so fast that prediction becomes impossible in practice, even with perfect knowledge of those laws. It’s “I know exactly how this works, but I still can’t tell you what happens next.” <strong>(Epistemic) randomness</strong> is like a card face-down on a table: the card is already the 7 of hearts (or whatever it is), it’s not changing or evolving. You just don’t know which card it is yet. The “randomness” is purely due to incomplete knowledge—flip the card over and the uncertainty vanishes completely. The key difference: chaos remains unpredictable even with perfect information about the rules, while epistemic randomness disappears the moment you gain the missing information about the current state.</p>
<p><strong>Entropy:</strong> A measure of disorder or uncertainty in a system. High entropy means high unpredictability; low entropy means high order (low uncertainty). In statistics, entropy quantifies the uncertainty in a probability distribution.</p>
<hr>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bias vs.&nbsp;Random Error
</div>
</div>
<div class="callout-body-container callout-body">
<p>Statistical (prediction) error can be decomposed into two main components: <strong>bias</strong> (systematic error) and <strong>random error</strong> (unpredictable variation).</p>
<p><strong>Bias</strong> is like a miscalibrated scale that consistently reads 2 kg too high—every measurement is wrong in the <em>same direction</em>. It’s systematic error.</p>
<p><strong>Random error</strong> is the unpredictable variation in your observations, like:</p>
<ul>
<li>A dart player aiming at the bullseye—each throw lands in a slightly different spot due to hand tremor, air currents, tiny muscle variations</li>
<li>Measuring someone’s height multiple times and getting 174.8 cm, 175.0 cm, 175.3 cm—small fluctuations from posture changes, breathing, how you read the scale, and natural body variations</li>
<li>A weather model that’s sometimes 2°C too high, sometimes 1°C too low, sometimes spot on</li>
<li><strong>Opinion polls</strong> showing 52%, 49%, 51% support across different surveys—each random sample gives slightly different results, but they cluster around the true value</li>
</ul>
<p><strong>Random error is measured by variance</strong>—the average squared deviation of observations from their mean. It quantifies how much your data points (predictions) scatter.</p>
<p>Random error is like asking 5 friends to estimate how many jellybeans are in a jar—they’ll all give different answers just due to chance, but those differences scatter randomly around the truth rather than all being wrong in the same direction.</p>
<p><strong>Polling example</strong>: Bias is like polling only at the gym at 6am—you’ll always get more health-conscious, early-rising, employed people and always miss night-shift workers, people with young kids, etc. The poll is broken in a predictable way. Or: only counting responses from people who actually answer unknown phone calls—you’ll systematically miss everyone (especially younger people) who screens their calls.</p>
<p><strong>Key difference</strong>: Averaging more observations reduces random error but <em>never</em> fixes bias. You can’t average your way out of a miscalibrated scale—or a biased sampling method!</p>
</div>
</div>
<hr>
</section>
</section>
<section id="populations-and-samples" class="level2" data-number="1.5">
<h2 data-number="1.5" class="anchored" data-anchor-id="populations-and-samples"><span class="header-section-number">1.5</span> Populations and Samples</h2>
<p>Understanding the distinction between populations and samples is crucial for proper statistical analysis.</p>
<section id="population" class="level3">
<h3 class="anchored" data-anchor-id="population">Population</h3>
<p>A <strong>population</strong> is the complete set of individuals, objects, or measurements about which we wish to draw conclusions. The key word here is “complete”—a population includes every single member of the group we’re studying.</p>
<p><strong>Examples of Populations in Demography:</strong></p>
<ul>
<li><strong>All residents of India as of January 1, 2024</strong>: This includes every person living in India on that specific date—approximately 1.4 billion people.</li>
<li><strong>All births in Sweden during 2023</strong>: Every baby born within Swedish borders during that calendar year—roughly 100,000 births.</li>
<li><strong>All households in Tokyo</strong>: Every residential unit where people live, cook, and sleep separately from others—about 7 million households.</li>
<li><strong>All deaths from COVID-19 worldwide in 2020</strong>: Every death where COVID-19 was listed as a cause—several million deaths.</li>
</ul>
<p>Populations can be:</p>
<p><strong>Finite</strong>: Having a countable number of members (all current U.S. citizens, all Polish municipalities in 2024)</p>
<p><strong>Infinite</strong>: Theoretical or uncountably large (all possible future births, all possible coin tosses or dice flips)</p>
<p><strong>Fixed</strong>: Defined at a specific point in time (all residents on census day)</p>
<p><strong>Dynamic</strong>: Changing over time (the population of a city that experiences births, deaths, and migration daily)</p>
</section>
<section id="sample" class="level3">
<h3 class="anchored" data-anchor-id="sample">Sample</h3>
<p>A <strong>sample</strong> is a subset of the population that is actually observed or measured. We study samples because examining entire populations is often impossible, impractical, or unnecessary.</p>
<p><strong>Why We Use Samples:</strong></p>
<p><strong>Practical Impossibility</strong>: Imagine testing every person in China for a disease. By the time you finished testing 1.4 billion people, the disease situation would have changed completely, and some people tested early would need retesting.</p>
<p><strong>Cost Considerations</strong>: The 2020 U.S. Census cost approximately $16 billion. Conducting such complete enumerations frequently would be prohibitively expensive. A well-designed sample survey can provide accurate estimates at a fraction of the cost.</p>
<p><strong>Time Constraints</strong>: Policy makers often need information quickly. A sample survey of 10,000 people can be completed in weeks, while a census takes years to plan, execute, and process.</p>
<p><strong>Destructive Measurement</strong>: Some measurements destroy what’s being measured. Testing the lifespan of light bulbs or the breaking point of materials requires using samples.</p>
<p><strong>Greater Accuracy</strong>: Surprisingly, samples can sometimes be more accurate than complete enumerations. With a sample, you can afford better training for interviewers, more careful data collection, and more thorough quality checks.</p>
<p><strong>Example of Sample vs.&nbsp;Population:</strong></p>
<p>Let’s say we want to know the average household size in New York City:</p>
<ul>
<li><strong>Population</strong>: All 3.2 million households in NYC</li>
<li><strong>Census approach</strong>: Attempt to contact every household (expensive, time-consuming, some will be missed)</li>
<li><strong>Sample approach</strong>: Randomly select 5,000 households, carefully measure their sizes, and use this to estimate the average for all households</li>
<li><strong>Result</strong>: The sample might find an average of 2.43 people per household with a margin of error of ±0.05, meaning we’re confident the true population average is between 2.38 and 2.48</li>
</ul>
<hr>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Sampling Methods Overview
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Sampling</strong> selects a subset from a population to estimate characteristics. The <strong>sampling frame</strong> (the list from which we sample) must ideally include every member exactly once. Frame problems include undercoverage, overcoverage, duplication, and clustering.</p>
<section id="probability-sampling-statistical-inference-possible" class="level3">
<h3 class="anchored" data-anchor-id="probability-sampling-statistical-inference-possible">Probability Sampling (Statistical Inference Possible)</h3>
<ul>
<li><p><strong>Simple Random Sampling (SRS)</strong>: Every sample of size <span class="math inline">n</span> has equal probability. Gold standard but often impractical. Each unit has probability <span class="math inline">n/N</span> of selection.</p></li>
<li><p><strong>Systematic Sampling</strong>: Select every <span class="math inline">k</span>th element where <span class="math inline">k = N/n</span>. Simple to implement but watch for hidden periodicity in the frame.</p></li>
<li><p><strong>Stratified Sampling</strong>: Divide population into homogeneous strata, sample independently within each. Ensures subgroup representation and can increase precision substantially. Allocation types: proportional, optimal (Neyman), or equal.</p></li>
<li><p><strong>Cluster Sampling</strong>: Select groups (clusters) rather than individuals. Cost-effective for geographically dispersed populations but less efficient than SRS (design effect: DEFF = Variance(cluster)/Variance(SRS)). Can be single-stage or multi-stage.</p></li>
</ul>
</section>
<section id="non-probability-sampling-limited-statistical-inference" class="level3">
<h3 class="anchored" data-anchor-id="non-probability-sampling-limited-statistical-inference">Non-Probability Sampling (Limited Statistical Inference)</h3>
<ul>
<li><p><strong>Convenience</strong>: Selection by ease of access. Useful for pilots/exploratory work but severe selection bias likely.</p></li>
<li><p><strong>Purposive/Judgmental</strong>: Deliberate selection of typical, extreme, or information-rich cases. Valuable for qualitative research and rare populations.</p></li>
<li><p><strong>Quota</strong>: Match population proportions but without random selection. Fast and cheap but hidden selection bias and no measure of sampling error. (See: 1948 Dewey-Truman polling failure)</p></li>
<li><p><strong>Snowball</strong>: Participants recruit others from their networks. Essential for hidden populations (drug users, undocumented immigrants) but biased toward well-connected individuals.</p></li>
</ul>
<p><strong>Key Principle</strong>: Probability sampling enables valid statistical inference; non-probability methods may be necessary for practical or ethical reasons but limit generalizability.</p>
</section>
</div>
</div>
<hr>
</section>
</section>
<section id="superpopulation-and-data-generating-process-dgp" class="level2 calout-note" data-number="1.6">
<h2 data-number="1.6" class="anchored" data-anchor-id="superpopulation-and-data-generating-process-dgp"><span class="header-section-number">1.6</span> Superpopulation and Data Generating Process (DGP) (*)</h2>
<hr>
<section id="superpopulation" class="level3">
<h3 class="anchored" data-anchor-id="superpopulation"><strong>Superpopulation</strong></h3>
<p>A <strong>superpopulation</strong> is a theoretical infinite population from which your finite population is considered to be one random sample.</p>
<p><strong>Think of it in three levels:</strong></p>
<ol type="1">
<li><strong>Superpopulation</strong>: An infinite collection of possible values (theoretical)</li>
<li><strong>Finite population</strong>: The actual population you could theoretically census (e.g., all 50 US states, all 10,000 firms in an industry)</li>
<li><strong>Sample</strong>: The subset you actually observe (e.g., 30 states, 500 firms)</li>
</ol>
<p><strong>Why do we need this concept?</strong></p>
<p>Consider the 50 US states. You might measure unemployment rate for all 50 states—a complete census, no sampling needed. But you still want to:</p>
<ul>
<li>Test if unemployment is related to education levels</li>
<li>Predict next year’s unemployment rates</li>
<li>Determine if differences between states are “statistically significant”</li>
</ul>
<p>Without the superpopulation concept, you’re stuck—you have all the data, so what’s left to infer? The answer: treat this year’s 50 values as one draw from an infinite superpopulation of possible values that could occur under similar conditions.</p>
<p><strong>Mathematical representation:</strong></p>
<ul>
<li>Finite population value: <span class="math inline">Y_i</span> (state i’s unemployment rate)</li>
<li>Superpopulation model: <span class="math inline">Y_i = \mu + \epsilon_i</span> where <span class="math inline">\epsilon_i \sim (0, \sigma^2)</span></li>
<li>The 50 observed values are one realization of this process</li>
</ul>
<hr>
</section>
<section id="data-generating-process-the-true-recipe" class="level3">
<h3 class="anchored" data-anchor-id="data-generating-process-the-true-recipe"><strong>Data Generating Process: The True Recipe</strong></h3>
<p>The <strong>Data Generating Process (DGP)</strong> is the actual mechanism that creates your data—including all factors, relationships, and random elements.</p>
<p><strong>An intuitive example:</strong> Suppose student test scores are truly generated by:</p>
<p><span class="math display">\text{Score}_i = 50 + 2(\text{StudyHours}_i) + 3(\text{SleepHours}_i) - 5(\text{Stress}_i) + 1.5(\text{Breakfast}_i) + \epsilon_i</span></p>
<p>This is the TRUE DGP. But you don’t know this! You might estimate:</p>
<p><span class="math display">\text{Score}_i = \alpha + \beta(\text{StudyHours}_i) + u_i</span></p>
<p>Your model is simpler than reality. You’re missing variables (sleep, stress, breakfast), so your estimates might be biased. The <span class="math inline">u_i</span> term captures everything you missed.</p>
<p><strong>Key insight</strong>: We never know the true DGP. Our statistical models are always approximations, trying to capture the most important parts of the unknown, complex truth.</p>
<hr>
</section>
<section id="two-approaches-to-statistical-inference" class="level3">
<h3 class="anchored" data-anchor-id="two-approaches-to-statistical-inference"><strong>Two Approaches to Statistical Inference</strong></h3>
<p>When analyzing data, especially from surveys or samples, we can take two philosophical approaches:</p>
<section id="design-based-inference" class="level4">
<h4 class="anchored" data-anchor-id="design-based-inference"><strong>1. Design-Based Inference</strong></h4>
<ul>
<li><strong>Philosophy</strong>: The population values are fixed numbers. Randomness comes ONLY from which units we happened to sample.</li>
<li><strong>Focus</strong>: How we selected the sample (simple random, stratified, cluster sampling, etc.)</li>
<li><strong>Example</strong>: The mean income of California counties is a fixed number. We sample 10 counties. Our uncertainty comes from which 10 we randomly selected.</li>
<li><strong>No models needed</strong>: We don’t assume anything about the population values’ distribution</li>
</ul>
</section>
<section id="model-based-inference" class="level4">
<h4 class="anchored" data-anchor-id="model-based-inference"><strong>2. Model-Based Inference</strong></h4>
<ul>
<li><strong>Philosophy</strong>: The population values themselves are realizations from some probability model (superpopulation)</li>
<li><strong>Focus</strong>: The statistical model generating the population values</li>
<li><strong>Example</strong>: Each California county’s income is drawn from: <span class="math inline">Y_i = \mu + \epsilon_i</span> where <span class="math inline">\epsilon_i \sim N(0, \sigma^2)</span></li>
<li><strong>Models required</strong>: We make assumptions about how the data were generated</li>
</ul>
<p><strong>Which is better?</strong></p>
<ul>
<li><strong>Large populations, good random samples</strong>: Design-based works well</li>
<li><strong>Small populations (like 50 states)</strong>: Model-based often necessary</li>
<li><strong>Complete enumeration</strong>: Only model-based allows inference</li>
<li><strong>Modern practice</strong>: Often combines both approaches</li>
</ul>
<hr>
</section>
</section>
<section id="practical-example-analyzing-state-education-spending" class="level3">
<h3 class="anchored" data-anchor-id="practical-example-analyzing-state-education-spending"><strong>Practical Example: Analyzing State Education Spending</strong></h3>
<p>Suppose you collect education spending per pupil for all 50 US states.</p>
<p><strong>Without superpopulation thinking:</strong></p>
<ul>
<li>You have all 50 values—that’s it</li>
<li>The mean is the mean, no uncertainty</li>
<li>You can’t test hypotheses or make predictions</li>
</ul>
<p><strong>With superpopulation thinking:</strong></p>
<ul>
<li>This year’s 50 values are one realization from a superpopulation</li>
<li>Model: <span class="math inline">\text{Spending}_i = \mu + \beta(\text{StateIncome}_i) + \epsilon_i</span></li>
<li>Now you can:
<ul>
<li>Test if spending relates to state income (<span class="math inline">\beta \neq 0</span>?)</li>
<li>Predict next year’s values</li>
<li>Calculate confidence intervals</li>
</ul></li>
</ul>
<p><strong>The key insight</strong>: Even with complete data, the superpopulation framework enables statistical inference by treating observed values as one possible outcome from an underlying stochastic process.</p>
<hr>
</section>
<section id="summary" class="level3">
<h3 class="anchored" data-anchor-id="summary"><strong>Summary</strong></h3>
<ul>
<li><p><strong>Superpopulation</strong>: Treats your finite population as one draw from an infinite possibility space—essential when your finite population is small or completely observed</p></li>
<li><p><strong>DGP</strong>: The true (unknown) process creating your data—your models try to approximate it</p></li>
</ul>
</section>
</section>
<hr>
<section id="data-and-distributions" class="level2" data-number="1.7">
<h2 data-number="1.7" class="anchored" data-anchor-id="data-and-distributions"><span class="header-section-number">1.7</span> Data and Distributions</h2>
<p><strong>Data</strong>: Information collected during research – this includes survey responses, experimental results, economic indicators, social media content, or any other measurable observations.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding Different Types of Data Structures (Data Sets) and Their Formats
</div>
</div>
<div class="callout-body-container callout-body">
<section id="cross-sectional-data" class="level4">
<h4 class="anchored" data-anchor-id="cross-sectional-data">Cross-sectional Data</h4>
<p>Observations for variables (columns in a database) collected at a single point in time across multiple entities/individuals:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Individual</th>
<th>Age</th>
<th>Income</th>
<th>Education</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>1</td>
<td>25</td>
<td>50000</td>
<td>Bachelor’s</td>
</tr>
<tr class="even">
<td>2</td>
<td>35</td>
<td>75000</td>
<td>Master’s</td>
</tr>
<tr class="odd">
<td>3</td>
<td>45</td>
<td>90000</td>
<td>PhD</td>
</tr>
</tbody>
</table>
</section>
<section id="time-series-data" class="level4">
<h4 class="anchored" data-anchor-id="time-series-data">Time Series Data</h4>
<p>Observations of a single entity tracked over multiple time points:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Year</th>
<th>GDP (in billions)</th>
<th>Unemployment Rate</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2018</td>
<td>20,580</td>
<td>3.9%</td>
</tr>
<tr class="even">
<td>2019</td>
<td>21,433</td>
<td>3.7%</td>
</tr>
<tr class="odd">
<td>2020</td>
<td>20,933</td>
<td>8.1%</td>
</tr>
</tbody>
</table>
</section>
<section id="panel-data-longitudinal-data" class="level4">
<h4 class="anchored" data-anchor-id="panel-data-longitudinal-data">Panel Data (Longitudinal Data)</h4>
<p>Observations of multiple entities tracked over time:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Country</th>
<th>Year</th>
<th>GDP per capita</th>
<th>Life Expectancy</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>USA</td>
<td>2018</td>
<td>62,794</td>
<td>78.7</td>
</tr>
<tr class="even">
<td>USA</td>
<td>2019</td>
<td>65,118</td>
<td>78.8</td>
</tr>
<tr class="odd">
<td>Canada</td>
<td>2018</td>
<td>46,194</td>
<td>81.9</td>
</tr>
<tr class="even">
<td>Canada</td>
<td>2019</td>
<td>46,194</td>
<td>82.0</td>
</tr>
</tbody>
</table>
</section>
<section id="time-series-cross-sectional-tscs-data" class="level4">
<h4 class="anchored" data-anchor-id="time-series-cross-sectional-tscs-data">Time-series Cross-sectional (TSCS) Data</h4>
<p>A special case of panel data where:</p>
<ul>
<li>Number of time points &gt; Number of entities</li>
<li>Similar structure to panel data but with emphasis on temporal depth</li>
<li>Common in political science and economics research</li>
</ul>
<hr>
</section>
<section id="data-formats" class="level3">
<h3 class="anchored" data-anchor-id="data-formats">Data Formats</h3>
<section id="wide-format" class="level4">
<h4 class="anchored" data-anchor-id="wide-format">Wide Format</h4>
<p>Each row represents an entity; columns represent variables/time points:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Country</th>
<th>GDP_2018</th>
<th>GDP_2019</th>
<th>LE_2018</th>
<th>LE_2019</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>USA</td>
<td>62,794</td>
<td>65,118</td>
<td>78.7</td>
<td>78.8</td>
</tr>
<tr class="even">
<td>Canada</td>
<td>46,194</td>
<td>46,194</td>
<td>81.9</td>
<td>82.0</td>
</tr>
</tbody>
</table>
</section>
<section id="long-format" class="level4">
<h4 class="anchored" data-anchor-id="long-format">Long Format</h4>
<p>Each row represents a unique entity-time-variable combination:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Country</th>
<th>Year</th>
<th>Variable</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>USA</td>
<td>2018</td>
<td>GDP per capita</td>
<td>62,794</td>
</tr>
<tr class="even">
<td>USA</td>
<td>2019</td>
<td>GDP per capita</td>
<td>65,118</td>
</tr>
<tr class="odd">
<td>USA</td>
<td>2018</td>
<td>Life Expectancy</td>
<td>78.7</td>
</tr>
<tr class="even">
<td>USA</td>
<td>2019</td>
<td>Life Expectancy</td>
<td>78.8</td>
</tr>
<tr class="odd">
<td>Canada</td>
<td>2018</td>
<td>GDP per capita</td>
<td>46,194</td>
</tr>
<tr class="even">
<td>Canada</td>
<td>2019</td>
<td>GDP per capita</td>
<td>46,194</td>
</tr>
<tr class="odd">
<td>Canada</td>
<td>2018</td>
<td>Life Expectancy</td>
<td>81.9</td>
</tr>
<tr class="even">
<td>Canada</td>
<td>2019</td>
<td>Life Expectancy</td>
<td>82.0</td>
</tr>
</tbody>
</table>
<p><strong>Note:</strong> Long format is generally preferred for:</p>
<ul>
<li>Data manipulation in R and Python</li>
<li>Statistical analysis</li>
<li>Data visualization</li>
</ul>
</section>
</section>
</div>
</div>
<hr>
<p>Understanding data types and distributions is fundamental to choosing appropriate analyses and interpreting results correctly.</p>
<section id="types-of-data" class="level3">
<h3 class="anchored" data-anchor-id="types-of-data">Types of Data</h3>
<p><strong>Data</strong> consists of collected observations or measurements. The type of data determines what mathematical operations (e.g.&nbsp;multiplication) are meaningful and what statistical methods apply.</p>
<section id="quantitative-data" class="level4">
<h4 class="anchored" data-anchor-id="quantitative-data">Quantitative Data</h4>
<p><strong>Continuous Data</strong> can take any value within a range:</p>
<p><strong>Examples with Demographic Relevance:</strong></p>
<ul>
<li><strong>Age</strong>: Can be 25.5 years, 25.51 years, 25.514 years (precision limited only by measurement)</li>
<li><strong>Body Mass Index</strong>: 23.7 kg/m²</li>
<li><strong>Fertility Rate</strong>: 1.73 children per woman</li>
<li><strong>Population Density</strong>: 4,521.3 people per km²</li>
</ul>
<p><strong>Properties:</strong></p>
<ul>
<li>Can perform all arithmetic operations</li>
<li>Can calculate means, standard deviations</li>
<li>Often follow known probability distributions (e.g.&nbsp;weight and Normal distribution)</li>
</ul>
<p><strong>Discrete Data</strong> can only take specific values:</p>
<p><strong>Examples:</strong></p>
<ul>
<li><strong>Number of Children</strong>: 0, 1, 2, 3… (can’t have 2.5 children)</li>
<li><strong>Number of Marriages</strong>: 0, 1, 2, 3…</li>
<li><strong>Household Size</strong>: 1, 2, 3, 4… people</li>
<li><strong>Number of Doctor Visits</strong>: 0, 1, 2, 3… per year</li>
</ul>
</section>
<section id="qualitativecategorical-data" class="level4">
<h4 class="anchored" data-anchor-id="qualitativecategorical-data">Qualitative/Categorical Data</h4>
<p><strong>Nominal Data</strong> represents categories with no inherent order:</p>
<p><strong>Examples:</strong></p>
<ul>
<li><strong>Country of Birth</strong>: USA, China, India, Brazil…</li>
<li><strong>Religion</strong>: Christian, Muslim, Hindu, Buddhist, None…</li>
<li><strong>Marital Status</strong>: Single, Married, Divorced, Widowed</li>
<li><strong>Cause of Death</strong>: Heart disease, Cancer, Accident, Stroke…</li>
<li><strong>Blood Type</strong>: A, B, AB, O</li>
</ul>
<p><strong>What We Can Do:</strong></p>
<ul>
<li>Count frequencies</li>
<li>Calculate proportions</li>
<li>Find mode</li>
<li>Test for independence</li>
</ul>
<p><strong>What We Cannot Do:</strong></p>
<ul>
<li>Calculate mean (average religion makes no sense)</li>
<li>Order categories meaningfully</li>
<li>Compute distances between categories</li>
</ul>
<p><strong>Ordinal Data</strong> represents ordered categories:</p>
<p><strong>Examples:</strong></p>
<ul>
<li><strong>Education Level</strong>: None &lt; Primary &lt; Secondary &lt; Tertiary</li>
<li><strong>Socioeconomic Status</strong>: Low &lt; Middle &lt; High</li>
<li><strong>Self-Rated Health</strong>: Poor &lt; Fair &lt; Good &lt; Excellent</li>
<li><strong>Agreement Scale</strong>: Strongly Disagree &lt; Disagree &lt; Neutral &lt; Agree &lt; Strongly Agree</li>
</ul>
<p><strong>The Challenge</strong>: Intervals between categories aren’t necessarily equal. The “distance” from Poor to Fair health may not equal the distance from Good to Excellent.</p>
</section>
</section>
<section id="data-distribution" class="level3">
<h3 class="anchored" data-anchor-id="data-distribution">Data Distribution</h3>
<p>A <strong>data distribution</strong> describes how values spread across possible outcomes (what values and how often a variable takes). Distributions tell us what values are common, what values are rare, and what patterns exist in our data.</p>
<p>Understanding distributions is fundamental to statistics because it helps us summarize large datasets, identify patterns, and make informed decisions.</p>
<p>For example, knowing that most students score between 60-80 on an exam tells us more than just knowing the average score.</p>
<section id="frequency-relative-frequency-and-density" class="level4">
<h4 class="anchored" data-anchor-id="frequency-relative-frequency-and-density">Frequency, Relative Frequency, and Density</h4>
<p>When we analyze data, we’re often interested in how many times each value (or range of values) appears. This leads us to three related concepts:</p>
<p><strong>(Absolute) Frequency</strong> is simply the count of how many times a particular value or category occurs in your data. If 15 students scored between 70-80 points on an exam, the frequency for that range is 15.</p>
<p><strong>Relative frequency</strong> expresses frequency as a proportion or percentage of the total. It answers the question: “What fraction of all observations fall into this category?” Relative frequency is calculated as:</p>
<p><span class="math display">\text{Relative Frequency} = \frac{\text{Frequency}}{\text{Total Number of Observations}}</span></p>
<p>If 15 out of 100 students scored 70-80 points, the relative frequency is 15/100 = 0.15 or 15%. Relative frequencies always sum to 1 (or 100%), making them useful for comparing distributions with different sample sizes.</p>
<p><strong>Density (the degree of compactness of something, the probability per unit length)</strong> is similar to relative frequency but accounts for the width of intervals. When we group continuous data (like time or unemployment rate) into bins of different widths, density ensures fair comparison. Density is calculated as:</p>
<p><span class="math inline">\text{Density} = \frac{\text{Relative Frequency}}{\text{Interval Width}}</span></p>
<p>Density is particularly important for continuous variables because it ensures that the total area under the distribution equals 1, which allows us to interpret areas as probabilities.</p>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>The probability of an event is a number between 0 and 1; the larger the probability, the more likely an event is to occur.</p>
</div>
</div>
<p><strong>Cumulative frequency</strong> tells us how many observations fall at or below a certain value. Instead of asking “how many observations are in this category?”, cumulative frequency answers “how many observations are in this category or any category below it?” It’s calculated by adding up all frequencies from the lowest value up to and including the current value.</p>
<p>Similarly, <strong>cumulative relative frequency</strong> expresses this as a proportion of the total, answering “what percentage of observations fall at or below this value?” For example, if the cumulative relative frequency at score 70 is 0.40, this means 40% of students scored 70 or below.</p>
</section>
<section id="distribution-tables" class="level4">
<h4 class="anchored" data-anchor-id="distribution-tables">Distribution Tables</h4>
<p>A <strong>frequency distribution table</strong> organizes data by showing how observations are distributed across different values or intervals. Here’s an example with exam scores:</p>
<table class="caption-top table">
<colgroup>
<col style="width: 12%">
<col style="width: 10%">
<col style="width: 18%">
<col style="width: 20%">
<col style="width: 29%">
<col style="width: 8%">
</colgroup>
<thead>
<tr class="header">
<th>Score Range</th>
<th>Frequency</th>
<th>Relative Frequency</th>
<th>Cumulative Frequency</th>
<th>Cumulative Relative Frequency</th>
<th>Density</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0-50</td>
<td>10</td>
<td>0.10</td>
<td>10</td>
<td>0.10</td>
<td>0.002</td>
</tr>
<tr class="even">
<td>50-70</td>
<td>30</td>
<td>0.30</td>
<td>40</td>
<td>0.40</td>
<td>0.015</td>
</tr>
<tr class="odd">
<td>70-90</td>
<td>45</td>
<td>0.45</td>
<td>85</td>
<td>0.85</td>
<td>0.0225</td>
</tr>
<tr class="even">
<td>90-100</td>
<td>15</td>
<td>0.15</td>
<td>100</td>
<td>1.00</td>
<td>0.015</td>
</tr>
<tr class="odd">
<td><strong>Total</strong></td>
<td><strong>100</strong></td>
<td><strong>1.00</strong></td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
</tbody>
</table>
<p>This table reveals that most students scored in the 70-90 range, while very few scored below 50 or above 90. The cumulative columns show us that 40% of students scored below 70, and 85% scored below 90. Such tables are invaluable for getting a quick overview of your data before conducting more complex analyses.</p>
</section>
<section id="visualizing-distributions-histograms" class="level4">
<h4 class="anchored" data-anchor-id="visualizing-distributions-histograms">Visualizing Distributions: Histograms</h4>
<p>A <strong>histogram</strong> is a graphical representation of a frequency distribution. It displays data using bars where:</p>
<ul>
<li>The x-axis shows the values or intervals (bins)</li>
<li>The y-axis can show frequency, relative frequency, or density</li>
<li>The height of each bar represents the count, proportion, or density for that interval</li>
<li>Bars touch each other (no gaps) for continuous variables</li>
</ul>
<p><strong>Choosing bin widths</strong>: The number and width of bins significantly affects how your histogram looks. Too few bins hide important patterns, while too many bins create “noise” and make patterns hard to see.</p>
<blockquote class="blockquote">
<p>In statistics, <strong>noise</strong> is unwanted random variation that obscures the pattern we’re trying to find. Think of it like static on a radio—it makes the music (the “signal”) harder to hear. In data, noise comes from measurement errors, random fluctuations, or the inherent variability in what we’re studying. Noise is random variation in data that hides the real patterns we want to see, similar to how background noise makes conversation difficult to hear.</p>
</blockquote>
<p>Several approaches help determine appropriate bin widths:</p>
<ul>
<li><p><strong>Sturges’ rule</strong>: Use <span class="math inline">k = 1 + \log_2(n)</span> bins, where <span class="math inline">n</span> is the sample size. This works well for roughly symmetric distributions.</p></li>
<li><p><strong>Square root rule</strong>: Use <span class="math inline">k = \sqrt{n}</span> bins. A simple, reasonable default for many situations.</p></li>
</ul>
<p>In R, you can specify bins in several ways:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify number of bins</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(exam_scores, <span class="at">breaks =</span> <span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify exact break points</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(exam_scores, <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">10</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-2-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Let R choose automatically (uses Sturges' rule by default)</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(exam_scores)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-2-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The best approach is often to experiment with different bin widths to find what best reveals your data’s pattern. Start with a default, then try fewer and more bins to see how the story changes.</p>
<p><strong>Defining bin boundaries</strong>: When creating bins for a frequency table, you must decide how to handle values that fall exactly on the boundaries. For example, if you have bins 0-10 and 10-20, which bin does the value 10 belong to?</p>
<p>The solution is to use <strong>interval notation</strong> to specify whether each boundary is included or excluded:</p>
<ul>
<li><strong>Closed interval</strong> <span class="math inline">[a, b]</span> includes both endpoints: <span class="math inline">a \leq x \leq b</span></li>
<li><strong>Open interval</strong> <span class="math inline">(a, b)</span> excludes both endpoints: <span class="math inline">a &lt; x &lt; b</span></li>
<li><strong>Half-open interval</strong> <span class="math inline">[a, b)</span> includes the left endpoint but excludes the right: <span class="math inline">a \leq x &lt; b</span></li>
<li><strong>Half-open interval</strong> <span class="math inline">(a, b]</span> excludes the left endpoint but includes the right: <span class="math inline">a &lt; x \leq b</span></li>
</ul>
<p><strong>Standard convention</strong>: Most statistical software, including R, uses <strong>left-closed, right-open intervals</strong> <span class="math inline">[a, b)</span> for all bins except the last one, which is fully closed <span class="math inline">[a, b]</span>. This means:</p>
<ul>
<li>The value at the lower boundary is included in the bin</li>
<li>The value at the upper boundary belongs to the next bin</li>
<li>The very last bin includes both boundaries to capture the maximum value</li>
</ul>
<p>For example, with bins 0-20, 20-40, 40-60, 60-80, 80-100:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Score Range</th>
<th>Interval Notation</th>
<th>Values Included</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>0-20</td>
<td><span class="math inline">[0, 20)</span></td>
<td>0 ≤ score &lt; 20</td>
</tr>
<tr class="even">
<td>20-40</td>
<td><span class="math inline">[20, 40)</span></td>
<td>20 ≤ score &lt; 40</td>
</tr>
<tr class="odd">
<td>40-60</td>
<td><span class="math inline">[40, 60)</span></td>
<td>40 ≤ score &lt; 60</td>
</tr>
<tr class="even">
<td>60-80</td>
<td><span class="math inline">[60, 80)</span></td>
<td>60 ≤ score &lt; 80</td>
</tr>
<tr class="odd">
<td>80-100</td>
<td><span class="math inline">[80, 100]</span></td>
<td>80 ≤ score ≤ 100</td>
</tr>
</tbody>
</table>
<p>This convention ensures that:</p>
<ul>
<li>Every value is counted exactly once (no double-counting)</li>
<li>No values fall through the cracks</li>
<li>The bins partition the entire range completely</li>
</ul>
<p>When presenting frequency tables in reports, you can simply write “0-20, 20-40, …” and note that bins are left-closed, right-open, or explicitly show the interval notation if precision is important.</p>
<p><strong>Frequency histogram</strong> shows the raw counts:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co"># R code example</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(exam_scores, </span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">10</span>),</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Distribution of Exam Scores"</span>,</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Score"</span>,</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Frequency"</span>,</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"lightblue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-3-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Relative frequency histogram</strong> shows proportions (useful when comparing groups of different sizes):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(exam_scores, </span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">10</span>),</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">freq =</span> <span class="cn">FALSE</span>,  <span class="co"># This creates relative frequency/density</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Distribution of Exam Scores"</span>,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Score"</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Relative Frequency"</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"lightgreen"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Density histogram</strong> adjusts for interval width and is used with density curves:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(exam_scores, </span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">10</span>),</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">freq =</span> <span class="cn">FALSE</span>,  <span class="co"># Creates density scale</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Distribution of Exam Scores"</span>,</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Score"</span>,</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Density"</span>,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"lightcoral"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-5-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="density-curves" class="level4">
<h4 class="anchored" data-anchor-id="density-curves">Density Curves</h4>
<p>A <strong>density curve</strong> is a smooth line that approximates/models the shape of a distribution. Unlike histograms that show actual data in discrete bins, density curves show the overall pattern as a continuous function. The area under the entire curve always equals 1, and the area under any portion of the curve represents the proportion of observations in that range.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Adding a density curve to a histogram</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(exam_scores, </span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">freq =</span> <span class="cn">FALSE</span>,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Exam Scores with Density Curve"</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Score"</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Density"</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"lightblue"</span>,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">border =</span> <span class="st">"white"</span>)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(exam_scores), </span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">"darkred"</span>, </span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-6-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Density curves are particularly useful for:</p>
<ul>
<li>Identifying the shape of the distribution (symmetric, skewed, bimodal)</li>
<li>Comparing multiple distributions on the same plot</li>
<li>Understanding the theoretical (true) distribution underlying your data</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Tip
</div>
</div>
<div class="callout-body-container callout-body">
<p>In statistics, a <em>percentile</em> indicates the relative position of a data point within a dataset by showing the percentage of observations that fall at or below that value. For example, if a student scores at the 90th percentile on a test, their score is equal to or higher than 90% of all other scores.</p>
<p><em>Quartiles</em> are special percentiles that divide data into four equal parts: the first quartile (Q1, 25th percentile), second quartile (Q2, 50th percentile, also the median), and third quartile (Q3, 75th percentile). If Q1 = 65 points, then 25% of students scored 65 or below.</p>
<p>More generally, <em>quantiles</em> are values that divide data into equal-sized groups—percentiles divide into 100 parts, quartiles into 4 parts, deciles into 10 parts, and so on.</p>
</div>
</div>
</section>
<section id="visualizing-cumulative-frequency" class="level4">
<h4 class="anchored" data-anchor-id="visualizing-cumulative-frequency">Visualizing Cumulative Frequency (*)</h4>
<p><strong>Cumulative frequency plots</strong>, also called <strong>ogives</strong> (pronounced “oh-jive”), display how frequencies accumulate across values. These plots use lines rather than bars and always increase from left to right, eventually reaching the total number of observations (for cumulative frequency) or 1.0 (for cumulative relative frequency).</p>
<p>Cumulative frequency plots are excellent for:</p>
<ul>
<li>Finding percentiles and quartiles visually</li>
<li>Determining what proportion of data falls below or above a certain value</li>
<li>Comparing distributions of different groups</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Creating cumulative frequency data</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>score_breaks <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">100</span>, <span class="at">by =</span> <span class="dv">10</span>)</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>freq_counts <span class="ot">&lt;-</span> <span class="fu">hist</span>(exam_scores, <span class="at">breaks =</span> score_breaks, <span class="at">plot =</span> <span class="cn">FALSE</span>)<span class="sc">$</span>counts</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>cumulative_freq <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(freq_counts)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Plotting cumulative frequency</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(score_breaks[<span class="sc">-</span><span class="dv">1</span>], cumulative_freq,</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">type =</span> <span class="st">"b"</span>,  <span class="co"># both points and lines</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Cumulative Frequency of Exam Scores"</span>,</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Score"</span>,</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Cumulative Frequency"</span>,</span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"darkblue"</span>,</span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="fu">grid</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>For cumulative relative frequency (which is more commonly used):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Cumulative relative frequency</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>cumulative_rel_freq <span class="ot">&lt;-</span> cumulative_freq <span class="sc">/</span> <span class="fu">length</span>(exam_scores)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(score_breaks[<span class="sc">-</span><span class="dv">1</span>], cumulative_rel_freq,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">type =</span> <span class="st">"b"</span>,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Cumulative Relative Frequency of Exam Scores"</span>,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Score"</span>,</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Cumulative Relative Frequency"</span>,</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"darkred"</span>,</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">lwd =</span> <span class="dv">2</span>,</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">pch =</span> <span class="dv">19</span>,</span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="fu">grid</span>()</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">c</span>(<span class="fl">0.25</span>, <span class="fl">0.5</span>, <span class="fl">0.75</span>), <span class="at">lty =</span> <span class="dv">2</span>, <span class="at">col =</span> <span class="st">"gray"</span>)  <span class="co"># Quartile lines</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-8-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The cumulative relative frequency curve makes it easy to read percentiles. For example, if you draw a horizontal line at 0.75 and see where it intersects the curve, the corresponding x-value is the 75th percentile—the score below which 75% of students fall.</p>
<hr>
</section>
<section id="discrete-vs.-continuous-distributions" class="level4">
<h4 class="anchored" data-anchor-id="discrete-vs.-continuous-distributions">Discrete vs.&nbsp;Continuous Distributions</h4>
<p>The type of variable you’re analyzing determines how you visualize its distribution:</p>
<p><strong>Discrete distributions</strong> apply to variables that can only take specific, countable values. Examples include number of children in a family (0, 1, 2, 3…), number of customer complaints per day, or responses on a 5-point Likert scale.</p>
<p>For discrete data, we typically use:</p>
<ul>
<li>Bar charts (with gaps between bars) rather than histograms</li>
<li>Frequency or relative frequency on the y-axis</li>
<li>Each distinct value gets its own bar</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Number of children per family</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>children <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>, <span class="dv">3</span>)</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="fu">barplot</span>(<span class="fu">table</span>(children),</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">main =</span> <span class="st">"Distribution of Number of Children"</span>,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">xlab =</span> <span class="st">"Number of Children"</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">ylab =</span> <span class="st">"Frequency"</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">col =</span> <span class="st">"skyblue"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Continuous distributions</strong> apply to variables that can take any value within a range. Examples include temperature, response time, height, or turnout percentage.</p>
<p>For continuous data, we use:</p>
<ul>
<li>Histograms (with touching bars) that group data into intervals</li>
<li>Density curves to show the smooth pattern</li>
<li>Density on the y-axis when using density curves</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example: Response time distribution</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(response_time, </span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">breaks =</span> <span class="dv">15</span>,</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">freq =</span> <span class="cn">FALSE</span>,</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">main =</span> <span class="st">"Distribution of Response Time"</span>,</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="st">"Response Time (seconds)"</span>,</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="st">"Density"</span>,</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">col =</span> <span class="st">"lightgreen"</span>,</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">border =</span> <span class="st">"white"</span>)</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(response_time), </span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>      <span class="at">col =</span> <span class="st">"darkgreen"</span>, </span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>      <span class="at">lwd =</span> <span class="dv">2</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The key difference is that discrete distributions show probability at specific points, while continuous distributions show probability density across ranges. For continuous variables, the probability of any exact value is essentially zero—instead, we talk about the probability of falling within an interval.</p>
<p>Understanding whether your variable is discrete or continuous guides your choice of visualization and statistical methods, ensuring your analysis accurately represents the nature of your data.</p>
</section>
<section id="describing-distributions" class="level4">
<h4 class="anchored" data-anchor-id="describing-distributions">Describing Distributions</h4>
<p><strong>Shape Characteristics:</strong></p>
<p><strong>Symmetry vs.&nbsp;Skewness:</strong></p>
<ul>
<li><strong>Symmetric</strong>: Mirror image around center (example: heights in homogeneous population)</li>
<li><strong>Right-skewed (positive skew)</strong>: Long tail to right (example: income, wealth)</li>
<li><strong>Left-skewed (negative skew)</strong>: Long tail to left (example: age at death in developed countries)</li>
</ul>
<p><strong>Example of Skewness Impact:</strong></p>
<p>Income distribution in the U.S.:</p>
<ul>
<li>Median household income: ~$70,000</li>
<li>Mean household income: ~$100,000</li>
<li>Mean &gt; Median indicates right skew</li>
<li>A few very high incomes pull the mean up</li>
</ul>
<p><a href="https://mathspace.co/textbooks/syllabuses/Syllabus-1189/topics/Topic-22474/subtopics/Subtopic-290603/?coreTextbookSubtopicActiveTab=solidifyLesson&amp;activeLessonTab=content"><img src="stat_imgs/skewness-2.svg" class="img-fluid"></a></p>
<p><strong>Modality:</strong></p>
<ul>
<li><strong>Unimodal</strong>: One peak (example: test scores)</li>
<li><strong>Bimodal</strong>: Two peaks (example: height when mixing males and females)</li>
<li><strong>Multimodal</strong>: Multiple peaks (example: age distribution in a college town—peaks at college age and middle age)</li>
</ul>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p><strong>Important Probability Distributions:</strong></p>
<p><strong>Normal (Gaussian) Distribution:</strong></p>
<ul>
<li>Bell-shaped, symmetric</li>
<li>Characterized by mean (<span class="math inline">\mu</span>) and standard deviation (<span class="math inline">\sigma</span>)</li>
<li>About 68% of values within <span class="math inline">\mu \pm \sigma</span></li>
<li>About 95% within <span class="math inline">\mu \pm 2\sigma</span></li>
<li>About 99.7% within <span class="math inline">\mu \pm 3\sigma</span></li>
</ul>
<p><em>Demographic Applications:</em></p>
<ul>
<li>Heights within homogeneous populations</li>
<li>Measurement errors</li>
<li>Sampling distributions of means (Central Limit Theorem)</li>
</ul>
<p><strong>Binomial Distribution:</strong></p>
<ul>
<li>Number of successes in <span class="math inline">n</span> independent trials</li>
<li>Each trial has probability <span class="math inline">p</span> of success</li>
<li>Mean = <span class="math inline">np</span>, Variance = <span class="math inline">np(1-p)</span></li>
</ul>
<p><em>Example</em>: Number of male births out of 100 births (<span class="math inline">p \approx 0.512</span>)</p>
<p><strong>Poisson Distribution:</strong></p>
<ul>
<li>Count of events in fixed time/space</li>
<li>Mean = Variance = <span class="math inline">\lambda</span></li>
<li>Good for rare events</li>
</ul>
<p><em>Demographic Applications:</em></p>
<ul>
<li>Number of deaths per day in small town</li>
<li>Number of births per hour in hospital</li>
<li>Number of accidents at intersection per month</li>
</ul>
<hr>
</section>
<section id="visualizing-frequency-distributions" class="level4">
<h4 class="anchored" data-anchor-id="visualizing-frequency-distributions">Visualizing Frequency Distributions (*)</h4>
<p><strong>Histogram</strong>: For continuous data, shows frequency with bar heights.</p>
<ul>
<li>X-axis: Value ranges (bins)</li>
<li>Y-axis: Frequency or density</li>
<li>No gaps between bars (continuous data)</li>
<li>Bin width affects appearance</li>
</ul>
<p><strong>Bar Chart</strong>: For categorical data, shows frequency with separated bars.</p>
<ul>
<li>X-axis: Categories</li>
<li>Y-axis: Frequency</li>
<li>Gaps between bars (discrete categories)</li>
<li>Order may or may not matter</li>
</ul>
<p><strong>Cumulative Distribution Function (CDF)</strong>: Shows proportion of values ≤ each point of data.</p>
<ul>
<li>Always increases (or stays flat)</li>
<li>Starts at 0, ends at 1</li>
<li>Steep slopes indicate common values</li>
<li>Flat areas indicate rare values</li>
</ul>
<p><strong>Box Plot (Box-and-Whisker Plot)</strong>: A visual summary that displays the distribution’s key statistics using five key values.</p>
<p><strong>The Five-Number Summary:</strong></p>
<ul>
<li><strong>Minimum</strong>: Leftmost whisker end (excluding outliers)</li>
<li><strong>Q1 (First Quartile)</strong>: Left edge of the box (25th percentile)</li>
<li><strong>Median (Q2)</strong>: Line inside the box (50th percentile)<br>
</li>
<li><strong>Q3 (Third Quartile)</strong>: Right edge of the box (75th percentile)</li>
<li><strong>Maximum</strong>: Rightmost whisker end (excluding outliers)</li>
</ul>
<p><strong>What It Reveals:</strong></p>
<ul>
<li><strong>Skewness</strong>: If median line is off-center in the box, or whiskers are unequal</li>
<li><strong>Spread</strong>: Wider boxes and longer whiskers indicate more variability</li>
<li><strong>Outliers</strong>: Immediately visible as separate points</li>
<li><strong>Symmetry</strong>: Equal whisker lengths and centered median suggest normal distribution</li>
</ul>
<p><strong>Quick Interpretation:</strong></p>
<ul>
<li>Narrow box = consistent data</li>
<li>Long whiskers = wide range of values<br>
</li>
<li>Many outliers = potential data quality issues or interesting extreme cases</li>
<li>Median closer to Q1 = right-skewed data (tail extends right)</li>
<li>Median closer to Q3 = left-skewed data (tail extends left)</li>
</ul>
<p>Box plots are especially useful for comparing multiple groups side-by-side!</p>
<hr>
</section>
</section>
</section>
<section id="variables-and-measurement-scales" class="level2" data-number="1.8">
<h2 data-number="1.8" class="anchored" data-anchor-id="variables-and-measurement-scales"><span class="header-section-number">1.8</span> Variables and Measurement Scales</h2>
<blockquote class="blockquote">
<p>A <strong>variable</strong> is any characteristic that can take different values across units of observation.</p>
</blockquote>
<section id="measurement-transforming-concepts-into-numbers" class="level3">
<h3 class="anchored" data-anchor-id="measurement-transforming-concepts-into-numbers">Measurement: Transforming Concepts into Numbers</h3>
<section id="the-political-world-is-full-of-data" class="level4">
<h4 class="anchored" data-anchor-id="the-political-world-is-full-of-data">The Political World is Full of Data</h4>
<p>Political science has evolved from a primarily theoretical discipline to one that increasingly relies on empirical evidence. Whether we’re studying:</p>
<ul>
<li><strong>Election outcomes</strong>: Why do people vote the way they do?</li>
<li><strong>Public opinion</strong>: What shapes attitudes toward immigration or climate policy?</li>
<li><strong>International relations</strong>: What factors predict conflict between nations?</li>
<li><strong>Policy effectiveness</strong>: Did a new education policy actually improve outcomes?</li>
</ul>
<p>We need systematic ways to analyze data and draw conclusions that go beyond anecdotes and personal impressions.</p>
<blockquote class="blockquote">
<p>Consider this question: “Does democracy lead to economic growth?”</p>
</blockquote>
<p>Your intuition might suggest yes—democratic countries tend to be wealthier. But is this causation or correlation? Are there exceptions? How confident can we be in our conclusions?</p>
<p>Statistics provides the tools to move from hunches to evidence-based answers, helping us distinguish between what seems true and what actually is true.</p>
</section>
<section id="the-challenge-of-measurement-in-social-sciences" class="level4">
<h4 class="anchored">The Challenge of Measurement in Social Sciences</h4>
<p>In social sciences, we often struggle with the fact that key concepts do not translate directly into numbers:</p>
<ul>
<li>How do we measure “democracy”?</li>
<li>What number captures “political ideology”?</li>
<li>How do we quantify “institutional strength”?</li>
<li>How do we measure “political participation”?</li>
</ul>
<hr>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
🔍 Correlation ≠ Causation: Understanding Spurious Relationships
</div>
</div>
<div class="callout-body-container callout-body">
<section id="the-fundamental-distinction" class="level3">
<h3 class="anchored" data-anchor-id="the-fundamental-distinction"><strong>The Fundamental Distinction</strong></h3>
<p><strong>Correlation</strong> measures how two variables move together:</p>
<ul>
<li>Positive: Both increase together (study hours ↑, grades ↑)</li>
<li>Negative: One increases while other decreases (TV hours ↑, grades ↓)</li>
<li>Measured by correlation coefficient: <span class="math inline">r \in [-1, 1]</span></li>
</ul>
<p><strong>Causation</strong> means one variable directly influences another:</p>
<ul>
<li><span class="math inline">X \rightarrow Y</span>: Changes in X directly cause changes in Y</li>
<li>Requires: (1) correlation, (2) temporal precedence, (3) no alternative explanations</li>
</ul>
</section>
<section id="the-danger-spurious-correlation" class="level3">
<h3 class="anchored" data-anchor-id="the-danger-spurious-correlation"><strong>The Danger: Spurious Correlation</strong></h3>
<p>A <strong>spurious correlation</strong> occurs when two variables appear related but are actually both influenced by a third variable (a <strong>confounder</strong>).</p>
<p><strong>Classic Example:</strong></p>
<ul>
<li><p><strong>Observed</strong>: Ice cream sales correlate with drowning deaths</p></li>
<li><p><strong>Spurious conclusion</strong>: Ice cream causes drowning (❌)</p></li>
<li><p><strong>Reality</strong>: Summer weather (confounder) causes both:</p></li>
<li><p>Summer → More ice cream sales</p></li>
<li><p>Summer → More swimming → More drownings</p></li>
</ul>
<p><strong>Mathematical representation:</strong></p>
<ul>
<li>Observed correlation: <span class="math inline">\text{Cor}(X,Y) \neq 0</span></li>
<li>But the true model: <span class="math inline">X = \alpha Z + \epsilon_1</span> and <span class="math inline">Y = \beta Z + \epsilon_2</span></li>
<li>Where <span class="math inline">Z</span> is the confounding variable causing both</li>
</ul>
</section>
<section id="confounding-the-hidden-influence" class="level3">
<h3 class="anchored" data-anchor-id="confounding-the-hidden-influence"><strong>Confounding: The Hidden Influence</strong></h3>
<p>A <strong>confounding variable</strong> (confounder):</p>
<ol type="1">
<li>Affects both the presumed cause and effect</li>
<li>Creates an illusion of direct causation 3. Must be controlled for valid causal inference</li>
</ol>
<p><strong>Research Example:</strong></p>
<ul>
<li><p><strong>Observed</strong>: Coffee consumption correlates with heart disease</p></li>
<li><p><strong>Potential confounder</strong>: Smoking (coffee drinkers more likely to smoke)</p></li>
<li><p><strong>True relationships</strong>:</p></li>
<li><p>Smoking → Heart disease (causal)</p></li>
<li><p>Smoking → Coffee consumption (association)</p></li>
<li><p>Coffee → Heart disease (spurious without controlling for smoking)</p></li>
</ul>
</section>
<section id="how-to-identify-causal-relationships" class="level3">
<h3 class="anchored" data-anchor-id="how-to-identify-causal-relationships"><strong>How to Identify Causal Relationships</strong></h3>
<ol type="1">
<li><strong>Randomized Controlled Trials (RCTs)</strong>: Random assignment breaks confounding</li>
<li><strong>Natural Experiments</strong>: External events create “as-if” random variation</li>
<li><strong>Statistical Control</strong>: Include confounders in regression models</li>
<li><strong>Instrumental Variables</strong>: Find variables affecting X but not Y directly</li>
</ol>
</section>
<section id="key-takeaway" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaway"><strong>Key Takeaway</strong></h3>
<p>Finding correlation is easy. Establishing causation is hard. Always ask: “What else could explain this relationship?”</p>
<p><strong>Remember</strong>: The most dangerous phrase in empirical research is “our data shows that X causes Y” when all you’ve measured is correlation.</p>
</section>
</div>
</div>
<hr>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
📊 Quick Test: Correlation or Causation?
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For each scenario, identify whether the relationship is likely causal or spurious:</p>
<ol type="1">
<li><strong>Cities with more churches have more crime</strong>
<ul>
<li>Answer: Spurious (confounder: population size)</li>
</ul></li>
<li><strong>Smoking leads to lung cancer</strong>
<ul>
<li>Answer: Causal (established through multiple study designs)</li>
</ul></li>
<li><strong>Students with more books at home get better grades</strong>
<ul>
<li>Answer: Likely spurious (confounders: parental education, income)</li>
</ul></li>
<li><strong>Countries with higher chocolate consumption have more Nobel laureates</strong>
<ul>
<li>Answer: Spurious (confounder: wealth/development level)</li>
</ul></li>
</ol>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="types-of-variables" class="level3">
<h3 class="anchored" data-anchor-id="types-of-variables">Types of Variables</h3>
<p><strong>Quantitative Variables</strong> represent amounts or quantities and can be:</p>
<p><strong>Continuous Variables</strong>: Can take any value within a range, limited only by measurement precision.</p>
<ul>
<li>Age (22.5 years, 22.51 years, 22.514 years…)</li>
<li>Income ($45,234.67)</li>
<li>Height (175.3 cm)</li>
<li>Population density (432.7 people per square kilometer)</li>
</ul>
<p><strong>Discrete Variables</strong>: Can only take specific values, usually counts.</p>
<ul>
<li>Number of children in a family (0, 1, 2, 3…)</li>
<li>Number of marriages (0, 1, 2…)</li>
<li>Number of rooms in a dwelling (1, 2, 3…)</li>
<li>Number of migrants entering a country per year</li>
</ul>
<p><strong>Qualitative Variables</strong> represent categories or qualities and can be:</p>
<p><strong>Nominal Variables</strong>: Categories with no inherent order.</p>
<ul>
<li>Country of birth (USA, Mexico, Canada…)</li>
<li>Religion (Christian, Muslim, Hindu, Buddhist…)</li>
<li>Blood type (A, B, AB, O)</li>
<li>Cause of death (heart disease, cancer, accident…)</li>
</ul>
<p><strong>Ordinal Variables</strong>: Categories with a meaningful order but unequal intervals.</p>
<ul>
<li>Education level (no schooling, primary, secondary, tertiary)</li>
<li>Satisfaction with healthcare (very dissatisfied, dissatisfied, neutral, satisfied, very satisfied)</li>
<li>Socioeconomic status (low, middle, high)</li>
<li>Self-rated health (poor, fair, good, excellent)</li>
</ul>
</section>
<section id="measurement-scales" class="level3">
<h3 class="anchored" data-anchor-id="measurement-scales">Measurement Scales</h3>
<p>Understanding measurement scales is crucial because they determine which statistical methods are appropriate:</p>
<p><strong>Nominal Scale</strong>: Categories only—we can count frequencies but cannot order or perform arithmetic. Example: We can say 45% of residents were born locally, but we cannot calculate an “average birthplace.”</p>
<p><strong>Ordinal Scale</strong>: Order matters but differences between values are not necessarily equal. Example: The difference between “poor” and “fair” health may not equal the difference between “good” and “excellent” health.</p>
<p><strong>Interval Scale</strong>: Equal intervals between values but no true zero point. Example: Temperature in Celsius—the difference between 20°C and 30°C equals the difference between 30°C and 40°C, but 0°C doesn’t mean “no temperature.”</p>
<p><strong>Ratio Scale</strong>: Equal intervals with a true zero point, allowing all mathematical operations. Example: Income—$40,000 is twice as much as $20,000, and $0 means no income.</p>
<hr>
</section>
</section>
<section id="parameters-statistics-and-estimation" class="level2" data-number="1.9">
<h2 data-number="1.9" class="anchored" data-anchor-id="parameters-statistics-and-estimation"><span class="header-section-number">1.9</span> Parameters, Statistics, and Estimation</h2>
<p>These concepts form the core of statistical inference—how we learn about populations from samples. Understanding the relationships between these terms is essential for proper statistical reasoning.</p>
<section id="parameter" class="level3">
<h3 class="anchored" data-anchor-id="parameter">Parameter</h3>
<p>A <strong>parameter</strong> is a numerical characteristic of a population. Parameters are typically unknown because we cannot measure the entire population. They are fixed values (not random) but unknown to us. We denote parameters with Greek letters.</p>
<p><strong>Common Demographic Parameters:</strong></p>
<ul>
<li><span class="math inline">\mu</span> (mu): Population mean age. For example, the true average age of all Europeans.</li>
<li><span class="math inline">\sigma^2</span> (sigma squared): Population variance in income across all households in Brazil.</li>
<li><span class="math inline">p</span>: Population proportion. For example, the true proportion of all adults in Japan who are married.</li>
<li><span class="math inline">\beta</span> (beta): Regression coefficient. The true relationship between education and fertility in a population.</li>
<li><span class="math inline">\lambda</span> (lambda): Rate parameter. The true rate of migration from rural to urban areas.</li>
</ul>
<p><strong>Example</strong>: The true mean age at first birth for all women in France who gave birth in 2023 is a parameter. Let’s call it <span class="math inline">\mu = 31.2</span> years. We don’t know this value without measuring every single birth.</p>
</section>
<section id="statistic" class="level3">
<h3 class="anchored" data-anchor-id="statistic">Statistic</h3>
<p>A <strong>statistic</strong> is a numerical characteristic calculated from sample data. Statistics are random variables—their values vary from sample to sample. We use Roman letters for statistics.</p>
<p><strong>Common Sample Statistics:</strong></p>
<ul>
<li><span class="math inline">\bar{x}</span> (x-bar): Sample mean age from a survey of 1,000 people</li>
<li><span class="math inline">s^2</span>: Sample variance in income from 500 surveyed households</li>
<li><span class="math inline">\hat{p}</span> (p-hat): Sample proportion married from a survey</li>
<li><span class="math inline">r</span>: Sample correlation between education and income</li>
<li><span class="math inline">b</span>: Sample regression coefficient</li>
</ul>
<p><strong>Example</strong>: From a sample of 500 births in France, we calculate a sample mean age at first birth of <span class="math inline">\bar{x} = 30.9</span> years. This is our statistic. A different sample might yield <span class="math inline">\bar{x} = 31.4</span> years.</p>
</section>
<section id="the-relationship-between-parameters-and-statistics" class="level3">
<h3 class="anchored" data-anchor-id="the-relationship-between-parameters-and-statistics">The Relationship Between Parameters and Statistics</h3>
<p>Think of this relationship like trying to understand the depth of a lake:</p>
<ul>
<li><strong>Parameter</strong>: The true average depth of the lake (unknown, fixed)</li>
<li><strong>Statistic</strong>: The average depth from several measurement points (known, varies with different samples)</li>
<li><strong>Estimation</strong>: Using our measurements to guess the true average depth</li>
</ul>
</section>
<section id="estimator" class="level3">
<h3 class="anchored" data-anchor-id="estimator">Estimator</h3>
<p>An <strong>estimator</strong> is a rule or formula for calculating an estimate of a population parameter from sample data. An estimator is a function that maps sample data to parameter estimates. It’s the recipe, not the cake.</p>
<p><strong>Properties of Good Estimators:</strong></p>
<p><strong>Unbiasedness</strong>: On average, the estimator equals the true parameter value. If we repeated sampling many times, the average of all our estimates would equal the true parameter.</p>
<p><strong>Example</strong>: The sample mean <span class="math inline">\bar{x}</span> is an unbiased estimator of population mean <span class="math inline">\mu</span>. If we took 1,000 different samples and calculated 1,000 sample means, their average would be very close to <span class="math inline">\mu</span>.</p>
<p><strong>Consistency</strong>: As sample size increases, the estimator converges to the true parameter value.</p>
<p>Example: With <span class="math inline">n=10</span>, our estimate of average income might be off by $5,000. With <span class="math inline">n=1,000</span>, we might be off by only $500. With <span class="math inline">n=100,000</span>, we might be off by only $50.</p>
<p><strong>Efficiency</strong>: Among unbiased estimators, the one with the smallest variance. The sample mean is more efficient than the sample median for estimating the population mean of a normal distribution.</p>
<p><strong>Common Estimators:</strong></p>
<ul>
<li>Sample mean as estimator of population mean: <span class="math inline">\bar{x} = \frac{\sum x_i}{n}</span></li>
<li>Sample proportion as estimator of population proportion: <span class="math inline">\hat{p} = \frac{x}{n}</span> (where <span class="math inline">x</span> is the count of successes)</li>
<li>Sample variance as estimator of population variance: <span class="math inline">s^2 = \frac{\sum(x_i - \bar{x})^2}{n-1}</span></li>
</ul>
<p>Note: We divide by <span class="math inline">(n-1)</span> not <span class="math inline">n</span> for sample variance to make it unbiased—this is called Bessel’s correction.</p>
</section>
<section id="estimand" class="level3">
<h3 class="anchored" data-anchor-id="estimand">Estimand</h3>
<p>The <strong>estimand</strong> is the specific population parameter we aim to estimate. It’s the target of our estimation procedure. Clear specification of the estimand is crucial for proper statistical inference and avoiding misinterpretation.</p>
<p><strong>Examples of Clearly Defined Estimands:</strong></p>
<ul>
<li>“The median household income for all households in California as of January 1, 2024”</li>
<li>“The difference in life expectancy between males and females born in Sweden in 2023”</li>
<li>“The proportion of all adults aged 25-34 in urban areas who completed tertiary education”</li>
</ul>
<p><strong>Why Precise Estimand Definition Matters:</strong></p>
<p>Consider studying “unemployment rate.” The estimand must specify:</p>
<ul>
<li>Who counts as unemployed? (Actively seeking work? Discouraged workers?)</li>
<li>What age range? (15+? 16-64?)</li>
<li>What geographic area?</li>
<li>What time period?</li>
</ul>
<p>Different definitions lead to different numbers. The U.S. Bureau of Labor Statistics publishes six different unemployment rates (U-1 through U-6) based on different definitions.</p>
</section>
<section id="estimate" class="level3">
<h3 class="anchored" data-anchor-id="estimate">Estimate</h3>
<p>An <strong>estimate</strong> is the specific numerical value calculated by applying an estimator to observed data. It’s our best guess at the true parameter value based on available information.</p>
<p><strong>Example of the Complete Process:</strong></p>
<ol type="1">
<li><strong>Estimand</strong> (target): The proportion of all U.S. adults who approve of the president’s performance</li>
<li><strong>Parameter</strong> (true unknown value): <span class="math inline">p = 0.42</span> (42%, but we don’t know this)</li>
<li><strong>Estimator</strong> (method): Sample proportion <span class="math inline">\hat{p} = \frac{x}{n}</span> where <span class="math inline">x</span> is approvals and <span class="math inline">n</span> is sample size</li>
<li><strong>Sample</strong>: Survey 1,500 randomly selected adults, 650 approve</li>
<li><strong>Estimate</strong> (calculated value): <span class="math inline">\hat{p} = \frac{650}{1,500} = 0.433</span> (43.3%)</li>
</ol>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Estimands: What Exactly Are We Trying to Estimate?
</div>
</div>
<div class="callout-body-container callout-body">
<p>An <strong>estimand</strong> is the specific quantity we aim to estimate—what we’re targeting with our statistical analysis. While this is often a population parameter, estimands can be more complex.</p>
<p><strong>Examples of different estimands</strong>:</p>
<p><strong>Simple parameter estimand</strong>: The population mean income (<span class="math inline">\mu</span>)<br>
<strong>Comparative estimand</strong>: The difference in mean income between two groups (<span class="math inline">\mu_1 - \mu_2</span>)<br>
<strong>Causal estimand</strong>: The average treatment effect of a job training program on earnings<br>
<strong>Conditional estimand</strong>: Expected voter turnout given specific weather conditions</p>
<section id="the-complete-framework" class="level3">
<h3 class="anchored" data-anchor-id="the-complete-framework">The Complete Framework</h3>
<p>Understanding statistical inference requires distinguishing between these related but distinct concepts:</p>
<ul>
<li><strong>Population Parameter</strong>: The true characteristic of the population (e.g., <span class="math inline">\mu</span>)</li>
<li><strong>Estimand</strong>: The specific quantity we want to estimate (often, but not always, a parameter)</li>
<li><strong>Estimator</strong>: The method for computing our estimate (e.g., sample mean)<br>
</li>
<li><strong>Estimate</strong>: The actual number we calculate from our data</li>
</ul>
<p><strong>Example in context</strong>:</p>
<ul>
<li><strong>Parameter</strong>: True mean voter turnout in all elections (<span class="math inline">\mu</span>)</li>
<li><strong>Estimand</strong>: Expected turnout difference between rainy vs.&nbsp;sunny election days (<span class="math inline">\mu_{\text{rainy}} - \mu_{\text{sunny}}</span>)</li>
<li><strong>Estimator</strong>: Difference between sample means from rainy and sunny elections</li>
<li><strong>Estimate</strong>: 3.2 percentage points lower turnout on rainy days</li>
</ul>
<p>This framework helps clarify exactly what question we’re answering and ensures our methods align with our research goals.</p>
</section>
</div>
</div>
<hr>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding Different Types of Unpredictability
</div>
</div>
<div class="callout-body-container callout-body">
<p>Not all uncertainty is the same. Understanding different sources of unpredictability helps us choose appropriate statistical methods and interpret results correctly.</p>
<table class="caption-top table">
<colgroup>
<col style="width: 24%">
<col style="width: 26%">
<col style="width: 24%">
<col style="width: 24%">
</colgroup>
<thead>
<tr class="header">
<th>Concept</th>
<th>What is it?</th>
<th>Source of unpredictability</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Randomness</strong></td>
<td>Individual outcomes are uncertain, but the <strong>probability distribution</strong> is known or modeled.</td>
<td>Fluctuations across realizations; lack of information about a specific outcome.</td>
<td>Dice roll, coin toss, polling sample</td>
</tr>
<tr class="even">
<td><strong>Chaos</strong></td>
<td><strong>Deterministic</strong> dynamics <strong>highly sensitive</strong> to initial conditions (butterfly effect).</td>
<td>Tiny initial differences grow rapidly → large trajectory divergences.</td>
<td>Weather forecasting, double pendulum, population dynamics</td>
</tr>
<tr class="odd">
<td><strong>Entropy</strong></td>
<td>A <strong>measure</strong> of uncertainty/dispersion (information-theoretic or thermodynamic).</td>
<td>Larger when outcomes are more evenly distributed (less predictive information).</td>
<td>Shannon entropy in data compression</td>
</tr>
<tr class="even">
<td><strong>“Haphazardness”</strong> (colloquial)</td>
<td>A felt lack of order without an explicit model; a mixture of mechanisms.</td>
<td>No structured description or stable rules; overlapping processes.</td>
<td>Traffic patterns, social media trends</td>
</tr>
<tr class="odd">
<td><strong>Quantum randomness</strong></td>
<td>A single outcome is <strong>not determined</strong>; only the distribution is specified (Born rule).</td>
<td><strong>Fundamental (ontological)</strong> indeterminacy of individual measurements.</td>
<td>Electron spin measurement, photon polarization</td>
</tr>
</tbody>
</table>
<section id="key-distinctions-for-statistical-practice" class="level3">
<h3 class="anchored" data-anchor-id="key-distinctions-for-statistical-practice">Key Distinctions for Statistical Practice</h3>
<p><strong>Deterministic chaos ≠ statistical randomness</strong>: A chaotic system is fully deterministic yet practically unpredictable due to extreme sensitivity to initial conditions. Statistical randomness, by contrast, models uncertainty via probability distributions where individual outcomes are genuinely uncertain.</p>
<p><strong>Why this matters</strong>: In statistics, we typically model phenomena as random processes, assuming we can specify probability distributions even when individual outcomes are unpredictable. This assumption underlies most statistical inference.</p>
</section>
<section id="quantum-mechanics-and-fundamental-randomness" class="level3">
<h3 class="anchored" data-anchor-id="quantum-mechanics-and-fundamental-randomness">Quantum Mechanics and Fundamental Randomness</h3>
<p>In the Copenhagen interpretation, randomness is <strong>fundamental (ontological)</strong>: a <strong>single</strong> outcome cannot be predicted, but the <strong>probability distribution</strong> is given by the Born rule.</p>
<p>This represents true randomness at the most basic level of nature, not just our ignorance of determining factors.</p>
</section>
</div>
</div>
<hr>
</section>
</section>
<section id="statistical-error-and-uncertainty" class="level2" data-number="1.10">
<h2 data-number="1.10" class="anchored" data-anchor-id="statistical-error-and-uncertainty"><span class="header-section-number">1.10</span> Statistical Error and Uncertainty</h2>
<section id="introduction-why-uncertainty-matters" class="level3">
<h3 class="anchored" data-anchor-id="introduction-why-uncertainty-matters">Introduction: Why Uncertainty Matters</h3>
<p>No measurement or estimate is perfect. Understanding different types of error is crucial for interpreting results and improving study design.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The Central Challenge
</div>
</div>
<div class="callout-body-container callout-body">
<p>Every time we use a <strong>sample</strong> to learn about a <strong>population</strong>, we introduce uncertainty. The key is to:</p>
<ol type="1">
<li>Quantify this uncertainty honestly</li>
<li>Distinguish between different sources of error</li>
<li>Communicate results transparently</li>
</ol>
</div>
</div>
<hr>
</section>
</section>
<section id="statistical-error-and-uncertainty-1" class="level2" data-number="1.11">
<h2 data-number="1.11" class="anchored" data-anchor-id="statistical-error-and-uncertainty-1"><span class="header-section-number">1.11</span> Statistical Error and Uncertainty</h2>
<section id="introduction-why-uncertainty-matters-1" class="level3">
<h3 class="anchored" data-anchor-id="introduction-why-uncertainty-matters-1">Introduction: Why Uncertainty Matters</h3>
<p>No measurement or estimate is perfect. Understanding different types of error is crucial for interpreting results and improving study design.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The Central Challenge
</div>
</div>
<div class="callout-body-container callout-body">
<p>Every time we use a <strong>sample</strong> to learn about a <strong>population</strong>, we introduce uncertainty. The key is to:</p>
<ol type="1">
<li>Quantify this uncertainty honestly</li>
<li>Distinguish between different sources of error</li>
<li>Communicate results transparently</li>
</ol>
</div>
</div>
<hr>
</section>
<section id="types-of-error" class="level3">
<h3 class="anchored" data-anchor-id="types-of-error">Types of Error</h3>
<section id="random-error" class="level4">
<h4 class="anchored" data-anchor-id="random-error">Random Error</h4>
<p><strong>Random error</strong> represents unpredictable fluctuations that vary from observation to observation without a consistent pattern. These errors arise from various sources of natural variability in the data collection and measurement process.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Characteristics
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li><strong>Unpredictable Direction</strong>: Sometimes too high, sometimes too low</li>
<li><strong>No Consistent Pattern</strong>: Varies randomly across observations</li>
<li><strong>Averages to Zero</strong>: Over many measurements, positive and negative errors cancel out</li>
<li><strong>Quantifiable</strong>: Can be estimated and reduced through appropriate methods</li>
</ul>
</div>
</div>
<p>Random error encompasses several subtypes:</p>
<section id="sampling-error" class="level5">
<h5 class="anchored" data-anchor-id="sampling-error">Sampling Error</h5>
<p><strong>Sampling error</strong> is the most common type of random error—it arises because we observe a sample rather than the entire population. Different random samples from the same population will yield different estimates purely by chance.</p>
<p><strong>Key properties:</strong></p>
<ul>
<li>Decreases with sample size: <span class="math inline">\propto 1/\sqrt{n}</span></li>
<li>Quantifiable using probability theory</li>
<li>Inevitable when working with samples</li>
</ul>
<p><strong>Example: Internet Access Survey</strong></p>
<p>Imagine surveying 100 random households about internet access:</p>
<div class="cell">
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-12-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>The variation around the true value (red line) represents sampling error. With larger samples, estimates would cluster more tightly.</p>
</section>
<section id="measurement-error" class="level5">
<h5 class="anchored" data-anchor-id="measurement-error">Measurement Error</h5>
<p><strong>Measurement error</strong> is random variation in the measurement process itself—even when measuring the same thing repeatedly.</p>
<p><strong>Examples:</strong></p>
<ul>
<li>Slight variations when reading a thermometer due to parallax</li>
<li>Random fluctuations in electronic instruments</li>
<li>Inconsistencies in human judgment when coding qualitative data</li>
</ul>
<p>Unlike sampling error (which comes from who/what we observe), measurement error comes from <em>how</em> we observe.</p>
</section>
<section id="other-sources-of-random-error" class="level5">
<h5 class="anchored" data-anchor-id="other-sources-of-random-error">Other Sources of Random Error</h5>
<ul>
<li><strong>Processing error</strong>: Random mistakes in data entry, coding, or computation</li>
<li><strong>Model specification error</strong>: When the true relationship is more complex than assumed</li>
<li><strong>Temporal variation</strong>: Natural day-to-day fluctuations in the phenomenon being measured</li>
</ul>
</section>
</section>
<section id="systematic-error-bias" class="level4">
<h4 class="anchored" data-anchor-id="systematic-error-bias">Systematic Error (Bias)</h4>
<p><strong>Systematic error</strong> represents consistent deviation in a particular direction. Unlike random error, it doesn’t average out with repeated sampling or measurement—it persists and pushes results consistently away from the truth.</p>
<div class="tabset-margin-container"></div><div class="panel-tabset">
<ul class="nav nav-tabs" role="tablist"><li class="nav-item" role="presentation"><a class="nav-link active" id="tabset-1-1-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-1" role="tab" aria-controls="tabset-1-1" aria-selected="true">Selection Bias</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-2-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-2" role="tab" aria-controls="tabset-1-2" aria-selected="false">Measurement Bias</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-3-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-3" role="tab" aria-controls="tabset-1-3" aria-selected="false">Response Bias</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-4-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-4" role="tab" aria-controls="tabset-1-4" aria-selected="false">Non-response Bias</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-5-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-5" role="tab" aria-controls="tabset-1-5" aria-selected="false">Survivorship Bias</a></li><li class="nav-item" role="presentation"><a class="nav-link" id="tabset-1-6-tab" data-bs-toggle="tab" data-bs-target="#tabset-1-6" role="tab" aria-controls="tabset-1-6" aria-selected="false">Observer/Interviewer Bias</a></li></ul>
<div class="tab-content">
<div id="tabset-1-1" class="tab-pane active" role="tabpanel" aria-labelledby="tabset-1-1-tab">
<p>Sampling method systematically excludes certain groups.</p>
<p><strong>Example</strong>: Phone surveys during business hours underrepresent employed people.</p>
</div>
<div id="tabset-1-2" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-2-tab">
<p>Measurement instrument consistently over/under-measures.</p>
<p><strong>Example</strong>: Scales that always read 2 pounds heavy; survey questions that lead respondents toward particular answers.</p>
</div>
<div id="tabset-1-3" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-3-tab">
<p>Respondents systematically misreport.</p>
<p><strong>Example</strong>: People underreport alcohol consumption, overreport voting, or give socially desirable answers.</p>
</div>
<div id="tabset-1-4" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-4-tab">
<p>Non-responders differ systematically from responders.</p>
<p><strong>Example</strong>: Very sick and very healthy people less likely to respond to health surveys, leaving only those with moderate health.</p>
</div>
<div id="tabset-1-5" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-5-tab">
<p>Only observing “survivors” of some process.</p>
<p><strong>Example</strong>: During WWII, the military analyzed returning bombers to determine where to add armor. Planes showed the most damage on wings and tail sections. Abraham Wald realized the flaw: they should armor where there <em>weren’t</em> bullet holes—the engine and cockpit. Planes hit in those areas never made it back to be analyzed. They were only studying the survivors.</p>
</div>
<div id="tabset-1-6" class="tab-pane" role="tabpanel" aria-labelledby="tabset-1-6-tab">
<p>Observers or interviewers systematically influence results.</p>
<p><strong>Example</strong>: Interviewers unconsciously prompting certain responses or recording observations that confirm their expectations.</p>
</div>
</div>
</div>
</section>
<section id="the-bias-variance-decomposition" class="level4">
<h4 class="anchored" data-anchor-id="the-bias-variance-decomposition">The Bias-Variance Decomposition</h4>
<p>Mathematically, total error (Mean Squared Error) decomposes into:</p>
<p><span class="math display">\mathrm{MSE}(\hat\theta) = \underbrace{\mathrm{Var}(\hat\theta)}_{\text{random error}} + \underbrace{\big(\mathrm{Bias}(\hat\theta)\big)^2}_{\text{systematic error}}</span></p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Critical Insight
</div>
</div>
<div class="callout-body-container callout-body">
<blockquote class="blockquote">
<p>A large <strong>biased</strong> sample gives a <strong>precisely wrong</strong> answer.</p>
</blockquote>
<ul>
<li>Increase <span class="math inline">n</span> → reduces random error (specifically sampling error)</li>
<li>Improve study design → reduces systematic error</li>
<li>Better instruments → reduces measurement error</li>
</ul>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="stat_imgs/bias-variance-targets.svg" class="img-fluid figure-img"></p>
<figcaption>Different combinations of bias and variance in estimation</figcaption>
</figure>
</div>
<p><strong>Intuitive analogy:</strong> Think of trying to hit a bullseye:</p>
<ul>
<li><strong>Random error</strong> = scattered shots around a target (sometimes left, sometimes right, sometimes high, sometimes low)</li>
<li><strong>Systematic error</strong> = consistently hitting the same wrong spot (all shots clustered, but away from the bullseye)</li>
<li><strong>Ideal</strong> = shots tightly clustered at the bullseye center</li>
</ul>
<hr>
</section>
</section>
<section id="quantifying-uncertainty" class="level3">
<h3 class="anchored" data-anchor-id="quantifying-uncertainty">Quantifying Uncertainty</h3>
<section id="standard-error" class="level4">
<h4 class="anchored" data-anchor-id="standard-error">Standard Error</h4>
<p>The <strong>standard error</strong> (SE) quantifies how much an estimate varies across different possible samples. It measures sampling error specifically.</p>
<div class="columns">
<div class="column" style="width:50%;">
<p><strong>For a Proportion:</strong></p>
<p><span class="math display">SE(\hat{p}) = \sqrt{\frac{\hat{p}(1-\hat{p})}{n}}</span></p>
<p><strong>For a Mean:</strong></p>
<p><span class="math display">SE(\bar{x}) = \frac{s}{\sqrt{n}}</span></p>
</div><div class="column" style="width:50%;">
<p><strong>For a Difference:</strong></p>
<p><span class="math display">SE(\bar{x}_1 - \bar{x}_2) = \sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}</span></p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What SE Tells Us
</div>
</div>
<div class="callout-body-container callout-body">
<p>Standard error quantifies <strong>sampling error</strong> only. It does not account for systematic errors (bias), measurement error, or other sources of uncertainty.</p>
</div>
</div>
</section>
<section id="margin-of-error" class="level4">
<h4 class="anchored" data-anchor-id="margin-of-error">Margin of Error</h4>
<p>The <strong>margin of error</strong> (MOE) represents the expected maximum difference between sample estimate and true parameter.</p>
<p><span class="math display">\text{MOE} = \text{Critical Value} \times \text{Standard Error}</span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-27-contents" aria-controls="callout-27" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding the Critical Value
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-27" class="callout-27-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>For 95% confidence, we use 1.96 (often simplified to 2). This ensures that ~95% of intervals constructed this way will contain the true parameter.</p>
<ul>
<li>90% confidence: z = 1.645</li>
<li>95% confidence: z = 1.96</li>
<li>99% confidence: z = 2.576</li>
</ul>
</div>
</div>
</div>
</section>
<section id="confidence-intervals" class="level4">
<h4 class="anchored" data-anchor-id="confidence-intervals">Confidence Intervals</h4>
<p>A <strong>confidence interval</strong> provides a range of plausible values:</p>
<p><span class="math display">\text{CI} = \text{Estimate} \pm (\text{Critical Value} \times \text{Standard Error})</span></p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important Limitation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Confidence intervals quantify <strong>sampling uncertainty</strong> but assume no systematic error. A perfectly precise estimate (narrow CI) can still be biased if the study design is flawed.</p>
</div>
</div>
<hr>
</section>
</section>
<section id="practical-application-opinion-polling" class="level3">
<h3 class="anchored" data-anchor-id="practical-application-opinion-polling">Practical Application: Opinion Polling</h3>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Case Study: Political Polls
</div>
</div>
<div class="callout-body-container callout-body">
<p>When a poll reports “Candidate A: 52%, Candidate B: 48%”, this is <strong>incomplete</strong> without uncertainty quantification.</p>
</div>
</div>
<section id="the-golden-rule-of-polling" class="level4">
<h4 class="anchored" data-anchor-id="the-golden-rule-of-polling">The Golden Rule of Polling</h4>
<p>With ~1,000 randomly selected respondents:</p>
<ul>
<li><strong>Margin of error</strong>: ±3 percentage points (95% confidence)</li>
<li><strong>Interpretation</strong>: A reported 52% means true support likely between 49% and 55%</li>
<li><strong>What this covers</strong>: Only random sampling error—assumes no systematic bias</li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Critical Distinction
</div>
</div>
<div class="callout-body-container callout-body">
<p>The ±3% margin of error quantifies <strong>sampling uncertainty only</strong>. It does not account for:</p>
<ul>
<li>Coverage bias (who’s excluded from the sampling frame)</li>
<li>Non-response bias (who refuses to participate)</li>
<li>Response bias (people misreporting their true views)</li>
<li>Timing effects (opinions changing between poll and election)</li>
</ul>
</div>
</div>
</section>
<section id="sample-size-and-precision" class="level4">
<h4 class="anchored" data-anchor-id="sample-size-and-precision">Sample Size and Precision</h4>
<table class="table-striped table-hover caption-top table">
<thead>
<tr class="header">
<th>Sample Size</th>
<th>Margin of Error (95%)</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>n = 100</td>
<td>± 10 pp</td>
<td>Broad direction only</td>
</tr>
<tr class="even">
<td>n = 400</td>
<td>± 5 pp</td>
<td>General trends</td>
</tr>
<tr class="odd">
<td>n = 1,000</td>
<td>± 3 pp</td>
<td><strong>Standard polls</strong></td>
</tr>
<tr class="even">
<td>n = 2,500</td>
<td>± 2 pp</td>
<td>High precision</td>
</tr>
<tr class="odd">
<td>n = 10,000</td>
<td>± 1 pp</td>
<td>Very high precision</td>
</tr>
</tbody>
</table>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Law of Diminishing Returns
</div>
</div>
<div class="callout-body-container callout-body">
<p>To halve the margin of error, you need <strong>four times</strong> the sample size because <span class="math inline">\text{MOE} \propto 1/\sqrt{n}</span></p>
<p>This applies only to <strong>sampling error</strong>. Doubling your sample size from 1,000 to 2,000 won’t fix systematic problems like biased question wording or unrepresentative sampling methods.</p>
</div>
</div>
</section>
<section id="what-quality-polls-should-report" class="level4">
<h4 class="anchored" data-anchor-id="what-quality-polls-should-report">What Quality Polls Should Report</h4>
<p>A transparent poll discloses:</p>
<ul>
<li><strong>Field dates</strong>: When was data collected?</li>
<li><strong>Population and sampling method</strong>: Who was surveyed and how were they selected?</li>
<li><strong>Sample size</strong>: How many people responded?</li>
<li><strong>Response rate</strong>: What proportion of contacted people participated?</li>
<li><strong>Weighting procedures</strong>: How was the sample adjusted to match population characteristics?</li>
<li><strong>Margin of sampling error</strong>: Quantification of sampling uncertainty</li>
<li><strong>Question wording</strong>: Exact text of questions asked</li>
</ul>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The Reporting Gap
</div>
</div>
<div class="callout-body-container callout-body">
<p>Most news reports mention only the topline numbers and occasionally the margin of error. They rarely discuss potential systematic biases, which can be much larger than sampling error.</p>
</div>
</div>
<hr>
</section>
</section>
<section id="visualization-sampling-variability" class="level3">
<h3 class="anchored" data-anchor-id="visualization-sampling-variability">Visualization: Sampling Variability</h3>
<p>The following simulation demonstrates how confidence intervals behave across repeated sampling:</p>
<div class="cell">
<details class="code-fold">
<summary>Show simulation code</summary>
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Parameters</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>n_polls      <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>n_people     <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>true_support <span class="ot">&lt;-</span> <span class="fl">0.50</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate independent polls</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>support <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_polls, n_people, true_support) <span class="sc">/</span> n_people</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate standard errors and margins of error</span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>se   <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(support <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> support) <span class="sc">/</span> n_people)</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>moe  <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> se  <span class="co"># Simplified multiplier for clarity</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Create confidence intervals</span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>lower <span class="ot">&lt;-</span> <span class="fu">pmax</span>(<span class="dv">0</span>, support <span class="sc">-</span> moe)</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>upper <span class="ot">&lt;-</span> <span class="fu">pmin</span>(<span class="dv">1</span>, support <span class="sc">+</span> moe)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Check coverage</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>covers <span class="ot">&lt;-</span> (lower <span class="sc">&lt;=</span> true_support) <span class="sc">&amp;</span> (upper <span class="sc">&gt;=</span> true_support)</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>n_cover <span class="ot">&lt;-</span> <span class="fu">sum</span>(covers)</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">poll =</span> <span class="fu">seq_len</span>(n_polls),</span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a>  support, se, moe, lower, upper, covers</span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(results, <span class="fu">aes</span>(<span class="at">x =</span> poll, <span class="at">y =</span> support, <span class="at">color =</span> covers)) <span class="sc">+</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper), </span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a>                <span class="at">width =</span> <span class="fl">0.3</span>, <span class="at">alpha =</span> <span class="fl">0.8</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> true_support, </span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>, </span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> <span class="st">"black"</span>,</span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a>             <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb12-38"><a href="#cb12-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(</span>
<span id="cb12-39"><a href="#cb12-39" aria-hidden="true" tabindex="-1"></a>    <span class="at">values =</span> <span class="fu">c</span>(<span class="st">"TRUE"</span> <span class="ot">=</span> <span class="st">"forestgreen"</span>, <span class="st">"FALSE"</span> <span class="ot">=</span> <span class="st">"darkorange"</span>),</span>
<span id="cb12-40"><a href="#cb12-40" aria-hidden="true" tabindex="-1"></a>    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"TRUE"</span> <span class="ot">=</span> <span class="st">"Covers truth"</span>, <span class="st">"FALSE"</span> <span class="ot">=</span> <span class="st">"Misses truth"</span>),</span>
<span id="cb12-41"><a href="#cb12-41" aria-hidden="true" tabindex="-1"></a>    <span class="at">name   =</span> <span class="cn">NULL</span></span>
<span id="cb12-42"><a href="#cb12-42" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-43"><a href="#cb12-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> scales<span class="sc">::</span>percent,</span>
<span id="cb12-44"><a href="#cb12-44" aria-hidden="true" tabindex="-1"></a>                     <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb12-45"><a href="#cb12-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb12-46"><a href="#cb12-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">title    =</span> <span class="st">"Sampling Variability in 20 Independent Polls"</span>,</span>
<span id="cb12-47"><a href="#cb12-47" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">paste0</span>(</span>
<span id="cb12-48"><a href="#cb12-48" aria-hidden="true" tabindex="-1"></a>      <span class="st">"Each poll: n = "</span>, n_people, <span class="st">" | True value = "</span>,</span>
<span id="cb12-49"><a href="#cb12-49" aria-hidden="true" tabindex="-1"></a>      scales<span class="sc">::</span><span class="fu">percent</span>(true_support),</span>
<span id="cb12-50"><a href="#cb12-50" aria-hidden="true" tabindex="-1"></a>      <span class="st">" | Coverage: "</span>, n_cover, <span class="st">"/"</span>, n_polls,</span>
<span id="cb12-51"><a href="#cb12-51" aria-hidden="true" tabindex="-1"></a>      <span class="st">" ("</span>, <span class="fu">round</span>(<span class="dv">100</span> <span class="sc">*</span> n_cover <span class="sc">/</span> n_polls), <span class="st">"%)"</span></span>
<span id="cb12-52"><a href="#cb12-52" aria-hidden="true" tabindex="-1"></a>    ),</span>
<span id="cb12-53"><a href="#cb12-53" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Poll Number"</span>,</span>
<span id="cb12-54"><a href="#cb12-54" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Estimated Support"</span>,</span>
<span id="cb12-55"><a href="#cb12-55" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">"Error bars show approximate 95% confidence intervals"</span></span>
<span id="cb12-56"><a href="#cb12-56" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb12-57"><a href="#cb12-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">13</span>) <span class="sc">+</span></span>
<span id="cb12-58"><a href="#cb12-58" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb12-59"><a href="#cb12-59" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"top"</span>,</span>
<span id="cb12-60"><a href="#cb12-60" aria-hidden="true" tabindex="-1"></a>    <span class="at">panel.grid.minor =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb12-61"><a href="#cb12-61" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>)</span>
<span id="cb12-62"><a href="#cb12-62" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Key Observation
</div>
</div>
<div class="callout-body-container callout-body">
<p>Most intervals capture the true value, but some “miss” purely due to <strong>sampling randomness</strong>. This is expected and quantifiable—it’s the nature of random sampling error.</p>
<p><strong>Important</strong>: This simulation assumes <strong>no systematic bias</strong>. In real polling, systematic errors (non-response bias, coverage problems, question wording effects) can shift all estimates in the same direction, making them consistently wrong even with large samples.</p>
</div>
</div>
<hr>
</section>
<section id="common-misconceptions" class="level3">
<h3 class="anchored" data-anchor-id="common-misconceptions">Common Misconceptions</h3>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Misconception #1: Margin of Error Covers All Uncertainty
</div>
</div>
<div class="callout-body-container callout-body">
<p>❌ <strong>Myth</strong>: “The true value is definitely within the margin of error”</p>
<p>✅ <strong>Reality</strong>:</p>
<ul>
<li>With 95% confidence, there’s still a <strong>5% chance</strong> the true value falls outside the interval due to sampling randomness alone</li>
<li>More importantly, margin of error <strong>only covers sampling error</strong>, not systematic biases</li>
<li>Real polls often have larger errors from non-response bias, question wording, or coverage problems than from sampling error</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Misconception #2: Larger Samples Fix Everything
</div>
</div>
<div class="callout-body-container callout-body">
<p>❌ <strong>Myth</strong>: “If we just survey more people, we’ll eliminate all error”</p>
<p>✅ <strong>Reality</strong>:</p>
<ul>
<li>Larger samples reduce <strong>random error</strong> (particularly sampling error): more precise estimates</li>
<li>Larger samples do <strong>NOT</strong> reduce <strong>systematic error</strong>: bias remains unchanged</li>
<li>A poll of 10,000 people with 70% response rate and biased sampling frame will give a precisely wrong answer</li>
<li>Better to have 1,000 well-selected respondents than 10,000 poorly selected ones</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Misconception #3: Random = Careless
</div>
</div>
<div class="callout-body-container callout-body">
<p>❌ <strong>Myth</strong>: “Random error means someone made mistakes”</p>
<p>✅ <strong>Reality</strong>:</p>
<ul>
<li>Random error is <strong>inherent</strong> in sampling and measurement—it’s not a mistake</li>
<li>Even with perfect methodology, different random samples yield different results</li>
<li>Random errors are <strong>predictable in aggregate</strong> even though unpredictable individually</li>
<li>The term “random” refers to the pattern (no systematic direction), not to carelessness</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Misconception #4: Confidence Intervals are Guarantees
</div>
</div>
<div class="callout-body-container callout-body">
<p>❌ <strong>Myth</strong>: “95% confidence means there’s a 95% chance the true value is in this specific interval”</p>
<p>✅ <strong>Reality</strong>:</p>
<ul>
<li>The true value is fixed (but unknown)—it either is or isn’t in the interval</li>
<li>“95% confidence” means: if we repeated this process many times, about 95% of the intervals we construct would contain the true value</li>
<li>Each specific interval either captures the truth or doesn’t—we just don’t know which</li>
</ul>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Misconception #5: Bias Can Be Calculated Like Random Error
</div>
</div>
<div class="callout-body-container callout-body">
<p>❌ <strong>Myth</strong>: “We can calculate the bias just like we calculate standard error”</p>
<p>✅ <strong>Reality</strong>:</p>
<ul>
<li><strong>Random error</strong> is quantifiable using probability theory because we know the sampling process</li>
<li><strong>Systematic error</strong> is usually <strong>unknown and unknowable</strong> without external validation</li>
<li>You can’t use the sample itself to detect bias—you need independent information about the population</li>
<li>This is why comparing polls to election results is valuable: it reveals biases that weren’t quantifiable beforehand</li>
</ul>
</div>
</div>
<hr>
</section>
<section id="real-world-example-polling-failures" class="level3">
<h3 class="anchored" data-anchor-id="real-world-example-polling-failures">Real-World Example: Polling Failures</h3>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Case Study: When Polls Mislead
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider a scenario where 20 polls all show Candidate A leading by 3-5 points, with margins of error around ±3%. The polls seem consistent, but Candidate B wins.</p>
<p><strong>What happened?</strong></p>
<ul>
<li><strong>Not sampling error</strong>: All polls agreed—unlikely if only random variation</li>
<li><strong>Likely systematic error</strong>:
<ul>
<li>Non-response bias: Certain voters consistently refused to participate</li>
<li>Social desirability bias: Some voters misreported their true preference</li>
<li>Turnout modeling error: Wrong assumptions about who would actually vote</li>
<li>Coverage bias: Sampling frame (e.g., phone lists) systematically excluded certain groups</li>
</ul></li>
</ul>
<p><strong>The lesson</strong>: Consistency among polls doesn’t guarantee accuracy. All polls can share the same systematic biases, giving false confidence in wrong estimates.</p>
</div>
</div>
<hr>
</section>
<section id="key-takeaways" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaways">Key Takeaways</h3>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Essential Points
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Understanding Error Types:</strong></p>
<ol type="1">
<li><strong>Random error</strong> is unpredictable variation that averages to zero
<ul>
<li><strong>Sampling error</strong>: From observing a sample, not the whole population</li>
<li><strong>Measurement error</strong>: From imperfect measurement instruments or processes</li>
<li>Reduced by: larger samples, better instruments, more measurements</li>
</ul></li>
<li><strong>Systematic error (bias)</strong> is consistent deviation in one direction
<ul>
<li>Selection bias, measurement bias, response bias, non-response bias, etc.</li>
<li>Reduced by: better study design, not larger samples</li>
</ul></li>
</ol>
<p><strong>Quantifying Uncertainty:</strong></p>
<ol start="3" type="1">
<li><p><strong>Standard error</strong> measures typical sampling variability (one type of random error)</p></li>
<li><p><strong>Margin of error</strong> ≈ 2 × SE gives a range for 95% confidence about sampling uncertainty</p></li>
<li><p><strong>Sample size</strong> and <strong>sampling error</strong> precision follow: <span class="math inline">\text{SE} \propto 1/\sqrt{n}</span></p>
<ul>
<li>Quadrupling sample size halves sampling error</li>
<li>Diminishing returns as n increases</li>
</ul></li>
<li><p><strong>Confidence intervals</strong> provide plausible ranges but assume no systematic bias</p></li>
</ol>
<p><strong>Critical Insights:</strong></p>
<ol start="7" type="1">
<li><p><strong>A precisely wrong answer</strong> (large biased sample) is often worse than an <strong>imprecisely right answer</strong> (small unbiased sample)</p></li>
<li><p><strong>Always consider both</strong> sampling error AND potential systematic biases—published margins of error typically ignore the latter</p></li>
<li><p><strong>Transparency matters</strong>: Report methodology, response rates, and potential biases, not just point estimates and margins of error</p></li>
<li><p><strong>Validation is essential</strong>: Compare estimates to known values whenever possible to detect systematic errors</p></li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
The Practitioner’s Priority
</div>
</div>
<div class="callout-body-container callout-body">
<p>When designing studies:</p>
<p><strong>First</strong>: Minimize systematic error through careful design</p>
<ul>
<li>Representative sampling methods</li>
<li>High response rates</li>
<li>Unbiased measurement tools</li>
<li>Proper question wording</li>
</ul>
<p><strong>Then</strong>: Optimize sample size to achieve acceptable precision</p>
<ul>
<li>Larger samples help only after bias is addressed</li>
<li>Balance cost vs.&nbsp;precision improvement</li>
<li>Remember diminishing returns</li>
</ul>
<p><strong>Finally</strong>: Report uncertainty honestly</p>
<ul>
<li>State assumptions clearly</li>
<li>Acknowledge potential biases</li>
<li>Don’t let precise estimates create false confidence</li>
</ul>
</div>
</div>
<hr>
</section>
</section>
<section id="sampling-and-sampling-methods" class="level2" data-number="1.12">
<h2 data-number="1.12" class="anchored" data-anchor-id="sampling-and-sampling-methods"><span class="header-section-number">1.12</span> Sampling and Sampling Methods (*)</h2>
<p><strong>Sampling</strong> is the process of selecting a subset of individuals from a population to estimate characteristics of the whole population. The way we sample profoundly affects what we can conclude from our data.</p>
<section id="the-sampling-frame" class="level3">
<h3 class="anchored" data-anchor-id="the-sampling-frame">The Sampling Frame</h3>
<p>Before discussing methods, we must understand the <strong>sampling frame</strong>—the list or device from which we draw our sample. The frame should ideally include every population member exactly once.</p>
<p><strong>Common Sampling Frames:</strong></p>
<ul>
<li>Electoral rolls (for adult citizens)</li>
<li>Telephone directories (increasingly problematic due to mobile phones and unlisted numbers)</li>
<li>Address lists from postal services</li>
<li>Birth registrations (for newborns)</li>
<li>School enrollment lists (for children)</li>
<li>Tax records (for income earners)</li>
<li>Satellite imagery (for dwellings in remote areas)</li>
</ul>
<p><strong>Frame Problems:</strong></p>
<ul>
<li><strong>Undercoverage</strong>: Frame missing population members (homeless individuals not on address lists)</li>
<li><strong>Overcoverage</strong>: Frame includes non-population members (deceased people still on voter rolls)</li>
<li><strong>Duplication</strong>: Same unit appears multiple times (people with multiple phone numbers)</li>
<li><strong>Clustering</strong>: Multiple population members per frame unit (multiple families at one address)</li>
</ul>
</section>
<section id="probability-sampling-methods" class="level3">
<h3 class="anchored" data-anchor-id="probability-sampling-methods">Probability Sampling Methods</h3>
<p><strong>Probability sampling</strong> gives every population member a known, non-zero probability of selection. This allows us to make statistical inferences about the population.</p>
<section id="simple-random-sampling-srs" class="level4">
<h4 class="anchored" data-anchor-id="simple-random-sampling-srs">Simple Random Sampling (SRS)</h4>
<p>Every possible sample of size <span class="math inline">n</span> has equal probability of selection. It’s the gold standard for statistical theory but often impractical for large populations.</p>
<p><strong>How It Works:</strong></p>
<ol type="1">
<li>Number every unit in the population from 1 to <span class="math inline">N</span></li>
<li>Use random numbers to select <span class="math inline">n</span> units</li>
<li>Each unit has probability <span class="math inline">n/N</span> of selection</li>
</ol>
<p><strong>Example</strong>: To sample 50 students from a school of 1,000:</p>
<ul>
<li>Assign each student a number from 1 to 1,000</li>
<li>Generate 50 random numbers between 1 and 1,000</li>
<li>Select students with those numbers</li>
</ul>
<p><strong>Advantages:</strong></p>
<ul>
<li>Statistically optimal</li>
<li>Easy to analyze</li>
<li>No need for additional information about population</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Requires complete sampling frame</li>
<li>Can be expensive (selected units might be far apart)</li>
<li>May not represent important subgroups well by chance</li>
</ul>
</section>
<section id="systematic-sampling" class="level4">
<h4 class="anchored" data-anchor-id="systematic-sampling">Systematic Sampling</h4>
<p>Select every <span class="math inline">k</span>th element from an ordered sampling frame, where <span class="math inline">k = N/n</span> (the sampling interval).</p>
<p><strong>How It Works:</strong></p>
<ol type="1">
<li>Calculate sampling interval <span class="math inline">k = N/n</span></li>
<li>Randomly select starting point between 1 and <span class="math inline">k</span></li>
<li>Select every <span class="math inline">k</span>th unit thereafter</li>
</ol>
<p><strong>Example</strong>: To sample 100 houses from 5,000 on a street listing:</p>
<ul>
<li><span class="math inline">k = 5,000/100 = 50</span></li>
<li>Random start: 23</li>
<li>Sample houses: 23, 73, 123, 173, 223…</li>
</ul>
<p><strong>Advantages:</strong></p>
<ul>
<li>Simple to implement in field</li>
<li>Spreads sample throughout population</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Can introduce bias if there’s periodicity in the frame</li>
</ul>
<p><strong>Hidden Periodicity Example</strong>: Sampling every 10th apartment in buildings where corner apartments (numbers ending in 0) are all larger. This would bias our estimate of average apartment size.</p>
</section>
<section id="stratified-sampling" class="level4">
<h4 class="anchored" data-anchor-id="stratified-sampling">Stratified Sampling</h4>
<p>Divide population into homogeneous subgroups (strata) before sampling. Sample independently within each stratum.</p>
<p><strong>How It Works:</strong></p>
<ol type="1">
<li>Divide population into non-overlapping strata</li>
<li>Sample independently from each stratum</li>
<li>Combine results with appropriate weights</li>
</ol>
<p><strong>Example</strong>: Studying income in a city with distinct neighborhoods:</p>
<ul>
<li>Stratum 1: High-income neighborhood (10% of population) - sample 100</li>
<li>Stratum 2: Middle-income neighborhood (60% of population) - sample 600</li>
<li>Stratum 3: Low-income neighborhood (30% of population) - sample 300</li>
</ul>
<p><strong>Types of Allocation:</strong></p>
<p><strong>Proportional</strong>: Sample size in each stratum proportional to stratum size</p>
<ul>
<li>If stratum has 20% of population, it gets 20% of sample</li>
</ul>
<p><strong>Optimal (Neyman)</strong>: Larger samples from more variable strata</p>
<ul>
<li>If income varies more in high-income areas, sample more there</li>
</ul>
<p><strong>Equal</strong>: Same sample size per stratum regardless of population size</p>
<ul>
<li>Useful when comparing strata is primary goal</li>
</ul>
<p><strong>Advantages:</strong></p>
<ul>
<li>Ensures representation of all subgroups</li>
<li>Can increase precision substantially</li>
<li>Allows different sampling methods per stratum</li>
<li>Provides estimates for each stratum</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Requires information to create strata</li>
<li>Can be complex to analyze</li>
</ul>
</section>
<section id="cluster-sampling" class="level4">
<h4 class="anchored" data-anchor-id="cluster-sampling">Cluster Sampling</h4>
<p>Select groups (clusters) rather than individuals. Often used when population is naturally grouped or when creating a complete frame is difficult.</p>
<p><strong>Single-Stage Cluster Sampling:</strong></p>
<ol type="1">
<li>Divide population into clusters</li>
<li>Randomly select some clusters</li>
<li>Include all units from selected clusters</li>
</ol>
<p><strong>Two-Stage Cluster Sampling:</strong></p>
<ol type="1">
<li>Randomly select clusters (Primary Sampling Units)</li>
<li>Within selected clusters, randomly select individuals (Secondary Sampling Units)</li>
</ol>
<p><strong>Example</strong>: Surveying rural households in a large country:</p>
<ul>
<li>Stage 1: Randomly select 50 villages from 1,000 villages</li>
<li>Stage 2: Within each selected village, randomly select 20 households</li>
<li>Total sample: 50 × 20 = 1,000 households</li>
</ul>
<p><strong>Multi-Stage Example</strong>: National health survey:</p>
<ul>
<li>Stage 1: Select states</li>
<li>Stage 2: Select counties within selected states</li>
<li>Stage 3: Select census blocks within selected counties</li>
<li>Stage 4: Select households within selected blocks</li>
<li>Stage 5: Select one adult within selected households</li>
</ul>
<p><strong>Advantages:</strong></p>
<ul>
<li>Doesn’t require complete population list</li>
<li>Reduces travel costs (units clustered geographically)</li>
<li>Can use different methods at different stages</li>
<li>Natural for hierarchical populations</li>
</ul>
<p><strong>Disadvantages:</strong></p>
<ul>
<li>Less statistically efficient than SRS</li>
<li>Complex variance estimation</li>
<li>Larger samples needed for same precision</li>
</ul>
<p><strong>Design Effect</strong>: Cluster sampling typically requires larger samples than SRS. The design effect (DEFF) quantifies this:</p>
<p><span class="math display">\text{DEFF} = \frac{\text{Variance(cluster sample)}}{\text{Variance(SRS)}}</span></p>
<p>If DEFF = 2, you need twice the sample size to achieve the same precision as SRS.</p>
</section>
</section>
<section id="non-probability-sampling-methods" class="level3">
<h3 class="anchored" data-anchor-id="non-probability-sampling-methods">Non-Probability Sampling Methods</h3>
<p><strong>Non-probability sampling</strong> doesn’t guarantee known selection probabilities. While limiting statistical inference, these methods may be necessary or useful in certain situations.</p>
<section id="convenience-sampling" class="level4">
<h4 class="anchored" data-anchor-id="convenience-sampling">Convenience Sampling</h4>
<p>Selection based purely on ease of access. No attempt at representation.</p>
<p><strong>Examples:</strong></p>
<ul>
<li>Surveying students in your class about study habits</li>
<li>Interviewing people at a shopping mall about consumer preferences</li>
<li>Online polls where anyone can participate</li>
<li>Medical studies using volunteers who respond to advertisements</li>
</ul>
<p><strong>When It Might Be Acceptable:</strong></p>
<ul>
<li>Pilot studies to test survey instruments</li>
<li>Exploratory research to identify issues</li>
<li>When studying processes believed to be universal</li>
</ul>
<p><strong>Major Problems:</strong></p>
<ul>
<li>No basis for inference to population</li>
<li>Severe selection bias likely</li>
<li>Results may be completely misleading</li>
</ul>
<p><strong>Real Example</strong>: Literary Digest’s 1936 U.S. presidential poll surveyed 2.4 million people (huge sample!) but used telephone directories and club memberships as frames during the Depression, dramatically overrepresenting wealthy voters and incorrectly predicting Landon would defeat Roosevelt.</p>
</section>
<section id="purposive-judgmental-sampling" class="level4">
<h4 class="anchored" data-anchor-id="purposive-judgmental-sampling">Purposive (Judgmental) Sampling</h4>
<p>Deliberate selection of specific cases based on researcher judgment about what’s “typical” or “interesting.”</p>
<p><strong>Examples:</strong></p>
<ul>
<li>Selecting “typical” villages to represent rural areas</li>
<li>Choosing specific age groups for a developmental study</li>
<li>Selecting extreme cases to understand range of variation</li>
<li>Picking information-rich cases for in-depth study</li>
</ul>
<p><strong>Types of Purposive Sampling:</strong></p>
<p><strong>Typical Case</strong>: Choose average or normal examples</p>
<ul>
<li>Studying “typical” American suburbs</li>
</ul>
<p><strong>Extreme/Deviant Case</strong>: Choose unusual examples</p>
<ul>
<li>Studying villages with unusually low infant mortality to understand success factors</li>
</ul>
<p><strong>Maximum Variation</strong>: Deliberately pick diverse cases</p>
<ul>
<li>Selecting diverse schools (urban/rural, rich/poor, large/small) for education research</li>
</ul>
<p><strong>Critical Case</strong>: Choose cases that will be definitive</p>
<ul>
<li>“If it doesn’t work here, it won’t work anywhere”</li>
</ul>
<p><strong>When It’s Useful:</strong></p>
<ul>
<li>Qualitative research focusing on depth over breadth</li>
<li>When studying rare populations</li>
<li>Resource constraints limit sample size severely</li>
<li>Exploratory phases of research</li>
</ul>
<p><strong>Problems:</strong></p>
<ul>
<li>Entirely dependent on researcher judgment</li>
<li>No statistical inference possible</li>
<li>Different researchers might select different “typical” cases</li>
</ul>
</section>
<section id="quota-sampling" class="level4">
<h4 class="anchored" data-anchor-id="quota-sampling">Quota Sampling</h4>
<p>Selection to match population proportions on key characteristics. Like stratified sampling but without random selection within groups.</p>
<p><strong>How Quota Sampling Works:</strong></p>
<ol type="1">
<li>Identify key characteristics (age, sex, race, education)</li>
<li>Determine population proportions for these characteristics</li>
<li>Set quotas for each combination</li>
<li>Interviewers fill quotas using convenience methods</li>
</ol>
<p><strong>Detailed Example</strong>: Political poll with quotas:</p>
<p>Population proportions:</p>
<ul>
<li>Male 18-34: 15%</li>
<li>Male 35-54: 20%</li>
<li>Male 55+: 15%</li>
<li>Female 18-34: 16%</li>
<li>Female 35-54: 19%</li>
<li>Female 55+: 15%</li>
</ul>
<p>For a sample of 1,000:</p>
<ul>
<li>Interview 150 males aged 18-34</li>
<li>Interview 200 males aged 35-54</li>
<li>And so on…</li>
</ul>
<p>Interviewers might stand on street corners approaching people who appear to fit needed categories until quotas are filled.</p>
<p><strong>Why It’s Popular in Market Research:</strong></p>
<ul>
<li>Faster than probability sampling</li>
<li>Cheaper (no callbacks for specific individuals)</li>
<li>Ensures demographic representation</li>
<li>No sampling frame needed</li>
</ul>
<p><strong>Why It’s Problematic for Statistical Inference:</strong></p>
<p><strong>Hidden Selection Bias</strong>: Interviewers approach people who look approachable, speak the language well, aren’t in a hurry—systematically excluding certain types within each quota cell.</p>
<p><strong>Example of Bias</strong>: An interviewer filling a quota for “women 18-34” might approach women at a shopping mall on Tuesday afternoon, systematically missing:</p>
<ul>
<li>Women who work during weekdays</li>
<li>Women who can’t afford to shop at malls</li>
<li>Women with young children who avoid malls</li>
<li>Women who shop online</li>
</ul>
<p>Even though the final sample has the “right” proportion of young women, they’re not representative of all young women.</p>
<p><strong>No Measure of Sampling Error</strong>: Without selection probabilities, we can’t calculate standard errors or confidence intervals.</p>
<p><strong>Historical Cautionary Tale</strong>: Quota sampling was standard in polling until the 1948 U.S. presidential election, when polls using quota sampling incorrectly predicted Dewey would defeat Truman. The failure led to adoption of probability sampling in polling.</p>
</section>
<section id="snowball-sampling" class="level4">
<h4 class="anchored" data-anchor-id="snowball-sampling">Snowball Sampling</h4>
<p>Participants recruit additional subjects from their acquaintances. The sample grows like a rolling snowball.</p>
<p><strong>How It Works:</strong></p>
<ol type="1">
<li>Identify initial participants (seeds)</li>
<li>Ask them to refer others with required characteristics</li>
<li>Ask new participants for further referrals</li>
<li>Continue until sample size reached or referrals exhausted</li>
</ol>
<p><strong>Example</strong>: Studying undocumented immigrants:</p>
<ul>
<li>Start with 5 immigrants you can identify</li>
<li>Each refers 3 others they know</li>
<li>Those 15 each refer 2-3 others</li>
<li>Continue until you have 100+ participants</li>
</ul>
<p><strong>When It’s Valuable:</strong></p>
<p><strong>Hidden Populations</strong>: Groups without sampling frames</p>
<ul>
<li>Drug users</li>
<li>Homeless individuals</li>
<li>People with rare diseases</li>
<li>Members of underground movements</li>
</ul>
<p><strong>Socially Connected Populations</strong>: When relationships matter</p>
<ul>
<li>Studying social network effects</li>
<li>Researching community transmission of diseases</li>
<li>Understanding information diffusion</li>
</ul>
<p><strong>Trust-Dependent Research</strong>: When referrals increase participation</p>
<ul>
<li>Sensitive topics where trust is essential</li>
<li>Closed communities suspicious of outsiders</li>
</ul>
<p><strong>Major Limitations:</strong></p>
<ul>
<li>Samples biased toward cooperative, well-connected individuals</li>
<li>Isolated members of population missed entirely</li>
<li>Statistical inference generally impossible</li>
<li>Can reinforce social divisions (chains rarely cross social boundaries)</li>
</ul>
<p><strong>Advanced Version - Respondent-Driven Sampling (RDS):</strong></p>
<p>Attempts to make snowball sampling more rigorous by:</p>
<ul>
<li>Tracking who recruited whom</li>
<li>Limiting number of referrals per person</li>
<li>Weighting based on network size</li>
<li>Using mathematical models to adjust for bias</li>
</ul>
<p>Still controversial whether RDS truly allows valid inference.</p>
<hr>
</section>
</section>
</section>
<section id="probability-concepts-for-statistical-analysis" class="level2" data-number="1.13">
<h2 data-number="1.13" class="anchored" data-anchor-id="probability-concepts-for-statistical-analysis"><span class="header-section-number">1.13</span> Probability Concepts for Statistical Analysis</h2>
<p>While this is primarily a statistics course, understanding basic probability is essential for statistical inference.</p>
<section id="basic-probability" class="level3">
<h3 class="anchored" data-anchor-id="basic-probability">Basic Probability</h3>
<p><strong>Probability</strong> quantifies uncertainty on a scale from 0 (impossible) to 1 (certain).</p>
<p><strong>Classical Probability</strong>: <span class="math display">P(\text{event}) = \frac{\text{Number of favorable outcomes}}{\text{Total possible outcomes}}</span></p>
<p>Example: Probability a randomly selected person is female <span class="math inline">\approx 0.5</span></p>
<p><strong>Empirical Probability</strong>: Based on observed frequencies</p>
<p>Example: In a village, 423 of 1,000 residents are female, so <span class="math inline">P(\text{female}) \approx 0.423</span></p>
</section>
<section id="conditional-probability" class="level3">
<h3 class="anchored" data-anchor-id="conditional-probability">Conditional Probability</h3>
<p><strong>Conditional Probability</strong> is the probability of event A given that event B has occurred: <span class="math inline">P(A|B)</span></p>
<p><strong>Demographic Example</strong>: Probability of dying within a year given current age:</p>
<ul>
<li><span class="math inline">P(\text{death within year} | \text{age 30}) \approx 0.001</span></li>
<li><span class="math inline">P(\text{death within year} | \text{age 80}) \approx 0.05</span></li>
</ul>
<p>These conditional probabilities form the basis of life tables.</p>
</section>
<section id="independence" class="level3">
<h3 class="anchored" data-anchor-id="independence">Independence</h3>
<p>Events A and B are <strong>independent</strong> if <span class="math inline">P(A|B) = P(A)</span>.</p>
<p><strong>Testing Independence in Demographic Data:</strong></p>
<p>Are education and fertility independent?</p>
<ul>
<li><span class="math inline">P(\text{3+ children}) = 0.3</span> overall</li>
<li><span class="math inline">P(\text{3+ children} | \text{college degree}) = 0.15</span></li>
<li>Different probabilities indicate dependence</li>
</ul>
</section>
<section id="law-of-large-numbers" class="level3">
<h3 class="anchored" data-anchor-id="law-of-large-numbers">Law of Large Numbers</h3>
<p>As sample size increases, sample statistics converge to population parameters.</p>
<p><strong>Demonstration</strong>: Estimating sex ratio at birth:</p>
<ul>
<li>10 births: 7 males (70% - very unstable)</li>
<li>100 births: 53 males (53% - getting closer to ~51.2%)</li>
<li>1,000 births: 515 males (51.5% - quite close)</li>
<li>10,000 births: 5,118 males (51.18% - very close)</li>
</ul>
</section>
<section id="visualizing-the-law-of-large-numbers-coin-flips" class="level3">
<h3 class="anchored" data-anchor-id="visualizing-the-law-of-large-numbers-coin-flips">Visualizing the Law of Large Numbers: Coin Flips</h3>
<p>Let’s see this in action with coin flips. A fair coin has a 50% chance of landing heads, but individual flips are unpredictable.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate coin flips and show convergence</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>n_flips <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>flips <span class="ot">&lt;-</span> <span class="fu">rbinom</span>(n_flips, <span class="dv">1</span>, <span class="fl">0.5</span>)  <span class="co"># 1 = heads, 0 = tails</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate cumulative proportion of heads</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>cumulative_prop <span class="ot">&lt;-</span> <span class="fu">cumsum</span>(flips) <span class="sc">/</span> <span class="fu">seq_along</span>(flips)</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data frame for plotting</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>lln_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">flip_number =</span> <span class="dv">1</span><span class="sc">:</span>n_flips,</span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">cumulative_proportion =</span> cumulative_prop</span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the convergence</span></span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(lln_data, <span class="fu">aes</span>(<span class="at">x =</span> flip_number, <span class="at">y =</span> cumulative_proportion)) <span class="sc">+</span></span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">color =</span> <span class="st">"steelblue"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.5</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fu">c</span>(<span class="fl">0.45</span>, <span class="fl">0.55</span>), <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Law of Large Numbers: Coin Flip Proportions Converge to 0.5"</span>,</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Number of coin flips"</span>,</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Cumulative proportion of heads"</span>,</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">caption =</span> <span class="st">"Red dashed line = true probability (0.5)</span><span class="sc">\n</span><span class="st">Dotted lines = ±5% range"</span></span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb13-26"><a href="#cb13-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.7</span>), <span class="at">breaks =</span> <span class="fu">seq</span>(<span class="fl">0.3</span>, <span class="fl">0.7</span>, <span class="fl">0.1</span>)) <span class="sc">+</span></span>
<span id="cb13-27"><a href="#cb13-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/lln-demo-1.png" class="img-fluid figure-img" width="768"></p>
</figure>
</div>
</div>
</div>
<p><strong>What this shows:</strong></p>
<ul>
<li>Early flips show wild variation (first 10 flips might be 70% or 30% heads)</li>
<li>As we add more flips, the proportion stabilizes around 50%</li>
<li>The “noise” of individual outcomes averages out over time</li>
</ul>
</section>
<section id="the-mathematical-statement" class="level3">
<h3 class="anchored" data-anchor-id="the-mathematical-statement">The Mathematical Statement</h3>
<p>Let <span class="math inline">A</span> denote an event of interest (e.g., “heads on a coin flip”, “vote for party X”, “sum of dice equals 7”). If <span class="math inline">P(A) = p</span> and we observe <span class="math inline">n</span> <strong>independent trials with the same distribution</strong> (i.i.d.), then the <strong>sample frequency of</strong> <span class="math inline">A</span>:</p>
<p><span class="math display">\hat{p}_n = \frac{\text{number of occurrences of } A}{n}</span></p>
<p><strong>converges to</strong> <span class="math inline">p</span> as <span class="math inline">n</span> increases.</p>
</section>
<section id="examples-in-different-contexts" class="level3">
<h3 class="anchored" data-anchor-id="examples-in-different-contexts">Examples in Different Contexts</h3>
<p><strong>Dice example</strong>: The event “sum = 7” with two dice has probability <span class="math inline">6/36 ≈ 16.7\%</span>, while “sum = 4” has <span class="math inline">3/36 ≈ 8.3\%</span>. Over many throws, a sum of 7 appears about twice as often as a sum of 4.</p>
<p><strong>Election polling</strong>: If population support for a party equals <span class="math inline">p</span>, then under random sampling of size <span class="math inline">n</span>, the observed frequency <span class="math inline">\hat{p}_n</span> will approach <span class="math inline">p</span> as <span class="math inline">n</span> grows (assuming random sampling and independence).</p>
<p><strong>Quality control</strong>: If 2% of products are defective, then in large batches, approximately 2% will be found defective (assuming independent production).</p>
</section>
<section id="why-this-matters-for-statistics" class="level3">
<h3 class="anchored" data-anchor-id="why-this-matters-for-statistics">Why This Matters for Statistics</h3>
<p><strong>Bottom line</strong>: Randomness underpins statistical inference by turning uncertainty in individual outcomes into <strong>predictable distributions</strong> for estimates. The Law of Large Numbers guarantees that the “noise” of individual outcomes averages out, allowing us to:</p>
<ul>
<li>Predict long-run frequencies</li>
<li>Quantify uncertainty (margins of error)<br>
</li>
<li>Draw reliable inferences from samples</li>
<li>Make probabilistic statements about populations</li>
</ul>
<p>This principle works in surveys, experiments, and even quantum phenomena (in the frequentist interpretation).</p>
<hr>
</section>
<section id="central-limit-theorem-clt" class="level3">
<h3 class="anchored" data-anchor-id="central-limit-theorem-clt">Central Limit Theorem (CLT)</h3>
<p>The Central Limit Theorem states that the distribution of sample means approaches a normal distribution as sample size increases, <strong>regardless of the shape of the original population distribution</strong>. This holds true even for highly skewed or non-normal populations.</p>
<section id="key-insights" class="level4">
<h4 class="anchored" data-anchor-id="key-insights">Key Insights</h4>
<ul>
<li><strong>Sample Size Threshold</strong>: Sample sizes of n ≥ 30 are typically sufficient for the CLT to apply</li>
<li><strong>Standard Error</strong>: The standard deviation of sample means equals σ/√n, where σ is the population standard deviation</li>
<li><strong>Statistical Foundation</strong>: We can make inferences about population parameters using normal distribution properties, even when the underlying data is non-normal</li>
</ul>
</section>
<section id="why-this-matters-in-practice" class="level4">
<h4 class="anchored" data-anchor-id="why-this-matters-in-practice">Why This Matters in Practice</h4>
<p>Consider income data, which is typically right-skewed with a long tail of high earners. While individual incomes don’t follow a normal distribution, something remarkable happens when we repeatedly take samples and calculate their means:</p>
<p><strong>What “normally distributed sample means” actually means:</strong></p>
<ol type="1">
<li>If you take many different groups of 30+ people and calculate each group’s average income</li>
<li>These group averages will form a bell-shaped pattern when plotted</li>
<li>Most group averages will cluster near the true population mean</li>
<li>The probability of getting a group average far from the population mean becomes predictable</li>
</ol>
<p>This predictable pattern (normal distribution) allows us to:</p>
<ul>
<li>Calculate confidence intervals using normal distribution properties</li>
<li>Perform statistical hypothesis tests</li>
<li>Make predictions about sample means with known probability</li>
</ul>
<p><strong>Concrete Example:</strong> Imagine a city where individual incomes range from $20,000 to $10,000,000, heavily skewed right. If you:</p>
<ul>
<li>Randomly select 100 people and calculate their mean income: maybe $75,000</li>
<li>Repeat this 1000 times (1000 different groups of 100 people)</li>
<li>Plot these 1000 group means: they’ll form a bell curve centered around the true population mean</li>
<li>About 95% of these group means will fall within a predictable range</li>
<li>This happens even though individual incomes are extremely skewed!</li>
</ul>
</section>
<section id="mathematical-foundation" class="level4">
<h4 class="anchored" data-anchor-id="mathematical-foundation">Mathematical Foundation</h4>
<p>For a population with mean μ and finite variance σ²:</p>
<ul>
<li><strong>Sampling distribution of the mean</strong>: <span class="math inline">\bar{X} \sim N(\mu, \frac{\sigma^2}{n})</span> as <span class="math inline">n \to \infty</span></li>
<li><strong>Standard error of the mean</strong>: <span class="math inline">SE_{\bar{X}} = \frac{\sigma}{\sqrt{n}}</span></li>
<li><strong>Standardized sample mean</strong>: <span class="math inline">Z = \frac{\bar{X} - \mu}{\sigma/\sqrt{n}} \sim N(0,1)</span> for large n</li>
</ul>
</section>
<section id="key-takeaways-1" class="level4">
<h4 class="anchored" data-anchor-id="key-takeaways-1">Key Takeaways</h4>
<ol type="1">
<li><strong>Universal Application</strong>: The CLT applies to any distribution with finite variance</li>
<li><strong>Convergence to Normality</strong>: The approximation to normal distribution improves as sample size increases</li>
<li><strong>Foundation for Inference</strong>: Most parametric statistical tests rely on the CLT</li>
<li><strong>Sample Size Considerations</strong>: While n ≥ 30 is a common guideline, highly skewed distributions may require larger samples for accurate approximation</li>
</ol>
<hr>
</section>
</section>
</section>
<section id="statistical-significance-a-quick-start-guide" class="level2" data-number="1.14">
<h2 data-number="1.14" class="anchored" data-anchor-id="statistical-significance-a-quick-start-guide"><span class="header-section-number">1.14</span> Statistical Significance: A Quick Start Guide</h2>
<p>Imagine you flip a coin 10 times and get 8 heads. Is the coin biased, or did you just get lucky? This is the core question statistical significance (statistical inference) helps us answer.</p>
<p><strong>Statistical significance</strong> tells us whether patterns in our data likely reflect something real or could have happened by pure chance.</p>
<p><strong>Statistical significance</strong> is a measure (p-value) of how confident we can be that patterns observed in our sample are not due to chance alone. When a result is statistically significant (typically p-value &lt; 0.05), it means the probability of obtaining such data in the absence of a real effect is very low.</p>
<section id="the-courtroom-analogy" class="level3">
<h3 class="anchored" data-anchor-id="the-courtroom-analogy">The Courtroom Analogy</h3>
<p>Statistical hypothesis testing works like a criminal trial:</p>
<ul>
<li><strong>Null Hypothesis (</strong><span class="math inline">H_0</span>): The defendant is innocent (no effect exists)</li>
<li><strong>Alternative Hypothesis (</strong><span class="math inline">H_1</span>): The defendant is guilty (an effect exists)</li>
<li><strong>The Evidence</strong>: Your data and test results</li>
<li><strong>The Verdict</strong>: “Guilty” (reject <span class="math inline">H_0</span>) or “Not Guilty” (fail to reject <span class="math inline">H_0</span>)</li>
</ul>
<p><strong>Crucial distinction</strong>: “Not guilty” ≠ “Innocent”</p>
<ul>
<li>A “not guilty” verdict means insufficient evidence to convict</li>
<li>Similarly, “not statistically significant” means insufficient evidence for an effect, NOT proof of no effect</li>
</ul>
</section>
<section id="start-with-skepticism-presumption-of-innocence" class="level3">
<h3 class="anchored" data-anchor-id="start-with-skepticism-presumption-of-innocence">Start with Skepticism (Presumption of Innocence)</h3>
<p>In statistics, we always start by assuming nothing special is happening:</p>
<ul>
<li><strong>Null Hypothesis (</strong><span class="math inline">H_0</span>): “There’s no effect”
<ul>
<li>The coin is fair</li>
<li>The new drug doesn’t work</li>
<li>Study time doesn’t affect grades</li>
</ul></li>
<li><strong>Alternative Hypothesis (</strong><span class="math inline">H_1</span>): “There IS an effect”
<ul>
<li>The coin is biased</li>
<li>The drug works</li>
<li>More study time improves grades</li>
</ul></li>
</ul>
<p><strong>Key principle</strong>: We maintain the null hypothesis (innocence) unless our data provides strong evidence against it—“beyond a reasonable doubt” in legal terms, or “p &lt; 0.05” in statistical terms.</p>
</section>
</section>
<section id="the-p-value-your-surprise-meter" class="level2" data-number="1.15">
<h2 data-number="1.15" class="anchored" data-anchor-id="the-p-value-your-surprise-meter"><span class="header-section-number">1.15</span> The p-value: Your “Surprise Meter”</h2>
<p>The <strong>p-value</strong> answers one specific question:</p>
<blockquote class="blockquote">
<p>“If nothing special were happening (null hypothesis is true), how surprising would our results be?”</p>
<p>A p-value is&nbsp;the probability of observing the study’s results, or more extreme results, if the null hypothesis (a statement of no effect or no difference) is true.</p>
</blockquote>
<section id="three-ways-to-think-about-p-values" class="level3">
<h3 class="anchored" data-anchor-id="three-ways-to-think-about-p-values">Three Ways to Think About p-values</h3>
<section id="the-surprise-scale" class="level4">
<h4 class="anchored" data-anchor-id="the-surprise-scale">1. The Surprise Scale</h4>
<ul>
<li><strong>p &lt; 0.01</strong>: Very surprising! (Strong evidence against <span class="math inline">H_0</span>)</li>
<li><strong>p &lt; 0.05</strong>: Pretty surprising (Moderate evidence against <span class="math inline">H_0</span>)</li>
<li><strong>p &gt; 0.05</strong>: Not that surprising (Insufficient evidence against <span class="math inline">H_0</span>)</li>
</ul>
</section>
<section id="concrete-example-the-suspicious-coin" class="level4">
<h4 class="anchored" data-anchor-id="concrete-example-the-suspicious-coin">2. Concrete Example: The Suspicious Coin</h4>
<p>You flip a coin 10 times and get 8 heads. What’s the p-value?</p>
<p><strong>The calculation</strong>: If the coin were fair, the probability of getting 8 or more heads is: <span class="math display">p = P(≥8 \text{ heads in 10 flips}) \approx 0.055 \approx 5.5\%</span></p>
<p><span class="math display">P(X \geq 8) = \sum_{k=8}^{10} \binom{10}{k} 0,5^{10} = \frac{56}{1024} \approx 0,0547</span></p>
<p><strong>Interpretation</strong>: There’s a 5.5% chance of getting results this extreme with a fair coin. That’s somewhat unusual but not shocking.</p>
</section>
<section id="the-formal-definition" class="level4">
<h4 class="anchored" data-anchor-id="the-formal-definition">3. The Formal Definition</h4>
<p>A p-value is the probability of getting results at least as extreme as what you observed, <strong>assuming the null hypothesis is true</strong>.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Common Mistake</strong>: The p-value is NOT the probability that the null hypothesis is true! It assumes the null is true and tells you how unusual your data would be in that world.</p>
</div>
</div>
</section>
</section>
</section>
<section id="the-prosecutor-fallacy-a-warning" class="level2" data-number="1.16">
<h2 data-number="1.16" class="anchored" data-anchor-id="the-prosecutor-fallacy-a-warning"><span class="header-section-number">1.16</span> The Prosecutor Fallacy: A Warning</h2>
<p>I can see why the example might be challenging for beginners! Here’s a revised version that builds up the intuition more gradually without requiring knowledge of Bayes theorem or significance levels:</p>
</section>
<section id="the-prosecutor-fallacy-a-warning-1" class="level2" data-number="1.17">
<h2 data-number="1.17" class="anchored" data-anchor-id="the-prosecutor-fallacy-a-warning-1"><span class="header-section-number">1.17</span> The Prosecutor Fallacy: A Warning</h2>
<section id="the-fallacy-explained" class="level3">
<h3 class="anchored" data-anchor-id="the-fallacy-explained">The Fallacy Explained</h3>
<p>Imagine this courtroom scenario:</p>
<p><strong>Prosecutor</strong>: “If the defendant were innocent, there’s only a 1% chance we’d find his DNA at the crime scene. We found his DNA. Therefore, there’s a 99% chance he’s guilty!”</p>
<p><strong>This is WRONG!</strong> The prosecutor confused:</p>
<ul>
<li>P(Evidence | Innocent) = 0.01 ← What we know</li>
<li>P(Innocent | Evidence) = ? ← What we want to know (but can’t get from the p-value alone!)</li>
</ul>
<hr>
<p>When we get p = 0.01, it’s tempting to think:</p>
<p>❌ <strong>WRONG</strong>: “There’s only a 1% chance the null hypothesis is true”<br>
❌ <strong>WRONG</strong>: “There’s a 99% chance our treatment works”</p>
<p>✅ <strong>CORRECT</strong>: “If the null hypothesis were true, there’s only a 1% chance we’d see data this extreme”</p>
</section>
<section id="why-this-matters-a-simple-medical-testing-example" class="level3">
<h3 class="anchored" data-anchor-id="why-this-matters-a-simple-medical-testing-example">Why This Matters: A Simple Medical Testing Example</h3>
<p>Imagine a rare disease test that’s 99% accurate:</p>
<ul>
<li>If you have the disease, the test is positive 99% of the time</li>
<li>If you don’t have the disease, the test is negative 99% of the time (so 1% false positive rate)</li>
</ul>
<p><strong>Here’s the key</strong>: Suppose only 1 in 1000 people actually have this disease.</p>
<p>Now let’s test 10,000 people:</p>
<ul>
<li><strong>10 people have the disease</strong> → 10 test positive (rounded)</li>
<li><strong>9,990 people don’t have the disease</strong> → about 100 test positive by mistake (1% of 9,990)</li>
<li><strong>Total positive tests</strong>: 110</li>
</ul>
<p><strong>If you test positive, what’s the chance you actually have the disease?</strong></p>
<ul>
<li>Only 10 out of 110 positive tests are real</li>
<li>That’s about 9%, not 99%!</li>
</ul>
</section>
<section id="the-research-analogy" class="level3">
<h3 class="anchored" data-anchor-id="the-research-analogy">The Research Analogy</h3>
<p>The same thing happens in research:</p>
<ul>
<li>When we test many hypotheses (like testing many potential drugs)</li>
<li>Most don’t work (like most people don’t have the rare disease)</li>
<li>Even with “significant” results (like a positive test), most findings might be false positives</li>
</ul>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>A p-value tells you how surprising your data would be IF the null hypothesis were true. It doesn’t tell you the probability that the null hypothesis IS true.</p>
<p>Think of it like this: The probability of the ground being wet IF it rained is very different from the probability it rained IF the ground is wet—the ground could be wet from a sprinkler!</p>
<hr>
<p><strong>Remember</strong>: A p-value tells you P(Data | Null is true), not P(Null is true | Data). These are as different as P(Wet ground | Rain) and P(Rain | Wet ground)—the ground could be wet from a sprinkler!</p>
</div>
</div>
<hr>
</section>
</section>
<section id="introduction-to-regression-analysis-modeling-relationships-between-variables" class="level2" data-number="1.18">
<h2 data-number="1.18" class="anchored" data-anchor-id="introduction-to-regression-analysis-modeling-relationships-between-variables"><span class="header-section-number">1.18</span> Introduction to Regression Analysis: Modeling Relationships Between Variables</h2>
<p>One of the most powerful tools in statistical analysis is <strong>regression analysis</strong>—a method for understanding and quantifying relationships between variables.</p>
<p>The core idea is simple: How does one thing relate to another, and can we use that relationship to make predictions?</p>
<blockquote class="blockquote">
<p><strong>The One-Sentence Summary:</strong> Regression helps us understand how things relate to each other in a messy, complicated world where everything affects everything else.</p>
</blockquote>
<section id="what-is-regression-analysis" class="level3">
<h3 class="anchored" data-anchor-id="what-is-regression-analysis">What is Regression Analysis?</h3>
<p>Imagine you’re curious about the relationship between education and income. You notice that people with more education tend to earn more money, but you want to understand this relationship more precisely:</p>
<ul>
<li>How much does each additional year of education increase income, on average?</li>
<li>How strong is this relationship?</li>
<li>Are there other factors we should consider?</li>
<li>Can we predict someone’s likely income if we know their education level?</li>
</ul>
<p>Regression analysis provides systematic answers to these questions. It’s like finding the “best-fitting story” that describes how variables relate to each other.</p>
</section>
<section id="variables-and-variation" class="level3">
<h3 class="anchored" data-anchor-id="variables-and-variation">Variables and Variation</h3>
<p>A <strong>variable</strong> is any characteristic that can take different values across units of observation. In political science:</p>
<ul>
<li><strong>Units of analysis</strong>: Countries, individuals, elections, policies, years</li>
<li><strong>Variables</strong>: GDP, voting preference, democracy score, conflict occurrence</li>
</ul>
<blockquote class="blockquote">
<p><strong>💡 In Plain English:</strong> A variable is anything that changes. If everyone voted the same way, “voting preference” wouldn’t be a variable—it would be a constant. We study variables because we want to understand why things differ.</p>
</blockquote>
<hr>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Consider a typical pre-election news headline: “Candidate Smith’s approval rating reaches 68%.” Your immediate inference likely suggests favorable electoral prospects for Smith—not guaranteed victory, but a strong position. You naturally understand that higher approval ratings tend to predict better electoral performance, even though the relationship is not perfect.</p>
<p>This intuitive assessment exemplifies the core logic of regression analysis. You used one piece of information (approval rating) to make a prediction about another outcome (electoral success). Moreover, you recognized both the relationship between these variables and the uncertainty inherent in your prediction.</p>
<p>While such informal reasoning serves us well in daily life, it has important limitations. How much better are Smith’s chances at 68% approval compared to 58%? What happens when we need to consider multiple factors simultaneously—approval ratings, economic conditions, and incumbency status? How confident should we be in our predictions?</p>
<p>Regression analysis provides a systematic framework for addressing these questions. It transforms our intuitive understanding of relationships into precise mathematical models that can be tested and refined. Through regression analysis, researchers can:</p>
<ul>
<li><p><strong>Generate precise predictions</strong>: Move beyond general assessments to specific numerical estimates—for instance, predicting not just that Smith will “probably win,” but estimating the expected vote share and range of likely outcomes.</p></li>
<li><p><strong>Identify which factors matter most</strong>: Determine the relative importance of different variables—perhaps discovering that economic conditions influence elections more strongly than approval ratings.</p></li>
<li><p><strong>Quantify uncertainty in predictions</strong>: Explicitly measure how confident we should be in our predictions, distinguishing between near-certain outcomes and educated guesses.</p></li>
<li><p><strong>Test theoretical propositions with empirical data</strong>: Evaluate whether our beliefs about cause-and-effect relationships hold up when examined systematically across many observations.</p></li>
</ul>
<blockquote class="blockquote">
<p>In essence, regression analysis systematizes the pattern recognition we perform intuitively, providing tools to make our predictions more accurate, our comparisons more meaningful, and our conclusions more reliable.</p>
</blockquote>
<hr>
<section id="the-fundamental-model" class="level3">
<h3 class="anchored" data-anchor-id="the-fundamental-model">The Fundamental Model</h3>
<p>A model represents an object, person, or system in an informative way. Models divide into physical representations (such as architectural models) and abstract representations (such as mathematical equations describing atmospheric dynamics).</p>
<p>The core of statistical thinking can be expressed as:</p>
<p><span class="math display">Y = f(X) + \text{error}</span></p>
<p>This equation states that our outcome (<span class="math inline">Y</span>) equals some function of our predictors (<span class="math inline">X</span>), plus unpredictable variation.</p>
<p><strong>Components</strong>:</p>
<ul>
<li><span class="math inline">Y</span> = Dependent variable (the phenomenon we seek to explain)</li>
<li><span class="math inline">X</span> = Independent variable(s) (explanatory factors)</li>
<li><span class="math inline">f()</span> = The functional relationship (often assumed linear)</li>
<li>error (<span class="math inline">\epsilon</span>) = Unexplained variation</li>
</ul>
<blockquote class="blockquote">
<p><strong>💡 What This Really Means:</strong> Think of it like a recipe. Your grade in a class (<span class="math inline">Y</span>) depends on study hours (<span class="math inline">X</span>), but not perfectly. Two students studying 10 hours might get different grades because of test anxiety, prior knowledge, or just luck (the error term). Regression finds the average relationship.</p>
</blockquote>
<p>This model provides the foundation for all statistical analysis—from simple correlations to complex machine learning algorithms.</p>
<p>Regression helps answer fundamental questions such as:</p>
<ul>
<li>How much does education increase political participation?</li>
<li>What factors predict electoral success?</li>
<li>Do democratic institutions promote economic growth?</li>
</ul>
</section>
</div>
</div>
</section>
<section id="the-basic-idea-drawing-the-best-line-through-points" class="level3">
<h3 class="anchored" data-anchor-id="the-basic-idea-drawing-the-best-line-through-points">The Basic Idea: Drawing the Best Line Through Points</h3>
<section id="simple-linear-regression" class="level4">
<h4 class="anchored" data-anchor-id="simple-linear-regression">Simple Linear Regression</h4>
<p>Let’s start with the simplest case: the relationship between two variables. Suppose we plot education (years of schooling) on the x-axis and annual income on the y-axis for 100 people. We’d see a cloud of points, and regression finds the straight line that best represents the pattern in these points.</p>
<p><strong>What makes a line “best”?</strong> The regression line minimizes the total squared vertical distances from all points to the line. Think of it as finding the line that makes the smallest total prediction error.</p>
<p>The equation of this line is: <span class="math display">Y = a + bX + \text{error}</span></p>
<p>Or in our example: <span class="math display">\text{Income} = a + b \times \text{Education} + \text{error}</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">a</span> (intercept) = predicted income with zero education</li>
<li><span class="math inline">b</span> (slope) = change in income per additional year of education</li>
<li>error (<span class="math inline">e</span>) = difference between actual and predicted income</li>
</ul>
<p><strong>Interpreting the Results:</strong></p>
<p>If our analysis finds: <span class="math display">\text{Income} = 15,000 + 4,000 \times \text{Education}</span></p>
<p>This tells us:</p>
<ul>
<li>Someone with 0 years of education is predicted to earn $15,000</li>
<li>Each additional year of education is associated with $4,000 more income</li>
<li>Someone with 12 years of education is predicted to earn: $15,000 + (4,000 ) = $63,000</li>
<li>Someone with 16 years (bachelor’s degree) is predicted to earn: $15,000 + (4,000 ) = $79,000</li>
</ul>
</section>
</section>
<section id="understanding-relationships-vs.-proving-causation" class="level3">
<h3 class="anchored" data-anchor-id="understanding-relationships-vs.-proving-causation">Understanding Relationships vs.&nbsp;Proving Causation</h3>
<p>A crucial distinction: regression shows <strong>association</strong>, not necessarily <strong>causation</strong>. Our education-income regression shows they’re related, but doesn’t prove education causes higher income. Other explanations are possible:</p>
<ul>
<li><strong>Reverse causation</strong>: Maybe wealthier families can afford more education for their children</li>
<li><strong>Common cause</strong>: Perhaps intelligence or motivation affects both education and income</li>
<li><strong>Coincidence</strong>: In small samples, patterns can appear by chance</li>
</ul>
<p><strong>Example of Spurious Correlation</strong>: A regression might show that ice cream sales strongly predict drowning deaths. Does ice cream cause drowning? No! Both increase in summer (the common cause, <em>confounding variable</em>).</p>
<hr>
</section>
<section id="multiple-regression-controlling-for-other-factors" class="level3">
<h3 class="anchored" data-anchor-id="multiple-regression-controlling-for-other-factors">Multiple Regression: Controlling for Other Factors</h3>
<p>Real life is complicated—many factors influence outcomes simultaneously. <strong>Multiple regression</strong> lets us examine one relationship while “controlling for” or “holding constant” other variables.</p>
<section id="the-power-of-statistical-control" class="level4">
<h4 class="anchored" data-anchor-id="the-power-of-statistical-control">The Power of Statistical Control</h4>
<p>Returning to education and income, we might wonder: Is the education effect just because educated people tend to be from wealthier families, or live in cities? Multiple regression can separate these effects:</p>
<p><span class="math display">\text{Income} = a + b_1 \times \text{Education} + b_2 \times \text{Age} + b_3 \times \text{Urban} + b_4 \times \text{Parent Income} + \text{error}</span></p>
<p>Now <span class="math inline">b_1</span> represents the education effect <em>after accounting for</em> age, location, and family background. If <span class="math inline">b_1 = 3,000</span>, it means: “Comparing people of the same age, location, and family background, each additional year of education is associated with $3,000 more income.”</p>
<p><strong>Demographic Example</strong>: Fertility and Women’s Education</p>
<p>Researchers studying fertility might find: <span class="math display">\text{Children} = 4.5 - 0.3 \times \text{Education}</span></p>
<p>This suggests each year of women’s education is associated with 0.3 fewer children. But is education the cause, or are educated women different in other ways? Adding controls:</p>
<p><span class="math display">\text{Children} = a - 0.15 \times \text{Education} - 0.2 \times \text{Urban} + 0.1 \times \text{Husband Education} - 0.4 \times \text{Contraceptive Access}</span></p>
<p>Now we see education’s association is weaker (-0.15 instead of -0.3) after accounting for urban residence and contraceptive access. This suggests part of education’s apparent effect operates through these other pathways.</p>
</section>
</section>
<section id="types-of-variables-in-regression" class="level3">
<h3 class="anchored" data-anchor-id="types-of-variables-in-regression">Types of Variables in Regression</h3>
<section id="outcome-dependent-variable" class="level4">
<h4 class="anchored" data-anchor-id="outcome-dependent-variable">Outcome (Dependent) Variable</h4>
<p>This is what we’re trying to understand or predict:</p>
<ul>
<li>Income in our first example</li>
<li>Number of children in our fertility example</li>
<li>Life expectancy in health studies</li>
<li>Migration probability in population studies</li>
</ul>
</section>
<section id="predictor-independent-variables" class="level4">
<h4 class="anchored" data-anchor-id="predictor-independent-variables">Predictor (Independent) Variables</h4>
<p>These are factors we think might influence the outcome:</p>
<ul>
<li><strong>Quantitative</strong>: Age, years of education, income, distance</li>
<li><strong>Qualitative (categorical)</strong>: Gender, race, marital status, region</li>
<li><strong>Binary (Dummy)</strong>: Urban/rural, employed/unemployed, married/unmarried</li>
</ul>
<p><strong>Handling Categorical Variables</strong>: We can’t directly put “religion” into an equation. Instead, we create binary variables:</p>
<ul>
<li>Christian = 1 if Christian, 0 otherwise</li>
<li>Muslim = 1 if Muslim, 0 otherwise</li>
<li>Hindu = 1 if Hindu, 0 otherwise</li>
<li>(One category becomes the reference group)</li>
</ul>
</section>
</section>
<section id="different-types-of-regression-for-different-outcomes" class="level3">
<h3 class="anchored" data-anchor-id="different-types-of-regression-for-different-outcomes">Different Types of Regression for Different Outcomes</h3>
<p>The basic regression idea adapts to many situations:</p>
<section id="linear-regression" class="level4">
<h4 class="anchored" data-anchor-id="linear-regression">Linear Regression</h4>
<p>For continuous outcomes (income, height, blood pressure): <span class="math display">Y = a + b_1X_1 + b_2X_2 + … + \text{error}</span></p>
</section>
<section id="logistic-regression" class="level4">
<h4 class="anchored" data-anchor-id="logistic-regression">Logistic Regression</h4>
<p>For binary outcomes (died/survived, migrated/stayed, married/unmarried):</p>
<p>Instead of predicting the outcome directly, we predict the probability: <span class="math display">\log\left(\frac{p}{1-p}\right) = a + b_1X_1 + b_2X_2 + …</span></p>
<p>Where <span class="math inline">p</span> is the probability of the event occurring.</p>
<p><strong>Example</strong>: Predicting migration probability based on age, education, and marital status. The model might find young, educated, unmarried people have 40% probability of migrating, while older, less educated, married people have only 5% probability.</p>
</section>
<section id="poisson-regression" class="level4">
<h4 class="anchored" data-anchor-id="poisson-regression">Poisson Regression</h4>
<p>For count outcomes (number of children, number of doctor visits): <span class="math display">\log(\text{expected count}) = a + b_1X_1 + b_2X_2 + …</span></p>
<p><strong>Example</strong>: Modeling number of children based on women’s characteristics. Useful because it ensures predictions are never negative (can’t have -0.5 children!).</p>
</section>
<section id="survival-cox-modelhazard-regression" class="level4">
<h4 class="anchored" data-anchor-id="survival-cox-modelhazard-regression">Survival (Cox model)/Hazard Regression</h4>
<p><strong>What it’s for:</strong> Predicting <em>when</em> something will happen, not just <em>if</em> it will happen.</p>
<p><strong>The challenge:</strong> Imagine you’re studying how long marriages last. You follow 1,000 couples for 10 years, but by the end of your study:</p>
<ul>
<li>400 couples divorced (you know exactly when)</li>
<li>600 couples are still married (you don’t know if/when they’ll divorce)</li>
</ul>
<p>Regular regression can’t handle this “incomplete story” problem—those 600 ongoing marriages contain valuable information, but we don’t know their endpoints yet.</p>
<p><strong>How Cox models help:</strong> Instead of trying to predict the exact timing, they focus on <em>relative risk</em>—who’s more likely to experience the event sooner. Think of it like asking “At any given moment, who’s at higher risk?” rather than “Exactly when will this happen?”</p>
<p><strong>Real-world applications:</strong></p>
<ul>
<li>Medical research: Who responds to treatment faster?</li>
<li>Business: Which customers cancel subscriptions sooner?</li>
<li>Social science: What factors make life events happen earlier/later?</li>
</ul>
<hr>
</section>
</section>
<section id="interpreting-regression-results" class="level3">
<h3 class="anchored" data-anchor-id="interpreting-regression-results">Interpreting Regression Results</h3>
<section id="coefficients" class="level4">
<h4 class="anchored" data-anchor-id="coefficients">Coefficients</h4>
<p>The coefficient tells us the expected change in outcome for a one-unit increase in the predictor, holding other variables constant.</p>
<p><strong>Examples of Interpretation:</strong></p>
<p>Linear regression for income:</p>
<ul>
<li>“Each additional year of education is associated with $3,500 higher annual income, controlling for age and experience”</li>
</ul>
<p>Logistic regression for infant mortality:</p>
<ul>
<li>“Each additional prenatal visit is associated with 15% lower odds of infant death, controlling for mother’s age and education”</li>
</ul>
<p>Multiple regression for life expectancy:</p>
<ul>
<li>“Each $1,000 increase in per-capita GDP is associated with 0.4 years longer life expectancy, after controlling for education and healthcare access”</li>
</ul>
</section>
<section id="statistical-significance" class="level4">
<h4 class="anchored" data-anchor-id="statistical-significance">Statistical Significance</h4>
<p>The regression also tests whether relationships could be due to chance:</p>
<ul>
<li><strong>p-value &lt; 0.05</strong>: Relationship unlikely due to chance (statistically significant)</li>
<li><strong>p-value &gt; 0.05</strong>: Relationship could plausibly be random variation</li>
</ul>
<blockquote class="blockquote">
<p>But remember: Statistical significance ≠ practical importance. With large samples, tiny effects become “significant.”</p>
</blockquote>
</section>
<section id="confidence-intervals-for-coefficients" class="level4">
<h4 class="anchored" data-anchor-id="confidence-intervals-for-coefficients">Confidence Intervals for Coefficients</h4>
<p>Just as we have confidence intervals for means or proportions, we have them for regression coefficients:</p>
<p>“The effect of education on income is $3,500 per year, 95% CI: [$2,800, $4,200]”</p>
<p>This means we’re 95% confident the true effect is between $2,800 and $4,200.</p>
</section>
<section id="r-squared-how-well-does-the-model-fit" class="level4">
<h4 class="anchored" data-anchor-id="r-squared-how-well-does-the-model-fit">R-squared: How Well Does the Model Fit?</h4>
<p><span class="math inline">R^2</span> (R-squared) measures the proportion of variation in the outcome explained by the predictors:</p>
<ul>
<li><span class="math inline">R^2 = 0</span>: Predictors explain nothing</li>
<li><span class="math inline">R^2 = 1</span>: Predictors explain everything</li>
<li><span class="math inline">R^2 = 0.3</span>: Predictors explain 30% of variation</li>
</ul>
<p><strong>Example</strong>: A model of income with only education might have <span class="math inline">R^2 = 0.15</span> (education explains 15% of income variation). Adding age, experience, and location might increase <span class="math inline">R^2</span> to 0.35 (together they explain 35%).</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Assumptions and Limitations
</div>
</div>
<div class="callout-body-container callout-body">
<p>Regression makes assumptions that may not hold:</p>
<section id="exogeneity-no-hidden-relationships" class="level4">
<h4 class="anchored" data-anchor-id="exogeneity-no-hidden-relationships">Exogeneity (No Hidden Relationships)</h4>
<p>The most fundamental assumption: predictors must not be correlated with errors. In simple terms, there shouldn’t be hidden factors that affect both your predictors and outcome.</p>
<p><strong>Example</strong>: If studying education’s effect on income but omitting “ability,” your results are biased - ability affects both education level and income. This assumption is written as: <span class="math inline">E[\varepsilon | X] = 0</span></p>
<p><strong>Why it matters</strong>: Without it, all your coefficients are wrong, even with millions of observations!</p>
</section>
<section id="linearity" class="level4">
<h4 class="anchored" data-anchor-id="linearity">Linearity</h4>
<p>Assumes straight-line relationships. But what if education’s effect on income is stronger at higher levels? We can add polynomial terms: <span class="math display">\text{Income} = a + b_1 \times \text{Education} + b_2 \times \text{Education}^2</span></p>
</section>
<section id="independence-1" class="level4">
<h4 class="anchored" data-anchor-id="independence-1">Independence</h4>
<p>Assumes observations are independent. But family members might be similar, repeated measures on the same person are related, and neighbors might influence each other. Special methods handle these dependencies.</p>
</section>
<section id="homoscedasticity" class="level4">
<h4 class="anchored" data-anchor-id="homoscedasticity">Homoscedasticity</h4>
<p>Assumes error variance is constant. But prediction errors might be larger for high-income people than low-income people. Diagnostic plots help detect this.</p>
</section>
<section id="normality" class="level4">
<h4 class="anchored" data-anchor-id="normality">Normality</h4>
<p>Assumes errors follow normal distribution. Important for small samples and hypothesis tests, less critical for large samples.</p>
<p><strong>Note</strong>: The first assumption (exogeneity) is about getting the right answer. The others are mostly about precision and statistical inference. Violating exogeneity means your model is fundamentally wrong; violating the others means your confidence intervals and p-values might be off.</p>
</section>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Common Statistical Pitfalls
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><p><strong>Endogeneity (omitted variable bias)</strong>: Forgetting about hidden factors that affect both X and Y, violating the fundamental exogeneity assumption. <em>Example</em>: Studying education→income without accounting for ability.</p></li>
<li><p><strong>Simultaneity/Reverse causality</strong>: When X and Y determine each other at the same time. Simple regression assumes one-way causation, but reality is often bidirectional. <em>Example</em>: Price affects demand AND demand affects price simultaneously.</p></li>
<li><p><strong>Confounding</strong>: Failing to account for variables that affect both predictor and outcome, leading to spurious relationships. <em>Example</em>: Ice cream sales correlate with drownings (both caused by summer).</p></li>
<li><p><strong>Selection bias</strong>: Non-random samples that systematically exclude certain groups, making results ungeneralizable. <em>Example</em>: Surveying only smartphone users about internet usage.</p></li>
<li><p><strong>Ecological fallacy</strong>: Assuming group-level patterns apply to individuals. <em>Example</em>: Rich countries have lower birth rates ≠ rich people have fewer children.</p></li>
<li><p><strong>P-hacking (data dredging)</strong>: Testing multiple hypotheses until finding significance, or tweaking analysis until p &lt; 0.05. With 20 tests, you expect 1 false positive by chance alone!</p></li>
<li><p><strong>Overfitting</strong>: Building a model too complex for your data - perfect on training data, useless for prediction. <em>Remember</em>: With enough parameters, you can fit an elephant.</p></li>
<li><p><strong>Survivorship bias</strong>: Analyzing only “survivors” while ignoring failures. <em>Example</em>: Studying successful companies while ignoring those that went bankrupt.</p></li>
<li><p><strong>Overgeneralization</strong>: Extending findings beyond the studied population, time period, or context. <em>Example</em>: Results from US college students ≠ universal human behavior.</p></li>
</ol>
<p><strong>Remember</strong>: The first three are forms of <strong>endogeneity</strong> - they violate <span class="math inline">E[\varepsilon|X]=0</span> and make your coefficients <em>fundamentally wrong</em>. The others make results <em>misleading</em> or <em>non-representative</em>.</p>
</div>
</div>
<hr>
</section>
</section>
<section id="applications-in-demography" class="level3">
<h3 class="anchored" data-anchor-id="applications-in-demography">Applications in Demography</h3>
<section id="fertility-analysis" class="level4">
<h4 class="anchored" data-anchor-id="fertility-analysis">Fertility Analysis</h4>
<p>Understanding what factors influence fertility decisions: <span class="math display">\text{Children} = f(\text{Education, Income, Urban, Religion, Contraception, …})</span></p>
<p>Helps identify policy levers for countries concerned about high or low fertility.</p>
<p><strong>Policy levers</strong> are the tools and methods that governments and organizations use to influence events and achieve specific goals by affecting behavior and outcomes.</p>
</section>
<section id="mortality-modeling" class="level4">
<h4 class="anchored" data-anchor-id="mortality-modeling">Mortality Modeling</h4>
<p>Predicting life expectancy or mortality risk: <span class="math display">\text{Mortality Risk} = f(\text{Age, Sex, Smoking, Education, Healthcare Access, …})</span></p>
<p>Used by insurance companies, public health officials, and researchers.</p>
</section>
<section id="migration-prediction" class="level4">
<h4 class="anchored" data-anchor-id="migration-prediction">Migration Prediction</h4>
<p>Understanding who migrates and why: <span class="math display">P(\text{Migration}) = f(\text{Age, Education, Employment, Family Ties, Distance, …})</span></p>
<p>Helps predict population flows and plan for demographic change.</p>
</section>
<section id="marriage-and-divorce" class="level4">
<h4 class="anchored" data-anchor-id="marriage-and-divorce">Marriage and Divorce</h4>
<p>Analyzing union formation and dissolution: <span class="math display">P(\text{Divorce}) = f(\text{Age at Marriage, Education Match, Income, Children, Duration, …})</span></p>
<p>Informs social policy and support services.</p>
</section>
</section>
<section id="common-pitfalls-and-how-to-avoid-them" class="level3">
<h3 class="anchored" data-anchor-id="common-pitfalls-and-how-to-avoid-them">Common Pitfalls and How to Avoid Them</h3>
<section id="overfitting" class="level4">
<h4 class="anchored" data-anchor-id="overfitting">Overfitting</h4>
<p>Including too many predictors can make the model fit perfectly in your sample but fail with new data. Like memorizing exam answers instead of understanding concepts.</p>
<p><strong>Solution</strong>: Use simpler models, cross-validation, or reserve some data for testing.</p>
</section>
<section id="multicollinearity" class="level4">
<h4 class="anchored" data-anchor-id="multicollinearity">Multicollinearity</h4>
<p>When predictors are highly correlated (e.g., years of education and degree level), the model can’t separate their effects.</p>
<p><strong>Solution</strong>: Choose one variable or combine them into an index.</p>
</section>
<section id="omitted-variable-bias" class="level4">
<h4 class="anchored" data-anchor-id="omitted-variable-bias">Omitted Variable Bias</h4>
<p>Leaving out important variables can make other effects appear stronger or weaker than they really are.</p>
<p><strong>Example</strong>: The relationship between ice cream sales and crime rates disappears when you control for temperature.</p>
</section>
<section id="extrapolation" class="level4">
<h4 class="anchored" data-anchor-id="extrapolation">Extrapolation</h4>
<p>Using the model outside the range of observed data.</p>
<p><strong>Example</strong>: If your data includes education from 0-20 years, don’t predict income for someone with 30 years of education.</p>
</section>
</section>
<section id="making-regression-intuitive" class="level3">
<h3 class="anchored" data-anchor-id="making-regression-intuitive">Making Regression Intuitive</h3>
<p>Think of regression as a sophisticated averaging technique:</p>
<ul>
<li><strong>Simple average</strong>: “The average income is $50,000”</li>
<li><strong>Conditional average</strong>: “The average income for college graduates is $70,000”</li>
<li><strong>Regression</strong>: “The average income for 35-year-old college graduates in urban areas is $78,000”</li>
</ul>
<p>Each added variable makes our prediction more specific and (hopefully) more accurate.</p>
</section>
<section id="regression-in-practice-a-complete-example" class="level3">
<h3 class="anchored" data-anchor-id="regression-in-practice-a-complete-example">Regression in Practice: A Complete Example</h3>
<p><strong>Research Question</strong>: What factors influence age at first birth?</p>
<p><strong>Data</strong>: Survey of 1,000 women who have had at least one child</p>
<p><strong>Variables</strong>:</p>
<ul>
<li>Outcome: Age at first birth (years)</li>
<li>Predictors: Education (years), Urban (0/1), Income (thousands), Religious (0/1)</li>
</ul>
<p><strong>Simple Regression Result</strong>: <span class="math display">\text{Age at First Birth} = 18 + 0.8 \times \text{Education}</span></p>
<p>Interpretation: Each year of education associated with 0.8 years later first birth.</p>
<p><strong>Multiple Regression Result</strong>: <span class="math display">\text{Age at First Birth} = 16 + 0.5 \times \text{Education} + 2 \times \text{Urban} + 0.03 \times \text{Income} - 1.5 \times \text{Religious}</span></p>
<p>Interpretation:</p>
<ul>
<li>Education effect reduced but still positive (0.5 years per education year)</li>
<li>Urban women have first births 2 years later</li>
<li>Each $1,000 income associated with 0.03 years (11 days) later</li>
<li>Religious women have first births 1.5 years earlier</li>
<li><span class="math inline">R^2 = 0.42</span> (model explains 42% of variation)</li>
</ul>
<p>This richer model helps us understand that education’s effect partly operates through urban residence and income.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Regression is a gateway to advanced statistical modeling. Once you understand the basic concept—using variables to predict outcomes and quantifying relationships—you can explore:</p>
<ul>
<li><strong>Interaction effects</strong>: When one variable’s effect depends on another</li>
<li><strong>Non-linear relationships</strong>: Curves, thresholds, and complex patterns</li>
<li><strong>Multilevel models</strong>: Accounting for grouped data (students in schools, people in neighborhoods)</li>
<li><strong>Time series regression</strong>: Analyzing change over time</li>
<li><strong>Machine learning extensions</strong>: Random forests, neural networks, and more</li>
</ul>
<p>The key insight remains: We’re trying to understand how things relate to each other in a systematic, quantifiable way.</p>
</div>
</div>
</section>
</section>
<section id="data-quality-and-sources" class="level2" data-number="1.19">
<h2 data-number="1.19" class="anchored" data-anchor-id="data-quality-and-sources"><span class="header-section-number">1.19</span> Data Quality and Sources</h2>
<p>No analysis is better than the data it’s based on. Understanding data quality issues is crucial for demographic and social research.</p>
<section id="dimensions-of-data-quality" class="level3">
<h3 class="anchored" data-anchor-id="dimensions-of-data-quality">Dimensions of Data Quality</h3>
<p><strong>Accuracy</strong>: How close are measurements to true values?</p>
<p>Example: Age reporting often shows “heaping” at round numbers (30, 40, 50) because people round their ages.</p>
<p><strong>Completeness</strong>: What proportion of the population is covered?</p>
<p>Example: Birth registration completeness varies widely:</p>
<ul>
<li>Developed countries: &gt;99%</li>
<li>Some developing countries: &lt;50%</li>
</ul>
<p><strong>Timeliness</strong>: How current is the data?</p>
<p>Example: Census conducted every 10 years becomes increasingly outdated, especially in rapidly changing areas.</p>
<p><strong>Consistency</strong>: Are definitions and methods stable over time and space?</p>
<p>Example: Definition of “urban” varies by country, making international comparisons difficult.</p>
<p><strong>Accessibility</strong>: Can researchers and policy makers actually use the data?</p>
</section>
<section id="common-data-sources-in-demography" class="level3">
<h3 class="anchored" data-anchor-id="common-data-sources-in-demography">Common Data Sources in Demography</h3>
<p><strong>Census</strong>: Complete enumeration of population</p>
<p><em>Advantages:</em></p>
<ul>
<li>Complete coverage (in theory)</li>
<li>Small area data available</li>
<li>Baseline for other estimates</li>
</ul>
<p><em>Disadvantages:</em></p>
<ul>
<li>Expensive and infrequent</li>
<li>Some populations hard to count</li>
<li>Limited variables collected</li>
</ul>
<p><strong>Sample Surveys</strong>: Detailed data from population subset</p>
<p><em>Examples:</em></p>
<ul>
<li>Demographic and Health Surveys (DHS)</li>
<li>American Community Survey (ACS)</li>
<li>Labour Force Surveys</li>
</ul>
<p><em>Advantages:</em></p>
<ul>
<li>Can collect detailed information</li>
<li>More frequent than census</li>
<li>Can focus on specific topics</li>
</ul>
<p><em>Disadvantages:</em></p>
<ul>
<li>Sampling error present</li>
<li>Small areas not represented</li>
<li>Response burden may reduce quality</li>
</ul>
<p><strong>Administrative Records</strong>: Data collected for non-statistical purposes</p>
<p><em>Examples:</em></p>
<ul>
<li>Tax records</li>
<li>School enrollment</li>
<li>Health insurance claims</li>
<li>Mobile phone data</li>
</ul>
<p><em>Advantages:</em></p>
<ul>
<li>Already collected (no additional burden)</li>
<li>Often complete for covered population</li>
<li>Continuously updated</li>
</ul>
<p><em>Disadvantages:</em></p>
<ul>
<li>Coverage may be selective</li>
<li>Definitions may not match research needs</li>
<li>Access often restricted</li>
</ul>
</section>
<section id="data-quality-issues-specific-to-demography" class="level3">
<h3 class="anchored" data-anchor-id="data-quality-issues-specific-to-demography">Data Quality Issues Specific to Demography</h3>
<p><strong>Age Heaping</strong>: Tendency to report ages ending in 0 or 5</p>
<p><em>Detection</em>: Calculate Whipple’s Index or Myers’ Index</p>
<p><em>Impact</em>: Affects age-specific rates and projections</p>
<p><strong>Digit Preference</strong>: Reporting certain final digits more than others</p>
<p><em>Example</em>: Birth weights often reported as 3,000g, 3,500g rather than precise values</p>
<p><strong>Recall Bias</strong>: Difficulty remembering past events accurately</p>
<p><em>Example</em>: “How many times did you visit a doctor last year?” Often underreported for frequent visitors, overreported for rare visitors.</p>
<p><strong>Proxy Reporting</strong>: Information provided by someone else</p>
<p><em>Challenge</em>: Household head reporting for all members may not know everyone’s exact age or education</p>
</section>
</section>
<section id="ethical-considerations-in-statistical-demographics" class="level2" data-number="1.20">
<h2 data-number="1.20" class="anchored" data-anchor-id="ethical-considerations-in-statistical-demographics"><span class="header-section-number">1.20</span> Ethical Considerations in Statistical Demographics</h2>
<p>Statistics isn’t just about numbers—it involves real people and has real consequences.</p>
<section id="informed-consent" class="level3">
<h3 class="anchored" data-anchor-id="informed-consent">Informed Consent</h3>
<p>Participants should understand:</p>
<ul>
<li>Purpose of data collection</li>
<li>How data will be used</li>
<li>Risks and benefits</li>
<li>Their right to refuse or withdraw</li>
</ul>
<p><strong>Challenge in Demographics</strong>: Census participation is often mandatory, raising ethical questions about consent.</p>
</section>
<section id="confidentiality-and-privacy" class="level3">
<h3 class="anchored" data-anchor-id="confidentiality-and-privacy">Confidentiality and Privacy</h3>
<p><strong>Statistical Disclosure Control</strong>: Protecting individual identity in published data</p>
<p>Methods include:</p>
<ul>
<li>Suppressing small cells (e.g., “&lt;5” instead of “2”)</li>
<li>Geographic aggregation</li>
</ul>
<p><strong>Example</strong>: In a table of occupation by age by sex for a small town, there might be only one female doctor aged 60-65, making her identifiable.</p>
</section>
<section id="representation-and-fairness" class="level3">
<h3 class="anchored" data-anchor-id="representation-and-fairness">Representation and Fairness</h3>
<p><strong>Who’s Counted?</strong>: Decisions about who to include affect representation</p>
<ul>
<li>Prisoners: Where are they counted—prison location or home address?</li>
<li>Homeless: How to ensure coverage?</li>
<li>Undocumented immigrants: Include or exclude?</li>
</ul>
<p><strong>Differential Privacy</strong>: Mathematical framework for privacy protection while maintaining statistical utility</p>
<p>Trade-off: More privacy protection = less accurate statistics</p>
</section>
<section id="misuse-of-statistics" class="level3">
<h3 class="anchored" data-anchor-id="misuse-of-statistics">Misuse of Statistics</h3>
<p><strong>Cherry-Picking</strong>: Selecting only favorable results</p>
<p>Example: Reporting decline in teen pregnancy from peak year rather than showing full trend</p>
<p><strong>P-Hacking</strong>: Manipulating analysis to achieve statistical significance</p>
<p><strong>Ecological Fallacy</strong>: Inferring individual relationships from group data</p>
<p>Example: Counties with more immigrants have higher average incomes ≠ immigrants have higher incomes</p>
</section>
<section id="responsible-reporting" class="level3">
<h3 class="anchored" data-anchor-id="responsible-reporting">Responsible Reporting</h3>
<p><strong>Uncertainty Communication</strong>: Always report confidence intervals or margins of error</p>
<p><strong>Context Provision</strong>: Include relevant comparison groups and historical trends</p>
<p><strong>Limitation Acknowledgment</strong>: Clearly state what data can and cannot show</p>
</section>
</section>
<section id="common-misconceptions-in-statistics" class="level2" data-number="1.21">
<h2 data-number="1.21" class="anchored" data-anchor-id="common-misconceptions-in-statistics"><span class="header-section-number">1.21</span> Common Misconceptions in Statistics</h2>
<p>Understanding what statistics is NOT is as important as understanding what it is.</p>
<section id="misconception-1-statistics-can-prove-anything" class="level3">
<h3 class="anchored" data-anchor-id="misconception-1-statistics-can-prove-anything">Misconception 1: “Statistics Can Prove Anything”</h3>
<p><strong>Reality</strong>: Statistics can only provide evidence, never absolute proof. And proper statistics, honestly applied, constrains conclusions significantly.</p>
<p><strong>Example</strong>: A study finds correlation between ice cream sales and drowning deaths. Statistics doesn’t “prove” ice cream causes drowning—both are related to summer weather.</p>
</section>
<section id="misconception-2-larger-samples-are-always-better" class="level3">
<h3 class="anchored" data-anchor-id="misconception-2-larger-samples-are-always-better">Misconception 2: “Larger Samples Are Always Better”</h3>
<p><strong>Reality</strong>: Beyond a certain point, larger samples add little precision but may add bias.</p>
<p><strong>Example</strong>: Online survey with 1 million responses may be less accurate than probability sample of 1,000 due to self-selection bias.</p>
<p><strong>Diminishing Returns</strong>:</p>
<ul>
<li><span class="math inline">n = 100</span>: Margin of error <span class="math inline">\approx 10</span> pp.</li>
<li><span class="math inline">n = 1,000</span>: Margin of error <span class="math inline">\approx 3.2</span> pp.</li>
<li><span class="math inline">n = 10,000</span>: Margin of error <span class="math inline">\approx 1</span> pp.</li>
<li><span class="math inline">n = 100,000</span>: Margin of error <span class="math inline">\approx 0.32</span> pp.</li>
</ul>
<p>The jump from 10,000 to 100,000 barely improves precision but costs <span class="math inline">10\times</span> more.</p>
</section>
<section id="misconception-3-statistical-significance-practical-importance" class="level3">
<h3 class="anchored" data-anchor-id="misconception-3-statistical-significance-practical-importance">Misconception 3: “Statistical Significance = Practical Importance”</h3>
<p><strong>Reality</strong>: With large samples, tiny differences become “statistically significant” even if meaningless.</p>
<p><strong>Example</strong>: Study of 100,000 people finds men are 0.1 cm taller on average (p &lt; 0.001). Statistically significant but practically irrelevant.</p>
</section>
<section id="misconception-4-correlation-implies-causation" class="level3">
<h3 class="anchored" data-anchor-id="misconception-4-correlation-implies-causation">Misconception 4: “Correlation Implies Causation”</h3>
<p><strong>Reality</strong>: Correlation is necessary but not sufficient for causation.</p>
<p><strong>Classic Examples</strong>:</p>
<ul>
<li>Cities with more churches have more crime (both correlate with population size)</li>
<li>Countries with more TV sets have longer life expectancy (both correlate with development)</li>
</ul>
</section>
<section id="misconception-5-random-means-haphazard" class="level3">
<h3 class="anchored" data-anchor-id="misconception-5-random-means-haphazard">Misconception 5: “Random Means Haphazard”</h3>
<p><strong>Reality</strong>: Statistical randomness is carefully controlled and systematic.</p>
<p><strong>Example</strong>: Random sampling requires careful procedure, not just grabbing whoever is convenient.</p>
</section>
<section id="misconception-6-average-represents-everyone" class="level3">
<h3 class="anchored" data-anchor-id="misconception-6-average-represents-everyone">Misconception 6: “Average Represents Everyone”</h3>
<p><strong>Reality</strong>: Averages can be misleading when distributions are skewed or multimodal.</p>
<p><strong>Example</strong>: Average income of bar patrons is $50,000. Bill Gates walks in. Now average is $1 million. Nobody’s actual income changed.</p>
</section>
<section id="misconception-7-past-patterns-guarantee-future-results" class="level3">
<h3 class="anchored" data-anchor-id="misconception-7-past-patterns-guarantee-future-results">Misconception 7: “Past Patterns Guarantee Future Results”</h3>
<p><strong>Reality</strong>: Extrapolation assumes conditions remain constant.</p>
<p><strong>Example</strong>: Linear population growth projection from 1950-2000 would badly overestimate 2050 population because it misses fertility decline.</p>
</section>
</section>
<section id="applications-in-demography-1" class="level2" data-number="1.22">
<h2 data-number="1.22" class="anchored" data-anchor-id="applications-in-demography-1"><span class="header-section-number">1.22</span> Applications in Demography</h2>
<p>These statistical foundations enable sophisticated demographic analyses. Let’s explore key applications.</p>
<section id="population-estimation-and-projection" class="level3">
<h3 class="anchored" data-anchor-id="population-estimation-and-projection">Population Estimation and Projection</h3>
<p><strong>Intercensal Estimates</strong>: Estimating population between censuses</p>
<p>Components Method: <span class="math display">P(t+1) = P(t) + B - D + I - E</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">P(t)</span> = Population at time <span class="math inline">t</span></li>
<li><span class="math inline">B</span> = Births</li>
<li><span class="math inline">D</span> = Deaths</li>
<li><span class="math inline">I</span> = Immigration</li>
<li><span class="math inline">E</span> = Emigration</li>
</ul>
<p>Each component estimated from different sources with different error structures.</p>
<p><strong>Population Projections</strong>: Forecasting future population</p>
<p>Cohort Component Method:</p>
<ol type="1">
<li>Project survival rates by age</li>
<li>Project fertility rates</li>
<li>Project migration rates</li>
<li>Apply to base population</li>
<li>Aggregate results</li>
</ol>
<p>Uncertainty increases with projection horizon.</p>
</section>
<section id="demographic-rate-calculation" class="level3">
<h3 class="anchored" data-anchor-id="demographic-rate-calculation">Demographic Rate Calculation</h3>
<p><strong>Crude Rates</strong>: Events per 1,000 population</p>
<p><span class="math display">\text{Crude Birth Rate} = \frac{\text{Births}}{\text{Mid-year Population}} \times 1,000</span></p>
<p><strong>Age-Specific Rates</strong>: Control for age structure</p>
<p><span class="math display">\text{Age-Specific Fertility Rate} = \frac{\text{Births to women aged } x}{\text{Women aged } x} \times 1,000</span></p>
<p><strong>Standardization</strong>: Compare populations with different structures</p>
<p>Direct Standardization: Apply population’s rates to standard age structure Indirect Standardization: Apply standard rates to population’s age structure</p>
</section>
<section id="life-table-analysis" class="level3">
<h3 class="anchored" data-anchor-id="life-table-analysis">Life Table Analysis</h3>
<p>Life tables summarize mortality experience of a population.</p>
<p>Key Columns:</p>
<ul>
<li><span class="math inline">q_x</span>: Probability of dying between age <span class="math inline">x</span> and <span class="math inline">x+1</span></li>
<li><span class="math inline">l_x</span>: Number surviving to age <span class="math inline">x</span> (from 100,000 births)</li>
<li><span class="math inline">d_x</span>: Deaths between age <span class="math inline">x</span> and <span class="math inline">x+1</span></li>
<li><span class="math inline">L_x</span>: Person-years lived between age <span class="math inline">x</span> and <span class="math inline">x+1</span></li>
<li><span class="math inline">e_x</span>: Life expectancy at age <span class="math inline">x</span></li>
</ul>
<p><strong>Example Interpretation</strong>: If <span class="math inline">q_{65} = 0.015</span>, then 1.5% of 65-year-olds die before reaching 66. If <span class="math inline">e_{65} = 18.5</span>, then 65-year-olds average 18.5 more years of life.</p>
</section>
<section id="fertility-analysis-1" class="level3">
<h3 class="anchored" data-anchor-id="fertility-analysis-1">Fertility Analysis</h3>
<p><strong>Total Fertility Rate (TFR)</strong>: Average children per woman given current age-specific rates</p>
<p><span class="math display">\text{TFR} = \sum (\text{ASFR} \times \text{age interval width})</span></p>
<p><strong>Example</strong>: If each 5-year age group from 15-49 has ASFR = 20 per 1,000: <span class="math display">\text{TFR} = 7 \text{ age groups} \times \frac{20}{1,000} \times 5 \text{ years} = 0.7 \text{ children per woman}</span></p>
<p>This very low TFR indicates below-replacement fertility.</p>
</section>
<section id="migration-analysis" class="level3">
<h3 class="anchored" data-anchor-id="migration-analysis">Migration Analysis</h3>
<p><strong>Net Migration Rate</strong>: <span class="math display">\text{NMR} = \frac{\text{Immigrants} - \text{Emigrants}}{\text{Population}} \times 1,000</span></p>
<p><strong>Migration Effectiveness Index</strong>: <span class="math display">\text{MEI} = \frac{|\text{In} - \text{Out}|}{\text{In} + \text{Out}}</span></p>
<ul>
<li>Values near 0: High turnover, little net change</li>
<li>Values near 1: Mostly one-way flow</li>
</ul>
</section>
<section id="population-health-metrics" class="level3">
<h3 class="anchored" data-anchor-id="population-health-metrics">Population Health Metrics</h3>
<p><strong>Disability-Adjusted Life Years (DALYs)</strong>: Years of healthy life lost</p>
<p>DALY = Years of Life Lost (YLL) + Years Lived with Disability (YLD)</p>
<p><strong>Healthy Life Expectancy</strong>: Expected years in good health</p>
<p>Combines mortality and morbidity information.</p>
</section>
</section>
<section id="software-and-tools" class="level2" data-number="1.23">
<h2 data-number="1.23" class="anchored" data-anchor-id="software-and-tools"><span class="header-section-number">1.23</span> Software and Tools</h2>
<p>Modern demographic and social statistics relies heavily on computational tools.</p>
<section id="statistical-software-packages" class="level3">
<h3 class="anchored" data-anchor-id="statistical-software-packages">Statistical Software Packages</h3>
<p><strong>R</strong>: Free, open-source, extensive demographic packages</p>
<ul>
<li>Packages: demography, popReconstruct, bayesPop</li>
<li>Advantages: Reproducible research, cutting-edge methods</li>
<li>Disadvantages: Steep learning curve</li>
</ul>
<p><strong>Stata</strong>: Widely used in social sciences</p>
<ul>
<li>Strengths: Survey data analysis, panel data</li>
<li>Common in: Economics, epidemiology</li>
</ul>
<p><strong>SPSS</strong>: User-friendly interface</p>
<ul>
<li>Strengths: Point-and-click interface</li>
<li>Common in: Social sciences, market research</li>
</ul>
<p><strong>Python</strong>: General programming language with statistical libraries</p>
<ul>
<li>Libraries: pandas, numpy, scipy, statsmodels</li>
<li>Advantages: Integration with other applications</li>
</ul>
</section>
</section>
<section id="conclusion" class="level2" data-number="1.24">
<h2 data-number="1.24" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">1.24</span> Conclusion</h2>
<section id="key-terms-summary" class="level3">
<h3 class="anchored" data-anchor-id="key-terms-summary">Key Terms Summary</h3>
<p><strong>Statistics</strong>: The science of collecting, organizing, analyzing, interpreting, and presenting data to understand phenomena and support decision-making</p>
<p><strong>Descriptive Statistics</strong>: Methods for summarizing and presenting data in meaningful ways without extending conclusions beyond the observed data</p>
<p><strong>Inferential Statistics</strong>: Techniques for drawing conclusions about populations from samples, including estimation and hypothesis testing</p>
<p><strong>Population</strong>: The complete set of individuals, objects, or measurements about which conclusions are to be drawn</p>
<p><strong>Sample</strong>: A subset of the population that is actually observed or measured to make inferences about the population</p>
<p><strong>Superpopulation</strong>: A theoretical infinite population from which observed finite populations are considered to be samples</p>
<p><strong>Parameter</strong>: A numerical characteristic of a population (usually unknown and denoted by Greek letters)</p>
<p><strong>Statistic</strong>: A numerical characteristic calculated from sample data (known and denoted by Roman letters)</p>
<p><strong>Estimator</strong>: A rule or formula for calculating estimates of population parameters from sample data</p>
<p><strong>Estimand</strong>: The specific population parameter targeted for estimation</p>
<p><strong>Estimate</strong>: The numerical value produced by applying an estimator to observed data</p>
<p><strong>Random Error (Sampling Error)</strong>: Unpredictable variation arising from the sampling process that decreases with larger samples</p>
<p><strong>Systematic Error (Bias)</strong>: Consistent deviation from true values that cannot be reduced by increasing sample size</p>
<p><strong>Sampling</strong>: The process of selecting a subset of units from a population for measurement</p>
<p><strong>Sampling Frame</strong>: The list or device from which a sample is drawn, ideally containing all population members</p>
<p><strong>Probability Sampling</strong>: Sampling methods where every population member has a known, non-zero probability of selection</p>
<p><strong>Simple Random Sampling</strong>: Every possible sample of size n has equal probability of selection</p>
<p><strong>Systematic Sampling</strong>: Selection of every kth element from an ordered sampling frame</p>
<p><strong>Stratified Sampling</strong>: Division of population into homogeneous subgroups before sampling within each</p>
<p><strong>Cluster Sampling</strong>: Selection of groups (clusters) rather than individuals</p>
<p><strong>Non-probability Sampling</strong>: Sampling methods without guaranteed known selection probabilities</p>
<p><strong>Convenience Sampling</strong>: Selection based purely on ease of access</p>
<p><strong>Purposive Sampling</strong>: Deliberate selection based on researcher judgment</p>
<p><strong>Quota Sampling</strong>: Selection to match population proportions on key characteristics without random selection</p>
<p><strong>Snowball Sampling</strong>: Participants recruit additional subjects from their acquaintances</p>
<p><strong>Standard Error</strong>: The standard deviation of the sampling distribution of a statistic</p>
<p><strong>Margin of Error</strong>: Maximum expected difference between estimate and parameter at specified confidence</p>
<p><strong>Confidence Interval</strong>: Range of plausible values for a parameter at specified confidence level</p>
<p><strong>Confidence Level</strong>: Probability that the confidence interval method produces intervals containing the parameter</p>
<p><strong>Data</strong>: Collected observations or measurements</p>
<p><strong>Quantitative Data</strong>: Numerical measurements (continuous or discrete)</p>
<p><strong>Qualitative Data</strong>: Categorical information (nominal or ordinal)</p>
<p><strong>Data Distribution</strong>: Description of how values spread across possible outcomes</p>
<p><strong>Frequency Distribution</strong>: Summary showing how often each value occurs in data</p>
<p><strong>Absolute Frequency</strong>: Count of observations for each value</p>
<p><strong>Relative Frequency</strong>: Proportion of observations in each category</p>
<p><strong>Cumulative Frequency</strong>: Running total of frequencies up to each value</p>
<hr>
</section>
</section>
<section id="appendix-a-visualizations-for-statistics-demography" class="level2" data-number="1.25">
<h2 data-number="1.25" class="anchored" data-anchor-id="appendix-a-visualizations-for-statistics-demography"><span class="header-section-number">1.25</span> Appendix A: Visualizations for Statistics &amp; Demography</h2>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="do">## ============================================</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a><span class="do">## Visualizations for Statistics &amp; Demography</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Chapter 1: Foundations</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="do">## ============================================</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Load required libraries</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyr)</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(scales)</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)  <span class="co"># for combining plots</span></span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Set theme for all plots</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">12</span>))</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Color palette for consistency</span></span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>colors <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"#2E86AB"</span>, <span class="st">"#A23B72"</span>, <span class="st">"#F18F01"</span>, <span class="st">"#C73E1D"</span>, <span class="st">"#6A994E"</span>)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. POPULATION vs SAMPLE VISUALIZATION</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Create a population and sample visualization</span></span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate population data (e.g., ages of 10,000 people)</span></span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>population <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">id =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">10000</span>,</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">age =</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">10000</span>, <span class="at">mean =</span> <span class="dv">40</span>, <span class="at">sd =</span> <span class="dv">15</span>))</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>population<span class="sc">$</span>age[population<span class="sc">$</span>age <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>population<span class="sc">$</span>age[population<span class="sc">$</span>age <span class="sc">&gt;</span> <span class="dv">100</span>] <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a><span class="co"># Take a random sample</span></span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>sample_size <span class="ot">&lt;-</span> <span class="dv">500</span></span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>sample_data <span class="ot">&lt;-</span> population[<span class="fu">sample</span>(<span class="fu">nrow</span>(population), sample_size), ]</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Create visualization</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(population, <span class="fu">aes</span>(<span class="at">x =</span> age)) <span class="sc">+</span></span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="dv">5</span>, <span class="at">fill =</span> colors[<span class="dv">1</span>], <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(population<span class="sc">$</span>age), </span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> colors[<span class="dv">2</span>], <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Population Distribution (N = 10,000)"</span>,</span>
<span id="cb14-46"><a href="#cb14-46" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">"Population mean (μ) ="</span>, <span class="fu">round</span>(<span class="fu">mean</span>(population<span class="sc">$</span>age), <span class="dv">2</span>), <span class="st">"years"</span>),</span>
<span id="cb14-47"><a href="#cb14-47" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Age (years)"</span>, <span class="at">y =</span> <span class="st">"Frequency"</span>) <span class="sc">+</span></span>
<span id="cb14-48"><a href="#cb14-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>))</span>
<span id="cb14-49"><a href="#cb14-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-50"><a href="#cb14-50" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(sample_data, <span class="fu">aes</span>(<span class="at">x =</span> age)) <span class="sc">+</span></span>
<span id="cb14-51"><a href="#cb14-51" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">binwidth =</span> <span class="dv">5</span>, <span class="at">fill =</span> colors[<span class="dv">3</span>], <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb14-52"><a href="#cb14-52" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">mean</span>(sample_data<span class="sc">$</span>age), </span>
<span id="cb14-53"><a href="#cb14-53" aria-hidden="true" tabindex="-1"></a>             <span class="at">color =</span> colors[<span class="dv">4</span>], <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb14-54"><a href="#cb14-54" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="fu">paste</span>(<span class="st">"Sample Distribution (n ="</span>, sample_size, <span class="st">")"</span>),</span>
<span id="cb14-55"><a href="#cb14-55" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">"Sample mean (x̄) ="</span>, <span class="fu">round</span>(<span class="fu">mean</span>(sample_data<span class="sc">$</span>age), <span class="dv">2</span>), <span class="st">"years"</span>),</span>
<span id="cb14-56"><a href="#cb14-56" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Age (years)"</span>, <span class="at">y =</span> <span class="st">"Frequency"</span>) <span class="sc">+</span></span>
<span id="cb14-57"><a href="#cb14-57" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>))</span>
<span id="cb14-58"><a href="#cb14-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-59"><a href="#cb14-59" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine plots</span></span>
<span id="cb14-60"><a href="#cb14-60" aria-hidden="true" tabindex="-1"></a>population_sample_plot <span class="ot">&lt;-</span> p1 <span class="sc">/</span> p2</span>
<span id="cb14-61"><a href="#cb14-61" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(population_sample_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-14-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. TYPES OF DATA DISTRIBUTIONS</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate different distribution types</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">456</span>)</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">5000</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Normal distribution</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>normal_data <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">50</span>, <span class="at">sd =</span> <span class="dv">10</span>)</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Right-skewed distribution (income-like)</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>right_skewed <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(n, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">scale =</span> <span class="dv">15</span>)</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Left-skewed distribution (age at death in developed country)</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>left_skewed <span class="ot">&lt;-</span> <span class="dv">90</span> <span class="sc">-</span> <span class="fu">rgamma</span>(n, <span class="at">shape =</span> <span class="dv">3</span>, <span class="at">scale =</span> <span class="dv">5</span>)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>left_skewed[left_skewed <span class="sc">&lt;</span> <span class="dv">0</span>] <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Bimodal distribution (e.g., height of mixed male/female population)</span></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>n2  <span class="ot">&lt;-</span> <span class="dv">20000</span></span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>nf <span class="ot">&lt;-</span> n2 <span class="sc">%/%</span> <span class="dv">2</span>; nm <span class="ot">&lt;-</span> n2 <span class="sc">-</span> nf</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>bimodal <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(nf, <span class="at">mean =</span> <span class="dv">164</span>, <span class="at">sd =</span> <span class="dv">5</span>),</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>             <span class="fu">rnorm</span>(nm, <span class="at">mean =</span> <span class="dv">182</span>, <span class="at">sd =</span> <span class="dv">5</span>))</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data frame</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>distributions_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>  <span class="at">Normal =</span> normal_data,</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Right Skewed</span><span class="st">`</span> <span class="ot">=</span> right_skewed,</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Left Skewed</span><span class="st">`</span> <span class="ot">=</span> left_skewed,</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">Bimodal =</span> bimodal</span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">everything</span>(), <span class="at">names_to =</span> <span class="st">"Distribution"</span>, <span class="at">values_to =</span> <span class="st">"Value"</span>)</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot distributions</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>distributions_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(distributions_df, <span class="fu">aes</span>(<span class="at">x =</span> Value, <span class="at">fill =</span> Distribution)) <span class="sc">+</span></span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>Distribution, <span class="at">scales =</span> <span class="st">"free"</span>, <span class="at">nrow =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> colors[<span class="dv">1</span><span class="sc">:</span><span class="dv">4</span>]) <span class="sc">+</span></span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Types of Data Distributions"</span>,</span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Common patterns in demographic data"</span>,</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Value"</span>, <span class="at">y =</span> <span class="st">"Frequency"</span>) <span class="sc">+</span></span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>),</span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="st">"none"</span>)</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(distributions_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-14-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. NORMAL DISTRIBUTION WITH 68-95-99.7 RULE</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate normal distribution data</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">789</span>)</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>mean_val <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>sd_val <span class="ot">&lt;-</span> <span class="dv">15</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">seq</span>(mean_val <span class="sc">-</span> <span class="dv">4</span><span class="sc">*</span>sd_val, mean_val <span class="sc">+</span> <span class="dv">4</span><span class="sc">*</span>sd_val, <span class="at">length.out =</span> <span class="dv">1000</span>)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> mean_val, <span class="at">sd =</span> sd_val)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>df_norm <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a>normal_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(df_norm, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Fill areas under the curve</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">data =</span> <span class="fu">subset</span>(df_norm, x <span class="sc">&gt;=</span> mean_val <span class="sc">-</span> sd_val <span class="sc">&amp;</span> x <span class="sc">&lt;=</span> mean_val <span class="sc">+</span> sd_val),</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">fill =</span> colors[<span class="dv">1</span>], <span class="at">alpha =</span> <span class="fl">0.3</span>) <span class="sc">+</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">data =</span> <span class="fu">subset</span>(df_norm, x <span class="sc">&gt;=</span> mean_val <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>sd_val <span class="sc">&amp;</span> x <span class="sc">&lt;=</span> mean_val <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>sd_val),</span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">fill =</span> colors[<span class="dv">2</span>], <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_area</span>(<span class="at">data =</span> <span class="fu">subset</span>(df_norm, x <span class="sc">&gt;=</span> mean_val <span class="sc">-</span> <span class="dv">3</span><span class="sc">*</span>sd_val <span class="sc">&amp;</span> x <span class="sc">&lt;=</span> mean_val <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>sd_val),</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>            <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y), <span class="at">fill =</span> colors[<span class="dv">3</span>], <span class="at">alpha =</span> <span class="fl">0.1</span>) <span class="sc">+</span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add the curve</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add vertical lines for standard deviations</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mean_val, <span class="at">linetype =</span> <span class="st">"solid"</span>, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(mean_val <span class="sc">-</span> sd_val, mean_val <span class="sc">+</span> sd_val), </span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">0.8</span>, <span class="at">color =</span> colors[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(mean_val <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>sd_val, mean_val <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>sd_val), </span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">0.8</span>, <span class="at">color =</span> colors[<span class="dv">2</span>]) <span class="sc">+</span></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="fu">c</span>(mean_val <span class="sc">-</span> <span class="dv">3</span><span class="sc">*</span>sd_val, mean_val <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>sd_val), </span>
<span id="cb16-31"><a href="#cb16-31" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="fl">0.8</span>, <span class="at">color =</span> colors[<span class="dv">3</span>]) <span class="sc">+</span></span>
<span id="cb16-32"><a href="#cb16-32" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add labels</span></span>
<span id="cb16-33"><a href="#cb16-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_val, <span class="at">y =</span> <span class="fu">max</span>(y) <span class="sc">*</span> <span class="fl">0.5</span>, <span class="at">label =</span> <span class="st">"68%"</span>, </span>
<span id="cb16-34"><a href="#cb16-34" aria-hidden="true" tabindex="-1"></a>           <span class="at">size =</span> <span class="dv">5</span>, <span class="at">fontface =</span> <span class="st">"bold"</span>, <span class="at">color =</span> colors[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb16-35"><a href="#cb16-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_val, <span class="at">y =</span> <span class="fu">max</span>(y) <span class="sc">*</span> <span class="fl">0.3</span>, <span class="at">label =</span> <span class="st">"95%"</span>, </span>
<span id="cb16-36"><a href="#cb16-36" aria-hidden="true" tabindex="-1"></a>           <span class="at">size =</span> <span class="dv">5</span>, <span class="at">fontface =</span> <span class="st">"bold"</span>, <span class="at">color =</span> colors[<span class="dv">2</span>]) <span class="sc">+</span></span>
<span id="cb16-37"><a href="#cb16-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> mean_val, <span class="at">y =</span> <span class="fu">max</span>(y) <span class="sc">*</span> <span class="fl">0.1</span>, <span class="at">label =</span> <span class="st">"99.7%"</span>, </span>
<span id="cb16-38"><a href="#cb16-38" aria-hidden="true" tabindex="-1"></a>           <span class="at">size =</span> <span class="dv">5</span>, <span class="at">fontface =</span> <span class="st">"bold"</span>, <span class="at">color =</span> colors[<span class="dv">3</span>]) <span class="sc">+</span></span>
<span id="cb16-39"><a href="#cb16-39" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Labels</span></span>
<span id="cb16-40"><a href="#cb16-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">c</span>(mean_val <span class="sc">-</span> <span class="dv">3</span><span class="sc">*</span>sd_val, mean_val <span class="sc">-</span> <span class="dv">2</span><span class="sc">*</span>sd_val, </span>
<span id="cb16-41"><a href="#cb16-41" aria-hidden="true" tabindex="-1"></a>                                mean_val <span class="sc">-</span> sd_val, mean_val, </span>
<span id="cb16-42"><a href="#cb16-42" aria-hidden="true" tabindex="-1"></a>                                mean_val <span class="sc">+</span> sd_val, mean_val <span class="sc">+</span> <span class="dv">2</span><span class="sc">*</span>sd_val, </span>
<span id="cb16-43"><a href="#cb16-43" aria-hidden="true" tabindex="-1"></a>                                mean_val <span class="sc">+</span> <span class="dv">3</span><span class="sc">*</span>sd_val),</span>
<span id="cb16-44"><a href="#cb16-44" aria-hidden="true" tabindex="-1"></a>                     <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"μ-3σ"</span>, <span class="st">"μ-2σ"</span>, <span class="st">"μ-σ"</span>, <span class="st">"μ"</span>, <span class="st">"μ+σ"</span>, <span class="st">"μ+2σ"</span>, <span class="st">"μ+3σ"</span>)) <span class="sc">+</span></span>
<span id="cb16-45"><a href="#cb16-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Normal Distribution: The 68-95-99.7 Rule"</span>,</span>
<span id="cb16-46"><a href="#cb16-46" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Proportion of data within standard deviations from the mean"</span>,</span>
<span id="cb16-47"><a href="#cb16-47" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Value"</span>, <span class="at">y =</span> <span class="st">"Probability Density"</span>) <span class="sc">+</span></span>
<span id="cb16-48"><a href="#cb16-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>))</span>
<span id="cb16-49"><a href="#cb16-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-50"><a href="#cb16-50" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(normal_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-14-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. SIMPLE LINEAR REGRESSION</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load required libraries</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(scales)</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Define color palette (this was missing in original code)</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>colors <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"#2E86AB"</span>, <span class="st">"#A23B72"</span>, <span class="st">"#F18F01"</span>, <span class="st">"#C73E1D"</span>, <span class="st">"#592E83"</span>)</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate data for regression example (Education vs Income)</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2024</span>)</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>n_reg <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>education <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(n_reg, <span class="at">mean =</span> <span class="dv">14</span>, <span class="at">sd =</span> <span class="dv">3</span>))</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>education[education <span class="sc">&lt;</span> <span class="dv">8</span>] <span class="ot">&lt;-</span> <span class="dv">8</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>education[education <span class="sc">&gt;</span> <span class="dv">22</span>] <span class="ot">&lt;-</span> <span class="dv">22</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Create income with linear relationship plus noise</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>income <span class="ot">&lt;-</span> <span class="dv">15000</span> <span class="sc">+</span> <span class="dv">4000</span> <span class="sc">*</span> education <span class="sc">+</span> <span class="fu">rnorm</span>(n_reg, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">8000</span>)</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>income[income <span class="sc">&lt;</span> <span class="dv">10000</span>] <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>reg_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">education =</span> education, <span class="at">income =</span> income)</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit linear model</span></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>lm_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(income <span class="sc">~</span> education, <span class="at">data =</span> reg_data)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create subset of data for residual lines</span></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a>subset_indices <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">nrow</span>(reg_data), <span class="dv">20</span>)</span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a>subset_data <span class="ot">&lt;-</span> reg_data[subset_indices, ]</span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>subset_data<span class="sc">$</span>predicted <span class="ot">&lt;-</span> <span class="fu">predict</span>(lm_model, <span class="at">newdata =</span> subset_data)</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Create regression plot</span></span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a>regression_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(reg_data, <span class="fu">aes</span>(<span class="at">x =</span> education, <span class="at">y =</span> income)) <span class="sc">+</span></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add points</span></span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">size =</span> <span class="dv">2</span>, <span class="at">color =</span> colors[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add regression line with confidence interval</span></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">TRUE</span>, <span class="at">color =</span> colors[<span class="dv">2</span>], <span class="at">fill =</span> colors[<span class="dv">2</span>], <span class="at">alpha =</span> <span class="fl">0.2</span>) <span class="sc">+</span></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add residual lines for a subset of points to show the concept</span></span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="at">data =</span> subset_data,</span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>               <span class="fu">aes</span>(<span class="at">x =</span> education, <span class="at">xend =</span> education, </span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a>                   <span class="at">y =</span> income, <span class="at">yend =</span> predicted),</span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a>               <span class="at">color =</span> colors[<span class="dv">4</span>], <span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">linetype =</span> <span class="st">"dotted"</span>) <span class="sc">+</span></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Add equation to plot (adjusted position based on data range)</span></span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">annotate</span>(<span class="st">"text"</span>, <span class="at">x =</span> <span class="fu">min</span>(reg_data<span class="sc">$</span>education) <span class="sc">+</span> <span class="dv">1</span>, <span class="at">y =</span> <span class="fu">max</span>(reg_data<span class="sc">$</span>income) <span class="sc">*</span> <span class="fl">0.9</span>, </span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a>           <span class="at">label =</span> <span class="fu">paste</span>(<span class="st">"Income = $"</span>, <span class="fu">format</span>(<span class="fu">round</span>(<span class="fu">coef</span>(lm_model)[<span class="dv">1</span>]), <span class="at">big.mark =</span> <span class="st">","</span>), </span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a>                        <span class="st">" + $"</span>, <span class="fu">format</span>(<span class="fu">round</span>(<span class="fu">coef</span>(lm_model)[<span class="dv">2</span>]), <span class="at">big.mark =</span> <span class="st">","</span>), <span class="st">" × Education"</span>,</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a>                        <span class="st">"</span><span class="sc">\n</span><span class="st">R² = "</span>, <span class="fu">round</span>(<span class="fu">summary</span>(lm_model)<span class="sc">$</span>r.squared, <span class="dv">3</span>), <span class="at">sep =</span> <span class="st">""</span>),</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a>           <span class="at">hjust =</span> <span class="dv">0</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">fontface =</span> <span class="st">"italic"</span>) <span class="sc">+</span></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Labels and formatting</span></span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> <span class="fu">dollar_format</span>()) <span class="sc">+</span></span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Simple Linear Regression: Education and Income"</span>,</span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Each year of education associated with higher income"</span>,</span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Years of Education"</span>, </span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Annual Income"</span>) <span class="sc">+</span></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>))</span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(regression_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-15-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. SAMPLING ERROR AND SAMPLE SIZE</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Show how standard error decreases with sample size</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">111</span>)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">25</span>, <span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">250</span>, <span class="dv">500</span>, <span class="dv">1000</span>, <span class="dv">2500</span>, <span class="dv">5000</span>)</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>n_simulations <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co"># True population parameters</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a>true_mean <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>true_sd <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Run simulations for each sample size</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>se_results <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> sample_sizes) {</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>  sample_means <span class="ot">&lt;-</span> <span class="fu">replicate</span>(n_simulations, <span class="fu">mean</span>(<span class="fu">rnorm</span>(n, true_mean, true_sd)))</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>  se_results <span class="ot">&lt;-</span> <span class="fu">rbind</span>(se_results, </span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">data.frame</span>(<span class="at">n =</span> n, </span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>                                <span class="at">se_empirical =</span> <span class="fu">sd</span>(sample_means),</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>                                <span class="at">se_theoretical =</span> true_sd <span class="sc">/</span> <span class="fu">sqrt</span>(n)))</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Create the plot</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>se_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(se_results, <span class="fu">aes</span>(<span class="at">x =</span> n)) <span class="sc">+</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> se_empirical, <span class="at">color =</span> <span class="st">"Empirical SE"</span>), <span class="at">size =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> se_empirical, <span class="at">color =</span> <span class="st">"Empirical SE"</span>), <span class="at">size =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> se_theoretical, <span class="at">color =</span> <span class="st">"Theoretical SE"</span>), </span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a>            <span class="at">size =</span> <span class="fl">1.5</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_log10</span>(<span class="at">breaks =</span> sample_sizes) <span class="sc">+</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Empirical SE"</span> <span class="ot">=</span> colors[<span class="dv">1</span>], </span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>                               <span class="st">"Theoretical SE"</span> <span class="ot">=</span> colors[<span class="dv">2</span>])) <span class="sc">+</span></span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Standard Error Decreases with Sample Size"</span>,</span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"The precision of estimates improves with larger samples"</span>,</span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Size (log scale)"</span>, </span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Standard Error"</span>,</span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>),</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(se_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-16-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 6. CONFIDENCE INTERVALS VISUALIZATION</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate multiple samples and their confidence intervals</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">999</span>)</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>n_samples <span class="ot">&lt;-</span> <span class="dv">20</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>sample_size_ci <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>true_mean_ci <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>true_sd_ci <span class="ot">&lt;-</span> <span class="dv">10</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Generate samples and calculate CIs</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>ci_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>n_samples) {</span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>  sample_i <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(sample_size_ci, true_mean_ci, true_sd_ci)</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a>  mean_i <span class="ot">&lt;-</span> <span class="fu">mean</span>(sample_i)</span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>  se_i <span class="ot">&lt;-</span> <span class="fu">sd</span>(sample_i) <span class="sc">/</span> <span class="fu">sqrt</span>(sample_size_ci)</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>  ci_lower <span class="ot">&lt;-</span> mean_i <span class="sc">-</span> <span class="fl">1.96</span> <span class="sc">*</span> se_i</span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a>  ci_upper <span class="ot">&lt;-</span> mean_i <span class="sc">+</span> <span class="fl">1.96</span> <span class="sc">*</span> se_i</span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a>  contains_true <span class="ot">&lt;-</span> (true_mean_ci <span class="sc">&gt;=</span> ci_lower) <span class="sc">&amp;</span> (true_mean_ci <span class="sc">&lt;=</span> ci_upper)</span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a>  ci_data <span class="ot">&lt;-</span> <span class="fu">rbind</span>(ci_data,</span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">data.frame</span>(<span class="at">sample =</span> i, <span class="at">mean =</span> mean_i, </span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a>                             <span class="at">lower =</span> ci_lower, <span class="at">upper =</span> ci_upper,</span>
<span id="cb19-25"><a href="#cb19-25" aria-hidden="true" tabindex="-1"></a>                             <span class="at">contains =</span> contains_true))</span>
<span id="cb19-26"><a href="#cb19-26" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb19-27"><a href="#cb19-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-28"><a href="#cb19-28" aria-hidden="true" tabindex="-1"></a><span class="co"># Create CI plot</span></span>
<span id="cb19-29"><a href="#cb19-29" aria-hidden="true" tabindex="-1"></a>ci_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(ci_data, <span class="fu">aes</span>(<span class="at">x =</span> sample, <span class="at">y =</span> mean)) <span class="sc">+</span></span>
<span id="cb19-30"><a href="#cb19-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> true_mean_ci, <span class="at">color =</span> <span class="st">"red"</span>, </span>
<span id="cb19-31"><a href="#cb19-31" aria-hidden="true" tabindex="-1"></a>             <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb19-32"><a href="#cb19-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_errorbar</span>(<span class="fu">aes</span>(<span class="at">ymin =</span> lower, <span class="at">ymax =</span> upper, <span class="at">color =</span> contains), </span>
<span id="cb19-33"><a href="#cb19-33" aria-hidden="true" tabindex="-1"></a>                <span class="at">width =</span> <span class="fl">0.3</span>, <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb19-34"><a href="#cb19-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> contains), <span class="at">size =</span> <span class="dv">2</span>) <span class="sc">+</span></span>
<span id="cb19-35"><a href="#cb19-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"TRUE"</span> <span class="ot">=</span> colors[<span class="dv">1</span>], <span class="st">"FALSE"</span> <span class="ot">=</span> colors[<span class="dv">4</span>]),</span>
<span id="cb19-36"><a href="#cb19-36" aria-hidden="true" tabindex="-1"></a>                    <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">"Misses true value"</span>, <span class="st">"Contains true value"</span>)) <span class="sc">+</span></span>
<span id="cb19-37"><a href="#cb19-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb19-38"><a href="#cb19-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"95% Confidence Intervals from 20 Different Samples"</span>,</span>
<span id="cb19-39"><a href="#cb19-39" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">"True population mean = "</span>, true_mean_ci, </span>
<span id="cb19-40"><a href="#cb19-40" aria-hidden="true" tabindex="-1"></a>                       <span class="st">" (red dashed line)"</span>, <span class="at">sep =</span> <span class="st">""</span>),</span>
<span id="cb19-41"><a href="#cb19-41" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Sample Number"</span>, </span>
<span id="cb19-42"><a href="#cb19-42" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Sample Mean with 95% CI"</span>,</span>
<span id="cb19-43"><a href="#cb19-43" aria-hidden="true" tabindex="-1"></a>       <span class="at">color =</span> <span class="st">""</span>) <span class="sc">+</span></span>
<span id="cb19-44"><a href="#cb19-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>),</span>
<span id="cb19-45"><a href="#cb19-45" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="st">"bottom"</span>)</span>
<span id="cb19-46"><a href="#cb19-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-47"><a href="#cb19-47" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(ci_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-16-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 7. SAMPLING DISTRIBUTIONS (CENTRAL LIMIT THEOREM)</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- Setup ----</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="fu">theme_set</span>(<span class="fu">theme_minimal</span>(<span class="at">base_size =</span> <span class="dv">13</span>))</span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2025</span>)</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Skewed population (Gamma); change if you want another DGP</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>Npop <span class="ot">&lt;-</span> <span class="dv">100000</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>population <span class="ot">&lt;-</span> <span class="fu">rgamma</span>(Npop, <span class="at">shape =</span> <span class="dv">2</span>, <span class="at">scale =</span> <span class="dv">10</span>)  <span class="co"># skewed right</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>mu    <span class="ot">&lt;-</span> <span class="fu">mean</span>(population)</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">sd</span>(population)</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a><span class="co"># ---- CLT: sampling distribution of the mean ----</span></span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">30</span>, <span class="dv">100</span>)</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="dv">2000</span>  <span class="co"># resamples per n</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>clt_df <span class="ot">&lt;-</span> purrr<span class="sc">::</span><span class="fu">map_dfr</span>(sample_sizes, \(n) {</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tibble</span>(<span class="at">n =</span> n,</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>         <span class="at">mean =</span> <span class="fu">replicate</span>(B, <span class="fu">mean</span>(<span class="fu">sample</span>(population, n, <span class="at">replace =</span> <span class="cn">TRUE</span>))))</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>})</span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Normal overlays: N(mu, sigma/sqrt(n))</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>clt_range <span class="ot">&lt;-</span> clt_df <span class="sc">|&gt;</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(n) <span class="sc">|&gt;</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">min_x =</span> <span class="fu">min</span>(mean), <span class="at">max_x =</span> <span class="fu">max</span>(mean), <span class="at">.groups =</span> <span class="st">"drop"</span>)</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>normal_df <span class="ot">&lt;-</span> clt_range <span class="sc">|&gt;</span></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">rowwise</span>() <span class="sc">|&gt;</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">x =</span> <span class="fu">list</span>(<span class="fu">seq</span>(min_x, max_x, <span class="at">length.out =</span> <span class="dv">200</span>))) <span class="sc">|&gt;</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">unnest</span>(x) <span class="sc">|&gt;</span></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">density =</span> <span class="fu">dnorm</span>(x, <span class="at">mean =</span> mu, <span class="at">sd =</span> sigma <span class="sc">/</span> <span class="fu">sqrt</span>(n)))</span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>clt_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(clt_df, <span class="fu">aes</span>(mean)) <span class="sc">+</span></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density), <span class="at">fill =</span> <span class="fu">factor</span>(n)),</span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>                 <span class="at">bins =</span> <span class="dv">30</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> normal_df, <span class="fu">aes</span>(x, density), <span class="at">linewidth =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> mu, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span> n, <span class="at">scales =</span> <span class="st">"free"</span>, <span class="at">ncol =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb20-43"><a href="#cb20-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb20-44"><a href="#cb20-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"CLT: Sampling distribution of the mean → Normal(μ, σ/√n)"</span>,</span>
<span id="cb20-45"><a href="#cb20-45" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">sprintf</span>(<span class="st">"Skewed population: Gamma(shape=2, scale=10).  μ≈%.2f, σ≈%.2f; B=%d resamples each."</span>, mu, sigma, B),</span>
<span id="cb20-46"><a href="#cb20-46" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Sample mean"</span>, <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb20-47"><a href="#cb20-47" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb20-48"><a href="#cb20-48" aria-hidden="true" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">fill =</span> <span class="st">"none"</span>)</span>
<span id="cb20-49"><a href="#cb20-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-50"><a href="#cb20-50" aria-hidden="true" tabindex="-1"></a>clt_plot</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-17-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 8. TYPES OF SAMPLING ERROR</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data to show random vs systematic error</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">321</span>)</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>n_measurements <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>true_value <span class="ot">&lt;-</span> <span class="dv">50</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Random error only</span></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>random_error <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_measurements, <span class="at">mean =</span> true_value, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Systematic error (bias) only</span></span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>systematic_error <span class="ot">&lt;-</span> <span class="fu">rep</span>(true_value <span class="sc">+</span> <span class="dv">10</span>, n_measurements) <span class="sc">+</span> <span class="fu">rnorm</span>(n_measurements, <span class="dv">0</span>, <span class="fl">0.5</span>)</span>
<span id="cb21-15"><a href="#cb21-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-16"><a href="#cb21-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Both errors</span></span>
<span id="cb21-17"><a href="#cb21-17" aria-hidden="true" tabindex="-1"></a>both_errors <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n_measurements, <span class="at">mean =</span> true_value <span class="sc">+</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb21-18"><a href="#cb21-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-19"><a href="#cb21-19" aria-hidden="true" tabindex="-1"></a>error_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb21-20"><a href="#cb21-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">measurement =</span> <span class="dv">1</span><span class="sc">:</span>n_measurements,</span>
<span id="cb21-21"><a href="#cb21-21" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Random Error Only</span><span class="st">`</span> <span class="ot">=</span> random_error,</span>
<span id="cb21-22"><a href="#cb21-22" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Systematic Error Only</span><span class="st">`</span> <span class="ot">=</span> systematic_error,</span>
<span id="cb21-23"><a href="#cb21-23" aria-hidden="true" tabindex="-1"></a>  <span class="st">`</span><span class="at">Both Errors</span><span class="st">`</span> <span class="ot">=</span> both_errors</span>
<span id="cb21-24"><a href="#cb21-24" aria-hidden="true" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb21-25"><a href="#cb21-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="sc">-</span>measurement, <span class="at">names_to =</span> <span class="st">"Error_Type"</span>, <span class="at">values_to =</span> <span class="st">"Value"</span>)</span>
<span id="cb21-26"><a href="#cb21-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-27"><a href="#cb21-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Create error visualization</span></span>
<span id="cb21-28"><a href="#cb21-28" aria-hidden="true" tabindex="-1"></a>error_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(error_data, <span class="fu">aes</span>(<span class="at">x =</span> measurement, <span class="at">y =</span> Value, <span class="at">color =</span> Error_Type)) <span class="sc">+</span></span>
<span id="cb21-29"><a href="#cb21-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> true_value, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">size =</span> <span class="dv">1</span>, <span class="at">color =</span> <span class="st">"black"</span>) <span class="sc">+</span></span>
<span id="cb21-30"><a href="#cb21-30" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.6</span>, <span class="at">size =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb21-31"><a href="#cb21-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"lm"</span>, <span class="at">se =</span> <span class="cn">FALSE</span>, <span class="at">size =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb21-32"><a href="#cb21-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>Error_Type, <span class="at">nrow =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb21-33"><a href="#cb21-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> colors[<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]) <span class="sc">+</span></span>
<span id="cb21-34"><a href="#cb21-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Random Error vs Systematic Error (Bias)"</span>,</span>
<span id="cb21-35"><a href="#cb21-35" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="fu">paste</span>(<span class="st">"True value = "</span>, true_value, <span class="st">" (black dashed line)"</span>, <span class="at">sep =</span> <span class="st">""</span>),</span>
<span id="cb21-36"><a href="#cb21-36" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Measurement Number"</span>, </span>
<span id="cb21-37"><a href="#cb21-37" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Measured Value"</span>) <span class="sc">+</span></span>
<span id="cb21-38"><a href="#cb21-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>),</span>
<span id="cb21-39"><a href="#cb21-39" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="st">"none"</span>)</span>
<span id="cb21-40"><a href="#cb21-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-41"><a href="#cb21-41" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(error_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-18-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 9. DEMOGRAPHIC PYRAMID</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Create age pyramid data</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">777</span>)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>age_groups <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"0-4"</span>, <span class="st">"5-9"</span>, <span class="st">"10-14"</span>, <span class="st">"15-19"</span>, <span class="st">"20-24"</span>, <span class="st">"25-29"</span>, </span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>               <span class="st">"30-34"</span>, <span class="st">"35-39"</span>, <span class="st">"40-44"</span>, <span class="st">"45-49"</span>, <span class="st">"50-54"</span>, </span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>               <span class="st">"55-59"</span>, <span class="st">"60-64"</span>, <span class="st">"65-69"</span>, <span class="st">"70-74"</span>, <span class="st">"75-79"</span>, <span class="st">"80+"</span>)</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Create data for a developing country pattern</span></span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>male_pop <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">12</span>, <span class="fl">11.5</span>, <span class="dv">11</span>, <span class="fl">10.5</span>, <span class="dv">10</span>, <span class="fl">9.5</span>, <span class="dv">9</span>, <span class="fl">8.5</span>, <span class="dv">8</span>, <span class="fl">7.5</span>, <span class="dv">7</span>, </span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>             <span class="dv">6</span>, <span class="dv">5</span>, <span class="dv">4</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="fl">1.5</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>female_pop <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">11.8</span>, <span class="fl">11.3</span>, <span class="fl">10.8</span>, <span class="fl">10.3</span>, <span class="fl">9.8</span>, <span class="fl">9.3</span>, <span class="fl">8.8</span>, <span class="fl">8.3</span>, <span class="fl">7.8</span>, </span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>               <span class="fl">7.3</span>, <span class="fl">6.8</span>, <span class="fl">5.8</span>, <span class="fl">4.8</span>, <span class="fl">3.8</span>, <span class="fl">2.8</span>, <span class="fl">2.2</span>, <span class="dv">2</span>)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a>pyramid_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">Age =</span> <span class="fu">factor</span>(<span class="fu">rep</span>(age_groups, <span class="dv">2</span>), <span class="at">levels =</span> <span class="fu">rev</span>(age_groups)),</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">Population =</span> <span class="fu">c</span>(<span class="sc">-</span>male_pop, female_pop),  <span class="co"># Negative for males</span></span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">Sex =</span> <span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">"Male"</span>, <span class="fu">length</span>(male_pop)), <span class="fu">rep</span>(<span class="st">"Female"</span>, <span class="fu">length</span>(female_pop)))</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-23"><a href="#cb22-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Create population pyramid</span></span>
<span id="cb22-24"><a href="#cb22-24" aria-hidden="true" tabindex="-1"></a>pyramid_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(pyramid_data, <span class="fu">aes</span>(<span class="at">x =</span> Age, <span class="at">y =</span> Population, <span class="at">fill =</span> Sex)) <span class="sc">+</span></span>
<span id="cb22-25"><a href="#cb22-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_bar</span>(<span class="at">stat =</span> <span class="st">"identity"</span>, <span class="at">width =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb22-26"><a href="#cb22-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">labels =</span> <span class="cf">function</span>(x) <span class="fu">paste0</span>(<span class="fu">abs</span>(x), <span class="st">"%"</span>)) <span class="sc">+</span></span>
<span id="cb22-27"><a href="#cb22-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Male"</span> <span class="ot">=</span> colors[<span class="dv">1</span>], <span class="st">"Female"</span> <span class="ot">=</span> colors[<span class="dv">3</span>])) <span class="sc">+</span></span>
<span id="cb22-28"><a href="#cb22-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_flip</span>() <span class="sc">+</span></span>
<span id="cb22-29"><a href="#cb22-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Population Pyramid"</span>,</span>
<span id="cb22-30"><a href="#cb22-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Age and sex distribution (typical developing country pattern)"</span>,</span>
<span id="cb22-31"><a href="#cb22-31" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Age Group"</span>, </span>
<span id="cb22-32"><a href="#cb22-32" aria-hidden="true" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">"Percentage of Population"</span>) <span class="sc">+</span></span>
<span id="cb22-33"><a href="#cb22-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">14</span>),</span>
<span id="cb22-34"><a href="#cb22-34" aria-hidden="true" tabindex="-1"></a>        <span class="at">legend.position =</span> <span class="st">"top"</span>)</span>
<span id="cb22-35"><a href="#cb22-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-36"><a href="#cb22-36" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(pyramid_plot)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-18-2.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 10. REGRESSION RESIDUALS AND DIAGNOSTICS</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Use the previous regression model for diagnostics</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>reg_diagnostics <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">fitted =</span> <span class="fu">fitted</span>(lm_model),</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">residuals =</span> <span class="fu">residuals</span>(lm_model),</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">standardized_residuals =</span> <span class="fu">rstandard</span>(lm_model),</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">education =</span> reg_data<span class="sc">$</span>education,</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">income =</span> reg_data<span class="sc">$</span>income</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Create diagnostic plots</span></span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. Residuals vs Fitted</span></span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>p_resid_fitted <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(reg_diagnostics, <span class="fu">aes</span>(<span class="at">x =</span> fitted, <span class="at">y =</span> residuals)) <span class="sc">+</span></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">color =</span> colors[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">se =</span> <span class="cn">TRUE</span>, <span class="at">color =</span> colors[<span class="dv">2</span>], <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Residuals vs Fitted Values"</span>,</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Check for homoscedasticity"</span>,</span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Fitted Values"</span>, <span class="at">y =</span> <span class="st">"Residuals"</span>)</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. Q-Q plot</span></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a>p_qq <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(reg_diagnostics, <span class="fu">aes</span>(<span class="at">sample =</span> standardized_residuals)) <span class="sc">+</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq</span>(<span class="at">color =</span> colors[<span class="dv">1</span>]) <span class="sc">+</span></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_qq_line</span>(<span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Normal Q-Q Plot"</span>,</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Check for normality of residuals"</span>,</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Theoretical Quantiles"</span>, <span class="at">y =</span> <span class="st">"Standardized Residuals"</span>)</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. Histogram of residuals</span></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a>p_hist_resid <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(reg_diagnostics, <span class="fu">aes</span>(<span class="at">x =</span> residuals)) <span class="sc">+</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="at">bins =</span> <span class="dv">30</span>, <span class="at">fill =</span> colors[<span class="dv">3</span>], <span class="at">alpha =</span> <span class="fl">0.7</span>, <span class="at">color =</span> <span class="st">"white"</span>) <span class="sc">+</span></span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">"red"</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Distribution of Residuals"</span>,</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Should be approximately normal"</span>,</span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Residuals"</span>, <span class="at">y =</span> <span class="st">"Frequency"</span>)</span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. Residuals vs Predictor</span></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a>p_resid_x <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(reg_diagnostics, <span class="fu">aes</span>(<span class="at">x =</span> education, <span class="at">y =</span> residuals)) <span class="sc">+</span></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">alpha =</span> <span class="fl">0.5</span>, <span class="at">color =</span> colors[<span class="dv">4</span>]) <span class="sc">+</span></span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>, <span class="at">color =</span> <span class="st">"red"</span>) <span class="sc">+</span></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">"loess"</span>, <span class="at">se =</span> <span class="cn">TRUE</span>, <span class="at">color =</span> colors[<span class="dv">2</span>], <span class="at">size =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Residuals vs Predictor"</span>,</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">"Check for patterns"</span>,</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"Education (years)"</span>, <span class="at">y =</span> <span class="st">"Residuals"</span>)</span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a><span class="co"># Combine diagnostic plots</span></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>diagnostic_plots <span class="ot">&lt;-</span> (p_resid_fitted <span class="sc">+</span> p_qq) <span class="sc">/</span> (p_hist_resid <span class="sc">+</span> p_resid_x)</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(diagnostic_plots)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/unnamed-chunk-18-3.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co"># 11. SAVE ALL PLOTS (Optional)</span></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># ==================================================</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Uncomment to save plots as high-resolution images</span></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("population_sample.png", population_sample_plot, width = 10, height = 8, dpi = 300)</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("distributions.png", distributions_plot, width = 12, height = 8, dpi = 300)</span></span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("normal_distribution.png", normal_plot, width = 10, height = 6, dpi = 300)</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("regression.png", regression_plot, width = 10, height = 7, dpi = 300)</span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("standard_error.png", se_plot, width = 10, height = 6, dpi = 300)</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("confidence_intervals.png", ci_plot, width = 10, height = 8, dpi = 300)</span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("central_limit_theorem.png", clt_plot, width = 14, height = 5, dpi = 300)</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("error_types.png", error_plot, width = 14, height = 5, dpi = 300)</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("population_pyramid.png", pyramid_plot, width = 8, height = 8, dpi = 300)</span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># ggsave("regression_diagnostics.png", diagnostic_plots, width = 12, height = 10, dpi = 300)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
</section>
<section id="appendix-b-central-limit-theorem-clt" class="level2" data-number="1.26">
<h2 data-number="1.26" class="anchored" data-anchor-id="appendix-b-central-limit-theorem-clt"><span class="header-section-number">1.26</span> Appendix B: Central Limit Theorem (CLT)</h2>
<p>The Central Limit Theorem states that the distribution of sample means approaches a normal distribution as sample size increases, <strong>regardless of the shape of the original population distribution</strong>.</p>
<section id="key-insights-1" class="level3">
<h3 class="anchored" data-anchor-id="key-insights-1">Key Insights</h3>
<ul>
<li><strong>Sample Size Threshold</strong>: Sample sizes of n ≥ 30 are typically sufficient for the CLT to apply</li>
<li><strong>Standard Error</strong>: The standard deviation of sample means equals σ/√n, where σ is the population standard deviation</li>
<li><strong>Statistical Foundation</strong>: We can make inferences about population parameters using normal distribution properties</li>
</ul>
</section>
</section>
<section id="visual-demonstration-step-by-step-progression" class="level2" data-number="1.27">
<h2 data-number="1.27" class="anchored" data-anchor-id="visual-demonstration-step-by-step-progression"><span class="header-section-number">1.27</span> Visual Demonstration: Step-by-Step Progression</h2>
<p>The most effective approach to understanding CLT is to observe the systematic transformation of the distribution as the number of dice increases. Beginning with 1 die (uniform distribution), we can observe how increasing the sample size gradually transforms the distribution into a normal distribution.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="the-progressive-transformation" class="level3">
<h3 class="anchored" data-anchor-id="the-progressive-transformation">The Progressive Transformation</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Sample sizes to demonstrate</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>sample_sizes <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">30</span>, <span class="dv">50</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>num_simulations <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Simulate for each sample size</span></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>all_data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>()</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (n <span class="cf">in</span> sample_sizes) {</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>  means <span class="ot">&lt;-</span> <span class="fu">replicate</span>(num_simulations, {</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>    dice <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>, n, <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>    <span class="fu">mean</span>(dice)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>  })</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>  temp_df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(</span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">mean =</span> means,</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">n =</span> n,</span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">label =</span> <span class="fu">paste</span>(n, <span class="fu">ifelse</span>(n <span class="sc">==</span> <span class="dv">1</span>, <span class="st">"die"</span>, <span class="st">"dice"</span>))</span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a>  all_data <span class="ot">&lt;-</span> <span class="fu">rbind</span>(all_data, temp_df)</span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Create ordered factor</span></span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>all_data<span class="sc">$</span>label <span class="ot">&lt;-</span> <span class="fu">factor</span>(all_data<span class="sc">$</span>label, </span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a>                         <span class="at">levels =</span> <span class="fu">paste</span>(sample_sizes, </span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a>                                       <span class="fu">ifelse</span>(sample_sizes <span class="sc">==</span> <span class="dv">1</span>, <span class="st">"die"</span>, <span class="st">"dice"</span>)))</span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot the progression</span></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(all_data, <span class="fu">aes</span>(<span class="at">x =</span> mean)) <span class="sc">+</span></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), </span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>                 <span class="at">bins =</span> <span class="dv">40</span>, <span class="at">fill =</span> <span class="st">"#3b82f6"</span>, <span class="at">color =</span> <span class="st">"white"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>label, <span class="at">scales =</span> <span class="st">"free"</span>, <span class="at">ncol =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Central Limit Theorem: Step-by-Step Progression"</span>,</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="fu">sprintf</span>(<span class="st">"Each panel shows %s simulations demonstrating the convergence to normality"</span>, </span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">format</span>(num_simulations, <span class="at">big.mark =</span> <span class="st">","</span>)),</span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Mean Value"</span>,</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">16</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.subtitle =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">11</span>, <span class="at">color =</span> <span class="st">"gray40"</span>),</span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a>    <span class="at">strip.text =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">12</span>),</span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>    <span class="at">strip.background =</span> <span class="fu">element_rect</span>(<span class="at">fill =</span> <span class="st">"#f0f0f0"</span>, <span class="at">color =</span> <span class="cn">NA</span>)</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/progression-1.png" class="img-fluid figure-img" width="1152"></p>
</figure>
</div>
</div>
</div>
<section id="analysis-of-progressive-stages" class="level4">
<h4 class="anchored" data-anchor-id="analysis-of-progressive-stages">Analysis of Progressive Stages:</h4>
<ul>
<li><strong>1 die</strong>: Uniform (discrete) distribution - all values 1 to 6 equally probable</li>
<li><strong>2 dice</strong>: Triangular tendency - central values more frequent</li>
<li><strong>5 dice</strong>: Emergent bell-shaped pattern - observable clustering around 3.5</li>
<li><strong>10 dice</strong>: Distinctly normal - narrow Gaussian curve forming</li>
<li><strong>30 dice</strong>: Normal distribution - practical demonstration of CLT</li>
<li><strong>50 dice</strong>: Near-ideal normal distribution - strong concentration around mean</li>
</ul>
<p>The distribution exhibits decreasing <strong>variability</strong> and increasingly pronounced <strong>bell-shaped characteristics</strong> as n increases.</p>
</section>
</section>
<section id="comparative-analysis" class="level3">
<h3 class="anchored" data-anchor-id="comparative-analysis">Comparative Analysis</h3>
<p>A cleaner comparison of key developmental stages:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>key_sizes <span class="ot">&lt;-</span> all_data <span class="sc">%&gt;%</span></span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(n <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">30</span>))</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(key_sizes, <span class="fu">aes</span>(<span class="at">x =</span> mean)) <span class="sc">+</span></span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">after_stat</span>(density)), </span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>                 <span class="at">bins =</span> <span class="dv">40</span>, <span class="at">fill =</span> <span class="st">"#3b82f6"</span>, <span class="at">color =</span> <span class="st">"white"</span>, <span class="at">alpha =</span> <span class="fl">0.7</span>) <span class="sc">+</span></span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="sc">~</span>label, <span class="at">scales =</span> <span class="st">"free_x"</span>, <span class="at">nrow =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"CLT Evolution: From Uniform to Normal"</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Mean Value"</span>,</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span></span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">14</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>    <span class="at">strip.text =</span> <span class="fu">element_text</span>(<span class="at">face =</span> <span class="st">"bold"</span>, <span class="at">size =</span> <span class="dv">11</span>),</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.text.y =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">axis.ticks.y =</span> <span class="fu">element_blank</span>()</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/horizontal-1.png" class="img-fluid figure-img" width="1152"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="superimposed-distributions" class="level3">
<h3 class="anchored" data-anchor-id="superimposed-distributions">Superimposed Distributions</h3>
<p>An alternative visualization method displaying all distributions simultaneously:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>comparison_data <span class="ot">&lt;-</span> all_data <span class="sc">%&gt;%</span></span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">filter</span>(n <span class="sc">%in%</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">30</span>))</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(comparison_data, <span class="fu">aes</span>(<span class="at">x =</span> mean, <span class="at">fill =</span> label, <span class="at">color =</span> label)) <span class="sc">+</span></span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_density</span>(<span class="at">alpha =</span> <span class="fl">0.3</span>, <span class="at">linewidth =</span> <span class="fl">1.2</span>) <span class="sc">+</span></span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_fill_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"#991b1b"</span>, <span class="st">"#ea580c"</span>, <span class="st">"#ca8a04"</span>, <span class="st">"#16a34a"</span>)) <span class="sc">+</span></span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"#991b1b"</span>, <span class="st">"#ea580c"</span>, <span class="st">"#ca8a04"</span>, <span class="st">"#16a34a"</span>)) <span class="sc">+</span></span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"CLT Progression: Superimposed Distributions"</span>,</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Systematic narrowing and convergence to normal form"</span>,</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Mean Value"</span>,</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Density"</span>,</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>    <span class="at">fill =</span> <span class="st">"Sample Size"</span>,</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="st">"Sample Size"</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">14</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"right"</span></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/overlaid-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
<p><strong>Key Observation</strong>: As sample size increases, the distribution exhibits:</p>
<ol type="1">
<li>Increased <strong>symmetry</strong> (bell-shaped form)</li>
<li>Greater <strong>concentration</strong> around the population mean (3.5)</li>
<li>Improved <strong>conformity</strong> to the normal distribution</li>
</ol>
</section>
<section id="standard-error-convergence" class="level3">
<h3 class="anchored" data-anchor-id="standard-error-convergence">Standard Error Convergence</h3>
<p>The dispersion (standard deviation) decreases according to the relationship SE = σ/√n:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>variance_data <span class="ot">&lt;-</span> all_data <span class="sc">%&gt;%</span></span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(n, label) <span class="sc">%&gt;%</span></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">observed_sd =</span> <span class="fu">sd</span>(mean),</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">theoretical_se =</span> <span class="fu">sqrt</span>(<span class="dv">35</span><span class="sc">/</span><span class="dv">12</span>) <span class="sc">/</span> <span class="fu">sqrt</span>(n),</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">.groups =</span> <span class="st">"drop"</span></span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(variance_data, <span class="fu">aes</span>(<span class="at">x =</span> n)) <span class="sc">+</span></span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> observed_sd, <span class="at">color =</span> <span class="st">"Observed SD"</span>), </span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>            <span class="at">linewidth =</span> <span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> observed_sd, <span class="at">color =</span> <span class="st">"Observed SD"</span>), </span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>             <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y =</span> theoretical_se, <span class="at">color =</span> <span class="st">"Theoretical SE"</span>), </span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a>            <span class="at">linewidth =</span> <span class="fl">1.5</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> theoretical_se, <span class="at">color =</span> <span class="st">"Theoretical SE"</span>), </span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>             <span class="at">size =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">"Observed SD"</span> <span class="ot">=</span> <span class="st">"#3b82f6"</span>, </span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>                                <span class="st">"Theoretical SE"</span> <span class="ot">=</span> <span class="st">"#ef4444"</span>)) <span class="sc">+</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> sample_sizes) <span class="sc">+</span></span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>    <span class="at">title =</span> <span class="st">"Standard Error Decreases as Sample Size Increases"</span>,</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>    <span class="at">subtitle =</span> <span class="st">"Following the SE = σ/√n relationship"</span>,</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="st">"Sample Size (n)"</span>,</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>    <span class="at">y =</span> <span class="st">"Standard Deviation / Standard Error"</span>,</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>    <span class="at">color =</span> <span class="cn">NULL</span></span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">+</span></span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>() <span class="sc">+</span></span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>    <span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">14</span>, <span class="at">face =</span> <span class="st">"bold"</span>),</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.position =</span> <span class="st">"top"</span>,</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>    <span class="at">legend.text =</span> <span class="fu">element_text</span>(<span class="at">size =</span> <span class="dv">11</span>)</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>  )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="chapter1_files/figure-html/variance-1.png" class="img-fluid figure-img" width="960"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="numerical-summary" class="level3">
<h3 class="anchored" data-anchor-id="numerical-summary">Numerical Summary</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>summary_stats <span class="ot">&lt;-</span> all_data <span class="sc">%&gt;%</span></span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(label) <span class="sc">%&gt;%</span></span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">n =</span> <span class="fu">first</span>(n),</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">Observed_Mean =</span> <span class="fu">round</span>(<span class="fu">mean</span>(mean), <span class="dv">3</span>),</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">Observed_SD =</span> <span class="fu">round</span>(<span class="fu">sd</span>(mean), <span class="dv">3</span>),</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">Theoretical_Mean =</span> <span class="fl">3.5</span>,</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">Theoretical_SE =</span> <span class="fu">round</span>(<span class="fu">sqrt</span>(<span class="dv">35</span><span class="sc">/</span><span class="dv">12</span>) <span class="sc">/</span> <span class="fu">sqrt</span>(<span class="fu">first</span>(n)), <span class="dv">3</span>),</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">Range =</span> <span class="fu">paste0</span>(<span class="st">"["</span>, <span class="fu">round</span>(<span class="fu">min</span>(mean), <span class="dv">2</span>), <span class="st">", "</span>, <span class="fu">round</span>(<span class="fu">max</span>(mean), <span class="dv">2</span>), <span class="st">"]"</span>)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>label)</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(summary_stats, </span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>             <span class="at">caption =</span> <span class="st">"Observed vs Theoretical Values Across Sample Sizes"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Observed vs Theoretical Values Across Sample Sizes</caption>
<colgroup>
<col style="width: 4%">
<col style="width: 18%">
<col style="width: 16%">
<col style="width: 22%">
<col style="width: 20%">
<col style="width: 17%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;">n</th>
<th style="text-align: right;">Observed_Mean</th>
<th style="text-align: right;">Observed_SD</th>
<th style="text-align: right;">Theoretical_Mean</th>
<th style="text-align: right;">Theoretical_SE</th>
<th style="text-align: left;">Range</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">3.470</td>
<td style="text-align: right;">1.716</td>
<td style="text-align: right;">3.5</td>
<td style="text-align: right;">1.708</td>
<td style="text-align: left;">[1, 6]</td>
</tr>
<tr class="even">
<td style="text-align: right;">2</td>
<td style="text-align: right;">3.503</td>
<td style="text-align: right;">1.213</td>
<td style="text-align: right;">3.5</td>
<td style="text-align: right;">1.208</td>
<td style="text-align: left;">[1, 6]</td>
</tr>
<tr class="odd">
<td style="text-align: right;">5</td>
<td style="text-align: right;">3.494</td>
<td style="text-align: right;">0.764</td>
<td style="text-align: right;">3.5</td>
<td style="text-align: right;">0.764</td>
<td style="text-align: left;">[1, 6]</td>
</tr>
<tr class="even">
<td style="text-align: right;">10</td>
<td style="text-align: right;">3.507</td>
<td style="text-align: right;">0.537</td>
<td style="text-align: right;">3.5</td>
<td style="text-align: right;">0.540</td>
<td style="text-align: left;">[1.7, 5.4]</td>
</tr>
<tr class="odd">
<td style="text-align: right;">30</td>
<td style="text-align: right;">3.500</td>
<td style="text-align: right;">0.311</td>
<td style="text-align: right;">3.5</td>
<td style="text-align: right;">0.312</td>
<td style="text-align: left;">[2.27, 4.63]</td>
</tr>
<tr class="even">
<td style="text-align: right;">50</td>
<td style="text-align: right;">3.498</td>
<td style="text-align: right;">0.239</td>
<td style="text-align: right;">3.5</td>
<td style="text-align: right;">0.242</td>
<td style="text-align: left;">[2.68, 4.3]</td>
</tr>
</tbody>
</table>
</div>
</div>
<p><strong>Observations:</strong></p>
<ul>
<li>The <strong>population mean</strong> remains constant at 3.5 (independent of sample size)</li>
<li>The <strong>standard error</strong> exhibits systematic decline as n increases (SE ∝ 1/√n)</li>
<li>The <strong>range</strong> narrows considerably with increasing sample size</li>
</ul>
</section>
</section>
<section id="mathematical-foundation-1" class="level2" data-number="1.28">
<h2 data-number="1.28" class="anchored" data-anchor-id="mathematical-foundation-1"><span class="header-section-number">1.28</span> Mathematical Foundation</h2>
<p>For a population with mean μ and finite variance σ²:</p>
<p><span class="math display">\bar{X} \sim N\left(\mu, \frac{\sigma^2}{n}\right) \text{ as } n \to \infty</span></p>
<p><strong>Standard error of the mean:</strong></p>
<p><span class="math display">SE_{\bar{X}} = \frac{\sigma}{\sqrt{n}}</span></p>
<p>For a fair die: μ = 3.5, σ² = 35/12 ≈ 2.917</p>
</section>
<section id="key-takeaways-2" class="level2" data-number="1.29">
<h2 data-number="1.29" class="anchored" data-anchor-id="key-takeaways-2"><span class="header-section-number">1.29</span> Key Takeaways</h2>
<ol type="1">
<li><strong>Initial Condition</strong>: A single die exhibits a uniform (discrete) distribution</li>
<li><strong>Progressive Transformation</strong>: As the number of observations increases, the distribution shape systematically evolves</li>
<li><strong>Convergence to Normality</strong>: At n=30, a distinct normal distribution is observable</li>
<li><strong>Variance Reduction</strong>: The distribution demonstrates increasing concentration around the expected value</li>
<li><strong>Universality</strong>: The theorem applies to any population distribution with finite variance</li>
</ol>
</section>
<section id="practical-significance" class="level2" data-number="1.30">
<h2 data-number="1.30" class="anchored" data-anchor-id="practical-significance"><span class="header-section-number">1.30</span> Practical Significance</h2>
<p>This distributional transformation enables:</p>
<ul>
<li>Application of normal distribution tables and properties for statistical inference</li>
<li>Construction of confidence intervals with specified confidence levels</li>
<li>Execution of hypothesis tests (t-tests, z-tests)</li>
<li>Formulation of predictions about sample means with known probability</li>
</ul>
<p><strong>Essential Property of CLT</strong>: Although individual die rolls follow a uniform distribution, the distribution of means from multiple dice converges asymptotically to a normal distribution in a predictable manner consistent with mathematical theory, providing the foundation for classical statistical inference.</p>
<hr>
</section>
<section id="appendix-c-standard-errors-and-margins-of-error-means-proportions-variance-and-covariance" class="level2" data-number="1.31">
<h2 data-number="1.31" class="anchored" data-anchor-id="appendix-c-standard-errors-and-margins-of-error-means-proportions-variance-and-covariance"><span class="header-section-number">1.31</span> Appendix C: Standard Errors and Margins of Error: Means, Proportions, Variance, and Covariance</h2>
<section id="key-insight-a-proportion-is-a-mean" class="level3">
<h3 class="anchored" data-anchor-id="key-insight-a-proportion-is-a-mean">Key Insight: A Proportion IS a Mean</h3>
<p><strong>A proportion is simply the mean of a binary (0/1) variable.</strong> If you code “success” as 1 and “failure” as 0, then:</p>
<p><span class="math display">\hat{p} = \bar{x} = \frac{\sum x_i}{n}</span></p>
<p>For example, if 6 out of 10 people support a policy (coded as 1=support, 0=don’t support):</p>
<ul>
<li>Proportion: <span class="math inline">\hat{p} = 0.6</span></li>
<li>Mean: <span class="math inline">\bar{x} = \frac{1+1+1+1+1+1+0+0+0+0}{10} = 0.6</span></li>
</ul>
<p>They’re identical! The special formulas for proportions are just the general formulas applied to binary data.</p>
</section>
<section id="the-universal-formula-for-means" class="level3">
<h3 class="anchored" data-anchor-id="the-universal-formula-for-means">The Universal Formula for Means</h3>
<p>Both proportions and continuous means use the same fundamental formula for standard error:</p>
<p><span class="math display">SE = \frac{SD}{\sqrt{n}}</span></p>
<p>The <strong>Margin of Error</strong> (for 95% confidence) is then:</p>
<p><span class="math display">MoE = 1.96 \times SE = 1.96 \times \frac{SD}{\sqrt{n}}</span></p>
</section>
<section id="calculating-se-and-moe-for-proportions" class="level3">
<h3 class="anchored" data-anchor-id="calculating-se-and-moe-for-proportions">Calculating SE and MoE for Proportions</h3>
<p>For a sample proportion <span class="math inline">\hat{p}</span>, the standard deviation is derived from the binomial distribution:</p>
<p><span class="math display">SD = \sqrt{p(1-p)}</span></p>
<p>Therefore:</p>
<p><span class="math display">SE_p = \sqrt{\frac{p(1-p)}{n}}</span></p>
<p><span class="math display">MoE_p = 1.96\sqrt{\frac{p(1-p)}{n}}</span></p>
<p><strong>Example: Political Poll</strong></p>
<p>If 60% of voters support a candidate (<span class="math inline">p = 0.6</span>) with <span class="math inline">n = 400</span>:</p>
<ul>
<li><span class="math inline">SD = \sqrt{0.6 \times 0.4} = \sqrt{0.24} = 0.490</span></li>
<li><span class="math inline">SE = \frac{0.490}{\sqrt{400}} = \frac{0.490}{20} = 0.0245</span> (or 2.45%)</li>
<li><span class="math inline">MoE = 1.96 \times 0.0245 = 0.048</span> (or ±4.8%)</li>
</ul>
</section>
<section id="calculating-se-and-moe-for-typical-means" class="level3">
<h3 class="anchored" data-anchor-id="calculating-se-and-moe-for-typical-means">Calculating SE and MoE for Typical Means</h3>
<p>For a continuous variable like height, weight, or test scores:</p>
<p><span class="math display">SE_{\bar{x}} = \frac{SD}{\sqrt{n}}</span></p>
<p><span class="math display">MoE_{\bar{x}} = 1.96 \times \frac{SD}{\sqrt{n}}</span></p>
<p><strong>Example: Mean Height</strong></p>
<p>If measuring height with <span class="math inline">SD = 10</span> cm and <span class="math inline">n = 100</span>:</p>
<ul>
<li><span class="math inline">SE = \frac{10}{\sqrt{100}} = \frac{10}{10} = 1.0</span> cm</li>
<li><span class="math inline">MoE = 1.96 \times 1.0 = ±1.96</span> cm</li>
</ul>
</section>
<section id="why-proportions-often-require-larger-samples" class="level3">
<h3 class="anchored" data-anchor-id="why-proportions-often-require-larger-samples">Why Proportions Often Require Larger Samples</h3>
<p>The perception that proportions need larger samples arises from several factors:</p>
<section id="maximum-variance-at-p-0.5" class="level4">
<h4 class="anchored" data-anchor-id="maximum-variance-at-p-0.5">1. <strong>Maximum Variance at p = 0.5</strong></h4>
<p>The variance <span class="math inline">p(1-p)</span> is maximized when <span class="math inline">p = 0.5</span>, giving:</p>
<p><span class="math display">SD_{max} = \sqrt{0.5 \times 0.5} = 0.5</span></p>
<p>This means on a 0-1 scale, the standard deviation can be quite large relative to the range. For “maximum uncertainty” scenarios (p = 0.5):</p>
<p><span class="math display">n = \left(\frac{1.96 \times 0.5}{MoE}\right)^2 = \frac{0.9604}{MoE^2}</span></p>
<p><strong>Sample size requirements for different margins of error (at p = 0.5):</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Desired MoE</th>
<th>Required n</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>±1% (0.01)</td>
<td>9,604</td>
</tr>
<tr class="even">
<td>±2% (0.02)</td>
<td>2,401</td>
</tr>
<tr class="odd">
<td>±3% (0.03)</td>
<td>1,068</td>
</tr>
<tr class="even">
<td>±5% (0.05)</td>
<td>385</td>
</tr>
</tbody>
</table>
</section>
<section id="context-of-precision" class="level4">
<h4 class="anchored" data-anchor-id="context-of-precision">2. <strong>Context of Precision</strong></h4>
<p>The <em>desired</em> precision differs by context:</p>
<ul>
<li><strong>Proportions</strong>: Political polls typically want ±3-4 percentage points</li>
<li><strong>Height</strong>: ±0.5 cm might suffice (only 5% of a 10 cm SD)</li>
<li><strong>Test scores</strong>: ±2 points might be acceptable (depends on scale)</li>
</ul>
<p>These represent different levels of <em>relative</em> precision.</p>
</section>
<section id="scale-matters" class="level4">
<h4 class="anchored" data-anchor-id="scale-matters">3. <strong>Scale Matters</strong></h4>
<p>For a proportion measured as ±0.02 (2 percentage points):</p>
<ul>
<li>This is 2% of the full 0-1 scale</li>
<li>Relatively speaking, this is very precise</li>
</ul>
<p>For height measured as ±2 cm with SD = 10 cm:</p>
<ul>
<li>This is only 20% of one standard deviation</li>
<li>Less stringent requirement</li>
</ul>
</section>
<section id="rare-events" class="level4">
<h4 class="anchored" data-anchor-id="rare-events">4. <strong>Rare Events</strong></h4>
<p>When estimating rare proportions (e.g., <span class="math inline">p = 0.01</span>), you need enough sample to actually <em>observe</em> the events:</p>
<ul>
<li>For <span class="math inline">p = 0.01</span> with <span class="math inline">n = 100</span>, you expect only 1 success</li>
<li>Need <span class="math inline">n \approx 1,500</span> for ±0.5% precision</li>
</ul>
</section>
</section>
<section id="margin-of-error-and-sample-size-for-variance" class="level3">
<h3 class="anchored" data-anchor-id="margin-of-error-and-sample-size-for-variance">Margin of Error and Sample Size for Variance</h3>
<p>Variance estimation is more complex because <strong>sample variance does not follow a normal distribution</strong> - it follows a scaled chi-squared distribution (for normally distributed data).</p>
<hr>
<section id="standard-error-of-variance" class="level4">
<h4 class="anchored" data-anchor-id="standard-error-of-variance">Standard Error of Variance</h4>
<p>For a normally distributed variable, the standard error of the sample variance <span class="math inline">s^2</span> is:</p>
<p><span class="math display">SE(s^2) = s^2\sqrt{\frac{2}{n-1}}</span></p>
<p><strong>Example: Height Variance</strong></p>
<p>If height has <span class="math inline">s^2 = 100</span> cm² (so <span class="math inline">s = 10</span> cm) with <span class="math inline">n = 101</span>:</p>
<ul>
<li><span class="math inline">SE(s^2) = 100\sqrt{\frac{2}{100}} = 100 \times 0.1414 = 14.14</span> cm²</li>
<li><span class="math inline">MoE = 1.96 \times 14.14 = ±27.7</span> cm²</li>
</ul>
<p><strong>Important considerations:</strong></p>
<ol type="1">
<li><strong>Confidence intervals are asymmetric</strong>: Because chi-squared distribution is skewed, exact CIs should use chi-squared quantiles, not the ±1.96 approach</li>
<li><strong>Normality assumption matters</strong>: The formula assumes underlying normality</li>
<li><strong>Larger samples needed</strong>: Note <span class="math inline">SE \propto 1/\sqrt{n-1}</span> means variance estimates converge slowly</li>
<li><strong>Sample size for given precision</strong>: To get MoE = 0.1 × <span class="math inline">s^2</span> (10% precision):</li>
</ol>
<p><span class="math display">n \approx 1 + 2\left(\frac{1.96}{0.1}\right)^2 = 769</span></p>
<p>This is much larger than for means!</p>
</section>
<section id="standard-error-of-standard-deviation" class="level4">
<h4 class="anchored" data-anchor-id="standard-error-of-standard-deviation">Standard Error of Standard Deviation</h4>
<p>For the standard deviation itself (using delta method):</p>
<p><span class="math display">SE(s) \approx \frac{s}{\sqrt{2(n-1)}}</span></p>
<p>This is approximately half the coefficient of variation of the variance.</p>
</section>
</section>
<section id="margin-of-error-and-sample-size-for-covariance" class="level3">
<h3 class="anchored" data-anchor-id="margin-of-error-and-sample-size-for-covariance">Margin of Error and Sample Size for Covariance</h3>
<p>Covariance estimation is even more complex because it depends on the <strong>joint distribution</strong> of two variables.</p>
<section id="standard-error-of-covariance" class="level4">
<h4 class="anchored" data-anchor-id="standard-error-of-covariance">Standard Error of Covariance</h4>
<p>For two variables X and Y from a bivariate normal distribution:</p>
<p><span class="math display">SE(Cov(X,Y)) \approx \sqrt{\frac{1}{n}\left[\sigma_X^2\sigma_Y^2 + \sigma_{XY}^2\right]}</span></p>
<p>Where:</p>
<ul>
<li><span class="math inline">\sigma_X^2</span>, <span class="math inline">\sigma_Y^2</span> are the population variances</li>
<li><span class="math inline">\sigma_{XY}</span> is the population covariance</li>
</ul>
<p>In practice, these are estimated from the sample.</p>
<p><strong>Example: Covariance of Height and Weight</strong></p>
<p>Suppose:</p>
<ul>
<li><span class="math inline">s_X = 10</span> cm (height SD)</li>
<li><span class="math inline">s_Y = 15</span> kg (weight SD)<br>
</li>
<li><span class="math inline">s_{XY} = 80</span> cm·kg (sample covariance)</li>
<li><span class="math inline">n = 100</span></li>
</ul>
<p><span class="math display">SE(s_{XY}) \approx \sqrt{\frac{1}{100}[(10^2)(15^2) + 80^2]} = \sqrt{\frac{1}{100}[22,500 + 6,400]}</span></p>
<p><span class="math display">= \sqrt{289} = 17.0 \text{ cm·kg}</span></p>
<p><span class="math display">MoE = 1.96 \times 17.0 = ±33.3 \text{ cm·kg}</span></p>
</section>
<section id="standard-error-of-correlation" class="level4">
<h4 class="anchored" data-anchor-id="standard-error-of-correlation">Standard Error of Correlation</h4>
<p>For the correlation coefficient <span class="math inline">r</span> (Pearson’s), when the true correlation <span class="math inline">\rho</span> is not zero:</p>
<p><span class="math display">SE(r) \approx \frac{(1-r^2)}{\sqrt{n}}</span></p>
<p>For <span class="math inline">r = 0.5</span> and <span class="math inline">n = 100</span>:</p>
<p><span class="math display">SE(r) = \frac{1-0.25}{\sqrt{100}} = \frac{0.75}{10} = 0.075</span></p>
<p><span class="math display">MoE = 1.96 \times 0.075 = ±0.147</span></p>
<p><strong>Important notes for variance/covariance:</strong></p>
<ol type="1">
<li><strong>Non-normal sampling distributions</strong>: These statistics don’t follow normal distributions, especially for small samples</li>
<li><strong>Fisher’s z-transformation</strong>: For correlation, CIs are typically computed using Fisher’s z-transform for better coverage</li>
<li><strong>Bootstrap methods recommended</strong>: For complex scenarios, bootstrap confidence intervals often perform better</li>
<li><strong>Larger samples required</strong>: Variance and covariance require substantially larger samples than means for equivalent precision</li>
</ol>
</section>
</section>
<section id="comparative-example-sample-size-requirements" class="level3">
<h3 class="anchored" data-anchor-id="comparative-example-sample-size-requirements">Comparative Example: Sample Size Requirements</h3>
<p>To achieve 10% relative precision (MoE = 10% of the estimate):</p>
<p><strong>For a Mean:</strong></p>
<ul>
<li>Need: <span class="math inline">n = \left(\frac{1.96 \times CV}{0.10}\right)^2</span> where <span class="math inline">CV = SD/\mu</span></li>
<li>If <span class="math inline">CV = 0.5</span>: <span class="math inline">n = 96</span></li>
</ul>
<p><strong>For a Proportion at p = 0.5:</strong></p>
<ul>
<li>Need: <span class="math inline">n = \left(\frac{1.96 \times 0.5}{0.05}\right)^2 = 384</span></li>
<li>(Here 10% relative = ±0.05 absolute on 0-1 scale)</li>
</ul>
<p><strong>For a Variance:</strong></p>
<ul>
<li>Need: <span class="math inline">n \approx 1 + 2\left(\frac{1.96}{0.10}\right)^2 = 769</span></li>
</ul>
<p>Variance requires approximately 8× the sample size of a mean for equivalent relative precision!</p>
</section>
<section id="key-takeaways-3" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaways-3">Key Takeaways</h3>
<p><strong>For Means (including proportions):</strong></p>
<ul>
<li><strong>Proportions ARE means</strong> - just means of 0/1 data</li>
<li>Standard errors decrease as <span class="math inline">1/\sqrt{n}</span></li>
<li>Normal approximation works well for moderate samples</li>
<li>Symmetric confidence intervals appropriate</li>
</ul>
<p><strong>For Variance and Covariance:</strong></p>
<ul>
<li>Standard errors decrease as <span class="math inline">1/\sqrt{n}</span> but with larger constants</li>
<li>Sampling distributions are skewed (chi-squared for variance)</li>
<li>Require substantially larger samples for equivalent precision</li>
<li>Asymmetric confidence intervals often needed</li>
<li>Bootstrap or exact methods recommended over simple ±1.96 approach</li>
</ul>
<p><strong>Why proportions seem to need larger samples:</strong></p>
<ol type="1">
<li>The <strong>scale</strong> of measurement (0-1 vs.&nbsp;unbounded)</li>
<li>The <strong>relative precision</strong> desired (±3% is stringent on 0-1 scale)</li>
<li>The <strong>maximum SD</strong> for proportions (0.5) being large relative to range</li>
<li><strong>Contextual standards</strong> in polling and surveys</li>
</ol>
<p>When comparing equivalent relative precision, sample size requirements for means and proportions are comparable!</p>
<hr>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./index.html" class="pagination-link" aria-label="Preface">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Preface</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./rozdzial1.html" class="pagination-link" aria-label="Podstawy Statystyki i Demografii">
        <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Podstawy Statystyki i Demografii</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>