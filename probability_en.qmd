# Introduction to (Discrete) Probability


## Fundamental Concepts

Before we dive into probability theory, let's establish some foundational concepts that we'll use throughout this course:


### Basic Set Concepts

Before we can understand probability, we need to grasp some fundamental concepts from set theory. A set is simply a collection of distinct objects. 

A set can be defined by:

-   Listing all elements: $A = \{1, 2, 3\}$

-   Describing a property: $B = \{\text{x | x is a positive integer less than 4}\}$

The empty set $\emptyset$ contains no elements.


### Set Operations

Given two sets $A$ and $B$:

1.  Union ($A \cup B$): Elements in either A OR B (or both)

2.  Intersection ($A \cap B$): Elements in BOTH A AND B

3.  Complement ($A^c$): Elements NOT in A

4.  Difference ($A \setminus B$): Elements in A but NOT in B


These operations follow important laws like:

$$(A \cup B)^c = A^c \cap B^c$$ (DeMorgan's Law)

$$(A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$$ (Distributive Law)


### Random Experiments and Outcomes

A random experiment is any procedure that meets these criteria:

1.  It can be repeated under identical conditions
2.  All possible results can be described in advance
3.  The specific result cannot be predicted with certainty

For example, rolling a die is a random experiment because:

-   We can roll the die many times under the same conditions
-   We know all possible results (1 through 6) before rolling
-   We cannot predict exactly which number will appear on any given roll

An outcome is a single possible result of a random experiment. When we roll a die, getting a 3 is an outcome. When we flip a coin, getting heads is an outcome. Each outcome represents the finest level of detail we care about in our experiment.


### Sample Space

The sample space, typically denoted by Ω or S, is the collection of all possible outcomes of a random experiment. For example:

-   For a coin flip: S = {heads, tails}
-   For a die roll: S = {1, 2, 3, 4, 5, 6}
-   For drawing a card: S = {ace of hearts, two of hearts, ..., king of spades}

The sample space should be:

1.  Exhaustive (includes all possible outcomes)
2.  Mutually exclusive (outcomes cannot overlap)


### Events

An event is a set of outcomes that we're interested in. While an outcome is a single result, an event can contain multiple outcomes. For instance:

-   When rolling a die, "getting an even number" is an event containing the outcomes {2, 4, 6}
-   When drawing a card, "getting a heart" is an event containing thirteen outcomes
-   When flipping two coins, "getting at least one head" is an event containing three outcomes {HH, HT, TH}


Events are subsets of the sample space, and we can perform set operations on them. Let's understand these operations both conceptually and through their connection to probability calculations:

Union ($A \cup B$) represents combining events - it gives us all outcomes that occur in either $A$ OR $B$ (or both). Think of it like combining two groups of students: if we have a group of math club members and a group of chess club members, their union includes everyone who's in either club (being careful not to count students in both clubs twice). When using tree diagrams, if we want the probability of getting either outcome A OR outcome B, we add the probabilities of the different paths that lead to these outcomes.

Intersection ($A \cap B$) finds shared outcomes - it gives us outcomes that occur in both $A$ AND $B$ simultaneously. Using our club analogy, the intersection would be students who are members of both the math club AND chess club. In tree diagrams, when we follow a path where both events A AND B occur, we multiply the probabilities along that path. This multiplication makes sense because each branch represents taking a portion of the previous outcomes - like taking half of a half to get a quarter.

Complement ($A^c$ or $A'$) gives us everything that's NOT in $A$. If $A$ represents math club members, $A^c$ would be all students who are not in the math club. In probability terms, if we know the probability of A, we can find the probability of "not A" by subtracting from 1.

Let's see these concepts in action:

1. With a single die roll:
   - Event $A$: "rolling an even number" = $\{2, 4, 6\}$
   - Event $B$: "rolling a number greater than 4" = $\{5, 6\}$
   - $A \cup B = \{2, 4, 5, 6\}$ (all numbers that are either even OR greater than 4)
   - $A \cap B = \{6\}$ (the only number that is both even AND greater than 4)
   - $A^c = \{1, 3, 5\}$ (all numbers that aren't even)

2. With two coin flips:
   - To find P(getting at least one heads), we ADD the probabilities of all paths leading to HT, TH, or HH
   - To find P(getting two heads), we MULTIPLY along the HH path: $\frac{1}{2} \times \frac{1}{2} = \frac{1}{4}$, because:
     * First H takes half of all possible outcomes
     * Second H takes half of those first-H outcomes
     * Just like taking half of a half gives you a quarter

The key is understanding that in tree diagrams:
- We MULTIPLY along a path because each branch takes a portion of the previous outcomes
- We ADD different paths because they represent different ways to achieve our desired outcome


```{mermaid}
graph LR
    Start[Start] --> H1[H]
    Start --> T1[T]
    H1 --> H2[H]
    H1 --> T2[T]
    T1 --> H3[H]
    T1 --> T3[T]
    
    H2 --> HH([HH: 1/4])
    T2 --> HT([HT: 1/4])
    H3 --> TH([TH: 1/4])
    T3 --> TT([TT: 1/4])
    
    linkStyle 0,2,3 stroke:#1e88e5,stroke-width:2px
    linkStyle 4,5 stroke:#ff5252,stroke-width:2px
    linkStyle 1 stroke:#ff5252,stroke-width:2px
    
    style Start fill:#f5f5f5,stroke:#333,stroke-width:2px
    style H1 fill:#bbdefb,stroke:#1e88e5,stroke-width:2px
    style T1 fill:#ffcdd2,stroke:#ff5252,stroke-width:2px
    style H2 fill:#bbdefb,stroke:#1e88e5,stroke-width:2px
    style T2 fill:#ffcdd2,stroke:#ff5252,stroke-width:2px
    style H3 fill:#bbdefb,stroke:#1e88e5,stroke-width:2px
    style T3 fill:#ffcdd2,stroke:#ff5252,stroke-width:2px
    
    style HH fill:#e3f2fd,stroke:#1e88e5,stroke-width:2px
    style HT fill:#e3f2fd,stroke:#1e88e5,stroke-width:2px
    style TH fill:#e3f2fd,stroke:#1e88e5,stroke-width:2px
    style TT fill:#ffebee,stroke:#ff5252,stroke-width:2px
```

This diagram shows:
- Blue paths and nodes represent Heads (H)
- Red paths and nodes represent Tails (T)
- Each branch splits the previous outcomes in half (probability 1/2)
- Final outcomes (HH, HT, TH, TT) each have probability 1/4
- To find P(at least one H), we add HH + HT + TH = 3/4
- To find P(two H), we multiply along the HH path: 1/2 × 1/2 = 1/4



## Why Focus on Discrete Probability?

When we say a probability problem is "discrete," we mean we're dealing with situations where:

1.  We can count the number of possible outcomes

2.  Each outcome is separate and distinct from others

3.  We can list all possible outcomes in our sample space

For example, when we:

-   Draw balls from an urn

-   Flip coins or roll dice

-   Count successes in a sequence of trials

-   Select items from a group

This approach is particularly valuable because:

1.  It allows us to build strong intuition about probability without requiring calculus

2.  It directly connects to many real-world applications in statistics

3.  It provides the foundation for understanding the binomial distribution, which we'll use later for hypothesis testing

## Key Questions Before Calculating Probabilities

Before we can correctly calculate probabilities in any discrete scenario, we must answer two fundamental questions:


### 1. Does Order Matter?

The importance of order fundamentally changes how we count outcomes. Consider selecting two cards from a deck:

-   If we're playing poker, order doesn't matter - getting an ace and then a king is the same hand as getting a king and then an ace.
-   If we're performing a magic trick where we need specific cards in sequence, order matters - getting an ace then a king is different from getting a king then an ace.

When order matters, we're dealing with permutations. When order doesn't matter, we're dealing with combinations. This distinction dramatically affects the number of possible outcomes and, consequently, our probability calculations.

### 2. Is Sampling With or Without Replacement?

After selecting an item, do we put it back before the next selection? This question fundamentally changes the probability structure:

-   With replacement: Each selection has the same probability distribution as the first selection. Drawing a red ball and replacing it means the probability of drawing red on the next try remains unchanged.
-   Without replacement: Each selection changes the probability distribution for subsequent selections. Drawing a red ball and not replacing it means there are fewer red balls available for the next draw.

These sampling schemes lead to different probability models:

-   With replacement leads to independent events and often simpler calculations
-   Without replacement leads to dependent events and requires conditional probability

Understanding these two questions helps us:

1.  Choose the correct counting method (permutations vs combinations)
2.  Determine whether we can treat events as independent
3.  Decide whether we need to use conditional probability

## Set Theory and Power Sets (Event Space)

The power set of a set, denoted as $\mathcal{F}(S)$ or $2^S$, is the set of all possible subsets of S, including the empty set and S itself. This concept is crucial in probability theory because it helps us understand the relationship between the sample space (all possible outcomes) and the event space (all possible events we might want to consider).

Let's explore this with a simple example. Consider flipping a single coin where: $S = \{H, T\}$ (our sample space)

The power set would be:

$\mathcal{F}(S) = \{\emptyset, \{H\}, \{T\}, \{H,T\}\}$

Each element in the power set represents a possible event. For instance:

-   $\emptyset$: The impossible event (e.g., the coin landing neither heads nor tails)
-   $\{H\}$: The event of getting heads
-   $\{T\}$: The event of getting tails
-   $\{H,T\}$: The certain event (the coin must land either heads or tails)

For a set with $n$ elements, its power set will have $2^n$ elements. This is because for each element, we have two choices: include it or not include it in a subset.

### Understanding Outcomes vs Events

There's an important distinction between outcomes (also called simple events) and events:

1.  An outcome or simple event is a single, indivisible result of an experiment. For example, getting heads on a single coin flip is an outcome.

2.  An event is a set of outcomes - it can contain one outcome, multiple outcomes, or even no outcomes (the empty set). For example, "getting at least one head when flipping two coins" is an event containing multiple outcomes.

Let's illustrate this with two coin flips where:

$S = \{HH, HT, TH, TT\}$ (our sample space)

The power set (all possible events) would contain $2^4 = 16$ events:

-   $\emptyset$ (impossible event)
-   Single outcomes: $\{HH\}$, $\{HT\}$, $\{TH\}$, $\{TT\}$
-   Pairs of outcomes: $\{HH,HT\}$, $\{HH,TH\}$, $\{HH,TT\}$, $\{HT,TH\}$, $\{HT,TT\}$, $\{TH,TT\}$
-   Triples: $\{HH,HT,TH\}$, $\{HH,HT,TT\}$, $\{HH,TH,TT\}$, $\{HT,TH,TT\}$
-   Complete sample space: $\{HH,HT,TH,TT\}$

### Understanding Set Relations: Elements vs Subsets

One of the most foundational distinctions in set theory – and one that often creates confusion for new students – is the difference between an element belonging to a set and one set being a subset of another. Let's explore this critical distinction through everyday analogies and probability examples.


#### The "Belongs To" Relationship ($\in$)

When we say an element belongs to a set (written as $x \in A$), we're describing membership of a single item in a collection. Think of a classroom: each individual student belongs to (is a member of) the class. They are elements of the set "class."

Consider a deck of cards and let $H$ be the set of all hearts:

$H = \{2♥, 3♥, 4♥, 5♥, 6♥, 7♥, 8♥, 9♥, 10♥, J♥, Q♥, K♥, A♥\}$

We can say:

-   $A♥ \in H$ (true, because the ace of hearts is one of the hearts)
-   $K♠ \notin H$ (false, because the king of spades is not a heart)
-   $\{A♥\} \notin H$ (false, this is a set containing the ace of hearts, not the card itself)

#### The "Is Contained In" Relationship ($\subseteq$)

A subset relationship (written as $A \subseteq B$) describes when one set is entirely contained within another set. Every element of the smaller set must appear in the larger set. Think of Russian nesting dolls – each smaller doll fits completely inside the larger ones.

Let's look at some sets of cards:

$H$ = all hearts $F$ = face cards of hearts = $\{J♥, Q♥, K♥\}$ $R$ = red cards

These sets demonstrate important subset relationships:

$F \subseteq H$ is true because every heart face card is also a heart. Similarly, $H \subseteq R$ is true because all hearts are red cards. An interesting case is $\{A♥\} \subseteq H$, which is true because the set containing just the ace of hearts is contained within the set of all hearts.

#### Why This Matters in Probability

This distinction becomes crucial when working with events in probability. Consider rolling a die. We can define our sample space and events:

$S = \{1, 2, 3, 4, 5, 6\}$ represents our sample space $E = \{2, 4, 6\}$ represents the event of rolling an even number $F = \{6\}$ represents the event of rolling a six

We use these relations differently in probability contexts: When discussing outcomes: $6 \in E$ tells us "6 is one of the possible even rolls" When discussing events: $F \subseteq E$ tells us "the event of rolling a six is contained within the event of rolling an even number"

Here's a helpful rule of thumb for working with probability: use $\in$ when checking if a specific outcome belongs to an event, and use $\subseteq$ when comparing one event to another event. This distinction helps us understand the structure of our probability space and apply probability rules correctly.

This becomes especially important in three key areas of probability theory. First, when defining events as collections of outcomes, we need to be clear about whether we're talking about individual outcomes or sets of outcomes. Second, when working with compound events through unions and intersections, understanding subset relationships helps us calculate probabilities correctly. Third, when applying probability rules to nested events, the subset relationship gives us important inequalities.

For example, if $A \subseteq B$, then $P(A) \leq P(B)$. This makes intuitive sense – the probability of a more specific event cannot exceed the probability of a more general event that contains it. Understanding the distinction between membership and subset relationships helps us see why this must be true.

### Classical (Naive) Probability

The classical or naive definition of probability provides a simple way to calculate probabilities when:

1.  The sample space is finite (we can count all possible outcomes)
2.  All outcomes are equally likely to occur (uniform probability measure)

Under these conditions, the probability of an event E is:

$P(E) = \frac{\text{number of favorable outcomes}}{\text{total number of possible outcomes}} = \frac{|E|}{|S|}$

This is why we often start teaching probability with examples like fair coins, fair dice, and well-shuffled decks of cards - they satisfy both conditions. However, it's important to understand that many real-world situations don't meet these criteria, which is why we need more sophisticated probability concepts.

For example, when flipping two coins:

-   P(getting exactly one head) = $\frac{|\{HT,TH\}|}{|\{HH,HT,TH,TT\}|} = \frac{2}{4} = 0.5$
-   P(getting at least one head) = $\frac{|\{HH,HT,TH\}|}{|\{HH,HT,TH,TT\}|} = \frac{3}{4} = 0.75$

This classical definition, while simple, serves as a foundation for understanding more complex probability concepts. Let's now explore these ideas further with set operations.


## Sample Space and Events

The sample space ($\Omega$) contains all possible outcomes of an experiment. An event is a subset of the sample space. Let's understand this through concrete examples.

### Example: Single Ball Draw

Consider an urn with 3 green and 2 red balls. For drawing one ball:

-   Sample space: $\Omega = \{G_1, G_2, G_3, R_1, R_2\}$

-   Event "draw green": $A = \{G_1, G_2, G_3\}$

-   Event "draw red": $B = \{R_1, R_2\}$

Note that $A \cup B = \Omega$ and $A \cap B = \emptyset$ (these events are mutually exclusive and exhaustive).

## Probability Measure Function

A probability measure $P$ assigns numbers to events following these axioms:

1.  $P(A) \geq 0$ for any event $A$ (non-negativity)

2.  $P(\Omega) = 1$ (normalization)

3.  For disjoint events: $P(A \cup B) = P(A) + P(B)$ (additivity)

### Understanding Through the Urn Example

In our urn with 3 green and 2 red balls:

-   $P(\text{green}) = \frac{3}{5}$

-   $P(\text{red}) = \frac{2}{5}$

-   $P(\text{green}) + P(\text{red}) = 1$


## Sequential Events and Tree Diagrams

Tree diagrams are powerful tools for visualizing sequential events. Each branch represents a possible outcome, and probabilities multiply along paths. Let's explore this through detailed examples.

### Example 1: Drawing Two Balls Without Replacement

Consider drawing two balls from an urn containing 3 green and 2 red balls. Let's analyze all scenarios systematically.

```{mermaid}
graph TD
    A[Start] --> B[First: Green 3/5]
    A --> C[First: Red 2/5]
    B --> D[Second: Green 2/4]
    B --> E[Second: Red 2/4]
    C --> F[Second: Green 3/4]
    C --> G[Second: Red 1/4]
```

Let's solve for different scenarios:

1.  First red, then green (order matters):

    $P(R \text{ then } G) = \frac{2}{5} \cdot \frac{3}{4} = \frac{6}{20} = 0.3$

2.  Different colors (order doesn't matter):

    $P(\text{different colors}) = P(R \text{ then } G) + P(G \text{ then } R)$

    $= \frac{2}{5} \cdot \frac{3}{4} + \frac{3}{5} \cdot \frac{2}{4} = \frac{6}{20} + \frac{6}{20} = \frac{12}{20} = 0.6$

### Example 2: Drawing With Replacement

When we replace the first ball before drawing the second, the probabilities for the second draw remain unchanged:

```{mermaid}
graph TD
    A[Start] --> B[First: Green 3/5]
    A --> C[First: Red 2/5]
    B --> D[Second: Green 3/5]
    B --> E[Second: Red 2/5]
    C --> F[Second: Green 3/5]
    C --> G[Second: Red 2/5]
```

Now:

1.  First red, then green:

    $P(R \text{ then } G) = \frac{2}{5} \cdot \frac{3}{5} = \frac{6}{25} = 0.24$

2.  Different colors:

    $P(\text{different colors}) = \frac{2}{5} \cdot \frac{3}{5} + \frac{3}{5} \cdot \frac{2}{5} = \frac{12}{25} = 0.48$

## The Four Types of Counting Problems

When we count possibilities in probability problems, we need to think about two important questions:

1.  Does the order of our selections matter? (Like picking a phone PIN where 1234 is different from 4321)
2.  Can we reuse items we've already selected? (Like picking letters where we can reuse them, versus picking students where we can't pick the same person twice)

Let's explore each type of counting using a simple example: We have an urn with 5 colored balls (Red, Blue, Green, Yellow, and Purple), and we'll make 2 draws. For each scenario, we'll think about what makes sense in real life and how to count correctly.

### 1. Order Matters, With Replacement

Think about picking a two-digit code where you can use any digit twice. This is similar to drawing a ball, writing down its color, putting it back, and drawing again.

For the first draw:

-   We can choose any of the 5 balls
-   After putting it back, we again have all 5 balls for our second draw
-   So for each first choice, we have 5 second choices

Let's count systematically:

-   If we pick Red first: we can then pick R,B,G,Y,or P (5 possibilities)
-   If we pick Blue first: we can then pick R,B,G,Y,or P (5 possibilities)
-   And so on for Green, Yellow, and Purple

Total outcomes: $5 \times 5 = 5^2 = 25$ possibilities The formula is $n^r$ where:

-   $n$ is how many options we have (5 balls)
-   $r$ is how many selections we make (2 draws)

### 2. Order Matters, Without Replacement

Now imagine picking two students to do tasks in order - the first student will present today, the second tomorrow. We can't pick the same student twice!

For our balls:

-   First draw: we can choose any of the 5 balls
-   Second draw: we only have 4 balls left
-   If we pick Red first: we can then pick B,G,Y,or P (4 possibilities)
-   If we pick Blue first: we can then pick R,G,Y,or P (4 possibilities)
-   And so on...

Total outcomes: $5 \times 4 = 20$ possibilities The formula is $P(n,r) = \frac{n!}{(n-r)!}$

### 3. Order Doesn't Matter, With Replacement

Imagine picking your two favorite colors - you can pick the same color twice, and it doesn't matter which you say first.

This is tricky! Here's why:

-   If we pick Red and then Blue, this is the same as picking Blue and then Red
-   But picking Red twice is still just one outcome

We need to be careful not to count the same outcome twice. The formula $\binom{n+r-1}{r}$ helps us avoid this overcounting.

In our example:

-   Total outcomes: $\binom{5+2-1}{2} = \binom{6}{2} = 15$ possibilities
-   This correctly counts (Red,Blue) and (Blue,Red) as one outcome

### 4. Order Doesn't Matter, Without Replacement

Think about picking two students to be on a team - it doesn't matter who you pick first, and you can't pick the same person twice.

For our balls:

-   We're just picking 2 balls out of 5
-   (Red,Blue) and (Blue,Red) count as the same outcome
-   The formula $\binom{n}{r} = \frac{n!}{r!(n-r)!}$ gives us the right count
-   Total outcomes: $\binom{5}{2} = 10$ possibilities

## Example: The 4 Red and 3 Black Balls Problem

Let's solve a real problem using what we learned. We have:

-   4 red balls (let's call them R₁, R₂, R₃, R₄)
-   3 black balls (B₁, B₂, B₃)
-   We'll draw 2 balls without replacement
-   Order doesn't matter (like picking team members)

We want to find three probabilities:

1.  Getting two red balls
2.  Getting two black balls
3.  Getting one of each color

### Method 1: Using Counting Rules

First, let's count the total possible outcomes:

-   We're picking 2 balls from 7 total balls, order doesn't matter
-   Total outcomes = $\binom{7}{2} = \frac{7!}{2!(7-2)!} = \frac{7 \times 6}{2 \times 1} = 21$

Now let's find each probability:

#### 1. Two Red Balls

-   We need to pick 2 red balls from 4 red balls
-   This is like picking 2 team members from 4 people
-   Number of ways = $\binom{4}{2} = \frac{4 \times 3}{2 \times 1} = 6$
-   Probability = $\frac{6}{21}$

#### 2. Two Black Balls

-   Similarly, we need to pick 2 black balls from 3 black balls
-   Number of ways = $\binom{3}{2} = \frac{3 \times 2}{2 \times 1} = 3$
-   Probability = $\frac{3}{21}$

#### 3. One Red and One Black

-   We need:
    -   One red ball (we have 4 to choose from)
    -   One black ball (we have 3 to choose from)
-   Number of ways = $4 \times 3 = 12$
-   Probability = $\frac{12}{21}$

Let's verify our work:

-   All probabilities should add to 1
-   $\frac{6}{21} + \frac{3}{21} + \frac{12}{21} = \frac{21}{21} = 1$ ✓

This matches what we expect - every time we draw two balls, we must get either:

-   Two red balls
-   Two black balls
-   One of each color

Understanding how to count correctly helps us solve these probability problems systematically and avoid common mistakes like counting the same outcome multiple times.

### Method 2: Tree Diagram Approach

The tree diagram helps us visualize the sequential nature of the draws:

```{mermaid}
graph TD
    A[Start] --> B[First: Red 4/7]
    A --> C[First: Black 3/7]
    B --> D[Second: Red 3/6]
    B --> E[Second: Black 3/6]
    C --> F[Second: Red 4/6]
    C --> G[Second: Black 2/6]
```

Using the tree diagram:

1.  P(both red) = $\frac{4}{7} \cdot \frac{3}{6} = \frac{12}{42} = \frac{6}{21}$

2.  P(red then black) = $\frac{4}{7} \cdot \frac{3}{6} = \frac{12}{42}$

3.  P(multi-colored) = P(red then black) + P(black then red)

    = $\frac{4}{7} \cdot \frac{3}{6} + \frac{3}{7} \cdot \frac{4}{6} = \frac{24}{42}$

### Method 3: Grid Diagram and Sample Space

Let's visualize the entire sample space using a grid where each cell represents selecting two balls in order:

| First Draw →  | R₁  | R₂  | R₃  | R₄  | B₁  | B₂  | B₃  |
|---------------|-----|-----|-----|-----|-----|-----|-----|
| Second Draw ↓ |     |     |     |     |     |     |     |
| R₁            | X   | ⚫  | ⚫  | ⚫  | ⚪  | ⚪  | ⚪  |
| R₂            | ⚫  | X   | ⚫  | ⚫  | ⚪  | ⚪  | ⚪  |
| R₃            | ⚫  | ⚫  | X   | ⚫  | ⚪  | ⚪  | ⚪  |
| R₄            | ⚫  | ⚫  | ⚫  | X   | ⚪  | ⚪  | ⚪  |
| B₁            | ⚪  | ⚪  | ⚪  | ⚪  | X   | ⚫  | ⚫  |
| B₂            | ⚪  | ⚪  | ⚪  | ⚪  | ⚫  | X   | ⚫  |
| B₃            | ⚪  | ⚪  | ⚪  | ⚪  | ⚫  | ⚫  | X   |

Where:

-   X: Impossible (same ball twice)

-   ⚫: Both red or both black

-   ⚪: Multi-colored outcome

From this grid:

1.  Both red = 12 outcomes (⚫ in upper-left quadrant)

2.  Red then black = 12 outcomes (⚪ in upper-right)

3.  Total possible outcomes = 42 (remove diagonal X's)

Therefore:

-   P(both red) = $\frac{12}{42} = \frac{6}{21}$

-   P(red then black) = $\frac{12}{42} = \frac{2}{7}$

-   P(multi-colored) = $\frac{24}{42} = \frac{4}{7}$

### Comparing the Methods

Each method highlights different aspects of the problem:

1.  Counting Rules:

    -   Most efficient for calculation

    -   Helps understand combinations and arrangements

    -   May obscure the actual outcomes

2.  Tree Diagram:

    -   Shows sequential nature of draws

    -   Makes conditional probability clear

    -   Visualizes how probabilities combine

    -   Good for checking intuition

3.  Grid Diagram:

    -   Shows entire sample space explicitly

    -   Makes it clear why diagonal is impossible

    -   Helps visualize groups of outcomes

    -   Demonstrates why we divide by total possibilities

    -   Shows symmetry in the problem

## Practice Problems

1.  An urn contains 5 white and 4 black balls. Three balls are drawn with replacement. Find the probability that:

    a)  All are white

    b)  Exactly two are white

    c)  At least two are white

2.  From a standard deck of 52 cards, two cards are drawn without replacement. Find the probability of:

    a)  Both being aces

    b)  Getting a pair (same rank)

    c)  Getting two cards of the same suit

## Key Takeaways

1.  The tree diagram method works because it:

    -   Visually represents the sample space

    -   Shows how probabilities combine multiplicatively for independent events

    -   Helps identify all possible outcomes systematically

2.  When solving probability problems:

    -   First identify if order matters

    -   Determine if sampling is with or without replacement

    -   Choose the appropriate counting method

    -   Calculate both favorable and total outcomes carefully

# Next Steps

This introduction prepares you for more advanced topics:

-   Conditional probability

-   Independence

-   Random variables

-   Probability distributions

Understanding these foundational concepts is crucial for grasping statistical inference and data analysis methods.

## Advanced Counting in Probability: A Student Guide

### Poker Hands: A Window into Complex Counting

Poker hands provide some of the most interesting examples for understanding counting in probability. They're perfect for learning because they combine multiple counting principles and help us understand common pitfalls. Let's explore these concepts step by step.

### Understanding Our Sample Space

Before we dive into specific hands, let's understand what we're working with. A poker hand consists of 5 cards drawn from a standard 52-card deck. Understanding the sample space is crucial because it forms the foundation of all our probability calculations.

The total number of possible poker hands represents how many different ways we can select 5 cards from 52 cards, where the order doesn't matter (getting ace-king-queen is the same hand as getting king-queen-ace), we can't reuse cards (we can't have the ace of spades twice in our hand), and we must take exactly 5 cards (not more, not less).

This means we're dealing with combinations. Let's calculate this step by step:

$\binom{52}{5} = \frac{52!}{5!(52-5)!} = \frac{52!}{5!(47)!} = \frac{52 \cdot 51 \cdot 50 \cdot 49 \cdot 48}{5 \cdot 4 \cdot 3 \cdot 2 \cdot 1} = 2,598,960$

This number, 2,598,960, will be our denominator for calculating the probability of any specific poker hand.

### Understanding Two Pairs: A Careful Counting Approach

Two pairs is one of the most interesting hands for understanding counting principles. To get two pairs, we need:

-   Two cards of one rank
-   Two cards of another rank
-   One card of a third rank (the kicker)

Let's build this hand step by step, being careful to understand each choice we make:

First, let's select our ranks. We might think we should just choose two ranks from 13 for our pairs using $\binom{13}{2}$, but this approach hides some important subtleties. Instead, let's think about the actual process of constructing the hand:

1.  We have 13 possible ranks for our first pair
2.  After choosing the first pair's rank, we have 12 ranks left for our second pair
3.  After choosing both pair ranks, we have 11 ranks left for our kicker

For each rank we've chosen, we need to select specific cards:

1.  For our first pair: we choose 2 cards from the 4 available cards of that rank: $\binom{4}{2} = 6$ ways
2.  For our second pair: again $\binom{4}{2} = 6$ ways
3.  For our kicker: we choose 1 card from 4: $\binom{4}{1} = 4$ ways

Now, here's where many students get confused: Does it matter which pair we count "first" and which we count "second"? The answer reveals a deep truth about counting in probability.

Let's use a concrete example. Suppose we want two pairs with Aces and Kings, and a Two as our kicker. We could:

1.  Choose Aces as our first pair, then Kings as our second pair
2.  Choose Kings as our first pair, then Aces as our second pair

These lead to the exact same hand type, but we need to count both paths to this hand because they represent different ways of constructing it. It's similar to how we can make a sandwich by putting either cheese slice on first - the order of construction matters for counting all possibilities, even though the final sandwich is the same.

This is why our final formula multiplies all these independent choices:

$13$ (first pair rank) × $12$ (second pair rank) × $11$ (kicker rank) × $\binom{4}{2}$ (first pair cards) × $\binom{4}{2}$ (second pair cards) × $\binom{4}{1}$ (kicker card)

Each term represents a separate decision we make in constructing the hand. While the order of these decisions doesn't affect the final hand we get, we need to account for all possible ways to arrive at each hand to get the correct total.

Let's calculate the total probability:

$P(\text{two pairs}) = \frac{13 \cdot 12 \cdot 11 \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2,598,960} = \frac{123,552}{2,598,960} \approx 0.0475$

This means about 4.75% of all possible poker hands are two pairs.

### Understanding Full House: A Different Counting Challenge

A full house gives us a perfect contrast to two pairs. While both hands involve multiple cards of the same rank, the counting process reveals important differences in how we approach probability problems.

In a full house, we need:

-   Three cards of one rank (called "three of a kind")
-   Two cards of another rank (a pair)

Let's think about why counting a full house is different from counting two pairs. With two pairs, we had to be careful about the order of selecting our pairs. With a full house, we have a natural order: we must choose our three of a kind first (because it's distinct from the pair), then choose our pair.

Let's count step by step:

1.  For the three of a kind:
    -   Choose the rank: 13 possible ranks
    -   Choose which three cards of that rank: $\binom{4}{3} = 4$ ways
2.  For the pair:
    -   Choose the rank: 12 remaining ranks
    -   Choose which two cards of that rank: $\binom{4}{2} = 6$ ways

Multiplying these together:

$13$ (three of a kind rank) × $\binom{4}{3}$ (specific three cards) × $12$ (pair rank) × $\binom{4}{2}$ (specific pair cards)

$= 13 \cdot 4 \cdot 12 \cdot 6 = 3,744$

Therefore:

$P(\text{full house}) = \frac{3,744}{2,598,960} \approx 0.0014$

About 0.14% of all poker hands are full houses, making them significantly rarer than two pairs (4.75%). This makes intuitive sense - it's harder to get three of the same rank plus a pair than to get two pairs plus a kicker.

### The Birthday Problem: A Beautiful Probability Surprise

The birthday problem provides a fascinating connection to our poker probability work, while teaching us something profound about the nature of counting. The classic question is: "How many people need to be in a room for there to be a 50% chance that at least two share a birthday?"

Most people guess around 183 (half of 365), but the actual answer is just 23 people! Let's understand why this connects to our previous counting work and why the answer is so surprising.

First, let's think about what makes this problem different from our poker calculations:

1.  In poker, we were looking for specific combinations (like two pairs)
2.  In the birthday problem, we're looking for any match at all

This is similar to the difference between asking: - "What's the probability of drawing the ace of spades and king of hearts specifically?" - "What's the probability of drawing any two cards of different ranks?"

The second question has many more ways to succeed.

Let's solve the birthday problem step by step:

1.  First, it's easier to calculate the probability of no matches
2.  Then we can subtract from 1 to get the probability of at least one match

For 23 people, we calculate no matches like this:

-   First person can have any birthday: $\frac{365}{365}$
-   Second person needs a different birthday: $\frac{364}{365}$
-   Third person needs a different birthday: $\frac{363}{365}$ And so on until person 23.

This gives us:

$P(\text{no matches}) = \frac{365}{365} \cdot \frac{364}{365} \cdot \frac{363}{365} \cdot ... \cdot \frac{343}{365}$

$= \frac{365!}{(365-23)! \cdot 365^{23}} \approx 0.492$

Therefore:

$P(\text{at least one match}) = 1 - 0.492 \approx 0.508$

This teaches us something profound about probability: when we're looking for any match among many possibilities (like in the birthday problem), we often get much higher probabilities than when we're looking for specific matches (like in poker hands).

### Lottery Mathematics: Putting It All Together

Let's apply everything we've learned to understand lottery probabilities. Consider a typical "6/49" lottery where players choose 6 numbers from 1-49. This gives us a perfect opportunity to apply our counting principles in a real-world context.

The fundamental question is: What's the probability of winning the jackpot (matching all 6 numbers)?

This is a combination problem because: - Order doesn't matter (matching 1-2-3-4-5-6 is the same as matching 6-5-4-3-2-1) - We can't use the same number twice - We need exactly 6 numbers

Therefore:

$P(\text{jackpot}) = \frac{1}{\binom{49}{6}} = \frac{1}{13,983,816}$

This tiny probability (about 0.0000000715) shows why lottery wins are so rare. But modern lotteries have multiple prize tiers, which gives us a chance to explore more interesting probability calculations.

Consider matching 5 numbers plus a bonus number. For this, we need to: 1. Match 5 of the 6 winning numbers: $\binom{6}{5}$ ways to choose which 5 2. Match 1 of the remaining 43 numbers with the bonus: $\binom{43}{1}$ ways

Therefore:

$P(\text{5 + bonus}) = \frac{\binom{6}{5} \cdot \binom{43}{1}}{\binom{49}{6}} = \frac{6 \cdot 43}{13,983,816} \approx 0.0000184$

This shows us how breaking down complex probability problems into simpler parts helps us solve them systematically.

### Alternative Approaches to Poker Hand Probabilities

Understanding different ways to calculate the same probability deepens our insight into counting principles. Let's explore several methods for finding the probabilities of two pairs and full house, seeing how each approach highlights different aspects of the problem.

#### Multiple Paths to Two Pairs Probability

Let's start with two pairs. We've seen one method, but there are several valid approaches:

Method 1: Sequential Selection (Our Original Approach) We build the hand step by step:

1.  Choose first pair's rank: 13 ways
2.  Choose second pair's rank: 12 ways
3.  Choose kicker's rank: 11 ways
4.  Choose specific cards for first pair: $\binom{4}{2}$ ways
5.  Choose specific cards for second pair: $\binom{4}{2}$ ways
6.  Choose specific card for kicker: $\binom{4}{1}$ ways

This gives us: $P(\text{two pairs}) = \frac{13 \cdot 12 \cdot 11 \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2,598,960}$

Method 2: Complementary Counting We can find two pairs probability by subtracting the probability of all other possible hands from 1. However, this is more complex than direct counting because we need to know the probabilities of all other poker hands. Still, it serves as a good verification:

$P(\text{two pairs}) = 1 - P(\text{high card}) - P(\text{one pair}) - P(\text{three of a kind}) - P(\text{straight}) - P(\text{flush}) - P(\text{full house}) - P(\text{four of a kind}) - P(\text{straight flush})$

Method 3: Using Permutations with Adjustment We can use permutations and then adjust for overcounting:

1.  Choose an ordered arrangement of two ranks for pairs: $P(13,2) = 13 \cdot 12$
2.  Choose kicker rank: 11 ways
3.  Choose specific cards for pairs and kicker: $\binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}$
4.  Divide by 2 to account for the fact that the order of pairs doesn't matter

This gives: $P(\text{two pairs}) = \frac{P(13,2) \cdot 11 \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2 \cdot 2,598,960}$

Method 4: Combination-Based Approach with Multiplication Principle We can separate rank selection from card selection:

1.  First, select three ranks: $\binom{13}{3}$ ways
2.  From these three ranks, designate two for pairs and one for kicker: $\binom{3}{2}$ ways
3.  For each pair rank, select two cards: $\binom{4}{2} \cdot \binom{4}{2}$ ways
4.  For the kicker rank, select one card: $\binom{4}{1}$ ways

This gives us: $P(\text{two pairs}) = \frac{\binom{13}{3} \cdot \binom{3}{2} \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2,598,960}$

#### Alternative Approaches to Full House Probability

The full house probability can also be calculated in several ways:

Method 1: Direct Sequential Selection (Our Original Approach) 1. Choose rank for three of a kind: 13 ways 2. Choose specific three cards: $\binom{4}{3}$ ways 3. Choose rank for pair: 12 ways 4. Choose specific two cards: $\binom{4}{2}$ ways

Leading to: $P(\text{full house}) = \frac{13 \cdot \binom{4}{3} \cdot 12 \cdot \binom{4}{2}}{2,598,960}$

Method 2: Using Combinations with Distribution We can think about it as: 1. Choose two ranks from 13: $\binom{13}{2}$ ways 2. Designate which rank gets three cards: 2 ways (since either rank could be the three of a kind) 3. Choose specific cards: $\binom{4}{3} \cdot \binom{4}{2}$ ways

This gives: $P(\text{full house}) = \frac{\binom{13}{2} \cdot 2 \cdot \binom{4}{3} \cdot \binom{4}{2}}{2,598,960}$

Method 3: Using the Multiplication Principle with Sets Think about constructing the hand as selecting two sets of cards:

1.  First set: three cards of the same rank from 13 ranks
    -   Choose rank: 13 ways
    -   Choose three cards: $\binom{4}{3}$ ways
2.  Second set: two cards of the same rank from 12 remaining ranks
    -   Choose rank: 12 ways
    -   Choose two cards: $\binom{4}{2}$ ways

This yields the same result: $P(\text{full house}) = \frac{13 \cdot \binom{4}{3} \cdot 12 \cdot \binom{4}{2}}{2,598,960}$

Each method illuminates different aspects of the counting process:

-   Sequential selection helps us understand the step-by-step construction of hands
-   Combination-based approaches highlight the underlying structure of the selections
-   Permutation-based methods with adjustment show how overcounting can be handled systematically

The fact that all these methods yield the same result serves as a powerful verification tool. When solving complex probability problems, being able to approach the solution in multiple ways not only confirms our answer but also deepens our understanding of the underlying counting principles.

## Advanced Counting in Probability: A Student Guide

### Poker Hands: A Window into Complex Counting

Poker hands provide some of the most interesting examples for understanding counting in probability. They're perfect for learning because they combine multiple counting principles and help us understand common pitfalls. Let's explore these concepts step by step.

### Understanding Our Sample Space

Before we dive into specific hands, let's understand what we're working with. A poker hand consists of 5 cards drawn from a standard 52-card deck. Understanding the sample space is crucial because it forms the foundation of all our probability calculations.

The total number of possible poker hands represents how many different ways we can select 5 cards from 52 cards, where the order doesn't matter (getting ace-king-queen is the same hand as getting king-queen-ace), we can't reuse cards (we can't have the ace of spades twice in our hand), and we must take exactly 5 cards (not more, not less).

This means we're dealing with combinations. Let's calculate this step by step:

$\binom{52}{5} = \frac{52!}{5!(52-5)!} = \frac{52!}{5!(47)!} = \frac{52 \cdot 51 \cdot 50 \cdot 49 \cdot 48}{5 \cdot 4 \cdot 3 \cdot 2 \cdot 1} = 2,598,960$

This number, 2,598,960, will be our denominator for calculating the probability of any specific poker hand.

### Understanding Two Pairs: A Careful Counting Approach

Two pairs is one of the most interesting hands for understanding counting principles. To get two pairs, we need:

-   Two cards of one rank
-   Two cards of another rank
-   One card of a third rank (the kicker)

Let's build this hand step by step, being careful to understand each choice we make:

First, let's select our ranks. We might think we should just choose two ranks from 13 for our pairs using $\binom{13}{2}$, but this approach hides some important subtleties. Instead, let's think about the actual process of constructing the hand:

1.  We have 13 possible ranks for our first pair
2.  After choosing the first pair's rank, we have 12 ranks left for our second pair
3.  After choosing both pair ranks, we have 11 ranks left for our kicker

For each rank we've chosen, we need to select specific cards:

1.  For our first pair: we choose 2 cards from the 4 available cards of that rank: $\binom{4}{2} = 6$ ways
2.  For our second pair: again $\binom{4}{2} = 6$ ways
3.  For our kicker: we choose 1 card from 4: $\binom{4}{1} = 4$ ways

Now, here's where many students get confused: Does it matter which pair we count "first" and which we count "second"? The answer reveals a deep truth about counting in probability.

Let's use a concrete example. Suppose we want two pairs with Aces and Kings, and a Two as our kicker. We could:

1.  Choose Aces as our first pair, then Kings as our second pair
2.  Choose Kings as our first pair, then Aces as our second pair

These lead to the exact same hand type, but we need to count both paths to this hand because they represent different ways of constructing it. It's similar to how we can make a sandwich by putting either cheese slice on first - the order of construction matters for counting all possibilities, even though the final sandwich is the same.

This is why our final formula multiplies all these independent choices:

$13$ (first pair rank) × $12$ (second pair rank) × $11$ (kicker rank) × $\binom{4}{2}$ (first pair cards) × $\binom{4}{2}$ (second pair cards) × $\binom{4}{1}$ (kicker card)

Each term represents a separate decision we make in constructing the hand. While the order of these decisions doesn't affect the final hand we get, we need to account for all possible ways to arrive at each hand to get the correct total.

Let's calculate the total probability:

$P(\text{two pairs}) = \frac{13 \cdot 12 \cdot 11 \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2,598,960} = \frac{123,552}{2,598,960} \approx 0.0475$

This means about 4.75% of all possible poker hands are two pairs.

### Understanding Full House: A Different Counting Challenge

A full house gives us a perfect contrast to two pairs. While both hands involve multiple cards of the same rank, the counting process reveals important differences in how we approach probability problems.

In a full house, we need: - Three cards of one rank (called "three of a kind") - Two cards of another rank (a pair)

Let's think about why counting a full house is different from counting two pairs. With two pairs, we had to be careful about the order of selecting our pairs. With a full house, we have a natural order: we must choose our three of a kind first (because it's distinct from the pair), then choose our pair.

Let's count step by step:

1.  For the three of a kind:
    -   Choose the rank: 13 possible ranks
    -   Choose which three cards of that rank: $\binom{4}{3} = 4$ ways
2.  For the pair:
    -   Choose the rank: 12 remaining ranks
    -   Choose which two cards of that rank: $\binom{4}{2} = 6$ ways

Multiplying these together:

$13$ (three of a kind rank) × $\binom{4}{3}$ (specific three cards) × $12$ (pair rank) × $\binom{4}{2}$ (specific pair cards)

$= 13 \cdot 4 \cdot 12 \cdot 6 = 3,744$

Therefore:

$P(\text{full house}) = \frac{3,744}{2,598,960} \approx 0.0014$

About 0.14% of all poker hands are full houses, making them significantly rarer than two pairs (4.75%). This makes intuitive sense - it's harder to get three of the same rank plus a pair than to get two pairs plus a kicker.

### The Birthday Problem: A Beautiful Probability Surprise

The birthday problem provides a fascinating connection to our poker probability work, while teaching us something profound about the nature of counting. The classic question is: "How many people need to be in a room for there to be a 50% chance that at least two share a birthday?"

Most people guess around 183 (half of 365), but the actual answer is just 23 people! Let's understand why this connects to our previous counting work and why the answer is so surprising.

First, let's think about what makes this problem different from our poker calculations:

1.  In poker, we were looking for specific combinations (like two pairs)
2.  In the birthday problem, we're looking for any match at all

This is similar to the difference between asking: - "What's the probability of drawing the ace of spades and king of hearts specifically?" - "What's the probability of drawing any two cards of different ranks?"

The second question has many more ways to succeed.

Let's solve the birthday problem step by step:

1.  First, it's easier to calculate the probability of no matches
2.  Then we can subtract from 1 to get the probability of at least one match

For 23 people, we calculate no matches like this: - First person can have any birthday: $\frac{365}{365}$ - Second person needs a different birthday: $\frac{364}{365}$ - Third person needs a different birthday: $\frac{363}{365}$ And so on until person 23.

This gives us:

$P(\text{no matches}) = \frac{365}{365} \cdot \frac{364}{365} \cdot \frac{363}{365} \cdot ... \cdot \frac{343}{365}$

$= \frac{365!}{(365-23)! \cdot 365^{23}} \approx 0.492$

Therefore:

$P(\text{at least one match}) = 1 - 0.492 \approx 0.508$

This teaches us something profound about probability: when we're looking for any match among many possibilities (like in the birthday problem), we often get much higher probabilities than when we're looking for specific matches (like in poker hands).

### Lottery Mathematics: Putting It All Together

Let's apply everything we've learned to understand lottery probabilities. Consider a typical "6/49" lottery where players choose 6 numbers from 1-49. This gives us a perfect opportunity to apply our counting principles in a real-world context.

The fundamental question is: What's the probability of winning the jackpot (matching all 6 numbers)?

This is a combination problem because: - Order doesn't matter (matching 1-2-3-4-5-6 is the same as matching 6-5-4-3-2-1) - We can't use the same number twice - We need exactly 6 numbers

Therefore:

$P(\text{jackpot}) = \frac{1}{\binom{49}{6}} = \frac{1}{13,983,816}$

This tiny probability (about 0.0000000715) shows why lottery wins are so rare. But modern lotteries have multiple prize tiers, which gives us a chance to explore more interesting probability calculations.

Consider matching 5 numbers plus a bonus number. For this, we need to: 1. Match 5 of the 6 winning numbers: $\binom{6}{5}$ ways to choose which 5 2. Match 1 of the remaining 43 numbers with the bonus: $\binom{43}{1}$ ways

Therefore:

$P(\text{5 + bonus}) = \frac{\binom{6}{5} \cdot \binom{43}{1}}{\binom{49}{6}} = \frac{6 \cdot 43}{13,983,816} \approx 0.0000184$

This shows us how breaking down complex probability problems into simpler parts helps us solve them systematically.

### Alternative Approaches to Poker Hand Probabilities

Understanding different ways to calculate the same probability deepens our insight into counting principles. Let's explore several methods for finding the probabilities of two pairs and full house, seeing how each approach highlights different aspects of the problem.

#### Multiple Paths to Two Pairs Probability

Let's start with two pairs. We've seen one method, but there are several valid approaches:

Method 1: Sequential Selection (Our Original Approach) We build the hand step by step: 1. Choose first pair's rank: 13 ways 2. Choose second pair's rank: 12 ways 3. Choose kicker's rank: 11 ways 4. Choose specific cards for first pair: $\binom{4}{2}$ ways 5. Choose specific cards for second pair: $\binom{4}{2}$ ways 6. Choose specific card for kicker: $\binom{4}{1}$ ways

This gives us: $P(\text{two pairs}) = \frac{13 \cdot 12 \cdot 11 \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2,598,960}$

Method 2: Complementary Counting We can find two pairs probability by subtracting the probability of all other possible hands from 1. However, this is more complex than direct counting because we need to know the probabilities of all other poker hands. Still, it serves as a good verification:

$P(\text{two pairs}) = 1 - P(\text{high card}) - P(\text{one pair}) - P(\text{three of a kind}) - P(\text{straight}) - P(\text{flush}) - P(\text{full house}) - P(\text{four of a kind}) - P(\text{straight flush})$

Method 3: Using Permutations with Adjustment We can use permutations and then adjust for overcounting:

1.  Choose an ordered arrangement of two ranks for pairs: $P(13,2) = 13 \cdot 12$
2.  Choose kicker rank: 11 ways
3.  Choose specific cards for pairs and kicker: $\binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}$
4.  Divide by 2 to account for the fact that the order of pairs doesn't matter

This gives: $P(\text{two pairs}) = \frac{P(13,2) \cdot 11 \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2 \cdot 2,598,960}$

Method 4: Combination-Based Approach with Multiplication Principle We can separate rank selection from card selection:

1.  First, select three ranks: $\binom{13}{3}$ ways
2.  From these three ranks, designate two for pairs and one for kicker: $\binom{3}{2}$ ways
3.  For each pair rank, select two cards: $\binom{4}{2} \cdot \binom{4}{2}$ ways
4.  For the kicker rank, select one card: $\binom{4}{1}$ ways

This gives us: $P(\text{two pairs}) = \frac{\binom{13}{3} \cdot \binom{3}{2} \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2,598,960}$

#### Alternative Approaches to Full House Probability

The full house probability can also be calculated in several ways:

Method 1: Direct Sequential Selection (Our Original Approach) 1. Choose rank for three of a kind: 13 ways 2. Choose specific three cards: $\binom{4}{3}$ ways 3. Choose rank for pair: 12 ways 4. Choose specific two cards: $\binom{4}{2}$ ways

Leading to: $P(\text{full house}) = \frac{13 \cdot \binom{4}{3} \cdot 12 \cdot \binom{4}{2}}{2,598,960}$

Method 2: Using Combinations with Distribution We can think about it as: 1. Choose two ranks from 13: $\binom{13}{2}$ ways 2. Designate which rank gets three cards: 2 ways (since either rank could be the three of a kind) 3. Choose specific cards: $\binom{4}{3} \cdot \binom{4}{2}$ ways

This gives: $P(\text{full house}) = \frac{\binom{13}{2} \cdot 2 \cdot \binom{4}{3} \cdot \binom{4}{2}}{2,598,960}$

Method 3: Using the Multiplication Principle with Sets Think about constructing the hand as selecting two sets of cards: 1. First set: three cards of the same rank from 13 ranks - Choose rank: 13 ways - Choose three cards: $\binom{4}{3}$ ways 2. Second set: two cards of the same rank from 12 remaining ranks - Choose rank: 12 ways - Choose two cards: $\binom{4}{2}$ ways

This yields the same result: $P(\text{full house}) = \frac{13 \cdot \binom{4}{3} \cdot 12 \cdot \binom{4}{2}}{2,598,960}$

Each method illuminates different aspects of the counting process: - Sequential selection helps us understand the step-by-step construction of hands - Combination-based approaches highlight the underlying structure of the selections - Permutation-based methods with adjustment show how overcounting can be handled systematically

The fact that all these methods yield the same result serves as a powerful verification tool. When solving complex probability problems, being able to approach the solution in multiple ways not only confirms our answer but also deepens our understanding of the underlying counting principles.

### Occupancy Problems and Statistical Physics

Understanding how objects can be distributed into containers forms the foundation for both probability theory and statistical mechanics. Let's explore this connection, starting with basic counting principles and building up to physical applications.

#### The Basic Occupancy Problem

Imagine we have $n$ identical balls and $k$ distinct boxes. How many ways can we distribute the balls? This simple question leads us to three fundamentally different scenarios that mirror important physical systems:

1.  Unrestricted occupancy (Bose-Einstein statistics)
    -   Each box can hold any number of balls
    -   The balls are indistinguishable
    -   Like photons in quantum states
2.  Maximum one per box (Fermi-Dirac statistics)
    -   Each box can hold at most one ball
    -   The balls are indistinguishable
    -   Like electrons in atomic orbitals
3.  All arrangements count separately (Maxwell-Boltzmann statistics)
    -   Each box can hold any number of balls
    -   The balls are distinguishable
    -   Like classical gas molecules

#### Stars and Bars: Understanding Unrestricted Occupancy

Let's start with the Bose-Einstein case. The "stars and bars" method provides a beautiful way to visualize and count these arrangements.

Imagine $n=5$ balls and $k=3$ boxes. We can represent any arrangement as a sequence of stars and bars: - Stars (\*) represent balls - Bars (\|) separate different boxes

For example: - \*\* \| \*\* \| \* represents 2 balls in first box, 2 in second, 1 in third - \*\*\*\*\* \| \| represents all 5 balls in first box, none in others - \| \*\*\*\*\* \| represents all 5 balls in middle box

The key insight is that we need: - $n$ stars (one for each ball) - $k-1$ bars (to create $k$ sections)

Therefore, we're really just choosing positions for the $k-1$ bars among $n+(k-1)$ total positions. This gives us:

$\text{Number of arrangements} = \binom{n+k-1}{k-1} = \binom{n+k-1}{n}$

#### From Counting to Physics

Now let's see how these counting principles reveal deep physical truths:

1.  Bose-Einstein Statistics (Unrestricted, Indistinguishable)

    -   Think of photons in a laser
    -   Many particles can occupy same energy state
    -   Total arrangements: $\binom{n+k-1}{k-1}$
    -   Example: Light in a cavity

2.  Fermi-Dirac Statistics (Restricted, Indistinguishable)

    -   Think of electrons in atoms
    -   Maximum one particle per state
    -   Total arrangements: $\binom{k}{n}$ if $n \leq k$, 0 otherwise
    -   Example: Electron configuration in atoms

3.  Maxwell-Boltzmann Statistics (Classical, Distinguishable)

    -   Think of gas molecules
    -   Particles are distinct
    -   Total arrangements: $k^n$
    -   Example: Air molecules in a room

#### An Intuitive Bridge to Physics

To understand why these statistics matter, consider three real scenarios:

1.  Photons in a Laser (Bose-Einstein) Imagine shining a laser into a mirror cavity. Photons are happy to bunch together in the same quantum state - they're "social particles." This is why lasers can produce intense, coherent light.

2.  Electrons in an Atom (Fermi-Dirac) Electrons are "antisocial" - they refuse to share quantum states (Pauli exclusion principle). This explains atomic structure and why matter is mostly empty space.

3.  Gas Molecules in a Room (Maxwell-Boltzmann) Air molecules bounce around randomly, and we can tell them apart (in principle). This gives us the familiar gas laws and diffusion.

#### The Power of the Star and Bars Method

The stars and bars visualization helps us understand more complex problems. For instance, if we have restrictions on box occupancy:

1.  At least one ball per box:
    -   First put one ball in each box
    -   Then distribute remaining balls freely
    -   Formula: $\binom{n-k+k-1}{k-1} = \binom{n-1}{k-1}$
2.  Maximum capacity per box:
    -   Use inclusion-exclusion principle
    -   Subtract arrangements that violate constraints
    -   More complex but same underlying principle

#### Connection to Partition Problems

This same framework helps us solve other important problems:

1.  Integer Partitions How many ways can we write $n$ as a sum of positive integers?
    -   Like distributing $n$ balls into unlimited boxes
    -   Each box represents a different term in the sum
2.  Compositions How many ways can we write $n$ as an ordered sum?
    -   Like distinguishable boxes
    -   Order matters here

#### Physical Implications and Applications

Understanding these counting principles helps explain:

1.  Why metals conduct electricity
    -   Electrons follow Fermi-Dirac statistics
    -   Creates "bands" of allowed energies
2.  Why lasers work
    -   Photons' Bose-Einstein nature enables stimulated emission
    -   Many photons can occupy same state
3.  Why gases behave as they do
    -   Maxwell-Boltzmann statistics gives velocity distribution
    -   Explains gas pressure and temperature

This connection between simple counting and profound physical phenomena shows the deep unity of mathematics and physics. The same principles that help us count poker hands and lottery combinations govern the behavior of the universe at its most fundamental level.
