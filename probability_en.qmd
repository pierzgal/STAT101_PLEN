# Introduction to (Discrete) Probability

## What is Probability?

Imagine you're trying to decide whether to bring an umbrella to class tomorrow. You check the weather forecast, which says there's a 30% chance of rain. But what does this number really mean? This is where probability comes in - it's a mathematical way to measure how likely something is to happen.

Before we dive into probability theory, let's establish some foundational concepts that we'll use throughout this course.


### Basic Set Concepts

Before we can understand probability, we need to grasp some fundamental concepts from set theory. A set is simply a collection of distinct objects.

A set can be defined by:

-   Listing all elements: $A = \{1, 2, 3\}$
-   Describing a property: $B = \{\text{x | x is a positive integer less than 4}\}$

The empty set $\emptyset$ contains no elements.

### Set Operations

Given two sets $A$ and $B$:

1.  Union ($A \cup B$): Elements in either A OR B (or both)
2.  Intersection ($A \cap B$): Elements in BOTH A AND B
3.  Complement ($A^c$): Elements NOT in A
4.  Difference ($A \setminus B$): Elements in A but NOT in B

These operations follow important laws like:

$$(A \cup B)^c = A^c \cap B^c$$ (DeMorgan's Law)

$$(A \cup (B \cap C) = (A \cup B) \cap (A \cup C)$$ (Distributive Law)

### Set Theory as a Language for Probability

Set theory provides the fundamental mathematical framework for understanding and working with probability theory.

The following table illustrates the key parallels between set theory concepts and their probability theory counterparts.

| Set Theory | Probability Theory | Description |
|--------------------|------------------------------|----------------------|
| $\Omega$ (Universal set) | Sample space ($S$) | The set of all possible outcomes in the experiment |
| $x \in A$ (Element) | Outcome | A single result from the sample space |
| $A \subseteq \Omega$ (Subset) | Event | A collection of outcomes we're interested in |
| $\emptyset$ (Empty set) | Impossible event | An event that cannot occur ($P(\emptyset) = 0$) |
| $\Omega$ (Universal set) | Certain event | An event that must occur ($P(\Omega) = 1$) |
| $A \cup B$ (Union) | Either A OR B occurs | $P(A \cup B) = P(A) + P(B) - P(A \cap B)$ |
| $A \cap B$ (Intersection) | Both A AND B occur | $P(A \cap B) = P(A)P(B)$ (if independent) |
| $A'$ (Complement) | Event A does not occur | $P(A') = 1 - P(A)$ |
| $A \cap B = \emptyset$ (Disjoint sets) | Mutually exclusive events | $P(A \cap B) = 0$ |
| Partition of $\Omega$ | Complete set of events | $\sum P(A_i) = 1$ |
| $A - B$ (Set difference) | A occurs without B | $P(A - B) = P(A) - P(A \cap B)$ |
| De Morgan's Laws | Probability Laws | $P((A \cup B)') = P(A') \cap P(B')$ |

::: {.callout-note}
## Cardinality of Sets

In probability theory, we denote cardinality (the number of elements in a set) using vertical bars: |A|

Key points:

- |A| means "number of elements in set A"
- For a finite set like A = {1, 2, 3}, we have |A| = 3
- Empty set has cardinality zero: |∅| = 0
- For two sets A and B:

  - Union (no overlap): |A ∪ B| = |A| + |B|
  - Union (with overlap): |A ∪ B| = |A| + |B| - |A ∩ B|
  - Cartesian product: |A × B| = |A| × |B|

**Example**: 

If A = {♠, ♣, ♥, ♦} and B = {K, Q, J}, then:

- |A| = 4
- |B| = 3
- |A × B| = 12 (all possible combinations)
:::


## Counting Rules in Probability: Multiplication and Addition Rules

### The Multiplication Rule: "AND" Situations

When we need to count outcomes where we need to make multiple choices in sequence (one AND another AND another...), we multiply the number of possibilities for each choice.

### Simple Example: Creating a Password
Imagine creating a 3-character password where:

- First character must be a letter (26 choices)
- Second character must be a digit (10 choices)
- Third character must be a symbol (@, #, $, % only - 4 choices)

Using the multiplication rule:
$$\text{Total possible passwords} = 26 \times 10 \times 4 = 1,040$$

This works because for EACH first character, we have ALL 10 digits available, and for EACH of those combinations, we have ALL 4 symbols available.

### The Addition Rule: "OR" Situations

When we want to count outcomes that can happen in different ways (this OR that), we add the number of possibilities.

#### Simple Example: License Plates
Let's say a special license plate can either be:

- 3 letters followed by 3 digits, OR
- 3 digits followed by 3 letters

For the first type: $$26 \times 26 \times 26 \times 10 \times 10 \times 10$$
For the second type: $$10 \times 10 \times 10 \times 26 \times 26 \times 26$$

Total number of possible plates:
$$\text{Total} = \text{First type} + \text{Second type}$$

### The Addition Rule for Non-Mutually Exclusive Events

Sometimes events can overlap. When this happens, we need to subtract the overlap to avoid counting it twice.

For events A and B:
$$P(A \text{ or } B) = P(A) + P(B) - P(A \text{ and } B)$$

#### Real-World Example: Student Clubs
In a class of 100 students:

- 45 play sports
- 55 are in academic clubs
- 20 do both

To find how many students are in either sports OR academic clubs:
$$\text{Total in either} = 45 + 55 - 20 = 80 \text{ students}$$

We subtract 20 because otherwise those students would be counted twice!

```{mermaid}
flowchart TD
    Start[Problem: Count possible outcomes] --> Q1{"Are events independent\nand sequential?"}
    
    Q1 -->|Yes| M1[Use Multiplication Rule]
    Q1 -->|No| Q2{"Are events mutually\nexclusive?"}
    
    M1 --> ME1["Example:\nRolling two dice"]
    ME1 --> MC1["6 outcomes for first die\n× 6 outcomes for second die\n= 36 total outcomes"]
    
    Q2 -->|Yes| A1[Use Addition Rule]
    Q2 -->|No| A2["Use Addition Rule\nsubtract overlap"]
    
    A1 --> AE1["Example:\nDrawing red or black card"]
    AE1 --> AC1["26 red cards\n+ 26 black cards\n= 52 total cards"]
    
    A2 --> AE2["Example:\nStudents taking\nMath OR Physics"]
    AE2 --> AC2["30 Math students\n+ 25 Physics students\n- 8 taking both\n= 47 total students"]
    
    classDef start fill:#d4426e,stroke:#333,color:#fff
    classDef question fill:#2d5a8c,stroke:#333,color:#fff
    classDef rule fill:#156b45,stroke:#333,color:#fff
    classDef example fill:#4a4a4a,stroke:#333,color:#fff
    classDef calculation fill:#4a4a4a,stroke:#333,color:#fff
    
    class Start start
    class Q1,Q2 question
    class M1,A1,A2 rule
    class ME1,AE1,AE2 example
    class MC1,AC1,AC2 calculation
```

```{mermaid}
flowchart TD
    subgraph Multiplication_Rule[Multiplication Rule]
        M1["First Choice: 3 Options"] --> M2["Each leads to 2 Options"]
        M2 --> M3["Total: 3 × 2 = 6 Possibilities"]
        
        MA((A)) --> MA1((1))
        MA --> MA2((2))
        MB((B)) --> MB1((1))
        MB --> MB2((2))
        MC((C)) --> MC1((1))
        MC --> MC2((2))
    end
    
    subgraph Addition_Rules[Addition Rules]
        A1[Set A] --> AE["Simple Addition:\nNo Overlap"]
        A2[Set B] --> AE
        AE --> AE1["Total = A + B"]
        
        O1[Set X] --> OE["Addition with Overlap"]
        O2[Set Y] --> OE
        OE --> OE1["Total = X + Y - Overlap"]
    end
    
    classDef default fill:#f9f9f9,stroke:#333,color:#000
    classDef set fill:#2d5a8c,stroke:#333,color:#fff
    classDef result fill:#156b45,stroke:#333,color:#fff
    classDef option fill:#f5f5f5,stroke:#333,color:#333
    
    class A1,A2,O1,O2 set
    class AE1,OE1,M3 result
    class MA,MB,MC,MA1,MA2,MB1,MB2,MC1,MC2 option
```

#### The Inclusion-Exclusion Principle (*)

**Venn diagrams are useful to visualize the inclusion-exclusion principle**, which states that for two sets A and B, the number of elements in their union equals the sum of elements in each set, minus the elements they share in common (to avoid double counting).

For general sets, this can be written as:

$$
|A \cup B| = |A| + |B| - |A \cap B|
$$ For three sets A, B, and C, the formula becomes more complex:

$$
|A \cup B \cup C| = |A| + |B| + |C| - |A \cap B| - |B \cap C| - |A \cap C| + |A \cap B \cap C|
$$

![https://en.wikipedia.org/wiki/Inclusion%E2%80%93exclusion_principle](stat_imgs/Inclusion-exclusion.svg)

Let's work through a simple example to make this concrete:

Imagine we're counting students in a school who play either basketball (set A) or volleyball (set B). Let's say:

-   15 students play basketball (\|A\| = 15)
-   12 students play volleyball (\|B\| = 12)
-   5 students play both sports (\|A ∩ B\| = 5)

To find the total number of students who play either sport (\|A ∪ B\|), we calculate:

$$
|A \cup B| = |A| + |B| - |A \cap B| = 15 + 12 - 5 = 22
$$

The reason we subtract the intersection is that these 5 students who play both sports were counted twice (once in \|A\| and once in \|B\|), so we need to subtract once to avoid double counting.

This principle extends to probability theory, where for events A and B:

$$
P(A \cup B) = P(A) + P(B) - P(A \cap B)
$$


### Combining Both Rules: A Complex Example

Let's create a password system where:

- Password must be 4 characters long
- Must contain at least one symbol (@, #)
- All other characters can be letters

This requires combining both rules because:

1. We can have a symbol in position 1, 2, 3, or 4 (OR - Addition Rule)
2. For each position of the symbol, we need to fill the other spots (AND - Multiplication Rule)

Let's solve step by step:

1. Symbol in first position:
   $$2 \times 26 \times 26 \times 26$$

2. Symbol in second position:
   $$26 \times 2 \times 26 \times 26$$

3. Symbol in third position:
   $$26 \times 26 \times 2 \times 26$$

4. Symbol in fourth position:
   $$26 \times 26 \times 26 \times 2$$

Total possibilities:
$$\text{Total} = (2 \times 26^3) \times 4 = 140,608$$

This example shows how we:

1. Used multiplication within each case (filling positions)
2. Used addition to combine all possible positions
3. Simplified the final answer

Remember: These rules help us count possibilities systematically, breaking complex problems into manageable pieces!


### Random Experiments and Outcomes

A **random experiment** is any procedure that meets these criteria:

1.  It can be repeated under identical conditions
2.  All possible results can be described in advance
3.  The specific result cannot be predicted with certainty

For example, rolling a die is a random experiment because:

-   We can roll the die many times under the same conditions
-   We know all possible results (1 through 6) before rolling
-   We cannot predict exactly which number will appear on any given roll

An **outcome** is a single possible result of a random experiment. When we roll a die, getting a 3 is an outcome. When we flip a coin, getting heads is an outcome.

### Sample Space

The sample space, typically denoted by Ω or S, is the collection of all possible outcomes of a random experiment. For example:

-   For a coin flip: S = {heads, tails}
-   For a die roll: S = {1, 2, 3, 4, 5, 6}
-   For drawing a card: S = {ace of hearts, two of hearts, ..., king of spades}

The sample space should be:

1.  Exhaustive (includes all possible outcomes)
2.  Mutually exclusive (outcomes cannot overlap)

### Events

An **event** is a set of outcomes that we're interested in. While an outcome is a single result, an event can contain multiple outcomes. For instance:

-   When rolling a die, "getting an even number" is an event containing the outcomes {2, 4, 6}
-   When drawing a card, "getting a heart" is an event containing thirteen outcomes
-   When flipping two coins, "getting at least one head" is an event containing three outcomes {HH, HT, TH}

In probability theory, a **tree diagram** may be used to represent a sample space and help calculate probabilities. A tree diagram may represent a series of independent events (such as a set of coin flips) or conditional probabilities (such as drawing cards from a deck, without replacing the cards).

**Events are subsets of the sample space, and we can perform set operations on them**.


### Visualizing Sample Spaces

In probability theory and statistics, being able to visualize sample spaces is crucial for understanding possible outcomes and their relationships. We'll explore three main approaches to visualizing sample spaces:

1.  Venn Diagrams
2.  Tree Diagrams
3.  Grid/Matrix Diagrams

#### Venn Diagrams

Venn diagrams provide a powerful visual tool for understanding sample spaces.

-   A Venn diagram is a visual representation that shows relationships between different sets or groups using overlapping circles.
-   Think of each circle in a Venn diagram as a container that holds items with specific characteristics. Where these circles overlap, we find items that share characteristics of multiple groups.

In probability theory, our sample space (usually denoted by Ω or S) represents all possible outcomes of an experiment. When we draw a Venn diagram, the rectangular frame represents this entire sample space, with a probability of 1. Any event is then a subset of this space.

![](stat_imgs/venn-diagram.svg)


#### Tree Diagrams

Tree diagrams are particularly useful for visualizing sequential events and their outcomes. Here's a tree diagram showing a simple probability experiment: We toss a fair coin twice.

```{mermaid}
graph LR
    Start[Start] --> H1[H]
    Start --> T1[T]
    H1 --> H2[H]
    H1 --> T2[T]
    T1 --> H3[H]
    T1 --> T3[T]
    
    H2 --> HH([HH: 1/4])
    T2 --> HT([HT: 1/4])
    H3 --> TH([TH: 1/4])
    T3 --> TT([TT: 1/4])
    
    linkStyle 0,2,3 stroke:#1e88e5,stroke-width:2px
    linkStyle 4,5 stroke:#ff5252,stroke-width:2px
    linkStyle 1 stroke:#ff5252,stroke-width:2px
    
    style Start fill:#f5f5f5,stroke:#333,stroke-width:2px
    style H1 fill:#bbdefb,stroke:#1e88e5,stroke-width:2px
    style T1 fill:#ffcdd2,stroke:#ff5252,stroke-width:2px
    style H2 fill:#bbdefb,stroke:#1e88e5,stroke-width:2px
    style T2 fill:#ffcdd2,stroke:#ff5252,stroke-width:2px
    style H3 fill:#bbdefb,stroke:#1e88e5,stroke-width:2px
    style T3 fill:#ffcdd2,stroke:#ff5252,stroke-width:2px
    
    style HH fill:#f5f5f5,stroke:#333,stroke-width:2px
    style HT fill:#f5f5f5,stroke:#333,stroke-width:2px
    style TH fill:#f5f5f5,stroke:#333,stroke-width:2px
    style TT fill:#f5f5f5,stroke:#333,stroke-width:2px
```


#### Grid/Matrix Diagrams

Grid diagrams are excellent for showing combinations of events.

Scenario. We have 7 balls in the bag:

-   4 red balls (let's call them R₁, R₂, R₃, R₄)
-   3 black balls (B₁, B₂, B₃)
-   We'll draw 2 balls without replacement
-   Order doesn't matter (like picking team members)

Let's visualize the entire sample space using a grid where each cell represents selecting two balls in order:

| First Draw →  | R₁  | R₂  | R₃  | R₄  | B₁  | B₂  | B₃  |
|---------------|-----|-----|-----|-----|-----|-----|-----|
| Second Draw ↓ |     |     |     |     |     |     |     |
| R₁            | X   | ⚫  | ⚫  | ⚫  | ⚪  | ⚪  | ⚪  |
| R₂            | ⚫  | X   | ⚫  | ⚫  | ⚪  | ⚪  | ⚪  |
| R₃            | ⚫  | ⚫  | X   | ⚫  | ⚪  | ⚪  | ⚪  |
| R₄            | ⚫  | ⚫  | ⚫  | X   | ⚪  | ⚪  | ⚪  |
| B₁            | ⚪  | ⚪  | ⚪  | ⚪  | X   | ⚫  | ⚫  |
| B₂            | ⚪  | ⚪  | ⚪  | ⚪  | ⚫  | X   | ⚫  |
| B₃            | ⚪  | ⚪  | ⚪  | ⚪  | ⚫  | ⚫  | X   |

Where:

-   X: Impossible (same ball twice)
-   ⚫: Both red or both black
-   ⚪: Multi-colored outcome

From this grid:

1.  Both red = 12 outcomes (⚫ in upper-left quadrant)
2.  Red then black = 12 outcomes (⚪ in upper-right)
3.  Total possible outcomes = 42 (remove diagonal X's)


#### Tips for Choosing the Right Visualization

-   Use **Venn diagrams** when:
    -   Showing overlapping sets or events
    -   Illustrating unions and intersections
    -   Demonstrating mutual exclusivity
-   Use **Tree diagrams** when:
    -   Showing sequential events
    -   Illustrating conditional probability
    -   Displaying all possible pathways of outcomes
-   Use **Grid diagrams** when:
    -   Showing combinations of two independent events
    -   Displaying frequency distributions
    -   Illustrating joint probability distributions


### Basic Set Operations Using Venn Diagrams

![https://www.nagwa.com/en/explainers/758149689032/](stat_imgs/set_operations_1.svg)

-   **Union** ($A \cup B$) represents combining events - it gives us all outcomes that occur in either $A$ OR $B$ (or both).

Think of it like combining two groups of students: if we have a group of math club members and a group of chess club members, their union includes everyone who's in either club (being careful not to count students in both clubs twice). When using tree diagrams, if we want the probability of getting either outcome A OR outcome B, we add the probabilities of the different paths that lead to these outcomes.

-   **Intersection** ($A \cap B$) finds shared outcomes - it gives us outcomes that occur in both $A$ AND $B$ simultaneously.

Using our club analogy, the intersection would be students who are members of both the math club AND chess club. In tree diagrams, when we follow a path where both events A AND B occur, we multiply the probabilities along that path. This multiplication makes sense because each branch represents taking a portion of the previous outcomes - like taking half of a half to get a quarter.

-   **Complement** ($A^c$ or $A'$) gives us everything that's NOT in $A$. 

If $A$ represents math club members, $A^c$ would be all students who are not in the math club. In probability terms, if we know the probability of A, we can find the probability of "not A" by subtracting from 1.

Let's see these concepts in action:

1.  With a single die roll:

    -   Event $A$: "rolling an even number" = $\{2, 4, 6\}$
    -   Event $B$: "rolling a number greater than 4" = $\{5, 6\}$
    -   $A \cup B = \{2, 4, 5, 6\}$ (all numbers that are either even OR greater than 4)
    -   $A \cap B = \{6\}$ (the only number that is both even AND greater than 4)
    -   $A^c = \{1, 3, 5\}$ (all numbers that aren't even)

2.  With two coin flips:

    -   To find P(getting at least one heads), we **ADD** the probabilities of all paths leading to HT, TH, or HH
    -   To find P(getting two heads), we **MULTIPLY** along the HH path: $\frac{1}{2} \times \frac{1}{2} = \frac{1}{4}$, because:
        -   First H takes half of all possible outcomes
        -   Second H takes half of those first-H outcomes
        -   Just like taking half of a half gives you a quarter

In tree diagrams:

-   We **MULTIPLY** along a path because each branch takes a portion of the previous outcomes.
-   We **ADD** different paths because they represent different ways to achieve our desired outcome.

```{mermaid}
graph LR
    Start[Start] --> H1[H]
    Start --> T1[T]
    H1 --> H2[H]
    H1 --> T2[T]
    T1 --> H3[H]
    T1 --> T3[T]
    
    H2 --> HH([HH: 1/4])
    T2 --> HT([HT: 1/4])
    H3 --> TH([TH: 1/4])
    T3 --> TT([TT: 1/4])
    
    linkStyle 0,2,3 stroke:#1e88e5,stroke-width:2px
    linkStyle 4,5 stroke:#ff5252,stroke-width:2px
    linkStyle 1 stroke:#ff5252,stroke-width:2px
    
    style Start fill:#f5f5f5,stroke:#333,stroke-width:2px
    style H1 fill:#bbdefb,stroke:#1e88e5,stroke-width:2px
    style T1 fill:#ffcdd2,stroke:#ff5252,stroke-width:2px
    style H2 fill:#bbdefb,stroke:#1e88e5,stroke-width:2px
    style T2 fill:#ffcdd2,stroke:#ff5252,stroke-width:2px
    style H3 fill:#bbdefb,stroke:#1e88e5,stroke-width:2px
    style T3 fill:#ffcdd2,stroke:#ff5252,stroke-width:2px
    
    style HH fill:#f5f5f5,stroke:#333,stroke-width:2px
    style HT fill:#f5f5f5,stroke:#333,stroke-width:2px
    style TH fill:#f5f5f5,stroke:#333,stroke-width:2px
    style TT fill:#f5f5f5,stroke:#333,stroke-width:2px
```

This diagram shows:

-   Blue paths and nodes represent Heads (H)
-   Red paths and nodes represent Tails (T)
-   Each branch splits the previous outcomes in half (probability 1/2)
-   Final outcomes (HH, HT, TH, TT) each have probability 1/4
-   To find P(at least one H), we add HH + HT + TH = 3/4
-   To find P(two H), we multiply along the HH path: 1/2 × 1/2 = 1/4


## Set Theory and Power Sets (Event Space)

The power set of a set, denoted as $\mathcal{F}(S)$ or $2^S$, is the set of all possible subsets of S, including the empty set and S itself. This concept is crucial in probability theory because it helps us understand the relationship between the sample space (all possible outcomes) and the event space (all possible events we might want to consider).

Let's explore this with a simple example. Consider flipping a single coin where: $S = \{H, T\}$ (our sample space)

The power set would be:

$\mathcal{F}(S) = \{\emptyset, \{H\}, \{T\}, \{H,T\}\}$

Each element in the power set represents a possible event. For instance:

-   $\emptyset$: The impossible event (e.g., the coin landing neither heads nor tails)
-   $\{H\}$: The event of getting heads
-   $\{T\}$: The event of getting tails
-   $\{H,T\}$: The certain event (the coin must land either heads or tails)

For a set with $n$ elements, its power set will have $2^n$ elements. This is because for each element, we have two choices: include it or not include it in a subset.

### Understanding Outcomes vs Events

There's an important distinction between outcomes (also called simple events) and events:

1.  **An outcome or simple event is a single, indivisible result of an experiment**. For example, getting heads on a single coin flip is an outcome.

2.  **An event is a set of outcomes** - it can contain one outcome, multiple outcomes, or even no outcomes (the empty set). For example, "getting at least one head when flipping two coins" is an event containing multiple outcomes.

Let's illustrate this with two coin flips where:

$S = \{HH, HT, TH, TT\}$ (our sample space)

The power set (all possible events) would contain $2^4 = 16$ events:

-   $\emptyset$ (impossible event)
-   Single outcomes: $\{HH\}$, $\{HT\}$, $\{TH\}$, $\{TT\}$
-   Pairs of outcomes: $\{HH,HT\}$, $\{HH,TH\}$, $\{HH,TT\}$, $\{HT,TH\}$, $\{HT,TT\}$, $\{TH,TT\}$
-   Triples: $\{HH,HT,TH\}$, $\{HH,HT,TT\}$, $\{HH,TH,TT\}$, $\{HT,TH,TT\}$
-   Complete sample space: $\{HH,HT,TH,TT\}$

### Understanding Set Relations: Elements vs Subsets (*)

**The difference between an element belonging to a set and one set being a subset of another**.

#### The "Belongs To" Relationship ($\in$)

When we say an element belongs to a set (written as $x \in A$), we're describing membership of a single item in a collection. Think of a classroom: each individual student belongs to (is a member of) the class. They are elements of the set "class."

Consider a deck of cards and let $H$ be the set of all hearts:

$H = \{2♥, 3♥, 4♥, 5♥, 6♥, 7♥, 8♥, 9♥, 10♥, J♥, Q♥, K♥, A♥\}$

We can say:

-   $A♥ \in H$ (true, because the ace of hearts is one of the hearts)
-   $K♠ \notin H$ (false, because the king of spades is not a heart)
-   $\{A♥\} \notin H$ (false, this is a set containing the ace of hearts, not the card itself)

#### The "Is Contained In" Relationship ($\subseteq$)

A subset relationship (written as $A \subseteq B$) describes when one set is entirely contained within another set. Every element of the smaller set must appear in the larger set. This is different from set membership ($\in$), which describes when a single element belongs to a set.

To understand the distinction, let's look at some examples:

Consider the following sets:

-   $A = \{1, 2\}$
-   $B = \{1, 2, 3, 4\}$
-   $C = \{1\}$

For set membership ($\in$):

-   $1 \in A$ (the number 1 is an element of set A)
-   $\{1\} \notin A$ (the set containing 1 is not an element of A)
-   $2 \in B$ (the number 2 is an element of B)

For subset relationships ($\subseteq$):

-   $A \subseteq B$ (all elements of A are in B)
-   $C \subseteq A$ (all elements of C are in A)
-   $\{1\} \subseteq A$ (the set containing 1 is a subset of A)

A key insight is that while $1 \in A$ is true (1 is an element of A), $\{1\} \in A$ is false (the set containing 1 is not an element of A). However, $\{1\} \subseteq A$ is true (the set containing 1 is a subset of A).

Think of it this way: membership ($\in$) asks "Is this single thing in the set?" while subset ($\subseteq$) asks "Is every element of this smaller set found in the larger set?"

Another helpful example is with the empty set $\emptyset$:

-   $\emptyset \subseteq A$ for any set A (the empty set is a subset of every set)
-   But $\emptyset \notin A$ unless A specifically contains the empty set as an element


## Probability as a Measure

Probability is a mathematical tool that helps us quantify uncertainty. Just like we use:

- Meters to measure distance
- Kilograms to measure weight
- Degrees to measure temperature

We use probability to measure the likelihood of events occurring.

The key thing to remember is that probability is always a number between 0 and 1 (or between 0% and 100% if we're using percentages):

- A probability of 0 means the event is impossible
- A probability of 1 means the event is certain
- Everything in between tells us how likely the event is to occur


## What is Discrete Probability?

When we say a probability problem is "discrete," we mean we're dealing with situations where:

1.  We can count the number of possible outcomes
2.  Each outcome is separate and distinct from others
3.  We can list all possible outcomes in our sample space

For example, when we:

-   Draw balls from an urn
-   Flip coins or roll dice
-   Count successes in a sequence of trials
-   Select items from a group

This approach is particularly valuable because:

1.  It allows us to build strong intuition about probability without requiring calculus
2.  It directly connects to many real-world applications in statistics
3.  It provides the foundation for understanding the binomial distribution, which we'll use later for hypothesis testing


## Understanding Probability Measures and Related Concepts

A probability measure is a fundamental way to quantify the likelihood of events mathematically. Let's explore this concept and related terms.

### Probability Measure Function

To understand probability properly, we start with three fundamental rules called axioms. Don't worry if the word "axiom" sounds intimidating - these are just basic rules that everything else builds upon.

A probability measure $P$ assigns numbers to events following a few axioms.


#### Probability Axioms: The Foundation

Think of axioms as the basic rules that probability must follow. There are three main axioms:

1. **Non-negativity**: The probability of any event must be greater than or equal to zero.
   
   $$P(A) \geq 0$$ 
   
   *Real-world meaning*: You can't have negative probabilities!

2. **Certain Event**: The probability of the entire sample space (all possible outcomes) equals 1.
   
   $$P(S) = 1$$ 
   
   *Real-world meaning*: Something must happen - the probability of all possibilities together is 100% or 1.

3. **Additivity**: For mutually exclusive events (events that can't happen at the same time), the probability of either event occurring is the sum of their individual probabilities.
   
   $$P(A \cup B) = P(A) + P(B)$$ 
   
   *Real-world meaning*: If events can't overlap, add their individual probabilities to find the probability of either happening.

#### Probability Measure Function and Related Terms

**Probability Distribution**

A probability distribution describes how likely different possible outcomes are. Think of it as a complete description of the probability for every possible event. For example, when rolling a fair six-sided die, each number has a probability of $\frac{1}{6}$. This forms a probability distribution because it tells us the probability for every possible outcome.

**Probability Law**

The probability law is another term for probability distribution. It refers to the rule or pattern that determines how probabilities are assigned to different outcomes. Using our die example, the probability law states that each face has an equal probability of $\frac{1}{6}$.


::: {callout-note}
### Common Types of (Discrete) Distributions (*)

**Uniform Distribution**

The uniform distribution is the simplest distribution where all outcomes have equal probability. Rolling a fair die or flipping a fair coin follows a uniform distribution. For a die, each number has probability $\frac{1}{6}$.

**Binomial Distribution**

The binomial distribution describes the number of successes in a fixed number of independent yes/no experiments. For example, if we flip a coin 10 times, the number of heads follows a binomial distribution. The probability of getting exactly $k$ heads in $n$ flips is:

$$P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}$$

where $p$ is the probability of success on each try.

**Geometric Distribution**

The geometric distribution describes the number of tries needed until the first success occurs. For example, the number of coin flips needed until we get our first heads. The probability of success on the $k$th try is:

$$P(X = k) = (1-p)^{k-1}p$$

where $p$ is the probability of success on each try.

### Simple Example

Let's consider flipping a fair coin:

-   The sample space $\Omega$ contains all possible outcomes: {Heads, Tails}

-   The probability measure assigns: $P(\text{Heads}) = \frac{1}{2}$ and $P(\text{Tails}) = \frac{1}{2}$

-   This forms a uniform distribution since both outcomes are equally likely

-   We can verify the axioms:

    -   Non-negativity: Both $\frac{1}{2} \geq 0$
    -   Normalization: $\frac{1}{2} + \frac{1}{2} = 1$
    -   Additivity: If we consider Heads and Tails as disjoint events, their probabilities add up correctly
:::


## Classical (Discrete) Probability: The "Equal Chances" Approach

Classical probability applies when we have:
1. A finite number of possible outcomes
2. All outcomes are equally likely to occur

For example, when you roll a fair die, there are:
- 6 possible outcomes (the numbers 1 through 6)
- Each number has an equal chance of coming up

In classical probability, we can calculate the probability of an event using this simple formula:

$$P(A) = \frac{\text{Number of favorable outcomes}}{\text{Number of possible outcomes}}$$

Let's break this down with our die example:

What's the probability of rolling an even number?
- Favorable outcomes: {2, 4, 6} (3 outcomes)
- Possible outcomes: {1, 2, 3, 4, 5, 6} (6 outcomes)
- Therefore: $$P(\text{even}) = \frac{3}{6} = \frac{1}{2} = 0.5 = 50\%$$


## The Path to Classical Probability

Now, let's see how the probability axioms lead to the familiar formula for classical (or 'naive') probability.

We'll use a simple example: rolling a fair die.

**Step 1**: Consider the Sample Space
Let's say we have a sample space $S$ with $n$ equally likely outcomes:
$$S = \{s_1, s_2, ..., s_n\}$$

For a fair die: $S = \{1, 2, 3, 4, 5, 6\}$ so $n = 6$

**Step 2**: Apply the Axioms

1. From Axiom 1 (Non-negativity):
   $$P(s_i) \geq 0$$ for each outcome $s_i$

2. From Axiom 2 (Certain Event):
   $$P(S) = P(s_1) + P(s_2) + ... + P(s_n) = 1$$

3. Since outcomes are equally likely:
   $$P(s_1) = P(s_2) = ... = P(s_n) = p$$

**Step 3**: Derive the Classical Formula

Let's call this common probability $p$.

Then:

$p + p + ... + p = 1$ (adding n times)

$np = 1$

Therefore: $p = \frac{1}{n}$

This means each individual outcome has probability $\frac{1}{n}$.

For any event $A$ containing $k$ favorable outcomes:
$$P(A) = \frac{k}{n} = \frac{\text{number of favorable outcomes}}{\text{total number of outcomes}}$$

## Example: Rolling a Fair Die
Let's find the probability of rolling an even number:

- Favorable outcomes: {2, 4, 6}, so $k = 3$
- Total outcomes: {1, 2, 3, 4, 5, 6}, so $n = 6$
- Therefore: $$P(\text{even}) = \frac{3}{6} = \frac{1}{2}$$

## Important Notes
1. This classical definition only works when:
   - The sample space is finite
   - All outcomes are equally likely
   
2. For non-uniform probability spaces or infinite sample spaces, we need different approaches.

We started with three basic rules (axioms) and showed how they naturally lead to the familiar "favorable outcomes over total outcomes" formula when all outcomes are equally likely.


### Summary

The classical or naive definition (measure) of probability provides a simple way to calculate probabilities when:

1.  The sample space is finite (we can count all possible outcomes)
2.  All outcomes are equally likely to occur (uniform probability measure)

Under these conditions, the probability of an event E is:

$P(E) = \frac{\text{number of favorable outcomes}}{\text{total number of possible outcomes}} = \frac{|E|}{|S|}$

This is why we often start teaching probability with examples like fair coins, fair dice, and well-shuffled decks of cards - they satisfy both conditions. However, it's important to understand that many real-world situations don't meet these criteria, which is why we need more sophisticated probability concepts.

For example, when flipping two coins:

-   P(getting exactly one head) = $\frac{|\{HT,TH\}|}{|\{HH,HT,TH,TT\}|} = \frac{2}{4} = 0.5$
-   P(getting at least one head) = $\frac{|\{HH,HT,TH\}|}{|\{HH,HT,TH,TT\}|} = \frac{3}{4} = 0.75$

This classical definition, while simple, serves as a foundation for understanding more complex probability concepts.


::: {.callout-note}
## Discrete vs. Continuous Probability: A Simple Guide

Imagine you're measuring different things in everyday life. Sometimes you're **counting** (like the number of books on a shelf), and sometimes you're **measuring** (like your height or the temperature outside). This same distinction appears in probability!

### Discrete Probability
- **What it is**: Probability of exact, countable outcomes
- **Key feature**: Outcomes have "gaps" between them
- **We can**: Count the exact value
- **Example 1**: Rolling a die
  - Possible outcomes: 1, 2, 3, 4, 5, or 6
  - Nothing in between (you can't roll a 2.5)
  - Probability of rolling a 6: $$P(X=6) = \frac{1}{6}$$
- **Example 2**: Number of students in a class
  - You can have 15 or 16 students, but never 15.5 students

### Continuous Probability
- **What it is**: Probability of outcomes in a continuous range
- **Key feature**: Outcomes flow smoothly with no gaps
- **We can**: Get as precise as we want
- **Example 1**: Height of students
  - Could be 170.0 cm, 170.1 cm, 170.15 cm...
  - Can always measure more precisely
  - We talk about ranges: $$P(170 \leq X \leq 171)$$
- **Example 2**: Temperature outside
  - Could be 20.0°C, 20.05°C, 20.005°C...

### Key Difference in Probability Values
For discrete:

- We can find probability of exact values
- $P(X = \text{specific value}) > 0$ is possible

For continuous:

- Probability of exact value is zero!
- $P(X = \text{specific value}) = 0$ always
- We must use ranges: $P(a \leq X \leq b)$

### Real-World Application
Think about your Spotify playlist:

- **Discrete**: Number of songs (10, 11, 12...)
- **Continuous**: Duration of playlist (3.33... hours)

Remember: If you can count it, it's discrete. If you can measure it with increasing precision, it's continuous!

### Why We Focus on Discrete Probability
In this course, we'll focus primarily on discrete probability because:

- It's easier to understand with basic math skills
- We can avoid using calculus (which is needed for continuous probability)
- Most real-world decisions involve counting discrete outcomes
- We can often "discretize" continuous situations by using ranges
  (like grouping temperatures into categories: cold, mild, hot)

This approach lets us build strong probability intuition without advanced mathematics!
:::


### Understanding Classical Probability Through the Urn Example

::: {callout-warning}
## Key Questions Before Calculating Probabilities

Before we can correctly calculate probabilities in any discrete scenario, we must answer two fundamental questions:

1.  **Does Order Matter?**

The importance of order fundamentally changes how we count outcomes. Consider selecting two cards from a deck:

-   If we're playing poker, order doesn't matter - getting an ace and then a king is the same hand as getting a king and then an ace.
-   If we're performing a magic trick where we need specific cards in sequence, order matters - getting an ace then a king is different from getting a king then an ace.

When order matters, we're dealing with permutations. When order doesn't matter, we're dealing with combinations. This distinction dramatically affects the number of possible outcomes and, consequently, our probability calculations.

2.  **Is Sampling With or Without Replacement?**

After selecting an item, do we put it back before the next selection? This question fundamentally changes the probability structure:

-   With replacement: Each selection has the same probability distribution as the first selection. Drawing a red ball and replacing it means the probability of drawing red on the next try remains unchanged.
-   Without replacement: Each selection changes the probability distribution for subsequent selections. Drawing a red ball and not replacing it means there are fewer red balls available for the next draw.

These sampling schemes lead to different probability models:

-   With replacement leads to independent events and often simpler calculations
-   Without replacement leads to dependent events and requires conditional probability
:::

In our urn with 3 green and 2 red balls:

-   $P(\text{green}) = \frac{3}{5}$
-   $P(\text{red}) = \frac{2}{5}$
-   $P(\text{green}) + P(\text{red}) = 1$

The classical definition of probability assumes:

1.  A finite sample space $\Omega$ with equally likely outcomes ('fair' experiment)
2.  For an event $A$, probability is defined as: $P(A) = \frac{\text{favorable outcomes}}{\text{total outcomes}}$

In our urn with 3 green and 2 red balls, these assumptions manifest as:

-   Sample space $\Omega = \{b_1, b_2, b_3, b_4, b_5\}$ where each ball is equally likely
-   For green: $P(\text{green}) = \frac{|\text{green balls}|}{|\Omega|} = \frac{3}{5}$
-   For red: $P(\text{red}) = \frac{|\text{red balls}|}{|\Omega|} = \frac{2}{5}$

Key probability axioms are demonstrated:

1.  Non-negativity: $P(\text{green}), P(\text{red}) \geq 0$
2.  Normalization: $P(\Omega) = P(\text{green}) + P(\text{red}) = 1$
3.  Additivity: Since green and red are disjoint events, $P(\text{green or red}) = P(\text{green}) + P(\text{red})$

**REMARK**: Many probabilistic situations have the property that they involve a number of different possible outcomes, all of which are equally likely. For example, Heads and Tails on a coin are equally likely to be tossed, the numbers 1 through 6 on a die are equally likely to be rolled, and the ten balls in the above box are all equally likely to be picked.

**'Naive' (classical) probability definition assumes uniform probability measure (all outcomes equally likely), and finite uniform sample space.**

When considering shapes or elements of the same color in an urn or box, treating them as distinguishable allows you to assume a uniform sample space — equally likely outcomes.

## How to Calculate Basic Probabilities

Let's explore some fundamental probability concepts using a simple example with colored balls in an urn/bag. This example will help us understand:

-   How to calculate basic probabilities using the tree diagrams
-   How replacement affects probability
-   How the importance of order affects our calculations
-   How to break down probability problems into steps

Tree diagrams are powerful tools for visualizing sequential events. Each branch represents a possible outcome, and probabilities multiply along paths.

::: callout-note
## Sampling Methods Overview

| Sampling Method | With Replacement | Without Replacement |
|------------------|:--------------------------|:--------------------------|
| **Order Matters** | Each selection sequence is counted separately | Each sequence is unique, items not replaced |
| **Order Does Not Matter** | Items can be repeated, sequence ignored | Each group is unique, no repeats allowed |
:::

### Example 1A: Drawing Two Balls from an Urn or a Bag

Consider drawing two balls from an urn containing 3 green and 2 red balls.

Find the probabilities of the following random events:

-   The first ball is red and the second one is green (**order matters, drawing without replacement**)
-   The first ball is red and the second one is green (**order matters, drawing with replacement**)
-   The balls are of different colors (**order doesn't matter, drawing without replacement**)
-   The balls are of different colors (**order doesn't matter, drawing with replacement)**

**Understanding Event Types in Probability:**

1.  **Simple events represent a single outcome from a single random action**, such as drawing one ball from an urn. The probability of a simple event is calculated directly from the number of favorable outcomes divided by the total possible outcomes.
2.  **Compound events involve multiple outcomes or conditions that must occur together**. These can occur **simultaneously** (like rolling two dice at once) or **sequentially** (like drawing two balls one after another). The key difference lies in whether the events happen at the same time or in sequence.

-   **Sequential events are a specific type of compound events where outcomes occur in a particular order over time.** Our urn example is particularly instructive here because it demonstrates sequential events through the process of drawing balls one after another. This allows us to explore how the probability of the second draw depends on what happened in the first draw (when sampling without replacement).

![Sample spaces (S) visualized using the grid diagrams](stat_imgs/probability-grid.svg)

To better understand how the sample space changes based on our sampling method, let's examine two scenarios:

1.  **With Replacement**

When we sample with replacement, we return the ball to the urn after the first draw. This means:

-   The probability remains constant for each draw
-   Total possible outcomes: 25 (5×5 grid)
-   Each outcome has equal probability
-   $P(\text{both green}) = \frac{3}{5} \times \frac{3}{5} = \frac{9}{25}$
-   $P(\text{both red}) = \frac{2}{5} \times \frac{2}{5} = \frac{4}{25}$
-   $P(\text{mixed}) = \frac{12}{25}$

2.  **Without Replacement**

When we sample without replacement, the first draw affects the probability of the second draw:

-   Total possible outcomes: 20 (removing diagonal cells where same ball is drawn twice)
-   Second draw probabilities change based on first draw
-   $P(\text{both green}) = \frac{3}{5} \times \frac{2}{4} = \frac{6}{20}$
-   $P(\text{both red}) = \frac{2}{5} \times \frac{1}{4} = \frac{2}{20}$
-   $P(\text{mixed}) = \frac{12}{20}$

The grid diagram above visualizes both scenarios, where:

-   Green cells represent both balls drawn being green
-   Red cells represent both balls drawn being red
-   Orange cells represent mixed outcomes (one green, one red)
-   Crossed-out cells in the "Without Replacement" grid show impossible outcomes

This visualization helps demonstrate how the sample space and probabilities change between the two sampling methods, while maintaining the fundamental principle that probabilities must sum to 1 in both cases.

I.  **Drawing Two Balls Without Replacement**

Consider drawing two balls from an urn containing 3 green and 2 red balls. Let's analyze all scenarios systematically.

```{mermaid}
graph TD
    A[Start] --> B[First: Green 3/5]
    A --> C[First: Red 2/5]
    B --> D[Second: Green 2/4]
    B --> E[Second: Red 2/4]
    C --> F[Second: Green 3/4]
    C --> G[Second: Red 1/4]
```

Let's solve for different scenarios:

1.  First red, then green (order matters):

    $P(R \text{ then } G) = \frac{2}{5} \cdot \frac{3}{4} = \frac{6}{20} = 0.3$

2.  Different colors (order doesn't matter):

    $P(\text{different colors}) = P(R \text{ then } G) + P(G \text{ then } R)$

    $= \frac{2}{5} \cdot \frac{3}{4} + \frac{3}{5} \cdot \frac{2}{4} = \frac{6}{20} + \frac{6}{20} = \frac{12}{20} = 0.6$

<!-- -->

II. **Drawing With Replacement**

When we replace the first ball before drawing the second, the probabilities for the second draw remain unchanged:

```{mermaid}
graph TD
    A[Start] --> B[First: Green 3/5]
    A --> C[First: Red 2/5]
    B --> D[Second: Green 3/5]
    B --> E[Second: Red 2/5]
    C --> F[Second: Green 3/5]
    C --> G[Second: Red 2/5]
```

Now:

1.  First red, then green:

    $P(R \text{ then } G) = \frac{2}{5} \cdot \frac{3}{5} = \frac{6}{25} = 0.24$

2.  Different colors:

    $P(\text{different colors}) = \frac{2}{5} \cdot \frac{3}{5} + \frac{3}{5} \cdot \frac{2}{5} = \frac{12}{25} = 0.48$

### Example 1B: Drawing Two Balls from an Urn or a Bag (\*)

Consider drawing two balls from an urn containing 3 green and 2 red balls.

Find the probabilities of the following random events:

-   The first ball is red and the second one is green (order matters, drawing without replacement)
-   The first ball is red and the second one is green (order matters, drawing with replacement)
-   The balls are of different colors (order doesn't matter, drawing without replacement)
-   The balls are of different colors (order doesn't matter, drawing with replacement)

**Understanding Event Types in Probability:**

-   **Simple events represent a single outcome from a single random action**, such as drawing one ball from an urn. The probability of a simple event is calculated directly from the number of favorable outcomes divided by the total possible outcomes.
-   **Compound events involve multiple outcomes or conditions that must occur together**. These can occur simultaneously (like rolling two dice at once) or sequentially (like drawing two balls one after another). The key difference lies in whether the events happen at the same time or in sequence.
-   **Sequential events are a specific type of compound events where outcomes occur in a particular order over time**. Our urn example is particularly instructive here because it demonstrates sequential events through the process of drawing balls one after another. This allows us to explore how the probability of the second draw depends on what happened in the first draw (when sampling without replacement).

![Sample spaces (S) visualized using the grid diagrams](stat_imgs/probability-grid.svg)

To better understand how the sample space changes based on our sampling method, let's examine two scenarios:

1.  **With Replacement**

When we sample with replacement, we return the ball to the urn after the first draw. This means:

-   The probability remains constant for each draw
-   Total possible outcomes: 25 (5×5 grid)
-   Each outcome has equal probability
-   $P(\text{both green}) = \frac{3}{5} \times \frac{3}{5} = \frac{9}{25}$
-   $P(\text{both red}) = \frac{2}{5} \times \frac{2}{5} = \frac{4}{25}$
-   $P(\text{mixed}) = \frac{12}{25}$

2.  **Without Replacement**

When we sample without replacement, the first draw affects the probability of the second draw:

-   Total possible outcomes: 20 (removing diagonal cells where same ball is drawn twice)
-   Second draw probabilities change based on first draw
-   $P(\text{both green}) = \frac{3}{5} \times \frac{2}{4} = \frac{6}{20}$
-   $P(\text{both red}) = \frac{2}{5} \times \frac{1}{4} = \frac{2}{20}$
-   $P(\text{mixed}) = \frac{12}{20}$

The grid diagram above visualizes both scenarios, where:

-   Green cells represent both balls drawn being green
-   Red cells represent both balls drawn being red
-   Orange cells represent mixed outcomes (one green, one red)
-   Crossed-out cells in the "Without Replacement" grid show impossible outcomes

This visualization helps demonstrate how the sample space and probabilities change between the two sampling methods, while maintaining the fundamental principle that probabilities must sum to 1 in both cases.

I.  **Drawing Two Balls Without Replacement**

When drawing without replacement, we'll examine both order-sensitive and order-insensitive probabilities.

```{mermaid}
flowchart TD
    A(["Initial State\n3G, 2R"]) --> B["First: Green\n3/5"]
    A --> C["First: Red\n2/5"]
    B --> D["Second: Green\n2/4"]
    B --> E["Second: Red\n2/4"]
    C --> F["Second: Green\n3/4"]
    C --> G["Second: Red\n1/4"]
    
    D --> H["GG: 3/5 × 2/4 = 6/20"]
    E --> I["GR: 3/5 × 2/4 = 6/20"]
    F --> J["RG: 2/5 × 3/4 = 6/20"]
    G --> K["RR: 2/5 × 1/4 = 2/20"]
```

A)  When order matters (ordered pairs):

<!-- -->

1.  P(G then G) = 6/20
2.  P(G then R) = 6/20
3.  P(R then G) = 6/20
4.  P(R then R) = 2/20

<!-- -->

B)  When order doesn't matter (combinations):

<!-- -->

1.  P(two greens) = 6/20

2.  P(different colors) = P(G,R) or P(R,G) = 12/20

3.  P(two reds) = 2/20

<!-- -->

II. **Drawing With Replacement**

```{mermaid}
flowchart TD
    A(["Initial State\n3G, 2R"]) --> B["First: Green\n3/5"]
    A --> C["First: Red\n2/5"]
    B --> D["Second: Green\n3/5"]
    B --> E["Second: Red\n2/5"]
    C --> F["Second: Green\n3/5"]
    C --> G["Second: Red\n2/5"]
    
    D --> H["GG: 3/5 × 3/5 = 9/25"]
    E --> I["GR: 3/5 × 2/5 = 6/25"]
    F --> J["RG: 2/5 × 3/5 = 6/25"]
    G --> K["RR: 2/5 × 2/5 = 4/25"]
```

A)  When order matters (ordered pairs):

<!-- -->

1.  P(G then G) = 9/25
2.  P(G then R) = 6/25
3.  P(R then G) = 6/25
4.  P(R then R) = 4/25

<!-- -->

B)  When order doesn't matter (combinations):

<!-- -->

1.  P(two greens) = 9/25
2.  P(different colors) = P(G,R) or P(R,G) = 12/25
3.  P(two reds) = 4/25

Key observations:

1.  Without replacement:
    -   Different orders of the same colors have different probabilities
    -   The second draw's probability depends on the first outcome
2.  With replacement:
    -   Each draw is independent
    -   Probabilities multiply directly because sample space remains unchanged

## The Four Types of Counting Problems (\*)

When we count possibilities in probability problems, we need to think about two important questions:

1.  Does the order of our selections matter? (Like picking a phone PIN where 1234 is different from 4321)
2.  Can we reuse items we've already selected? (Like picking letters where we can reuse them, versus picking students where we can't pick the same person twice)

Let's explore each type of counting using a simple example: We have an urn with 5 colored balls (Red, Blue, Green, Yellow, and Purple), and we'll make 2 draws. For each scenario, we'll think about what makes sense in real life and how to count correctly.

1.  Order Matters, With Replacement

Think about picking a two-digit code where you can use any digit twice. This is similar to drawing a ball, writing down its color, putting it back, and drawing again.

For the first draw:

-   We can choose any of the 5 balls
-   After putting it back, we again have all 5 balls for our second draw
-   So for each first choice, we have 5 second choices

Let's count systematically:

-   If we pick Red first: we can then pick R,B,G,Y,or P (5 possibilities)
-   If we pick Blue first: we can then pick R,B,G,Y,or P (5 possibilities)
-   And so on for Green, Yellow, and Purple

Total outcomes: $5 \times 5 = 5^2 = 25$ possibilities The formula is $n^r$ where:

-   $n$ is how many options we have (5 balls)
-   $r$ is how many selections we make (2 draws)

2.  Order Matters, Without Replacement

Now imagine picking two students to do tasks in order - the first student will present today, the second tomorrow. We can't pick the same student twice!

For our balls:

-   First draw: we can choose any of the 5 balls
-   Second draw: we only have 4 balls left
-   If we pick Red first: we can then pick B,G,Y,or P (4 possibilities)
-   If we pick Blue first: we can then pick R,G,Y,or P (4 possibilities)
-   And so on...

Total outcomes: $5 \times 4 = 20$ possibilities The formula is $P(n,r) = \frac{n!}{(n-r)!}$

3.  Order Doesn't Matter, With Replacement

Imagine picking your two favorite colors - you can pick the same color twice, and it doesn't matter which you say first.

This is tricky! Here's why:

-   If we pick Red and then Blue, this is the same as picking Blue and then Red
-   But picking Red twice is still just one outcome

We need to be careful not to count the same outcome twice. The formula $\binom{n+r-1}{r}$ helps us avoid this **overcounting**.

In our example:

-   Total outcomes: $\binom{5+2-1}{2} = \binom{6}{2} = 15$ possibilities
-   This correctly counts (Red,Blue) and (Blue,Red) as one outcome

4.  Order Doesn't Matter, Without Replacement

Think about picking two students to be on a team - it doesn't matter who you pick first, and you can't pick the same person twice.

For our balls:

-   We're just picking 2 balls out of 5
-   (Red,Blue) and (Blue,Red) count as the same outcome
-   The formula $\binom{n}{r} = \frac{n!}{r!(n-r)!}$ gives us the right count
-   Total outcomes: $\binom{5}{2} = 10$ possibilities

## Example: The 4 Red and 3 Black Balls Problem

Let's solve a real problem using what we learned. We have:

-   4 red balls (let's call them R₁, R₂, R₃, R₄)
-   3 black balls (B₁, B₂, B₃)
-   We'll draw 2 balls without replacement
-   Order doesn't matter (like picking team members)

We want to find three probabilities:

1.  Getting two red balls
2.  Getting two black balls
3.  Getting one of each color

### Method 1: Using Counting Rules

First, let's count the total possible outcomes:

-   We're picking 2 balls from 7 total balls, order doesn't matter
-   Total outcomes = $\binom{7}{2} = \frac{7!}{2!(7-2)!} = \frac{7 \times 6}{2 \times 1} = 21$

Now let's find each probability:

1.  Two Red Balls

-   We need to pick 2 red balls from 4 red balls
-   This is like picking 2 team members from 4 people
-   Number of ways = $\binom{4}{2} = \frac{4 \times 3}{2 \times 1} = 6$
-   Probability = $\frac{6}{21}$

2.  Two Black Balls

-   Similarly, we need to pick 2 black balls from 3 black balls
-   Number of ways = $\binom{3}{2} = \frac{3 \times 2}{2 \times 1} = 3$
-   Probability = $\frac{3}{21}$

3.  One Red and One Black

-   We need:
    -   One red ball (we have 4 to choose from)
    -   One black ball (we have 3 to choose from)
-   Number of ways = $4 \times 3 = 12$
-   Probability = $\frac{12}{21}$

Let's verify our work:

-   All probabilities should add to 1
-   $\frac{6}{21} + \frac{3}{21} + \frac{12}{21} = \frac{21}{21} = 1$ ✓

This matches what we expect - every time we draw two balls, we must get either:

-   Two red balls
-   Two black balls
-   One of each color

Understanding how to count correctly helps us solve these probability problems systematically and avoid common mistakes like counting the same outcome multiple times.

### Method 2: Tree Diagram Approach

The tree diagram helps us visualize the sequential nature of the draws:

```{mermaid}
graph TD
    A[Start] --> B[First: Red 4/7]
    A --> C[First: Black 3/7]
    B --> D[Second: Red 3/6]
    B --> E[Second: Black 3/6]
    C --> F[Second: Red 4/6]
    C --> G[Second: Black 2/6]
```

Using the tree diagram:

1.  P(both red) = $\frac{4}{7} \cdot \frac{3}{6} = \frac{12}{42} = \frac{6}{21}$

2.  P(red then black) = $\frac{4}{7} \cdot \frac{3}{6} = \frac{12}{42}$

3.  P(multi-colored) = P(red then black) + P(black then red)

    = $\frac{4}{7} \cdot \frac{3}{6} + \frac{3}{7} \cdot \frac{4}{6} = \frac{24}{42}$

### Method 3: Grid Diagram and Sample Space

Let's visualize the entire sample space using a grid where each cell represents selecting two balls in order:

| First Draw →  | R₁  | R₂  | R₃  | R₄  | B₁  | B₂  | B₃  |
|---------------|-----|-----|-----|-----|-----|-----|-----|
| Second Draw ↓ |     |     |     |     |     |     |     |
| R₁            | X   | ⚫  | ⚫  | ⚫  | ⚪  | ⚪  | ⚪  |
| R₂            | ⚫  | X   | ⚫  | ⚫  | ⚪  | ⚪  | ⚪  |
| R₃            | ⚫  | ⚫  | X   | ⚫  | ⚪  | ⚪  | ⚪  |
| R₄            | ⚫  | ⚫  | ⚫  | X   | ⚪  | ⚪  | ⚪  |
| B₁            | ⚪  | ⚪  | ⚪  | ⚪  | X   | ⚫  | ⚫  |
| B₂            | ⚪  | ⚪  | ⚪  | ⚪  | ⚫  | X   | ⚫  |
| B₃            | ⚪  | ⚪  | ⚪  | ⚪  | ⚫  | ⚫  | X   |

Where:

-   X: Impossible (same ball twice)
-   ⚫: Both red or both black
-   ⚪: Multi-colored outcome

From this grid:

1.  Both red = 12 outcomes (⚫ in upper-left quadrant)
2.  Red then black = 12 outcomes (⚪ in upper-right)
3.  Total possible outcomes = 42 (remove diagonal X's)

Therefore:

-   P(both red) = $\frac{12}{42} = \frac{6}{21}$
-   P(red then black) = $\frac{12}{42} = \frac{2}{7}$
-   P(multi-colored) = $\frac{24}{42} = \frac{4}{7}$

### Comparing the Methods

Each method highlights different aspects of the problem:

1.  Counting Rules:

    -   Most efficient for calculation
    -   Helps understand combinations and arrangements
    -   May obscure the actual outcomes

2.  Tree Diagram:

    -   Shows sequential nature of draws
    -   Makes conditional probability clear
    -   Visualizes how probabilities combine
    -   Good for checking intuition

3.  Grid Diagram:

    -   Shows entire sample space explicitly
    -   Makes it clear why diagonal is impossible
    -   Helps visualize groups of outcomes
    -   Demonstrates why we divide by total possibilities
    -   Shows symmetry in the problem
    
## Problem Solutions (1)


### Problem 1: Two-Ball Drawing from an Urn

An urn contains 3 red, 2 blue, and 1 yellow balls. Two balls are drawn sequentially without replacement. We need to find the probability that the balls drawn are different colors.

### Initial Conditions

Let's first state our starting conditions:

* Total number of balls: $n = 3 + 2 + 1 = 6$
* Distribution of balls:
  * Red: $n_R = 3$
  * Blue: $n_B = 2$
  * Yellow: $n_Y = 1$

### Visual Representation

Let's visualize all possible outcomes using a tree diagram:

```{mermaid}
graph TD
    A[Start] --> B["R (3/6)"]
    A --> C["B (2/6)"]
    A --> D["Y (1/6)"]
    
    B --> E["B (2/5)"]
    B --> F["Y (1/5)"]
    B --> G["R (2/5)"]
    
    C --> H["R (3/5)"]
    C --> I["Y (1/5)"]
    C --> J["B (1/5)"]
    
    D --> K["R (3/5)"]
    D --> L["B (2/5)"]
    D --> M["Y (0/5)"]
    
    E --> N["RB (Success)"]
    F --> O["RY (Success)"]
    G --> P["RR (Fail)"]
    H --> Q["BR (Success)"]
    I --> R["BY (Success)"]
    J --> S["BB (Fail)"]
    K --> T["YR (Success)"]
    L --> U["YB (Success)"]
    M --> V["YY (Fail)"]
```

### Probability Calculation

Let's calculate the probability of drawing different colors systematically:

1. Starting with Red (probability $\frac{3}{6}$):
   * Red → Blue: $P(R,B) = \frac{3}{6} \cdot \frac{2}{5} = \frac{6}{30}$
   * Red → Yellow: $P(R,Y) = \frac{3}{6} \cdot \frac{1}{5} = \frac{3}{30}$

2. Starting with Blue (probability $\frac{2}{6}$):
   * Blue → Red: $P(B,R) = \frac{2}{6} \cdot \frac{3}{5} = \frac{6}{30}$
   * Blue → Yellow: $P(B,Y) = \frac{2}{6} \cdot \frac{1}{5} = \frac{2}{30}$

3. Starting with Yellow (probability $\frac{1}{6}$):
   * Yellow → Red: $P(Y,R) = \frac{1}{6} \cdot \frac{3}{5} = \frac{3}{30}$
   * Yellow → Blue: $P(Y,B) = \frac{1}{6} \cdot \frac{2}{5} = \frac{2}{30}$

### Final Solution

The total probability of drawing two different colored balls is the sum of all favorable outcomes:

$$
\begin{align*}
P(\text{different colors}) &= P(R,B) + P(R,Y) + P(B,R) + P(B,Y) + P(Y,R) + P(Y,B) \\
&= \frac{6}{30} + \frac{3}{30} + \frac{6}{30} + \frac{2}{30} + \frac{3}{30} + \frac{2}{30} \\
&= \frac{22}{30} \\
&= \frac{11}{15} \\
&\approx 0.733 \text{ or } 73.3\%
\end{align*}
$$

### Verification

This result aligns with our intuition because:

1. The sample space contains more ways to draw different colors than same colors
2. The complementary probability (drawing same colors) would be $\frac{4}{15}$ or about 26.7%
3. Since same-color draws are limited to RR, BB, and YY combinations, it makes sense that different-color draws are more likely


### Problem 2: Die and Coin Probability Exercise

Let's analyze the probability of getting heads OR tails OR three dots when flipping both a coin and a die. This problem offers an excellent opportunity to explore probability unions and the importance of careful counting.

#### Understanding the Problem Space

In our experiment:

1. We flip a coin (possible outcomes: heads, tails)
2. We roll a die (possible outcomes: 1, 2, 3, 4, 5, 6 dots)
3. These events occur simultaneously 

Let's start with a visualization:

```{mermaid}
graph TD
    A[Experiment] --> B[Coin]
    A --> C[Die]
    B --> D[Heads]
    B --> E[Tails]
    C --> F[1 dot]
    C --> G[2 dots]
    C --> H[3 dots]
    C --> I[4 dots]
    C --> J[5 dots]
    C --> K[6 dots]
```

#### Common Mistakes and Overcounting Analysis

A common first instinct might be to simply add the individual probabilities:

P(heads) + P(tails) + P(three dots) = $\frac{1}{2} + \frac{1}{2} + \frac{1}{6}$ = $\frac{7}{6}$

This incorrect approach reveals several important issues:

1. The result exceeds 1, which is impossible for a probability
2. We've counted many outcomes multiple times
3. We've failed to recognize event overlaps

Let's analyze the overcounting:

```{mermaid}
graph TD
    A[Overcounting Analysis] --> B[Heads counted: 6/12]
    A --> C[Tails counted: 6/12]
    A --> D[Three dots counted: 2/12]
    B --> E[Including three with heads: 1/12]
    C --> F[Including three with tails: 1/12]
    E --> G[Double counted!]
    F --> G
```

#### Correct Solution Using Set Theory

Let's solve this properly using set theory:

- Set H: All outcomes with heads
- Set T: All outcomes with tails
- Set 3: All outcomes with three dots

Key insights:

1. Sets H and T are mutually exclusive
2. Set 3 is entirely contained within H ∪ T
3. Therefore, P(H ∪ T ∪ 3) = P(H ∪ T) = 1

We can write this formally:

P(H ∪ T ∪ 3) = P(H) + P(T) - P(H ∩ T) + P(3) - P(3 ∩ (H ∪ T))
= $\frac{1}{2} + \frac{1}{2} - 0 + \frac{1}{6} - \frac{1}{6}$ = 1

#### Sample Space Analysis

```{mermaid}
graph TD
    A[Total Outcomes: 12] --> B[Heads: 6]
    A --> C[Tails: 6]
    B --> D[With three: 1]
    C --> E[With three: 1]
    D --> F[Already counted in heads]
    E --> G[Already counted in tails]
```

This visual representation helps us understand why:

1. The sample space has 12 total outcomes (2 × 6)
2. The three-dot outcomes are already included in heads and tails counts
3. Adding P(three dots) would lead to double counting

#### Key Learning Points

This problem illustrates several fundamental probability concepts:

1. **Exhaustive Events**: Heads and tails together cover all possible coin outcomes, making additional events redundant unless they introduce new dimensions.

2. **Double Counting Protection**: The inclusion-exclusion principle helps us avoid counting outcomes multiple times.

3. **Sample Space Structure**: Understanding your sample space structure (12 total outcomes) helps verify solution logic.

#### Extension Question

To deepen understanding, consider: How would the solution change if instead of "three dots" we included "even numbers" on the die? This variation helps illustrate how overlapping events affect probability calculations.

The answer would be different because even numbers (2,4,6) would create a different overlap pattern with heads and tails, demonstrating how the nature of overlapping events can significantly impact our probability calculations.

### Problem 3: Laplace's Two-Draw Probability Problem

Suppose there are two urns of coloured marbles:

1. Urn X contains 3 black marbles, 1 white.
2. Urn Y contains 1 black marble, 3 white.

I flip a fair coin to decide which urn to draw from, heads for Urn X and tails for Urn Y. Then I draw marbles at random.

Laplace asked what happens if we do two draws, with replacement. What’s the probability both draws will come up black?

Let's solve this fascinating probability problem involving two draws with replacement. This is a particularly interesting case because the replacement aspect affects how we think about sequential probabilities.

#### Understanding the Initial Setup

First, let's clarify our starting conditions:

Urn X (selected with heads):

- 3 black marbles, 1 white marble
- Total: 4 marbles
- P(black|X) = $\frac{3}{4}$

Urn Y (selected with tails):

- 1 black marble, 3 white marbles
- Total: 4 marbles
- P(black|Y) = $\frac{1}{4}$

Let's visualize this with a tree diagram showing all possible paths:

```{mermaid}
graph TD
    A[Start] --> B[Urn X 1/2]
    A --> C[Urn Y 1/2]
    
    B --> D[Draw 1 Black 3/4]
    B --> E[Draw 1 White 1/4]
    
    C --> F[Draw 1 Black 1/4]
    C --> G[Draw 1 White 3/4]
    
    D --> H[Draw 2 Black 3/4]
    D --> I[Draw 2 White 1/4]
    
    E --> J[Draw 2 Black 3/4]
    E --> K[Draw 2 White 1/4]
    
    F --> L[Draw 2 Black 1/4]
    F --> M[Draw 2 White 3/4]
    
    G --> N[Draw 2 Black 1/4]
    G --> O[Draw 2 White 3/4]
```

#### Step-by-Step Solution

Let's break this down into manageable steps:

1. **First, consider the urn selection**:
   - P(Urn X) = P(heads) = $\frac{1}{2}$
   - P(Urn Y) = P(tails) = $\frac{1}{2}$

2. **For two black draws from Urn X**:
   - P(black and black|X) = $\frac{3}{4} \times \frac{3}{4}$ = $\frac{9}{16}$
   - P(X and both black) = $\frac{1}{2} \times \frac{9}{16}$ = $\frac{9}{32}$

3. **For two black draws from Urn Y**:
   - P(black and black|Y) = $\frac{1}{4} \times \frac{1}{4}$ = $\frac{1}{16}$
   - P(Y and both black) = $\frac{1}{2} \times \frac{1}{16}$ = $\frac{1}{32}$

4. **Total probability** (using the law of total probability):
   P(both black) = P(X and both black) + P(Y and both black)
   = $\frac{9}{32} + \frac{1}{32}$
   = $\frac{10}{32}$
   = $\frac{5}{16}$
   ≈ 0.3125 or about 31.25%

#### Key Insights from This Problem

1. **Replacement Matters**: 
   - Because we replace after the first draw, the probabilities remain constant for the second draw
   - This is different from drawing without replacement, where probabilities would change

2. **Conditional Independence**:
   - Once we know which urn we're using, the draws are independent
   - However, the draws are not unconditionally independent

3. **Law of Total Probability**:
   - We needed to consider both paths (Urn X and Urn Y) to find the total probability
   - Each path's contribution is weighted by the probability of selecting that urn

#### A Thought Experiment

To deepen understanding, consider: How would the probability change if we didn't replace the first marble? This would create dependent events, where:
- The second draw's probability would depend on the first draw's outcome
- We'd need to recalculate the ratios for each second draw



## Core Probability Rules

Before calculating any probability, we must carefully analyze the experiment's setup by answering four critical questions:

**1. Is the Sample Space Finite or Infinite?**

This distinction fundamentally affects our calculation approach:

**Finite Sample Spaces:**

- Example: Rolling a die (S = {1,2,3,4,5,6})
- Probability calculation: Count favorable outcomes and divide by total outcomes (when equally likely)
- Common in discrete probability problems

**Infinite Sample Spaces:**

- Example: Selecting a random real number between 0 and 1
- Requires calculus-based methods (integration) or geometric approaches
- Often involves continuous probability distributions

**2. Are All Outcomes Equally Likely?**

This determines our calculation method:

**Equally Likely Outcomes:**

- Use the classical probability formula: $P(A) = \frac{\text{favorable outcomes}}{\text{total outcomes}}$
- Example: Fair die roll - each face has probability $\frac{1}{6}$

**Unequally Likely Outcomes:**

- Must know or estimate individual outcome probabilities
- Example: Loaded die where P(6) = 0.3, other faces = 0.14
- Sum of probabilities must still equal 1

**3. Does Order Matter in Multi-Stage Experiments?**

This affects how we count outcomes:

**Order Matters (Permutations):**

- Example: Drawing cards and keeping them in drawn order
- Password entry where "123" ≠ "321"
- Use permutation formulas: $P(n,r) = \frac{n!}{(n-r)!}$

**Order Doesn't Matter (Combinations):**

- Example: Drawing poker hand where order is irrelevant
- Use combination formulas: $C(n,r) = \binom{n}{r} = \frac{n!}{r!(n-r)!}$

**4. Is Selection With or Without Replacement?**

This affects outcome independence:

**With Replacement:**

- Return item before next selection
- Probabilities remain constant across trials
- Events are independent
- Example: Rolling a die multiple times

**Without Replacement:**

- Don't return item before next selection
- Probabilities change after each selection
- Events are dependent
- Example: Drawing cards without returning them


**Example Application: Drawing two cards from a deck**

- Without replacement: P(second ace | first ace) = 3/51
- With replacement: P(second ace | first ace) = 4/52

These questions form the foundation for choosing the correct probability calculation method. Answering them first helps avoid common calculation errors and guides our solution strategy.


### The Complement Rule

The complement rule is one of the most fundamental concepts in probability theory. For any event A, there's always the possibility that A doesn't occur. We call this the complement of A, written as A' or A^c.

The complement rule states:

$$P(A') = 1 - P(A)$$

This makes intuitive sense because any outcome must either be in A or in A' (but not both), and something must happen (the total probability must be 1).

**Real-World Example**: Consider a weather forecast that predicts a 70% chance of rain tomorrow. Using the complement rule, we can immediately calculate that there's a 30% chance it won't rain:

$$P(\text{no rain}) = 1 - P(\text{rain}) = 1 - 0.70 = 0.30$$

**Another Example**: In a game of roulette, what's the probability of not landing on red? There are 18 red numbers, 18 black numbers, and 2 green numbers (0 and 00) on a roulette wheel. Therefore:

$$P(\text{red}) = \frac{18}{38}$$
$$P(\text{not red}) = 1 - \frac{18}{38} = \frac{20}{38}$$

### The Addition/Sum Rule

When we want to find the probability of either one event OR another occurring, we use the addition rule. However, we need to be careful about double-counting outcomes that are in both events.

For any two events A and B:

$$P(A \cup B) = P(A) + P(B) - P(A \cap B)$$

The term $P(A \cap B)$ represents the probability of both events occurring simultaneously. We subtract it to avoid counting these outcomes twice.

**Real-World Example**: In a college class, 65% of students play sports, 45% are in clubs, and 25% do both. What percentage of students are involved in either sports or clubs?

$$P(\text{sports or clubs}) = 65\% + 45\% - 25\% = 85\%$$

For mutually exclusive events (events that cannot occur simultaneously), $P(A \cap B) = 0$, so the formula simplifies to:

$$P(A \cup B) = P(A) + P(B)$$

**Example**: When rolling a die, what's the probability of rolling either a 1 or a 6?
Since these outcomes can't happen simultaneously:

$$P(1 \text{ or } 6) = P(1) + P(6) = \frac{1}{6} + \frac{1}{6} = \frac{1}{3}$$

### Conditional Probability, the Multiplication Rule, and Bayes' Theorem

Let's explore how these three concepts are deeply interconnected and build upon each other to help us solve complex probability problems.

#### Starting with Conditional Probability

Conditional probability answers the question: "Given that we know event B has occurred, what is the probability that event A will occur?" We write this as P(A|B), read as "the probability of A given B."

The formal definition of conditional probability is:

$P(A|B) = \frac{P(A \cap B)}{P(B)}$

This makes intuitive sense because when we know B has occurred, we're now working in a reduced sample space where B is certain. We take the probability of both events occurring and divide by the probability of the condition we know to be true.

**Real-World Example**: In a company, 60% of employees are women, and 25% of all employees are in management. If we want to know the probability that a randomly selected woman is in management, we're asking for a conditional probability:

$P(\text{management}|\text{woman}) = \frac{P(\text{management} \cap \text{woman})}{P(\text{woman})}$

#### The Bridge to the Multiplication Rule

The conditional probability formula can be rearranged to give us the multiplication rule:

$P(A|B) = \frac{P(A \cap B)}{P(B)}$
$P(A \cap B) = P(A|B) \cdot P(B)$

This same relationship must also hold if we condition on A instead of B:

$P(A \cap B) = P(B|A) \cdot P(A)$

This symmetry is crucial because it tells us:

$P(A|B) \cdot P(B) = P(B|A) \cdot P(A)$

#### The Natural Evolution to Bayes' Theorem

Bayes' theorem emerges naturally when we want to "reverse" a conditional probability. Suppose we know P(B|A), but we want to find P(A|B). Using the multiplication rule symmetry:

$P(A|B) \cdot P(B) = P(B|A) \cdot P(A)$

We can solve for P(A|B):

$P(A|B) = \frac{P(B|A) \cdot P(A)}{P(B)}$

This is Bayes' theorem! It allows us to update our initial beliefs (P(A), called the prior) based on new evidence (B).

The denominator P(B) can be expanded using the law of total probability:

$P(B) = P(B|A) \cdot P(A) + P(B|A') \cdot P(A')$

**Real-World Example**: Continuing our workplace example:
- If we know P(management|woman) = 0.30 and want to find P(woman|management)
- We can use Bayes' theorem:

$P(\text{woman}|\text{management}) = \frac{P(\text{management}|\text{woman}) \cdot P(\text{woman})}{P(\text{management})}$
$= \frac{0.30 \cdot 0.60}{0.25} = 0.72$

This tells us that 72% of managers are women, even though only 60% of all employees are women. This illustrates how Bayes' theorem helps us understand relationships from different perspectives.

The beauty of these interconnected concepts is that they all stem from the basic idea of conditional probability. The multiplication rule is a rearrangement of the conditional probability formula, and Bayes' theorem naturally emerges when we want to reverse the conditioning. Together, they form a powerful toolkit for solving complex probability problems.

### Independent and Disjoint Events

Understanding the difference between independent and disjoint events is crucial for correctly applying probability rules.

**Independent Events**: Events A and B are independent if knowing that one occurred doesn't affect the probability of the other occurring. Mathematically:

$$P(A|B) = P(A)$$ 
or equivalently: 
$$P(A \cap B) = P(A) \cdot P(B)$$

**Example**: When flipping a fair coin twice, the outcome of the first flip doesn't affect the second flip. Therefore:

$$P(\text{heads on both}) = P(\text{heads}) \cdot P(\text{heads}) = \frac{1}{2} \cdot \frac{1}{2} = \frac{1}{4}$$

**Disjoint Events**: Events A and B are disjoint (mutually exclusive) if they cannot occur simultaneously:

$$P(A \cap B) = 0$$

**Example**: When rolling a die, the events "rolling an even number" and "rolling a 3" are disjoint because a number cannot be both even and equal to 3.


## Problem Solutions (2)

### Problem 1: Cards - Diamonds or Tens

**Question**: From a standard deck of 52 cards, what is the probability of drawing either a diamond or a ten?

**Detailed Solution**:

Let's approach this methodically:

1. First, let's understand what we're looking for:
   - We want P(diamond OR ten)
   - This is a union of two events: P(D ∪ T)

2. Let's identify the events:
   - D = drawing a diamond
   - T = drawing a ten

3. Calculate P(D):
   - There are 13 diamonds in a deck of 52 cards
   - $$P(D) = \frac{13}{52} = \frac{1}{4}$$

4. Calculate P(T):
   - There are 4 tens in a deck (one in each suit)
   - $$P(T) = \frac{4}{52} = \frac{1}{13}$$

5. Calculate P(D ∩ T):
   - There is exactly one ten of diamonds
   - $$P(D \cap T) = \frac{1}{52}$$

6. Apply the addition rule:

   $$P(D \cup T) = P(D) + P(T) - P(D \cap T)$$
   $$= \frac{13}{52} + \frac{4}{52} - \frac{1}{52}$$
   $$= \frac{16}{52} - \frac{1}{52}$$
   $$= \frac{15}{52}$$
   $$\approx 0.288$$ or about 28.8%

**Verification**: We can verify this answer makes sense because:
- The probability should be less than the sum of individual probabilities ($\frac{13}{52} + \frac{4}{52} = \frac{17}{52}$)
- The probability should be greater than the larger individual probability ($\frac{13}{52}$)


### Problem 2: Colored Balls - At Least One Red

**Question**: A bag contains 5 red and 3 blue marbles. Two marbles are drawn simultaneously from the bag. What is the probability that at least one marble is red?

**Detailed Solution**:

Let's solve this problem using two different approaches to deepen our understanding.

**Approach 1: Using the Complement Rule**
Sometimes it's easier to find the probability of "at least one" by instead calculating the probability of "none" and subtracting from 1.

1. P(at least one red) = 1 - P(no red marbles)
2. P(no red marbles) = P(both marbles are blue)
3. When drawing simultaneously:
   $P(\text{both blue}) = \frac{\binom{3}{2}}{\binom{8}{2}}$
   - $\binom{3}{2}$ represents ways to choose 2 blue marbles from 3 blue marbles
   - $\binom{8}{2}$ represents ways to choose 2 marbles from all 8 marbles
4. Calculate:
   $P(\text{both blue}) = \frac{3!/(2!(3-2)!)}{8!/(2!(8-2)!)} = \frac{3}{28}$
5. Therefore:
   $P(\text{at least one red}) = 1 - \frac{3}{28} = \frac{25}{28}$

**Approach 2: Direct Calculation**
We can also solve this directly by adding the probability of getting one red and one blue or two red marbles:

1. P(at least one red) = P(one red and one blue) + P(both red)
2. Calculate each part:
   - P(both red) = $\frac{\binom{5}{2}}{\binom{8}{2}} = \frac{10}{28}$
   - P(one red and one blue) = $\frac{\binom{5}{1}\binom{3}{1}}{\binom{8}{2}} = \frac{15}{28}$
3. Therefore:
   $P(\text{at least one red}) = \frac{10}{28} + \frac{15}{28} = \frac{25}{28}$

**Understanding the Solution**:
- Both approaches give the same answer: $\frac{25}{28}$ (approximately 89.3%)
- The complement approach was simpler computationally because we only needed to calculate one combination
- The direct approach helps us understand the different ways we can get at least one red marble
- The high probability makes sense because:
  - Most marbles are red (5 out of 8)
  - We're drawing two marbles
  - We only need one of them to be red

This problem demonstrates how choosing the right approach can make solving probability problems easier. The complement rule is particularly useful when calculating "at least one" probabilities.

### Problem 3: Colored Balls with Replacement and Addition

**Question**: A box contains 5 red and 3 green balls. One ball is drawn at random, its color is noted, and it is replaced back. Then one more ball of the same color is added. Then a second ball is drawn. What is the probability that both balls drawn are green?

**Detailed Solution**:

This is a sequential probability problem where the probability of the second event depends on the outcome of the first. Let's solve it step by step:

1. Define our events:
   - G₁ = first ball is green
   - G₂ = second ball is green
   - We want P(G₁ ∩ G₂)

2. Calculate P(G₁):
   - Initially: 3 green balls out of 8 total
   - $$P(G_1) = \frac{3}{8}$$

3. Calculate P(G₂|G₁):
   - If first ball was green:
     - After replacement and adding another green: 4 green balls out of 9 total
   - $$P(G_2|G_1) = \frac{4}{9}$$

4. Apply the multiplication rule:

   $$P(G_1 \cap G_2) = P(G_1) \cdot P(G_2|G_1)$$
   $$= \frac{3}{8} \cdot \frac{4}{9}$$
   $$= \frac{12}{72}$$
   $$= \frac{1}{6}$$
   $$\approx 0.167$$ or about 16.7%

**Understanding the Solution**:

- The probability is relatively low because we need two specific events to occur in sequence
- The addition of a ball of the same color as the first draw creates a dependency between the draws
- If we had simply replaced the first ball without adding another, the draws would have been independent

### Problem 3: COVID-19 Test Analysis

**Question**: Given a COVID-19 test with:

- Sensitivity (P(T=1|D=1)) = 87.5%
- Specificity (P(T=0|D=0)) = 97.5%
- Disease prevalence (P(D=1)) = 10%
Find P(D=1|T=1), the probability that a person with a positive test actually has the disease.

**Detailed Solution**:

This is a perfect application of Bayes' Theorem. Let's break it down:

1. Define our variables:
   - D=1: Person has COVID-19
   - D=0: Person doesn't have COVID-19
   - T=1: Test is positive
   - T=0: Test is negative

2. Given information:
   - P(T=1|D=1) = 0.875 (sensitivity)
   - P(T=0|D=0) = 0.975 (specificity)
   - P(D=1) = 0.1 (prevalence)

3. Calculate additional probabilities:
   - P(D=0) = 1 - P(D=1) = 0.9
   - P(T=1|D=0) = 1 - P(T=0|D=0) = 0.025 (false positive rate)

4. Apply Bayes' Theorem:
   $$P(D=1|T=1) = \frac{P(T=1|D=1) \cdot P(D=1)}{P(T=1)}$$

5. Calculate P(T=1) using the law of total probability:
   $$P(T=1) = P(T=1|D=1)P(D=1) + P(T=1|D=0)P(D=0)$$
   $$= (0.875)(0.1) + (0.025)(0.9)$$
   $$= 0.0875 + 0.0225$$
   $$= 0.11$$

6. Now we can complete Bayes' Theorem:
   $$P(D=1|T=1) = \frac{(0.875)(0.1)}{0.11}$$
   $$= \frac{0.0875}{0.11}$$
   $$\approx 0.795$$ or about 79.5%

**Understanding the Result**:
This result tells us that even with a positive test, there's still about a 20.5% chance that the person doesn't have COVID-19. This might seem surprising, but it's due to the relatively low prevalence of the disease (10%) in the population. This is known as the base rate fallacy - even a test with good sensitivity and specificity can have a significant false positive rate when the condition being tested for is rare.

### Problem 4: Conditional Probability: Marble Drawing with Coin Flip

We have a probability experiment involving two boxes of marbles and a fair coin:

**Box X1:**

- 2 black marbles
- 3 red marbles
- Total: 5 marbles

**Box X2:**

- 1 black marble
- 1 red marble
- Total: 2 marbles

A fair coin is flipped to select the box (heads for X1, tails for X2), then one marble is drawn.

**Visual Representation**

Let's create a tree diagram to visualize all possible outcomes and their probabilities:

```{mermaid}
graph TD
    A[Start] --> B[X1 1/2]
    A --> C[X2 1/2]
    
    B --> D[Black 2/5]
    B --> E[Red 3/5]
    
    C --> F[Black 1/2]
    C --> G[Red 1/2]
    
    D --> H[Black & X1]
    E --> I[Red & X1]
    F --> J[Black & X2]
    G --> K[Red & X2]
```

#### Solution

Let's solve each part step by step:

#### P(Black | X1)

This is the probability of drawing a black marble *given that* we selected Box X1.

P(Black | X1) = $\frac{\text{Number of black marbles in X1}}{\text{Total marbles in X1}} = \frac{2}{5}$

This is a direct probability from the contents of Box X1. We only consider Box X1's marbles since we're given that Box X1 was selected.

#### P(Black and X1)

This is the probability of both selecting Box X1 *and* drawing a black marble.

P(Black and X1) = P(X1) × P(Black | X1) = $\frac{1}{2} \times \frac{2}{5} = \frac{1}{5}$

We multiply these probabilities because both events must occur (intersection).

#### P(Black)

This is the total probability of drawing a black marble from either box. We use the law of total probability:

P(Black) = P(X1) × P(Black | X1) + P(X2) × P(Black | X2)
= $\frac{1}{2} \times \frac{2}{5} + \frac{1}{2} \times \frac{1}{2}$
= $\frac{1}{5} + \frac{1}{4}$
= $\frac{4}{20} + \frac{5}{20}$
= $\frac{9}{20}$

#### P(X1 | Black)

This is the probability that we selected Box X1 given that we drew a black marble. We use Bayes' Theorem:

P(X1 | Black) = $\frac{P(Black | X1) \times P(X1)}{P(Black)}$
= $\frac{\frac{2}{5} \times \frac{1}{2}}{\frac{9}{20}}$
= $\frac{\frac{1}{5}}{\frac{9}{20}}$
= $\frac{4}{9}$

#### Key Concepts Demonstrated

1. **Conditional Probability**: Shown in P(Black | X1), where we consider probability within a subset of outcomes

2. **Multiplication Rule**: Used in finding P(Black and X1), where we multiply probabilities of sequential events

3. **Law of Total Probability**: Applied in finding P(Black), where we consider all possible ways an event can occur

4. **Bayes' Theorem**: Used to find P(X1 | Black), reversing the direction of conditioning

### Problem 5: Probability of Intersecting Events and Independence Analysis

You roll a fair die. What is the probability of getting an even number (A) and the number greater or equal to 4 (B)? Are events A and B independent?

Let's explore this problem by first understanding what each event means, then calculating their probabilities both separately and together, and finally examining their independence.

#### Understanding the Events

Let's first identify what numbers satisfy each condition on a standard six-sided die:

Event A (Even numbers): {2, 4, 6}
Event B (Numbers ≥ 4): {4, 5, 6}

We can visualize this using a Venn diagram:

```{mermaid}
graph TD
    subgraph A[Event A: Even Numbers]
        A2[2]
        A4[4]
        A6[6]
    end
    subgraph B[Event B: Numbers ≥ 4]
        B4[4]
        B5[5]
        B6[6]
    end
    style A2 fill:#f9f,stroke:#333,stroke-width:2px
    style A4 fill:#ff9,stroke:#333,stroke-width:2px
    style A6 fill:#ff9,stroke:#333,stroke-width:2px
    style B4 fill:#ff9,stroke:#333,stroke-width:2px
    style B5 fill:#f9f,stroke:#333,stroke-width:2px
    style B6 fill:#ff9,stroke:#333,stroke-width:2px
```

#### Calculating P(A ∩ B)

To find the probability of getting both an even number AND a number greater than or equal to 4:

1. First, let's identify the numbers that satisfy both conditions:
   - Must be even AND ≥ 4
   - Numbers that satisfy both: {4, 6}

2. Therefore:
   P(A ∩ B) = $\frac{\text{number of favorable outcomes}}{\text{total number of possible outcomes}}$
   = $\frac{2}{6}$
   = $\frac{1}{3}$

#### Testing for Independence

To determine if events A and B are independent, we need to check if:
P(A ∩ B) = P(A) × P(B)

Let's calculate each probability:

1. P(A) = P(even number) = $\frac{3}{6} = \frac{1}{2}$
   - Favorable outcomes: {2, 4, 6}

2. P(B) = P(number ≥ 4) = $\frac{3}{6} = \frac{1}{2}$
   - Favorable outcomes: {4, 5, 6}

3. P(A) × P(B) = $\frac{1}{2} \times \frac{1}{2} = \frac{1}{4}$

4. Compare:
   - P(A ∩ B) = $\frac{1}{3}$
   - P(A) × P(B) = $\frac{1}{4}$

Since $\frac{1}{3} \neq \frac{1}{4}$, events A and B are NOT independent.

#### Understanding the Meaning of Dependence

This dependence makes intuitive sense because:

- Knowing a number is even affects the probability it's ≥ 4
- If we know we rolled an even number, there are three possibilities (2, 4, 6)
- Within these possibilities, the probability of getting ≥ 4 is $\frac{2}{3}$, not $\frac{1}{2}$

This illustrates an important principle: events can be dependent even when they don't seem directly related. The overlap in their outcome spaces creates a subtle but measurable dependence.

#### Teaching Extension

To deepen understanding, consider this question: How would the independence calculation change if we used "numbers less than 4" instead of "numbers greater than or equal to 4"? This variation helps illustrate how the structure of event spaces influences their independence.

### Problem 6: The Monty Hall Problem - Two Solution Approaches

Let's analyze this fascinating probability problem that has puzzled many people, including mathematicians. We'll solve it using both a tree diagram and conditional probability to build a complete understanding.

#### Problem Statement

The Monty Hall problem:

1. There are three doors: behind one is a car, behind the others are goats
2. You pick a door
3. Monty Hall (who knows what's behind each door) opens another door, always showing a goat
4. You're offered the chance to switch to the remaining door
5. Question: Should you switch? What's the probability of winning if you switch vs. if you stay?

#### Approach 1: Tree Diagram Solution

Let's visualize all possible scenarios:

```{mermaid}
graph TD
    A[Initial Choice] --> B[Car 1/3]
    A --> C[Goat1 1/3]
    A --> D[Goat2 1/3]
    
    B --> E[Monty Shows Goat2]
    B --> F[Monty Shows Goat1]
    
    C --> G[Monty Must Show Goat2]
    D --> H[Monty Must Show Goat1]
    
    E --> I[Switch loses]
    F --> J[Switch loses]
    G --> K[Switch wins]
    H --> L[Switch wins]

    style I fill:#ffcccc
    style J fill:#ffcccc
    style K fill:#ccffcc
    style L fill:#ccffcc
```

Analyzing the outcomes:
1. If you initially picked the car (1/3 chance):
   - Monty can show either goat
   - Switching loses

2. If you initially picked a goat (2/3 chance):
   - Monty must show the other goat
   - Switching wins

Therefore:

- P(win if stay) = $\frac{1}{3}$
- P(win if switch) = $\frac{2}{3}$

#### Approach 2: Conditional Probability Solution

Let's use Bayes' Theorem to solve this. Define events:

- C₁: Car is behind Door 1 (your initial choice)
- M₂: Monty opens Door 2 showing a goat

P(Car behind Door 3 | Monty opens Door 2) = ?

We can write:
P(Car in 3 | M₂) = $\frac{P(M₂|Car in 3) \times P(Car in 3)}{P(M₂)}$

Let's calculate each term:

1. P(Car in 3) = $\frac{1}{3}$ (prior probability)
2. P(M₂|Car in 3) = 1 (Monty must open Door 2)
3. P(M₂) = P(M₂|Car in 1) × P(Car in 1) + P(M₂|Car in 2) × P(Car in 2) + P(M₂|Car in 3) × P(Car in 3)
   = $\frac{1}{2} \times \frac{1}{3} + 0 \times \frac{1}{3} + 1 \times \frac{1}{3}$
   = $\frac{1}{6} + \frac{1}{3}$
   = $\frac{1}{2}$

Therefore:

P(Car in 3 | M₂) = $\frac{1 \times \frac{1}{3}}{\frac{1}{2}}$ = $\frac{2}{3}$

#### Key Insights

1. **Why Intuition Fails**:
   - People often think it's 50-50 after Monty opens a door
   - This ignores the crucial fact that Monty's choice is informed, not random
   - His action provides information that should update our probabilities

2. **Information Value**:
   - Monty's choice is constrained (must show a goat)
   - This constraint carries information
   - The probability shifts from the initial $\frac{1}{3}$ to $\frac{2}{3}$ for switching

3. **Simulation Verification**:
   We could write a simple program to simulate this game thousands of times, and it would confirm these probabilities. The most convincing evidence is often seeing the results empirically.

Would you like to explore how this problem would change if Monty's behavior was different (e.g., if he randomly opened a door without knowing what's behind it), or shall we examine another probability puzzle?



## Study Tips

1. Always draw a probability tree or Venn diagram when possible - visual representations help clarify the problem structure.

2. When solving probability problems:
   - First identify whether events are independent or dependent
   - Look for opportunities to use the complement rule to simplify calculations
   - For complex problems, break them down into simpler steps
   - Always check if your answer makes logical sense (probabilities must be between 0 and 1)

3. Remember the key differences:
   - Independent vs. dependent events
   - Disjoint vs. non-disjoint events
   - With replacement vs. without replacement

4. Practice calculating probabilities both as fractions and decimals - being comfortable with both formats is important.



## Appendix 1. Advanced Counting in Probability: A Student Guide (\*)

### Poker Hands: A Window into Complex Counting

Poker hands provide some of the most interesting examples for understanding counting in probability. They're perfect for learning because they combine multiple counting principles and help us understand common pitfalls. Let's explore these concepts step by step.

### Understanding Our Sample Space

Before we dive into specific hands, let's understand what we're working with. A poker hand consists of 5 cards drawn from a standard 52-card deck. Understanding the sample space is crucial because it forms the foundation of all our probability calculations.

The total number of possible poker hands represents how many different ways we can select 5 cards from 52 cards, where the order doesn't matter (getting ace-king-queen is the same hand as getting king-queen-ace), we can't reuse cards (we can't have the ace of spades twice in our hand), and we must take exactly 5 cards (not more, not less).

This means we're dealing with combinations. Let's calculate this step by step:

$\binom{52}{5} = \frac{52!}{5!(52-5)!} = \frac{52!}{5!(47)!} = \frac{52 \cdot 51 \cdot 50 \cdot 49 \cdot 48}{5 \cdot 4 \cdot 3 \cdot 2 \cdot 1} = 2,598,960$

This number, 2,598,960, will be our denominator for calculating the probability of any specific poker hand.

### Understanding Two Pairs: A Careful Counting Approach

Two pairs is one of the most interesting hands for understanding counting principles. To get two pairs, we need:

-   Two cards of one rank
-   Two cards of another rank
-   One card of a third rank (the kicker)

Let's build this hand step by step, being careful to understand each choice we make:

First, let's select our ranks. We might think we should just choose two ranks from 13 for our pairs using $\binom{13}{2}$, but this approach hides some important subtleties. Instead, let's think about the actual process of constructing the hand:

1.  We have 13 possible ranks for our first pair
2.  After choosing the first pair's rank, we have 12 ranks left for our second pair
3.  After choosing both pair ranks, we have 11 ranks left for our kicker

For each rank we've chosen, we need to select specific cards:

1.  For our first pair: we choose 2 cards from the 4 available cards of that rank: $\binom{4}{2} = 6$ ways
2.  For our second pair: again $\binom{4}{2} = 6$ ways
3.  For our kicker: we choose 1 card from 4: $\binom{4}{1} = 4$ ways

Now, here's where many students get confused: Does it matter which pair we count "first" and which we count "second"? The answer reveals a deep truth about counting in probability.

Let's use a concrete example. Suppose we want two pairs with Aces and Kings, and a Two as our kicker. We could:

1.  Choose Aces as our first pair, then Kings as our second pair
2.  Choose Kings as our first pair, then Aces as our second pair

These lead to the exact same hand type, but we need to count both paths to this hand because they represent different ways of constructing it. It's similar to how we can make a sandwich by putting either cheese slice on first - the order of construction matters for counting all possibilities, even though the final sandwich is the same.

This is why our final formula multiplies all these independent choices:

$13$ (first pair rank) × $12$ (second pair rank) × $11$ (kicker rank) × $\binom{4}{2}$ (first pair cards) × $\binom{4}{2}$ (second pair cards) × $\binom{4}{1}$ (kicker card)

Each term represents a separate decision we make in constructing the hand. While the order of these decisions doesn't affect the final hand we get, we need to account for all possible ways to arrive at each hand to get the correct total.

Let's calculate the total probability:

$P(\text{two pairs}) = \frac{13 \cdot 12 \cdot 11 \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2,598,960} = \frac{123,552}{2,598,960} \approx 0.0475$

This means about 4.75% of all possible poker hands are two pairs.

### Understanding Full House: A Different Counting Challenge

A full house gives us a perfect contrast to two pairs. While both hands involve multiple cards of the same rank, the counting process reveals important differences in how we approach probability problems.

In a full house, we need: - Three cards of one rank (called "three of a kind") - Two cards of another rank (a pair)

Let's think about why counting a full house is different from counting two pairs. With two pairs, we had to be careful about the order of selecting our pairs. With a full house, we have a natural order: we must choose our three of a kind first (because it's distinct from the pair), then choose our pair.

Let's count step by step:

1.  For the three of a kind:
    -   Choose the rank: 13 possible ranks
    -   Choose which three cards of that rank: $\binom{4}{3} = 4$ ways
2.  For the pair:
    -   Choose the rank: 12 remaining ranks
    -   Choose which two cards of that rank: $\binom{4}{2} = 6$ ways

Multiplying these together:

$13$ (three of a kind rank) × $\binom{4}{3}$ (specific three cards) × $12$ (pair rank) × $\binom{4}{2}$ (specific pair cards)

$= 13 \cdot 4 \cdot 12 \cdot 6 = 3,744$

Therefore:

$P(\text{full house}) = \frac{3,744}{2,598,960} \approx 0.0014$

About 0.14% of all poker hands are full houses, making them significantly rarer than two pairs (4.75%). This makes intuitive sense - it's harder to get three of the same rank plus a pair than to get two pairs plus a kicker.

### The Birthday Problem: A Beautiful Probability Surprise

The birthday problem provides a fascinating connection to our poker probability work, while teaching us something profound about the nature of counting. The classic question is: "How many people need to be in a room for there to be a 50% chance that at least two share a birthday?"

Most people guess around 183 (half of 365), but the actual answer is just 23 people! Let's understand why this connects to our previous counting work and why the answer is so surprising.

First, let's think about what makes this problem different from our poker calculations:

1.  In poker, we were looking for specific combinations (like two pairs)
2.  In the birthday problem, we're looking for any match at all

This is similar to the difference between asking: - "What's the probability of drawing the ace of spades and king of hearts specifically?" - "What's the probability of drawing any two cards of different ranks?"

The second question has many more ways to succeed.

Let's solve the birthday problem step by step:

1.  First, it's easier to calculate the probability of no matches
2.  Then we can subtract from 1 to get the probability of at least one match

For 23 people, we calculate no matches like this: - First person can have any birthday: $\frac{365}{365}$ - Second person needs a different birthday: $\frac{364}{365}$ - Third person needs a different birthday: $\frac{363}{365}$ And so on until person 23.

This gives us:

$P(\text{no matches}) = \frac{365}{365} \cdot \frac{364}{365} \cdot \frac{363}{365} \cdot ... \cdot \frac{343}{365}$

$= \frac{365!}{(365-23)! \cdot 365^{23}} \approx 0.492$

Therefore:

$P(\text{at least one match}) = 1 - 0.492 \approx 0.508$

This teaches us something profound about probability: when we're looking for any match among many possibilities (like in the birthday problem), we often get much higher probabilities than when we're looking for specific matches (like in poker hands).

### Lottery Mathematics: Putting It All Together

Let's apply everything we've learned to understand lottery probabilities. Consider a typical "6/49" lottery where players choose 6 numbers from 1-49. This gives us a perfect opportunity to apply our counting principles in a real-world context.

The fundamental question is: What's the probability of winning the jackpot (matching all 6 numbers)?

This is a combination problem because: - Order doesn't matter (matching 1-2-3-4-5-6 is the same as matching 6-5-4-3-2-1) - We can't use the same number twice - We need exactly 6 numbers

Therefore:

$P(\text{jackpot}) = \frac{1}{\binom{49}{6}} = \frac{1}{13,983,816}$

This tiny probability (about 0.0000000715) shows why lottery wins are so rare. But modern lotteries have multiple prize tiers, which gives us a chance to explore more interesting probability calculations.

Consider matching 5 numbers plus a bonus number. For this, we need to: 1. Match 5 of the 6 winning numbers: $\binom{6}{5}$ ways to choose which 5 2. Match 1 of the remaining 43 numbers with the bonus: $\binom{43}{1}$ ways

Therefore:

$P(\text{5 + bonus}) = \frac{\binom{6}{5} \cdot \binom{43}{1}}{\binom{49}{6}} = \frac{6 \cdot 43}{13,983,816} \approx 0.0000184$

This shows us how breaking down complex probability problems into simpler parts helps us solve them systematically.

### Appendix 2. Alternative Approaches to Poker Hand Probabilities (\*)

Understanding different ways to calculate the same probability deepens our insight into counting principles. Let's explore several methods for finding the probabilities of two pairs and full house, seeing how each approach highlights different aspects of the problem.

#### Multiple Paths to Two Pairs Probability

Let's start with two pairs. We've seen one method, but there are several valid approaches:

Method 1: Sequential Selection (Our Original Approach) We build the hand step by step: 1. Choose first pair's rank: 13 ways 2. Choose second pair's rank: 12 ways 3. Choose kicker's rank: 11 ways 4. Choose specific cards for first pair: $\binom{4}{2}$ ways 5. Choose specific cards for second pair: $\binom{4}{2}$ ways 6. Choose specific card for kicker: $\binom{4}{1}$ ways

This gives us: $P(\text{two pairs}) = \frac{13 \cdot 12 \cdot 11 \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2,598,960}$

Method 2: Complementary Counting We can find two pairs probability by subtracting the probability of all other possible hands from 1. However, this is more complex than direct counting because we need to know the probabilities of all other poker hands. Still, it serves as a good verification:

$P(\text{two pairs}) = 1 - P(\text{high card}) - P(\text{one pair}) - P(\text{three of a kind}) - P(\text{straight}) - P(\text{flush}) - P(\text{full house}) - P(\text{four of a kind}) - P(\text{straight flush})$

Method 3: Using Permutations with Adjustment We can use permutations and then adjust for overcounting:

1.  Choose an ordered arrangement of two ranks for pairs: $P(13,2) = 13 \cdot 12$
2.  Choose kicker rank: 11 ways
3.  Choose specific cards for pairs and kicker: $\binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}$
4.  Divide by 2 to account for the fact that the order of pairs doesn't matter

This gives: $P(\text{two pairs}) = \frac{P(13,2) \cdot 11 \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2 \cdot 2,598,960}$

Method 4: Combination-Based Approach with Multiplication Principle We can separate rank selection from card selection:

1.  First, select three ranks: $\binom{13}{3}$ ways
2.  From these three ranks, designate two for pairs and one for kicker: $\binom{3}{2}$ ways
3.  For each pair rank, select two cards: $\binom{4}{2} \cdot \binom{4}{2}$ ways
4.  For the kicker rank, select one card: $\binom{4}{1}$ ways

This gives us: $P(\text{two pairs}) = \frac{\binom{13}{3} \cdot \binom{3}{2} \cdot \binom{4}{2} \cdot \binom{4}{2} \cdot \binom{4}{1}}{2,598,960}$

#### Alternative Approaches to Full House Probability

The full house probability can also be calculated in several ways:

Method 1: Direct Sequential Selection (Our Original Approach) 1. Choose rank for three of a kind: 13 ways 2. Choose specific three cards: $\binom{4}{3}$ ways 3. Choose rank for pair: 12 ways 4. Choose specific two cards: $\binom{4}{2}$ ways

Leading to: $P(\text{full house}) = \frac{13 \cdot \binom{4}{3} \cdot 12 \cdot \binom{4}{2}}{2,598,960}$

Method 2: Using Combinations with Distribution We can think about it as: 1. Choose two ranks from 13: $\binom{13}{2}$ ways 2. Designate which rank gets three cards: 2 ways (since either rank could be the three of a kind) 3. Choose specific cards: $\binom{4}{3} \cdot \binom{4}{2}$ ways

This gives: $P(\text{full house}) = \frac{\binom{13}{2} \cdot 2 \cdot \binom{4}{3} \cdot \binom{4}{2}}{2,598,960}$

Method 3: Using the Multiplication Principle with Sets Think about constructing the hand as selecting two sets of cards: 1. First set: three cards of the same rank from 13 ranks - Choose rank: 13 ways - Choose three cards: $\binom{4}{3}$ ways 2. Second set: two cards of the same rank from 12 remaining ranks - Choose rank: 12 ways - Choose two cards: $\binom{4}{2}$ ways

This yields the same result: $P(\text{full house}) = \frac{13 \cdot \binom{4}{3} \cdot 12 \cdot \binom{4}{2}}{2,598,960}$

Each method illuminates different aspects of the counting process: - Sequential selection helps us understand the step-by-step construction of hands - Combination-based approaches highlight the underlying structure of the selections - Permutation-based methods with adjustment show how overcounting can be handled systematically

The fact that all these methods yield the same result serves as a powerful verification tool. When solving complex probability problems, being able to approach the solution in multiple ways not only confirms our answer but also deepens our understanding of the underlying counting principles.

### Appendix 3: Occupancy Problems and Statistical Physics (\*)

Understanding how objects can be distributed into containers forms the foundation for both probability theory and statistical mechanics. Let's explore this connection, starting with basic counting principles and building up to physical applications.

#### The Basic Occupancy Problem

Imagine we have $n$ identical balls and $k$ distinct boxes. How many ways can we distribute the balls? This simple question leads us to three fundamentally different scenarios that mirror important physical systems:

1.  Unrestricted occupancy (Bose-Einstein statistics)
    -   Each box can hold any number of balls
    -   The balls are indistinguishable
    -   Like photons in quantum states
2.  Maximum one per box (Fermi-Dirac statistics)
    -   Each box can hold at most one ball
    -   The balls are indistinguishable
    -   Like electrons in atomic orbitals
3.  All arrangements count separately (Maxwell-Boltzmann statistics)
    -   Each box can hold any number of balls
    -   The balls are distinguishable
    -   Like classical gas molecules

#### Stars and Bars: Understanding Unrestricted Occupancy

Let's start with the Bose-Einstein case. The "stars and bars" method provides a beautiful way to visualize and count these arrangements.

Imagine $n=5$ balls and $k=3$ boxes. We can represent any arrangement as a sequence of stars and bars: - Stars (\*) represent balls - Bars (\|) separate different boxes

For example: - \*\* \| \*\* \| \* represents 2 balls in first box, 2 in second, 1 in third - \*\*\*\*\* \| \| represents all 5 balls in first box, none in others - \| \*\*\*\*\* \| represents all 5 balls in middle box

The key insight is that we need: - $n$ stars (one for each ball) - $k-1$ bars (to create $k$ sections)

Therefore, we're really just choosing positions for the $k-1$ bars among $n+(k-1)$ total positions. This gives us:

$\text{Number of arrangements} = \binom{n+k-1}{k-1} = \binom{n+k-1}{n}$

#### From Counting to Physics

Now let's see how these counting principles reveal deep physical truths:

1.  Bose-Einstein Statistics (Unrestricted, Indistinguishable)

    -   Think of photons in a laser
    -   Many particles can occupy same energy state
    -   Total arrangements: $\binom{n+k-1}{k-1}$
    -   Example: Light in a cavity

2.  Fermi-Dirac Statistics (Restricted, Indistinguishable)

    -   Think of electrons in atoms
    -   Maximum one particle per state
    -   Total arrangements: $\binom{k}{n}$ if $n \leq k$, 0 otherwise
    -   Example: Electron configuration in atoms

3.  Maxwell-Boltzmann Statistics (Classical, Distinguishable)

    -   Think of gas molecules
    -   Particles are distinct
    -   Total arrangements: $k^n$
    -   Example: Air molecules in a room

#### An Intuitive Bridge to Physics

To understand why these statistics matter, consider three real scenarios:

1.  Photons in a Laser (Bose-Einstein) Imagine shining a laser into a mirror cavity. Photons are happy to bunch together in the same quantum state - they're "social particles." This is why lasers can produce intense, coherent light.

2.  Electrons in an Atom (Fermi-Dirac) Electrons are "antisocial" - they refuse to share quantum states (Pauli exclusion principle). This explains atomic structure and why matter is mostly empty space.

3.  Gas Molecules in a Room (Maxwell-Boltzmann) Air molecules bounce around randomly, and we can tell them apart (in principle). This gives us the familiar gas laws and diffusion.

#### The Power of the Star and Bars Method

The stars and bars visualization helps us understand more complex problems. For instance, if we have restrictions on box occupancy:

1.  At least one ball per box:
    -   First put one ball in each box
    -   Then distribute remaining balls freely
    -   Formula: $\binom{n-k+k-1}{k-1} = \binom{n-1}{k-1}$
2.  Maximum capacity per box:
    -   Use inclusion-exclusion principle
    -   Subtract arrangements that violate constraints
    -   More complex but same underlying principle

#### Connection to Partition Problems

This same framework helps us solve other important problems:

1.  Integer Partitions How many ways can we write $n$ as a sum of positive integers?
    -   Like distributing $n$ balls into unlimited boxes
    -   Each box represents a different term in the sum
2.  Compositions How many ways can we write $n$ as an ordered sum?
    -   Like distinguishable boxes
    -   Order matters here

This connection between simple counting and profound physical phenomena shows the deep unity of mathematics and physics. The same principles that help us count poker hands and lottery combinations govern the behavior of the universe at its most fundamental level.
